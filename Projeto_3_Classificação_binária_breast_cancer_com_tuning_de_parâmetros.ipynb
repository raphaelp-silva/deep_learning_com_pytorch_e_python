{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raphaelp-silva/deep_learning_com_pytorch_e_python/blob/main/Projeto_3_Classifica%C3%A7%C3%A3o_bin%C3%A1ria_breast_cancer_com_tuning_de_par%C3%A2metros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 3: Classificação binária brest cancer com tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGW4fwZmkw6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1d4132-c4ab-4c5f-fa06-6d6eb45905c1"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.13.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf0FpJ35Lf-Z"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import skorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skorch import NeuralNetBinaryClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__, skorch.__version__, sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WN4QmB303kQ",
        "outputId": "dfa7b97e-b383-4ce1-985f-28e5db52ec3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.5.1+cu124', '1.1.0', '1.6.1')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9aIu62WMGo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b23da7-8dba-49e8-b4d9-575d296587ad"
      },
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f93ba9520d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u49yuDE9MJs6"
      },
      "source": [
        "previsores = pd.read_csv('entradas_breast.csv')\n",
        "classe = pd.read_csv('saidas_breast.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQ_cVSei2Bp"
      },
      "source": [
        "previsores = np.array(previsores, dtype = 'float32')\n",
        "classe = np.array(classe, dtype = 'float32').squeeze(1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6taWVK8i_PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07603fa8-a00d-495e-baf5-c285ce444dce"
      },
      "source": [
        "previsores.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeQ3eYXfjByQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9acfa8-760d-45a9-9d19-640a4653d71c"
      },
      "source": [
        "classe.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MI0xnzWjSJg"
      },
      "source": [
        "## Etapa 3: Classe para estrutura da rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\\*\\* ATUALIZAÇÃO JAN/2022 \\*\\*** : na versão atual do Skorch, os resultados da rede neural devem ser retornados sem ativação, ou seja, sem a camada sigmoide no final. Com isto, a função de custo deve ser `BCEWithLogitsLoss`."
      ],
      "metadata": {
        "id": "JBrLNkL02ar2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5WkE5vmQjjX"
      },
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self, activation, neurons, initializer):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1  // estrutura da rede neural\n",
        "    self.dense0 = nn.Linear(30, neurons)\n",
        "    initializer(self.dense0.weight)\n",
        "    self.activation0 = activation\n",
        "\n",
        "    self.dense1 = nn.Linear(neurons, neurons)\n",
        "    initializer(self.dense1.weight)\n",
        "    self.activation1 = activation\n",
        "\n",
        "    self.dense2 = nn.Linear(neurons, 1)\n",
        "    initializer(self.dense2.weight)\n",
        "    self.output_activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dense0(x)\n",
        "    x = self.activation0(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.activation1(x)\n",
        "    x = self.dense2(x)\n",
        "    x = self.output_activation(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kstsTBpKj3yO"
      },
      "source": [
        "## Etapa 4: Skorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXdmN9NxSGQo"
      },
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module = classificador_torch,\n",
        "                                                  lr = 0.001,\n",
        "                                                  optimizer__weight_decay = 0.0001,\n",
        "                                                  train_split=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzxX25OfpQsc"
      },
      "source": [
        "## Etapa 5: Tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjDt9Ob5SwH4"
      },
      "source": [
        "# definindo os parâmetros que serão testados na rede para encontrar o que melhor perfomou nos testes:\n",
        "# O ideal é ir testando parâmetro por parâmetro e não todos de uma vez só.\n",
        "\n",
        "params = {'batch_size' : [10,30],\n",
        "          'max_epochs' : [50,100],\n",
        "          'optimizer' : [torch.optim.Adam, torch.optim.SGD],\n",
        "          'criterion' : [torch.nn.BCELoss, torch.nn.HingeEmbeddingLoss],\n",
        "          'module__activation' : [F.relu, F.tanh],\n",
        "          'module__neurons' : [8, 16],\n",
        "          'module__initializer' : [torch.nn.init.uniform_, torch.nn.init.normal_]}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "id": "ox4pgQD3QTm1",
        "outputId": "af9d4ea0-5c24-4345-db42-e4f49c662490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': [10, 30],\n",
              " 'max_epochs': [50, 100],\n",
              " 'optimizer': [torch.optim.adam.Adam, torch.optim.sgd.SGD],\n",
              " 'criterion': [torch.nn.modules.loss.BCELoss,\n",
              "  torch.nn.modules.loss.HingeEmbeddingLoss],\n",
              " 'module__activation': [<function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
              "  <function torch.nn.functional.tanh(input)>],\n",
              " 'module__neurons': [8, 16],\n",
              " 'module__initializer': [<function torch.nn.init.uniform_(tensor: torch.Tensor, a: float = 0.0, b: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor>,\n",
              "  <function torch.nn.init.normal_(tensor: torch.Tensor, mean: float = 0.0, std: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor>]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(estimator = classificador_sklearn, param_grid = params,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 2)\n",
        "grid_search = grid_search.fit(previsores, classe)"
      ],
      "metadata": {
        "id": "IPPYNE9IQ4OL",
        "outputId": "dda5d385-8a30-4d39-9d18-805f5edacb49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0599\n",
            "      2       37.3239  0.0397\n",
            "      3       37.3239  0.0436\n",
            "      4       37.3239  0.0378\n",
            "      5       37.3239  0.0365\n",
            "      6       37.3239  0.0371\n",
            "      7       37.3239  0.0406\n",
            "      8       37.3239  0.0401\n",
            "      9       37.3239  0.0517\n",
            "     10       37.3239  0.0541\n",
            "     11       37.3239  0.0568\n",
            "     12       37.3239  0.0540\n",
            "     13       37.3239  0.0540\n",
            "     14       37.3239  0.0576\n",
            "     15       37.3239  0.0527\n",
            "     16       37.3239  0.0505\n",
            "     17       37.3239  0.0479\n",
            "     18       37.3239  0.0516\n",
            "     19       37.3239  0.0519\n",
            "     20       37.3239  0.0625\n",
            "     21       37.3239  0.0758\n",
            "     22       37.3239  0.0707\n",
            "     23       37.3239  0.0496\n",
            "     24       37.3239  0.0482\n",
            "     25       37.3239  0.0504\n",
            "     26       37.3239  0.0495\n",
            "     27       37.3239  0.0477\n",
            "     28       37.3239  0.0463\n",
            "     29       37.3239  0.0521\n",
            "     30       37.3239  0.0489\n",
            "     31       37.3239  0.0494\n",
            "     32       37.3239  0.0467\n",
            "     33       37.3239  0.0457\n",
            "     34       37.3239  0.0461\n",
            "     35       37.3239  0.0459\n",
            "     36       37.3239  0.0544\n",
            "     37       37.3239  0.0545\n",
            "     38       37.3239  0.0556\n",
            "     39       37.3239  0.0608\n",
            "     40       37.3239  0.0579\n",
            "     41       37.3239  0.0552\n",
            "     42       37.3239  0.0561\n",
            "     43       37.3239  0.0584\n",
            "     44       37.3239  0.0597\n",
            "     45       37.3239  0.0520\n",
            "     46       37.3239  0.0549\n",
            "     47       37.3239  0.0542\n",
            "     48       37.3239  0.0531\n",
            "     49       37.3239  0.0520\n",
            "     50       37.3239  0.0515\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0523\n",
            "      2       37.1930  0.0507\n",
            "      3       37.1930  0.0539\n",
            "      4       37.1930  0.0583\n",
            "      5       37.1930  0.0720\n",
            "      6       37.1930  0.0520\n",
            "      7       37.1930  0.0564\n",
            "      8       37.1930  0.0574\n",
            "      9       37.1930  0.0643\n",
            "     10       37.1930  0.0584\n",
            "     11       37.1930  0.0372\n",
            "     12       37.1930  0.0373\n",
            "     13       37.1930  0.0376\n",
            "     14       37.1930  0.0390\n",
            "     15       37.1930  0.0404\n",
            "     16       37.1930  0.0370\n",
            "     17       37.1930  0.0424\n",
            "     18       37.1930  0.0390\n",
            "     19       37.1930  0.0395\n",
            "     20       37.1930  0.0388\n",
            "     21       37.1930  0.0412\n",
            "     22       37.1930  0.0391\n",
            "     23       37.1930  0.0402\n",
            "     24       37.1930  0.0414\n",
            "     25       37.1930  0.0409\n",
            "     26       37.1930  0.0511\n",
            "     27       37.1930  0.0446\n",
            "     28       37.1930  0.0369\n",
            "     29       37.1930  0.0375\n",
            "     30       37.1930  0.0389\n",
            "     31       37.1930  0.0386\n",
            "     32       37.1930  0.0489\n",
            "     33       37.1930  0.0383\n",
            "     34       37.1930  0.0393\n",
            "     35       37.1930  0.0385\n",
            "     36       37.1930  0.0373\n",
            "     37       37.1930  0.0370\n",
            "     38       37.1930  0.0438\n",
            "     39       37.1930  0.0420\n",
            "     40       37.1930  0.0386\n",
            "     41       \u001b[36m31.0629\u001b[0m  0.0403\n",
            "     42        \u001b[36m0.8390\u001b[0m  0.0392\n",
            "     43        \u001b[36m0.6180\u001b[0m  0.0385\n",
            "     44        \u001b[36m0.6005\u001b[0m  0.0388\n",
            "     45        0.6158  0.0457\n",
            "     46        \u001b[36m0.6000\u001b[0m  0.0387\n",
            "     47        \u001b[36m0.5950\u001b[0m  0.0399\n",
            "     48        \u001b[36m0.5903\u001b[0m  0.0401\n",
            "     49        \u001b[36m0.5762\u001b[0m  0.0476\n",
            "     50        \u001b[36m0.5638\u001b[0m  0.0500\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0307\n",
            "      2       37.3239  0.0291\n",
            "      3       37.3239  0.0293\n",
            "      4       37.3239  0.0288\n",
            "      5       37.3239  0.0287\n",
            "      6       37.3239  0.0289\n",
            "      7       37.3239  0.0355\n",
            "      8       37.3239  0.0309\n",
            "      9       37.3239  0.0282\n",
            "     10       37.3239  0.0288\n",
            "     11       37.3239  0.0309\n",
            "     12       37.3239  0.0294\n",
            "     13       37.3239  0.0289\n",
            "     14       37.3239  0.0287\n",
            "     15       37.3239  0.0284\n",
            "     16       37.3239  0.0286\n",
            "     17       37.3239  0.0285\n",
            "     18       37.3239  0.0309\n",
            "     19       37.3239  0.0284\n",
            "     20       37.3239  0.0287\n",
            "     21       37.3239  0.0288\n",
            "     22       37.3239  0.0302\n",
            "     23       37.3239  0.0300\n",
            "     24       37.3239  0.0307\n",
            "     25       37.3239  0.0273\n",
            "     26       37.3239  0.0283\n",
            "     27       37.3239  0.0283\n",
            "     28       37.3239  0.0322\n",
            "     29       37.3239  0.0322\n",
            "     30       37.3239  0.0354\n",
            "     31       37.3239  0.0360\n",
            "     32       37.3239  0.0355\n",
            "     33       37.3239  0.0319\n",
            "     34       37.3239  0.0268\n",
            "     35       37.3239  0.0304\n",
            "     36       37.3239  0.0284\n",
            "     37       37.3239  0.0279\n",
            "     38       37.3239  0.0284\n",
            "     39       37.3239  0.0301\n",
            "     40       37.3239  0.0335\n",
            "     41       37.3239  0.0280\n",
            "     42       37.3239  0.0317\n",
            "     43       37.3239  0.0282\n",
            "     44       37.3239  0.0284\n",
            "     45       37.3239  0.0284\n",
            "     46       37.3239  0.0282\n",
            "     47       37.3239  0.0276\n",
            "     48       37.3239  0.0280\n",
            "     49       37.3239  0.0294\n",
            "     50       37.3239  0.0320\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0287\n",
            "      2       37.1930  0.0300\n",
            "      3       37.1930  0.0318\n",
            "      4       37.1930  0.0298\n",
            "      5       37.1930  0.0292\n",
            "      6       37.1930  0.0291\n",
            "      7       37.1930  0.0295\n",
            "      8       37.1930  0.0298\n",
            "      9       37.1930  0.0287\n",
            "     10       37.1930  0.0360\n",
            "     11       37.1930  0.0380\n",
            "     12       37.1930  0.0378\n",
            "     13       37.1930  0.0345\n",
            "     14       37.1930  0.0290\n",
            "     15       37.1930  0.0303\n",
            "     16       37.1930  0.0298\n",
            "     17       37.1930  0.0301\n",
            "     18       37.1930  0.0326\n",
            "     19       37.1930  0.0293\n",
            "     20       37.1930  0.0314\n",
            "     21       37.1930  0.0355\n",
            "     22       37.1930  0.0288\n",
            "     23       37.1930  0.0269\n",
            "     24       37.1930  0.0297\n",
            "     25       37.1930  0.0317\n",
            "     26       37.1930  0.0292\n",
            "     27       37.1930  0.0326\n",
            "     28       37.1930  0.0302\n",
            "     29       37.1930  0.0289\n",
            "     30       37.1930  0.0305\n",
            "     31       37.1930  0.0297\n",
            "     32       37.1930  0.0294\n",
            "     33       37.1930  0.0297\n",
            "     34       37.1930  0.0291\n",
            "     35       37.1930  0.0326\n",
            "     36       37.1930  0.0298\n",
            "     37       37.1930  0.0302\n",
            "     38       37.1930  0.0294\n",
            "     39       37.1930  0.0322\n",
            "     40       37.1930  0.0329\n",
            "     41       37.1930  0.0357\n",
            "     42       37.1930  0.0354\n",
            "     43       37.1930  0.0417\n",
            "     44       37.1930  0.0342\n",
            "     45       37.1930  0.0315\n",
            "     46       37.1930  0.0294\n",
            "     47       37.1930  0.0284\n",
            "     48       37.1930  0.0294\n",
            "     49       37.1930  0.0302\n",
            "     50       37.1930  0.0314\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0477\n",
            "      2       37.3239  0.0407\n",
            "      3       37.3239  0.0407\n",
            "      4       37.3239  0.0393\n",
            "      5       37.3239  0.0394\n",
            "      6       37.3239  0.0388\n",
            "      7       37.3239  0.0392\n",
            "      8       37.3239  0.0391\n",
            "      9       37.3239  0.0435\n",
            "     10       37.3239  0.0413\n",
            "     11       37.3239  0.0399\n",
            "     12       37.3239  0.0378\n",
            "     13       37.3239  0.0398\n",
            "     14       37.3239  0.0401\n",
            "     15       37.3239  0.0472\n",
            "     16       37.3239  0.0501\n",
            "     17       37.3239  0.0469\n",
            "     18       37.3239  0.0396\n",
            "     19       37.3239  0.0393\n",
            "     20       37.3239  0.0438\n",
            "     21       37.3239  0.0392\n",
            "     22       37.3239  0.0391\n",
            "     23       37.3239  0.0393\n",
            "     24       37.3239  0.0390\n",
            "     25       37.3239  0.0484\n",
            "     26       37.3239  0.0379\n",
            "     27       37.3239  0.0371\n",
            "     28       37.3239  0.0387\n",
            "     29       37.3239  0.0469\n",
            "     30       37.3239  0.0394\n",
            "     31       37.3239  0.0421\n",
            "     32       37.3239  0.0401\n",
            "     33       37.3239  0.0397\n",
            "     34       37.3239  0.0396\n",
            "     35       37.3239  0.0381\n",
            "     36       37.3239  0.0390\n",
            "     37       37.3239  0.0392\n",
            "     38       37.3239  0.0500\n",
            "     39       37.3239  0.0527\n",
            "     40       37.3239  0.0454\n",
            "     41       37.3239  0.0374\n",
            "     42       37.3239  0.0379\n",
            "     43       37.3239  0.0406\n",
            "     44       37.3239  0.0364\n",
            "     45       37.3239  0.0392\n",
            "     46       37.3239  0.0400\n",
            "     47       37.3239  0.0376\n",
            "     48       37.3239  0.0374\n",
            "     49       37.3239  0.0470\n",
            "     50       37.3239  0.0376\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0360\n",
            "      2       37.1930  0.0419\n",
            "      3       37.1930  0.0378\n",
            "      4       37.1930  0.0382\n",
            "      5       37.1930  0.0385\n",
            "      6       37.1930  0.0373\n",
            "      7       37.1930  0.0371\n",
            "      8       37.1930  0.0381\n",
            "      9       37.1930  0.0377\n",
            "     10       37.1930  0.0371\n",
            "     11       37.1930  0.0517\n",
            "     12       37.1930  0.0488\n",
            "     13       37.1930  0.0491\n",
            "     14       37.1930  0.0448\n",
            "     15       37.1930  0.0417\n",
            "     16       37.1930  0.0383\n",
            "     17       37.1930  0.0372\n",
            "     18       37.1930  0.0359\n",
            "     19       37.1930  0.0382\n",
            "     20       37.1930  0.0394\n",
            "     21       37.1930  0.0385\n",
            "     22       37.1930  0.0409\n",
            "     23       37.1930  0.0479\n",
            "     24       37.1930  0.0367\n",
            "     25       37.1930  0.0376\n",
            "     26       37.1930  0.0370\n",
            "     27       37.1930  0.0388\n",
            "     28       37.1930  0.0371\n",
            "     29       37.1930  0.0415\n",
            "     30       37.1930  0.0394\n",
            "     31       37.1930  0.0406\n",
            "     32       37.1930  0.0391\n",
            "     33       37.1930  0.0378\n",
            "     34       37.1930  0.0389\n",
            "     35       37.1930  0.0414\n",
            "     36       37.1930  0.0492\n",
            "     37       37.1930  0.0508\n",
            "     38       37.1930  0.0413\n",
            "     39       37.1930  0.0383\n",
            "     40       37.1930  0.0404\n",
            "     41       37.1930  0.0428\n",
            "     42       37.1930  0.0396\n",
            "     43       \u001b[36m31.3527\u001b[0m  0.1030\n",
            "     44        \u001b[36m0.6321\u001b[0m  0.1212\n",
            "     45        \u001b[36m0.6172\u001b[0m  0.0515\n",
            "     46        \u001b[36m0.6161\u001b[0m  0.0619\n",
            "     47        \u001b[36m0.6152\u001b[0m  0.0409\n",
            "     48        \u001b[36m0.6144\u001b[0m  0.0393\n",
            "     49        \u001b[36m0.6138\u001b[0m  0.0396\n",
            "     50        \u001b[36m0.6132\u001b[0m  0.0401\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0302\n",
            "      2       37.3239  0.0297\n",
            "      3       37.3239  0.0292\n",
            "      4       37.3239  0.0287\n",
            "      5       37.3239  0.0287\n",
            "      6       37.3239  0.0395\n",
            "      7       37.3239  0.0373\n",
            "      8       37.3239  0.0326\n",
            "      9       37.3239  0.0286\n",
            "     10       37.3239  0.0291\n",
            "     11       37.3239  0.1047\n",
            "     12       37.3239  0.0936\n",
            "     13       37.3239  0.0861\n",
            "     14       37.3239  0.0403\n",
            "     15       37.3239  0.0438\n",
            "     16       37.3239  0.0431\n",
            "     17       37.3239  0.0397\n",
            "     18       37.3239  0.0364\n",
            "     19       37.3239  0.0466\n",
            "     20       37.3239  0.0367\n",
            "     21       37.3239  0.0387\n",
            "     22       37.3239  0.0363\n",
            "     23       37.3239  0.0380\n",
            "     24       37.3239  0.0401\n",
            "     25       37.3239  0.0351\n",
            "     26       37.3239  0.0515\n",
            "     27       37.3239  0.0622\n",
            "     28       37.3239  0.0434\n",
            "     29       37.3239  0.0378\n",
            "     30       37.3239  0.0366\n",
            "     31       37.3239  0.0364\n",
            "     32       37.3239  0.0364\n",
            "     33       37.3239  0.0359\n",
            "     34       37.3239  0.0401\n",
            "     35       37.3239  0.0373\n",
            "     36       37.3239  0.0351\n",
            "     37       37.3239  0.0364\n",
            "     38       37.3239  0.0351\n",
            "     39       37.3239  0.0425\n",
            "     40       37.3239  0.0408\n",
            "     41       37.3239  0.0355\n",
            "     42       37.3239  0.0361\n",
            "     43       37.3239  0.0365\n",
            "     44       37.3239  0.0384\n",
            "     45       37.3239  0.0355\n",
            "     46       37.3239  0.0352\n",
            "     47       37.3239  0.0381\n",
            "     48       37.3239  0.0378\n",
            "     49       37.3239  0.0463\n",
            "     50       37.3239  0.0497\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0388\n",
            "      2       37.1930  0.0406\n",
            "      3       37.1930  0.0385\n",
            "      4       37.1930  0.0380\n",
            "      5       37.1930  0.0397\n",
            "      6       37.1930  0.0470\n",
            "      7       37.1930  0.0444\n",
            "      8       37.1930  0.0394\n",
            "      9       37.1930  0.0378\n",
            "     10       37.1930  0.0418\n",
            "     11       37.1930  0.0483\n",
            "     12       37.1930  0.0382\n",
            "     13       37.1930  0.0494\n",
            "     14       37.1930  0.0429\n",
            "     15       37.1930  0.0394\n",
            "     16       37.1930  0.0402\n",
            "     17       37.1930  0.0393\n",
            "     18       37.1930  0.0397\n",
            "     19       37.1930  0.0427\n",
            "     20       37.1930  0.0469\n",
            "     21       37.1930  0.0577\n",
            "     22       37.1930  0.0504\n",
            "     23       37.1930  0.0418\n",
            "     24       37.1930  0.0422\n",
            "     25       37.1930  0.0421\n",
            "     26       37.1930  0.0417\n",
            "     27       37.1930  0.0424\n",
            "     28       37.1930  0.0399\n",
            "     29       37.1930  0.0310\n",
            "     30       37.1930  0.0306\n",
            "     31       37.1930  0.0293\n",
            "     32       37.1930  0.0286\n",
            "     33       37.1930  0.0288\n",
            "     34       37.1930  0.0293\n",
            "     35       37.1930  0.0289\n",
            "     36       37.1930  0.0346\n",
            "     37       37.1930  0.0303\n",
            "     38       37.1930  0.0285\n",
            "     39       37.1930  0.0391\n",
            "     40       37.1930  0.0295\n",
            "     41       37.1930  0.0297\n",
            "     42       37.1930  0.0298\n",
            "     43       37.1930  0.0299\n",
            "     44       37.1930  0.0290\n",
            "     45       37.1930  0.0289\n",
            "     46       37.1930  0.0299\n",
            "     47       37.1930  0.0290\n",
            "     48       37.1930  0.0388\n",
            "     49       37.1930  0.0376\n",
            "     50       37.1930  0.0378\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m39.7887\u001b[0m  0.0377\n",
            "      2       \u001b[36m39.5418\u001b[0m  0.0378\n",
            "      3       \u001b[36m39.4366\u001b[0m  0.0371\n",
            "      4       39.4366  0.0431\n",
            "      5       39.4366  0.0390\n",
            "      6       \u001b[36m39.0845\u001b[0m  0.0399\n",
            "      7       39.0845  0.0395\n",
            "      8       \u001b[36m38.8296\u001b[0m  0.0386\n",
            "      9       39.0845  0.0379\n",
            "     10       39.0845  0.0428\n",
            "     11       39.0845  0.0386\n",
            "     12       39.0845  0.0386\n",
            "     13       39.0845  0.0380\n",
            "     14       \u001b[36m38.7545\u001b[0m  0.0363\n",
            "     15       38.9199  0.0372\n",
            "     16       \u001b[36m38.7324\u001b[0m  0.0473\n",
            "     17       38.7324  0.0391\n",
            "     18       38.7324  0.0425\n",
            "     19       38.7324  0.0383\n",
            "     20       38.7324  0.0394\n",
            "     21       38.7324  0.0377\n",
            "     22       38.7324  0.0489\n",
            "     23       38.7324  0.0502\n",
            "     24       38.7324  0.0444\n",
            "     25       38.7324  0.0412\n",
            "     26       38.7324  0.0385\n",
            "     27       38.7324  0.0395\n",
            "     28       38.7324  0.0380\n",
            "     29       38.7324  0.0428\n",
            "     30       38.7324  0.0410\n",
            "     31       38.7324  0.0398\n",
            "     32       38.7324  0.0378\n",
            "     33       38.7324  0.0408\n",
            "     34       38.7324  0.0385\n",
            "     35       38.7324  0.0377\n",
            "     36       38.7324  0.0384\n",
            "     37       38.7324  0.0386\n",
            "     38       38.7324  0.0375\n",
            "     39       38.7324  0.0411\n",
            "     40       38.7324  0.0502\n",
            "     41       38.7324  0.0391\n",
            "     42       38.7324  0.0386\n",
            "     43       38.7324  0.0374\n",
            "     44       38.7324  0.0369\n",
            "     45       38.7324  0.0362\n",
            "     46       38.7324  0.0512\n",
            "     47       38.7324  0.0484\n",
            "     48       38.7324  0.0370\n",
            "     49       38.7324  0.0380\n",
            "     50       38.7324  0.0371\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m51.3130\u001b[0m  0.0348\n",
            "      2       \u001b[36m51.2281\u001b[0m  0.0355\n",
            "      3       51.2281  0.0461\n",
            "      4       51.2281  0.0394\n",
            "      5       51.2281  0.0400\n",
            "      6       \u001b[36m51.1773\u001b[0m  0.0374\n",
            "      7       \u001b[36m51.1459\u001b[0m  0.0380\n",
            "      8       \u001b[36m51.1169\u001b[0m  0.0376\n",
            "      9       \u001b[36m51.0902\u001b[0m  0.0392\n",
            "     10       \u001b[36m51.0655\u001b[0m  0.0397\n",
            "     11       \u001b[36m51.0429\u001b[0m  0.0397\n",
            "     12       \u001b[36m51.0225\u001b[0m  0.0373\n",
            "     13       \u001b[36m51.0039\u001b[0m  0.0379\n",
            "     14       \u001b[36m50.9708\u001b[0m  0.0423\n",
            "     15       \u001b[36m50.9340\u001b[0m  0.0461\n",
            "     16       \u001b[36m50.9112\u001b[0m  0.0377\n",
            "     17       \u001b[36m50.8939\u001b[0m  0.0400\n",
            "     18       \u001b[36m50.8809\u001b[0m  0.0393\n",
            "     19       \u001b[36m50.8789\u001b[0m  0.0437\n",
            "     20       \u001b[36m50.8788\u001b[0m  0.0469\n",
            "     21       \u001b[36m50.8788\u001b[0m  0.0489\n",
            "     22       \u001b[36m50.8788\u001b[0m  0.0397\n",
            "     23       \u001b[36m50.8787\u001b[0m  0.0399\n",
            "     24       \u001b[36m50.8787\u001b[0m  0.0382\n",
            "     25       \u001b[36m50.8787\u001b[0m  0.0373\n",
            "     26       \u001b[36m50.8787\u001b[0m  0.0376\n",
            "     27       \u001b[36m50.8786\u001b[0m  0.0407\n",
            "     28       \u001b[36m50.8786\u001b[0m  0.0403\n",
            "     29       \u001b[36m50.8786\u001b[0m  0.0393\n",
            "     30       \u001b[36m50.8786\u001b[0m  0.0379\n",
            "     31       \u001b[36m50.8786\u001b[0m  0.0394\n",
            "     32       \u001b[36m50.8785\u001b[0m  0.0378\n",
            "     33       \u001b[36m50.8785\u001b[0m  0.0408\n",
            "     34       \u001b[36m50.8785\u001b[0m  0.0408\n",
            "     35       \u001b[36m50.8785\u001b[0m  0.0408\n",
            "     36       \u001b[36m50.8785\u001b[0m  0.0385\n",
            "     37       \u001b[36m50.8784\u001b[0m  0.0381\n",
            "     38       \u001b[36m50.8784\u001b[0m  0.0395\n",
            "     39       \u001b[36m50.8784\u001b[0m  0.0483\n",
            "     40       \u001b[36m50.8784\u001b[0m  0.0404\n",
            "     41       \u001b[36m50.8784\u001b[0m  0.0381\n",
            "     42       \u001b[36m50.8784\u001b[0m  0.0378\n",
            "     43       \u001b[36m50.8783\u001b[0m  0.0475\n",
            "     44       \u001b[36m50.8783\u001b[0m  0.0471\n",
            "     45       \u001b[36m50.8783\u001b[0m  0.0484\n",
            "     46       \u001b[36m50.8783\u001b[0m  0.0384\n",
            "     47       \u001b[36m50.8783\u001b[0m  0.0497\n",
            "     48       \u001b[36m50.8783\u001b[0m  0.0398\n",
            "     49       \u001b[36m50.8782\u001b[0m  0.0377\n",
            "     50       \u001b[36m50.8782\u001b[0m  0.0372\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0283\n",
            "      2       37.3239  0.0277\n",
            "      3       37.3239  0.0295\n",
            "      4       37.3239  0.0278\n",
            "      5       37.3239  0.0289\n",
            "      6       37.3239  0.0291\n",
            "      7       37.3239  0.0288\n",
            "      8       37.3239  0.0323\n",
            "      9       37.3239  0.0292\n",
            "     10       37.3239  0.0297\n",
            "     11       37.3239  0.0293\n",
            "     12       37.3239  0.0310\n",
            "     13       37.3239  0.0281\n",
            "     14       37.3239  0.0301\n",
            "     15       37.3239  0.0293\n",
            "     16       37.3239  0.0316\n",
            "     17       37.3239  0.0321\n",
            "     18       37.3239  0.0295\n",
            "     19       37.3239  0.0328\n",
            "     20       37.3239  0.0283\n",
            "     21       37.3239  0.0367\n",
            "     22       37.3239  0.0365\n",
            "     23       37.3239  0.0388\n",
            "     24       37.3239  0.0349\n",
            "     25       37.3239  0.0289\n",
            "     26       37.3239  0.0295\n",
            "     27       37.3239  0.0307\n",
            "     28       37.3239  0.0282\n",
            "     29       37.3239  0.0279\n",
            "     30       37.3239  0.0291\n",
            "     31       37.3239  0.0296\n",
            "     32       37.3239  0.0311\n",
            "     33       37.3239  0.0295\n",
            "     34       37.3239  0.0307\n",
            "     35       37.3239  0.0328\n",
            "     36       37.3239  0.0290\n",
            "     37       37.3239  0.0298\n",
            "     38       37.3239  0.0289\n",
            "     39       37.3239  0.0295\n",
            "     40       37.3239  0.0330\n",
            "     41       37.3239  0.0311\n",
            "     42       37.3239  0.0283\n",
            "     43       37.3239  0.0303\n",
            "     44       37.3239  0.0292\n",
            "     45       37.3239  0.0306\n",
            "     46       37.3239  0.0291\n",
            "     47       37.3239  0.0301\n",
            "     48       37.3239  0.0372\n",
            "     49       37.3239  0.0285\n",
            "     50       37.3239  0.0353\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.8070\u001b[0m  0.0341\n",
            "      2       62.8070  0.0360\n",
            "      3       62.8070  0.0379\n",
            "      4       62.8070  0.0352\n",
            "      5       62.8070  0.0285\n",
            "      6       62.8070  0.0282\n",
            "      7       62.8070  0.0322\n",
            "      8       62.8070  0.0277\n",
            "      9       62.8070  0.0277\n",
            "     10       62.8070  0.0271\n",
            "     11       62.8070  0.0311\n",
            "     12       62.8070  0.0332\n",
            "     13       62.8070  0.0290\n",
            "     14       62.8070  0.0305\n",
            "     15       62.8070  0.0336\n",
            "     16       62.8070  0.0298\n",
            "     17       62.8070  0.0345\n",
            "     18       62.8070  0.0303\n",
            "     19       62.8070  0.0296\n",
            "     20       62.8070  0.0290\n",
            "     21       62.8070  0.0295\n",
            "     22       62.8070  0.0298\n",
            "     23       62.8070  0.0293\n",
            "     24       62.8070  0.0301\n",
            "     25       62.8070  0.0285\n",
            "     26       62.8070  0.0293\n",
            "     27       62.8070  0.0289\n",
            "     28       62.8070  0.0289\n",
            "     29       62.8070  0.0429\n",
            "     30       62.8070  0.0293\n",
            "     31       62.8070  0.0276\n",
            "     32       62.8070  0.0387\n",
            "     33       62.8070  0.0366\n",
            "     34       62.8070  0.0368\n",
            "     35       62.8070  0.0371\n",
            "     36       62.8070  0.0296\n",
            "     37       62.8070  0.0294\n",
            "     38       62.8070  0.0287\n",
            "     39       62.8070  0.0279\n",
            "     40       62.8070  0.0291\n",
            "     41       62.8070  0.0295\n",
            "     42       62.8070  0.0292\n",
            "     43       62.8070  0.0297\n",
            "     44       62.8070  0.0322\n",
            "     45       62.8070  0.0294\n",
            "     46       62.8070  0.0282\n",
            "     47       62.8070  0.0298\n",
            "     48       62.8070  0.0290\n",
            "     49       62.8070  0.0290\n",
            "     50       62.8070  0.0291\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.0969\u001b[0m  0.0371\n",
            "      2       \u001b[36m36.9718\u001b[0m  0.0392\n",
            "      3       36.9718  0.0429\n",
            "      4       36.9718  0.0406\n",
            "      5       36.9718  0.0400\n",
            "      6       36.9718  0.0384\n",
            "      7       36.9718  0.0396\n",
            "      8       36.9718  0.0443\n",
            "      9       36.9718  0.0501\n",
            "     10       36.9718  0.0494\n",
            "     11       36.9718  0.0486\n",
            "     12       36.9718  0.0402\n",
            "     13       36.9718  0.0398\n",
            "     14       36.9718  0.0401\n",
            "     15       36.9718  0.0395\n",
            "     16       36.9718  0.0416\n",
            "     17       37.3239  0.0386\n",
            "     18       37.3239  0.0408\n",
            "     19       37.3239  0.0409\n",
            "     20       37.3239  0.0411\n",
            "     21       37.3239  0.0420\n",
            "     22       37.3239  0.0388\n",
            "     23       37.3239  0.0425\n",
            "     24       37.3239  0.0448\n",
            "     25       37.3239  0.0457\n",
            "     26       37.3239  0.0412\n",
            "     27       37.3239  0.0394\n",
            "     28       37.3265  0.0427\n",
            "     29       37.6761  0.0401\n",
            "     30       37.6761  0.0430\n",
            "     31       37.6761  0.0503\n",
            "     32       37.6761  0.0525\n",
            "     33       37.6761  0.0483\n",
            "     34       37.6761  0.0401\n",
            "     35       37.6761  0.0397\n",
            "     36       37.6761  0.0451\n",
            "     37       37.6761  0.0400\n",
            "     38       38.0282  0.0408\n",
            "     39       38.0282  0.0414\n",
            "     40       38.0282  0.0616\n",
            "     41       38.3803  0.0586\n",
            "     42       38.3803  0.0575\n",
            "     43       38.3803  0.0537\n",
            "     44       38.3803  0.0543\n",
            "     45       38.8845  0.0591\n",
            "     46       42.6056  0.0496\n",
            "     47       43.5682  0.0533\n",
            "     48       43.6620  0.0540\n",
            "     49       43.6620  0.0530\n",
            "     50       43.6620  0.0586\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m49.4737\u001b[0m  0.0648\n",
            "      2       \u001b[36m46.8155\u001b[0m  0.0587\n",
            "      3       51.4644  0.0512\n",
            "      4       56.4912  0.0492\n",
            "      5       54.4524  0.0518\n",
            "      6       48.4211  0.0538\n",
            "      7       47.6421  0.0541\n",
            "      8       \u001b[36m46.0807\u001b[0m  0.0503\n",
            "      9       \u001b[36m44.9263\u001b[0m  0.0491\n",
            "     10       \u001b[36m42.8120\u001b[0m  0.0483\n",
            "     11       47.6602  0.0518\n",
            "     12       48.0702  0.0491\n",
            "     13       46.3400  0.0515\n",
            "     14       45.3385  0.0520\n",
            "     15       46.6667  0.0506\n",
            "     16       45.3043  0.0512\n",
            "     17       45.1757  0.0569\n",
            "     18       45.2632  0.0740\n",
            "     19       45.2632  0.0625\n",
            "     20       45.2632  0.0549\n",
            "     21       45.2632  0.0543\n",
            "     22       45.2632  0.0493\n",
            "     23       45.2632  0.0596\n",
            "     24       45.2632  0.0612\n",
            "     25       45.2632  0.0610\n",
            "     26       45.2632  0.0525\n",
            "     27       45.2632  0.0567\n",
            "     28       45.2632  0.0586\n",
            "     29       45.2632  0.0563\n",
            "     30       45.2632  0.0558\n",
            "     31       45.2632  0.0579\n",
            "     32       45.2632  0.0536\n",
            "     33       45.2632  0.0549\n",
            "     34       45.2632  0.0651\n",
            "     35       45.2632  0.0676\n",
            "     36       45.2632  0.0654\n",
            "     37       45.2632  0.0591\n",
            "     38       45.2632  0.0630\n",
            "     39       45.2632  0.0417\n",
            "     40       45.2632  0.0434\n",
            "     41       45.2632  0.0413\n",
            "     42       45.2632  0.0388\n",
            "     43       45.2632  0.0426\n",
            "     44       45.2632  0.0415\n",
            "     45       45.2632  0.0398\n",
            "     46       45.2632  0.0400\n",
            "     47       45.2632  0.0380\n",
            "     48       45.2632  0.0389\n",
            "     49       45.2632  0.0438\n",
            "     50       45.2632  0.0380\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.8732\u001b[0m  0.0273\n",
            "      2       53.8732  0.0300\n",
            "      3       53.8732  0.0297\n",
            "      4       53.8732  0.0295\n",
            "      5       53.8732  0.0330\n",
            "      6       53.8732  0.0403\n",
            "      7       53.8732  0.0412\n",
            "      8       53.8732  0.0334\n",
            "      9       53.8732  0.0470\n",
            "     10       53.8732  0.0310\n",
            "     11       53.8732  0.0297\n",
            "     12       53.8732  0.0300\n",
            "     13       53.8732  0.0305\n",
            "     14       53.8732  0.0332\n",
            "     15       53.8732  0.0309\n",
            "     16       53.8732  0.0304\n",
            "     17       53.8732  0.0331\n",
            "     18       53.8732  0.0303\n",
            "     19       53.8732  0.0296\n",
            "     20       53.8732  0.0296\n",
            "     21       53.8732  0.0301\n",
            "     22       53.8732  0.0337\n",
            "     23       53.8732  0.0327\n",
            "     24       53.8732  0.0308\n",
            "     25       53.8732  0.0297\n",
            "     26       53.8732  0.0293\n",
            "     27       53.8732  0.0335\n",
            "     28       53.8732  0.0307\n",
            "     29       53.8732  0.0353\n",
            "     30       53.8732  0.0311\n",
            "     31       53.8732  0.0285\n",
            "     32       53.8732  0.0284\n",
            "     33       53.8732  0.0288\n",
            "     34       53.8732  0.0295\n",
            "     35       53.8732  0.0360\n",
            "     36       53.8732  0.0364\n",
            "     37       53.8732  0.0417\n",
            "     38       53.8732  0.0374\n",
            "     39       53.8732  0.0344\n",
            "     40       53.8732  0.0328\n",
            "     41       53.8732  0.0296\n",
            "     42       53.8732  0.0285\n",
            "     43       53.8732  0.0326\n",
            "     44       53.8732  0.0285\n",
            "     45       53.8732  0.0302\n",
            "     46       53.8732  0.0296\n",
            "     47       53.8732  0.0385\n",
            "     48       53.8732  0.0285\n",
            "     49       53.8732  0.0287\n",
            "     50       53.8732  0.0329\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m45.2632\u001b[0m  0.0265\n",
            "      2       45.2632  0.0305\n",
            "      3       45.2632  0.0313\n",
            "      4       45.2632  0.0354\n",
            "      5       45.2632  0.0361\n",
            "      6       45.2632  0.0360\n",
            "      7       45.2632  0.0312\n",
            "      8       45.2632  0.0332\n",
            "      9       45.2632  0.0301\n",
            "     10       45.2632  0.0291\n",
            "     11       45.2632  0.0284\n",
            "     12       45.2632  0.0285\n",
            "     13       45.2632  0.0297\n",
            "     14       45.2632  0.0383\n",
            "     15       45.2632  0.0414\n",
            "     16       45.2632  0.0372\n",
            "     17       45.2632  0.0332\n",
            "     18       45.2632  0.0293\n",
            "     19       45.2632  0.0374\n",
            "     20       45.2632  0.0295\n",
            "     21       45.2632  0.0284\n",
            "     22       45.2632  0.0325\n",
            "     23       45.2632  0.0305\n",
            "     24       45.2632  0.0290\n",
            "     25       45.2632  0.0315\n",
            "     26       45.2632  0.0331\n",
            "     27       45.2632  0.0313\n",
            "     28       45.2632  0.0304\n",
            "     29       45.2632  0.0321\n",
            "     30       45.2632  0.0316\n",
            "     31       45.2632  0.0279\n",
            "     32       45.2632  0.0308\n",
            "     33       45.2632  0.0312\n",
            "     34       45.2632  0.0296\n",
            "     35       45.2632  0.0306\n",
            "     36       45.2632  0.0302\n",
            "     37       45.2632  0.0317\n",
            "     38       45.2632  0.0301\n",
            "     39       45.2632  0.0299\n",
            "     40       45.2632  0.0310\n",
            "     41       45.2632  0.0306\n",
            "     42       45.2632  0.0305\n",
            "     43       45.2632  0.0320\n",
            "     44       45.2632  0.0427\n",
            "     45       45.2632  0.0464\n",
            "     46       45.2632  0.0398\n",
            "     47       45.2632  0.0350\n",
            "     48       45.2632  0.0291\n",
            "     49       45.2632  0.0338\n",
            "     50       45.2632  0.0348\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3822\u001b[0m  0.0411\n",
            "      2        \u001b[36m1.3210\u001b[0m  0.0430\n",
            "      3        \u001b[36m1.2581\u001b[0m  0.0429\n",
            "      4        \u001b[36m1.1943\u001b[0m  0.0405\n",
            "      5        \u001b[36m1.1293\u001b[0m  0.0375\n",
            "      6        \u001b[36m1.0614\u001b[0m  0.0384\n",
            "      7        \u001b[36m0.9871\u001b[0m  0.0394\n",
            "      8        \u001b[36m0.9034\u001b[0m  0.0404\n",
            "      9        \u001b[36m0.8148\u001b[0m  0.0391\n",
            "     10        \u001b[36m0.7405\u001b[0m  0.0374\n",
            "     11        \u001b[36m0.6977\u001b[0m  0.0393\n",
            "     12        \u001b[36m0.6797\u001b[0m  0.0407\n",
            "     13        \u001b[36m0.6728\u001b[0m  0.0400\n",
            "     14        \u001b[36m0.6702\u001b[0m  0.0414\n",
            "     15        \u001b[36m0.6689\u001b[0m  0.0386\n",
            "     16        \u001b[36m0.6683\u001b[0m  0.0397\n",
            "     17        \u001b[36m0.6679\u001b[0m  0.0383\n",
            "     18        \u001b[36m0.6676\u001b[0m  0.0503\n",
            "     19        \u001b[36m0.6674\u001b[0m  0.0481\n",
            "     20        \u001b[36m0.6672\u001b[0m  0.0406\n",
            "     21        \u001b[36m0.6671\u001b[0m  0.0401\n",
            "     22        \u001b[36m0.6670\u001b[0m  0.0383\n",
            "     23        \u001b[36m0.6669\u001b[0m  0.0421\n",
            "     24        \u001b[36m0.6668\u001b[0m  0.0414\n",
            "     25        \u001b[36m0.6667\u001b[0m  0.0380\n",
            "     26        \u001b[36m0.6667\u001b[0m  0.0402\n",
            "     27        \u001b[36m0.6666\u001b[0m  0.0420\n",
            "     28        \u001b[36m0.6665\u001b[0m  0.0402\n",
            "     29        \u001b[36m0.6665\u001b[0m  0.0390\n",
            "     30        \u001b[36m0.6665\u001b[0m  0.0408\n",
            "     31        \u001b[36m0.6664\u001b[0m  0.0381\n",
            "     32        \u001b[36m0.6664\u001b[0m  0.0387\n",
            "     33        \u001b[36m0.6664\u001b[0m  0.0430\n",
            "     34        \u001b[36m0.6663\u001b[0m  0.0397\n",
            "     35        \u001b[36m0.6663\u001b[0m  0.0428\n",
            "     36        \u001b[36m0.6663\u001b[0m  0.0370\n",
            "     37        \u001b[36m0.6662\u001b[0m  0.0386\n",
            "     38        \u001b[36m0.6662\u001b[0m  0.0383\n",
            "     39        \u001b[36m0.6662\u001b[0m  0.0382\n",
            "     40        \u001b[36m0.6662\u001b[0m  0.0395\n",
            "     41        \u001b[36m0.6662\u001b[0m  0.0463\n",
            "     42        \u001b[36m0.6661\u001b[0m  0.0492\n",
            "     43        \u001b[36m0.6661\u001b[0m  0.0438\n",
            "     44        \u001b[36m0.6661\u001b[0m  0.0425\n",
            "     45        0.6667  0.0399\n",
            "     46        \u001b[36m0.6660\u001b[0m  0.0378\n",
            "     47        0.6661  0.0390\n",
            "     48        \u001b[36m0.6660\u001b[0m  0.0469\n",
            "     49        \u001b[36m0.6660\u001b[0m  0.0420\n",
            "     50        \u001b[36m0.6660\u001b[0m  0.0393\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1993\u001b[0m  0.0361\n",
            "      2        \u001b[36m1.1413\u001b[0m  0.0397\n",
            "      3        \u001b[36m1.0869\u001b[0m  0.0386\n",
            "      4        \u001b[36m1.0336\u001b[0m  0.0413\n",
            "      5        \u001b[36m0.9823\u001b[0m  0.0418\n",
            "      6        \u001b[36m0.9328\u001b[0m  0.0423\n",
            "      7        \u001b[36m0.8846\u001b[0m  0.0378\n",
            "      8        \u001b[36m0.8363\u001b[0m  0.0382\n",
            "      9        \u001b[36m0.7875\u001b[0m  0.0373\n",
            "     10        \u001b[36m0.7417\u001b[0m  0.0399\n",
            "     11        \u001b[36m0.7065\u001b[0m  0.0388\n",
            "     12        \u001b[36m0.6852\u001b[0m  0.0411\n",
            "     13        \u001b[36m0.6747\u001b[0m  0.0385\n",
            "     14        \u001b[36m0.6699\u001b[0m  0.0464\n",
            "     15        \u001b[36m0.6677\u001b[0m  0.0522\n",
            "     16        \u001b[36m0.6666\u001b[0m  0.0431\n",
            "     17        \u001b[36m0.6660\u001b[0m  0.0386\n",
            "     18        \u001b[36m0.6656\u001b[0m  0.0403\n",
            "     19        \u001b[36m0.6653\u001b[0m  0.0411\n",
            "     20        \u001b[36m0.6652\u001b[0m  0.0382\n",
            "     21        \u001b[36m0.6650\u001b[0m  0.0479\n",
            "     22        \u001b[36m0.6649\u001b[0m  0.0403\n",
            "     23        \u001b[36m0.6648\u001b[0m  0.0390\n",
            "     24        \u001b[36m0.6648\u001b[0m  0.0416\n",
            "     25        \u001b[36m0.6647\u001b[0m  0.0382\n",
            "     26        \u001b[36m0.6647\u001b[0m  0.0411\n",
            "     27        \u001b[36m0.6646\u001b[0m  0.0392\n",
            "     28        \u001b[36m0.6646\u001b[0m  0.0388\n",
            "     29        \u001b[36m0.6645\u001b[0m  0.0410\n",
            "     30        \u001b[36m0.6645\u001b[0m  0.0403\n",
            "     31        \u001b[36m0.6645\u001b[0m  0.0389\n",
            "     32        \u001b[36m0.6644\u001b[0m  0.0426\n",
            "     33        \u001b[36m0.6644\u001b[0m  0.0426\n",
            "     34        \u001b[36m0.6644\u001b[0m  0.0395\n",
            "     35        \u001b[36m0.6644\u001b[0m  0.0388\n",
            "     36        \u001b[36m0.6644\u001b[0m  0.0398\n",
            "     37        \u001b[36m0.6643\u001b[0m  0.0413\n",
            "     38        \u001b[36m0.6643\u001b[0m  0.0526\n",
            "     39        \u001b[36m0.6643\u001b[0m  0.0528\n",
            "     40        \u001b[36m0.6643\u001b[0m  0.0399\n",
            "     41        \u001b[36m0.6643\u001b[0m  0.0405\n",
            "     42        \u001b[36m0.6643\u001b[0m  0.0413\n",
            "     43        \u001b[36m0.6642\u001b[0m  0.0384\n",
            "     44        \u001b[36m0.6642\u001b[0m  0.0415\n",
            "     45        \u001b[36m0.6642\u001b[0m  0.0490\n",
            "     46        \u001b[36m0.6642\u001b[0m  0.0382\n",
            "     47        \u001b[36m0.6642\u001b[0m  0.0411\n",
            "     48        \u001b[36m0.6642\u001b[0m  0.0401\n",
            "     49        \u001b[36m0.6642\u001b[0m  0.0400\n",
            "     50        \u001b[36m0.6642\u001b[0m  0.0404\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3861\u001b[0m  0.0298\n",
            "      2        \u001b[36m1.3541\u001b[0m  0.0283\n",
            "      3        \u001b[36m1.3226\u001b[0m  0.0319\n",
            "      4        \u001b[36m1.2917\u001b[0m  0.0321\n",
            "      5        \u001b[36m1.2612\u001b[0m  0.0300\n",
            "      6        \u001b[36m1.2313\u001b[0m  0.0292\n",
            "      7        \u001b[36m1.2020\u001b[0m  0.0289\n",
            "      8        \u001b[36m1.1733\u001b[0m  0.0289\n",
            "      9        \u001b[36m1.1453\u001b[0m  0.0289\n",
            "     10        \u001b[36m1.1180\u001b[0m  0.0294\n",
            "     11        \u001b[36m1.0914\u001b[0m  0.0320\n",
            "     12        \u001b[36m1.0657\u001b[0m  0.0293\n",
            "     13        \u001b[36m1.0407\u001b[0m  0.0356\n",
            "     14        \u001b[36m1.0166\u001b[0m  0.0360\n",
            "     15        \u001b[36m0.9933\u001b[0m  0.0384\n",
            "     16        \u001b[36m0.9709\u001b[0m  0.0299\n",
            "     17        \u001b[36m0.9495\u001b[0m  0.0284\n",
            "     18        \u001b[36m0.9290\u001b[0m  0.0373\n",
            "     19        \u001b[36m0.9094\u001b[0m  0.0319\n",
            "     20        \u001b[36m0.8908\u001b[0m  0.0284\n",
            "     21        \u001b[36m0.8731\u001b[0m  0.0292\n",
            "     22        \u001b[36m0.8564\u001b[0m  0.0296\n",
            "     23        \u001b[36m0.8407\u001b[0m  0.0292\n",
            "     24        \u001b[36m0.8259\u001b[0m  0.0374\n",
            "     25        \u001b[36m0.8120\u001b[0m  0.0319\n",
            "     26        \u001b[36m0.7990\u001b[0m  0.0307\n",
            "     27        \u001b[36m0.7869\u001b[0m  0.0284\n",
            "     28        \u001b[36m0.7756\u001b[0m  0.0293\n",
            "     29        \u001b[36m0.7652\u001b[0m  0.0308\n",
            "     30        \u001b[36m0.7555\u001b[0m  0.0321\n",
            "     31        \u001b[36m0.7466\u001b[0m  0.0323\n",
            "     32        \u001b[36m0.7384\u001b[0m  0.0319\n",
            "     33        \u001b[36m0.7309\u001b[0m  0.0306\n",
            "     34        \u001b[36m0.7240\u001b[0m  0.0295\n",
            "     35        \u001b[36m0.7177\u001b[0m  0.0303\n",
            "     36        \u001b[36m0.7120\u001b[0m  0.0331\n",
            "     37        \u001b[36m0.7068\u001b[0m  0.0307\n",
            "     38        \u001b[36m0.7020\u001b[0m  0.0322\n",
            "     39        \u001b[36m0.6977\u001b[0m  0.0326\n",
            "     40        \u001b[36m0.6939\u001b[0m  0.0299\n",
            "     41        \u001b[36m0.6904\u001b[0m  0.0299\n",
            "     42        \u001b[36m0.6872\u001b[0m  0.0285\n",
            "     43        \u001b[36m0.6843\u001b[0m  0.0368\n",
            "     44        \u001b[36m0.6818\u001b[0m  0.0362\n",
            "     45        \u001b[36m0.6795\u001b[0m  0.0378\n",
            "     46        \u001b[36m0.6774\u001b[0m  0.0393\n",
            "     47        \u001b[36m0.6756\u001b[0m  0.0309\n",
            "     48        \u001b[36m0.6739\u001b[0m  0.0294\n",
            "     49        \u001b[36m0.6725\u001b[0m  0.0292\n",
            "     50        \u001b[36m0.6711\u001b[0m  0.0318\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2965\u001b[0m  0.0278\n",
            "      2        \u001b[36m1.2673\u001b[0m  0.0438\n",
            "      3        \u001b[36m1.2387\u001b[0m  0.0468\n",
            "      4        \u001b[36m1.2105\u001b[0m  0.0473\n",
            "      5        \u001b[36m1.1830\u001b[0m  0.0409\n",
            "      6        \u001b[36m1.1561\u001b[0m  0.0398\n",
            "      7        \u001b[36m1.1298\u001b[0m  0.0363\n",
            "      8        \u001b[36m1.1041\u001b[0m  0.0448\n",
            "      9        \u001b[36m1.0792\u001b[0m  0.0410\n",
            "     10        \u001b[36m1.0550\u001b[0m  0.0360\n",
            "     11        \u001b[36m1.0316\u001b[0m  0.0373\n",
            "     12        \u001b[36m1.0090\u001b[0m  0.0428\n",
            "     13        \u001b[36m0.9871\u001b[0m  0.0402\n",
            "     14        \u001b[36m0.9661\u001b[0m  0.0370\n",
            "     15        \u001b[36m0.9460\u001b[0m  0.0382\n",
            "     16        \u001b[36m0.9267\u001b[0m  0.0347\n",
            "     17        \u001b[36m0.9082\u001b[0m  0.0565\n",
            "     18        \u001b[36m0.8907\u001b[0m  0.0456\n",
            "     19        \u001b[36m0.8740\u001b[0m  0.0423\n",
            "     20        \u001b[36m0.8582\u001b[0m  0.0352\n",
            "     21        \u001b[36m0.8432\u001b[0m  0.0387\n",
            "     22        \u001b[36m0.8291\u001b[0m  0.0372\n",
            "     23        \u001b[36m0.8159\u001b[0m  0.0369\n",
            "     24        \u001b[36m0.8034\u001b[0m  0.0422\n",
            "     25        \u001b[36m0.7918\u001b[0m  0.0347\n",
            "     26        \u001b[36m0.7810\u001b[0m  0.0383\n",
            "     27        \u001b[36m0.7708\u001b[0m  0.0420\n",
            "     28        \u001b[36m0.7615\u001b[0m  0.0395\n",
            "     29        \u001b[36m0.7528\u001b[0m  0.0357\n",
            "     30        \u001b[36m0.7447\u001b[0m  0.0353\n",
            "     31        \u001b[36m0.7373\u001b[0m  0.0352\n",
            "     32        \u001b[36m0.7304\u001b[0m  0.0350\n",
            "     33        \u001b[36m0.7241\u001b[0m  0.0393\n",
            "     34        \u001b[36m0.7183\u001b[0m  0.0363\n",
            "     35        \u001b[36m0.7131\u001b[0m  0.0376\n",
            "     36        \u001b[36m0.7082\u001b[0m  0.0356\n",
            "     37        \u001b[36m0.7038\u001b[0m  0.0409\n",
            "     38        \u001b[36m0.6998\u001b[0m  0.0425\n",
            "     39        \u001b[36m0.6961\u001b[0m  0.0450\n",
            "     40        \u001b[36m0.6927\u001b[0m  0.0557\n",
            "     41        \u001b[36m0.6897\u001b[0m  0.0439\n",
            "     42        \u001b[36m0.6869\u001b[0m  0.0419\n",
            "     43        \u001b[36m0.6844\u001b[0m  0.0416\n",
            "     44        \u001b[36m0.6822\u001b[0m  0.0382\n",
            "     45        \u001b[36m0.6801\u001b[0m  0.0415\n",
            "     46        \u001b[36m0.6782\u001b[0m  0.0433\n",
            "     47        \u001b[36m0.6766\u001b[0m  0.0433\n",
            "     48        \u001b[36m0.6750\u001b[0m  0.0416\n",
            "     49        \u001b[36m0.6737\u001b[0m  0.0389\n",
            "     50        \u001b[36m0.6724\u001b[0m  0.0435\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1045\u001b[0m  0.0681\n",
            "      2        \u001b[36m2.9775\u001b[0m  0.0578\n",
            "      3        \u001b[36m2.8453\u001b[0m  0.0610\n",
            "      4        \u001b[36m2.7100\u001b[0m  0.0522\n",
            "      5        \u001b[36m2.5727\u001b[0m  0.0531\n",
            "      6        \u001b[36m2.4315\u001b[0m  0.0539\n",
            "      7        \u001b[36m2.2601\u001b[0m  0.0531\n",
            "      8        \u001b[36m1.8814\u001b[0m  0.0560\n",
            "      9        \u001b[36m1.1515\u001b[0m  0.0634\n",
            "     10        \u001b[36m0.7533\u001b[0m  0.0573\n",
            "     11        \u001b[36m0.6830\u001b[0m  0.0533\n",
            "     12        \u001b[36m0.6743\u001b[0m  0.0573\n",
            "     13        \u001b[36m0.6733\u001b[0m  0.0525\n",
            "     14        \u001b[36m0.6728\u001b[0m  0.0567\n",
            "     15        \u001b[36m0.6723\u001b[0m  0.0577\n",
            "     16        \u001b[36m0.6720\u001b[0m  0.0561\n",
            "     17        \u001b[36m0.6717\u001b[0m  0.0520\n",
            "     18        \u001b[36m0.6715\u001b[0m  0.0399\n",
            "     19        \u001b[36m0.6713\u001b[0m  0.0441\n",
            "     20        \u001b[36m0.6711\u001b[0m  0.0465\n",
            "     21        \u001b[36m0.6710\u001b[0m  0.0397\n",
            "     22        \u001b[36m0.6709\u001b[0m  0.0385\n",
            "     23        \u001b[36m0.6708\u001b[0m  0.0394\n",
            "     24        \u001b[36m0.6707\u001b[0m  0.0419\n",
            "     25        \u001b[36m0.6706\u001b[0m  0.0455\n",
            "     26        \u001b[36m0.6705\u001b[0m  0.0404\n",
            "     27        \u001b[36m0.6704\u001b[0m  0.0396\n",
            "     28        \u001b[36m0.6703\u001b[0m  0.0407\n",
            "     29        \u001b[36m0.6703\u001b[0m  0.0517\n",
            "     30        \u001b[36m0.6702\u001b[0m  0.0507\n",
            "     31        \u001b[36m0.6701\u001b[0m  0.0419\n",
            "     32        \u001b[36m0.6695\u001b[0m  0.0387\n",
            "     33        \u001b[36m0.6695\u001b[0m  0.0407\n",
            "     34        \u001b[36m0.6687\u001b[0m  0.0393\n",
            "     35        \u001b[36m0.6682\u001b[0m  0.0412\n",
            "     36        \u001b[36m0.6676\u001b[0m  0.0393\n",
            "     37        \u001b[36m0.6669\u001b[0m  0.0421\n",
            "     38        \u001b[36m0.6661\u001b[0m  0.0458\n",
            "     39        \u001b[36m0.6653\u001b[0m  0.0412\n",
            "     40        \u001b[36m0.6645\u001b[0m  0.0395\n",
            "     41        \u001b[36m0.6638\u001b[0m  0.0389\n",
            "     42        0.6643  0.0393\n",
            "     43        0.6644  0.0509\n",
            "     44        \u001b[36m0.6633\u001b[0m  0.0437\n",
            "     45        \u001b[36m0.6624\u001b[0m  0.0400\n",
            "     46        \u001b[36m0.6622\u001b[0m  0.0386\n",
            "     47        \u001b[36m0.6619\u001b[0m  0.0392\n",
            "     48        \u001b[36m0.6616\u001b[0m  0.0388\n",
            "     49        \u001b[36m0.6598\u001b[0m  0.0393\n",
            "     50        \u001b[36m0.6583\u001b[0m  0.0399\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.0981\u001b[0m  0.0429\n",
            "      2        \u001b[36m1.9688\u001b[0m  0.0489\n",
            "      3        \u001b[36m1.8416\u001b[0m  0.0426\n",
            "      4        \u001b[36m1.7129\u001b[0m  0.0389\n",
            "      5        \u001b[36m1.5848\u001b[0m  0.0385\n",
            "      6        \u001b[36m1.4588\u001b[0m  0.0429\n",
            "      7        \u001b[36m1.3342\u001b[0m  0.0398\n",
            "      8        \u001b[36m1.1988\u001b[0m  0.0401\n",
            "      9        \u001b[36m1.0188\u001b[0m  0.0379\n",
            "     10        \u001b[36m0.8387\u001b[0m  0.0385\n",
            "     11        \u001b[36m0.7210\u001b[0m  0.0400\n",
            "     12        \u001b[36m0.6810\u001b[0m  0.0413\n",
            "     13        \u001b[36m0.6710\u001b[0m  0.0391\n",
            "     14        \u001b[36m0.6678\u001b[0m  0.0425\n",
            "     15        \u001b[36m0.6665\u001b[0m  0.0414\n",
            "     16        \u001b[36m0.6659\u001b[0m  0.0406\n",
            "     17        \u001b[36m0.6656\u001b[0m  0.0504\n",
            "     18        \u001b[36m0.6655\u001b[0m  0.0375\n",
            "     19        \u001b[36m0.6654\u001b[0m  0.0383\n",
            "     20        \u001b[36m0.6653\u001b[0m  0.0421\n",
            "     21        \u001b[36m0.6653\u001b[0m  0.0407\n",
            "     22        \u001b[36m0.6653\u001b[0m  0.0384\n",
            "     23        \u001b[36m0.6652\u001b[0m  0.0385\n",
            "     24        \u001b[36m0.6652\u001b[0m  0.0426\n",
            "     25        \u001b[36m0.6652\u001b[0m  0.0513\n",
            "     26        \u001b[36m0.6652\u001b[0m  0.0502\n",
            "     27        \u001b[36m0.6652\u001b[0m  0.0392\n",
            "     28        \u001b[36m0.6652\u001b[0m  0.0403\n",
            "     29        \u001b[36m0.6652\u001b[0m  0.0408\n",
            "     30        \u001b[36m0.6652\u001b[0m  0.0390\n",
            "     31        \u001b[36m0.6652\u001b[0m  0.0438\n",
            "     32        \u001b[36m0.6652\u001b[0m  0.0394\n",
            "     33        \u001b[36m0.6652\u001b[0m  0.0390\n",
            "     34        \u001b[36m0.6652\u001b[0m  0.0416\n",
            "     35        \u001b[36m0.6652\u001b[0m  0.0417\n",
            "     36        \u001b[36m0.6652\u001b[0m  0.0408\n",
            "     37        \u001b[36m0.6652\u001b[0m  0.0429\n",
            "     38        \u001b[36m0.6652\u001b[0m  0.0385\n",
            "     39        \u001b[36m0.6652\u001b[0m  0.0394\n",
            "     40        \u001b[36m0.6652\u001b[0m  0.0403\n",
            "     41        \u001b[36m0.6652\u001b[0m  0.0506\n",
            "     42        \u001b[36m0.6652\u001b[0m  0.0388\n",
            "     43        0.6692  0.0417\n",
            "     44        \u001b[36m0.6650\u001b[0m  0.0401\n",
            "     45        0.6650  0.0385\n",
            "     46        0.6651  0.0392\n",
            "     47        0.6651  0.0396\n",
            "     48        \u001b[36m0.6635\u001b[0m  0.0525\n",
            "     49        0.6656  0.0459\n",
            "     50        0.6650  0.0415\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0311\u001b[0m  0.0269\n",
            "      2        \u001b[36m2.9611\u001b[0m  0.0426\n",
            "      3        \u001b[36m2.8911\u001b[0m  0.0371\n",
            "      4        \u001b[36m2.8212\u001b[0m  0.0291\n",
            "      5        \u001b[36m2.7513\u001b[0m  0.0288\n",
            "      6        \u001b[36m2.6814\u001b[0m  0.0320\n",
            "      7        \u001b[36m2.6116\u001b[0m  0.0286\n",
            "      8        \u001b[36m2.5419\u001b[0m  0.0297\n",
            "      9        \u001b[36m2.4722\u001b[0m  0.0309\n",
            "     10        \u001b[36m2.4026\u001b[0m  0.0295\n",
            "     11        \u001b[36m2.3332\u001b[0m  0.0304\n",
            "     12        \u001b[36m2.2639\u001b[0m  0.0280\n",
            "     13        \u001b[36m2.1947\u001b[0m  0.0286\n",
            "     14        \u001b[36m2.1257\u001b[0m  0.0309\n",
            "     15        \u001b[36m2.0570\u001b[0m  0.0283\n",
            "     16        \u001b[36m1.9886\u001b[0m  0.0288\n",
            "     17        \u001b[36m1.9205\u001b[0m  0.0306\n",
            "     18        \u001b[36m1.8528\u001b[0m  0.0385\n",
            "     19        \u001b[36m1.7855\u001b[0m  0.0301\n",
            "     20        \u001b[36m1.7189\u001b[0m  0.0295\n",
            "     21        \u001b[36m1.6529\u001b[0m  0.0282\n",
            "     22        \u001b[36m1.5877\u001b[0m  0.0307\n",
            "     23        \u001b[36m1.5235\u001b[0m  0.0279\n",
            "     24        \u001b[36m1.4604\u001b[0m  0.0292\n",
            "     25        \u001b[36m1.3985\u001b[0m  0.0290\n",
            "     26        \u001b[36m1.3382\u001b[0m  0.0320\n",
            "     27        \u001b[36m1.2795\u001b[0m  0.0402\n",
            "     28        \u001b[36m1.2228\u001b[0m  0.0360\n",
            "     29        \u001b[36m1.1682\u001b[0m  0.0387\n",
            "     30        \u001b[36m1.1161\u001b[0m  0.0350\n",
            "     31        \u001b[36m1.0667\u001b[0m  0.0295\n",
            "     32        \u001b[36m1.0202\u001b[0m  0.0299\n",
            "     33        \u001b[36m0.9767\u001b[0m  0.0294\n",
            "     34        \u001b[36m0.9366\u001b[0m  0.0287\n",
            "     35        \u001b[36m0.8998\u001b[0m  0.0291\n",
            "     36        \u001b[36m0.8665\u001b[0m  0.0297\n",
            "     37        \u001b[36m0.8365\u001b[0m  0.0291\n",
            "     38        \u001b[36m0.8099\u001b[0m  0.0313\n",
            "     39        \u001b[36m0.7865\u001b[0m  0.0309\n",
            "     40        \u001b[36m0.7661\u001b[0m  0.0336\n",
            "     41        \u001b[36m0.7485\u001b[0m  0.0286\n",
            "     42        \u001b[36m0.7335\u001b[0m  0.0294\n",
            "     43        \u001b[36m0.7208\u001b[0m  0.0273\n",
            "     44        \u001b[36m0.7100\u001b[0m  0.0298\n",
            "     45        \u001b[36m0.7011\u001b[0m  0.0316\n",
            "     46        \u001b[36m0.6936\u001b[0m  0.0316\n",
            "     47        \u001b[36m0.6875\u001b[0m  0.0302\n",
            "     48        \u001b[36m0.6824\u001b[0m  0.0290\n",
            "     49        \u001b[36m0.6783\u001b[0m  0.0329\n",
            "     50        \u001b[36m0.6750\u001b[0m  0.0397\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.5146\u001b[0m  0.0275\n",
            "      2        \u001b[36m3.4476\u001b[0m  0.0297\n",
            "      3        \u001b[36m3.3806\u001b[0m  0.0297\n",
            "      4        \u001b[36m3.3136\u001b[0m  0.0300\n",
            "      5        \u001b[36m3.2467\u001b[0m  0.0312\n",
            "      6        \u001b[36m3.1798\u001b[0m  0.0366\n",
            "      7        \u001b[36m3.1128\u001b[0m  0.0421\n",
            "      8        \u001b[36m3.0458\u001b[0m  0.0379\n",
            "      9        \u001b[36m2.9789\u001b[0m  0.0313\n",
            "     10        \u001b[36m2.9120\u001b[0m  0.0288\n",
            "     11        \u001b[36m2.8452\u001b[0m  0.0298\n",
            "     12        \u001b[36m2.7783\u001b[0m  0.0337\n",
            "     13        \u001b[36m2.7115\u001b[0m  0.0287\n",
            "     14        \u001b[36m2.6448\u001b[0m  0.0294\n",
            "     15        \u001b[36m2.5781\u001b[0m  0.0294\n",
            "     16        \u001b[36m2.5115\u001b[0m  0.0290\n",
            "     17        \u001b[36m2.4449\u001b[0m  0.0325\n",
            "     18        \u001b[36m2.3784\u001b[0m  0.0294\n",
            "     19        \u001b[36m2.3121\u001b[0m  0.0332\n",
            "     20        \u001b[36m2.2459\u001b[0m  0.0300\n",
            "     21        \u001b[36m2.1798\u001b[0m  0.0333\n",
            "     22        \u001b[36m2.1139\u001b[0m  0.0298\n",
            "     23        \u001b[36m2.0483\u001b[0m  0.0310\n",
            "     24        \u001b[36m1.9829\u001b[0m  0.0288\n",
            "     25        \u001b[36m1.9179\u001b[0m  0.0289\n",
            "     26        \u001b[36m1.8532\u001b[0m  0.0284\n",
            "     27        \u001b[36m1.7889\u001b[0m  0.0321\n",
            "     28        \u001b[36m1.7252\u001b[0m  0.0295\n",
            "     29        \u001b[36m1.6621\u001b[0m  0.0283\n",
            "     30        \u001b[36m1.5997\u001b[0m  0.0361\n",
            "     31        \u001b[36m1.5382\u001b[0m  0.0336\n",
            "     32        \u001b[36m1.4776\u001b[0m  0.0284\n",
            "     33        \u001b[36m1.4182\u001b[0m  0.0283\n",
            "     34        \u001b[36m1.3601\u001b[0m  0.0282\n",
            "     35        \u001b[36m1.3035\u001b[0m  0.0313\n",
            "     36        \u001b[36m1.2486\u001b[0m  0.0335\n",
            "     37        \u001b[36m1.1956\u001b[0m  0.0379\n",
            "     38        \u001b[36m1.1448\u001b[0m  0.0367\n",
            "     39        \u001b[36m1.0963\u001b[0m  0.0406\n",
            "     40        \u001b[36m1.0503\u001b[0m  0.0312\n",
            "     41        \u001b[36m1.0071\u001b[0m  0.0296\n",
            "     42        \u001b[36m0.9668\u001b[0m  0.0321\n",
            "     43        \u001b[36m0.9296\u001b[0m  0.0298\n",
            "     44        \u001b[36m0.8954\u001b[0m  0.0284\n",
            "     45        \u001b[36m0.8643\u001b[0m  0.0290\n",
            "     46        \u001b[36m0.8364\u001b[0m  0.0309\n",
            "     47        \u001b[36m0.8114\u001b[0m  0.0293\n",
            "     48        \u001b[36m0.7894\u001b[0m  0.0289\n",
            "     49        \u001b[36m0.7700\u001b[0m  0.0309\n",
            "     50        \u001b[36m0.7532\u001b[0m  0.0338\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0462\u001b[0m  0.0370\n",
            "      2        \u001b[36m0.9982\u001b[0m  0.0382\n",
            "      3        \u001b[36m0.9594\u001b[0m  0.0388\n",
            "      4        \u001b[36m0.9170\u001b[0m  0.0389\n",
            "      5        \u001b[36m0.8833\u001b[0m  0.0396\n",
            "      6        \u001b[36m0.8452\u001b[0m  0.0415\n",
            "      7        \u001b[36m0.7933\u001b[0m  0.0401\n",
            "      8        \u001b[36m0.7745\u001b[0m  0.0483\n",
            "      9        \u001b[36m0.7608\u001b[0m  0.0386\n",
            "     10        \u001b[36m0.7467\u001b[0m  0.0388\n",
            "     11        \u001b[36m0.7363\u001b[0m  0.0395\n",
            "     12        \u001b[36m0.7248\u001b[0m  0.0431\n",
            "     13        \u001b[36m0.7140\u001b[0m  0.0500\n",
            "     14        \u001b[36m0.7033\u001b[0m  0.0480\n",
            "     15        \u001b[36m0.6951\u001b[0m  0.0387\n",
            "     16        \u001b[36m0.6845\u001b[0m  0.0397\n",
            "     17        \u001b[36m0.6774\u001b[0m  0.0407\n",
            "     18        \u001b[36m0.6749\u001b[0m  0.0398\n",
            "     19        \u001b[36m0.6721\u001b[0m  0.0399\n",
            "     20        \u001b[36m0.6655\u001b[0m  0.0394\n",
            "     21        \u001b[36m0.6606\u001b[0m  0.0393\n",
            "     22        \u001b[36m0.6530\u001b[0m  0.0425\n",
            "     23        \u001b[36m0.6472\u001b[0m  0.0405\n",
            "     24        \u001b[36m0.6420\u001b[0m  0.0391\n",
            "     25        \u001b[36m0.6376\u001b[0m  0.0406\n",
            "     26        \u001b[36m0.6339\u001b[0m  0.0393\n",
            "     27        \u001b[36m0.6308\u001b[0m  0.0431\n",
            "     28        \u001b[36m0.6281\u001b[0m  0.0397\n",
            "     29        \u001b[36m0.6258\u001b[0m  0.0420\n",
            "     30        \u001b[36m0.6237\u001b[0m  0.0389\n",
            "     31        \u001b[36m0.6218\u001b[0m  0.0386\n",
            "     32        \u001b[36m0.6200\u001b[0m  0.0454\n",
            "     33        0.6203  0.0374\n",
            "     34        \u001b[36m0.6170\u001b[0m  0.0406\n",
            "     35        \u001b[36m0.6155\u001b[0m  0.0529\n",
            "     36        \u001b[36m0.6152\u001b[0m  0.0502\n",
            "     37        \u001b[36m0.6140\u001b[0m  0.0458\n",
            "     38        \u001b[36m0.6129\u001b[0m  0.0380\n",
            "     39        \u001b[36m0.6118\u001b[0m  0.0382\n",
            "     40        \u001b[36m0.6108\u001b[0m  0.0389\n",
            "     41        \u001b[36m0.6100\u001b[0m  0.0433\n",
            "     42        \u001b[36m0.6082\u001b[0m  0.0392\n",
            "     43        \u001b[36m0.6073\u001b[0m  0.0400\n",
            "     44        \u001b[36m0.6065\u001b[0m  0.0388\n",
            "     45        \u001b[36m0.6053\u001b[0m  0.0406\n",
            "     46        \u001b[36m0.6045\u001b[0m  0.0411\n",
            "     47        \u001b[36m0.6038\u001b[0m  0.0390\n",
            "     48        \u001b[36m0.6031\u001b[0m  0.0419\n",
            "     49        \u001b[36m0.6025\u001b[0m  0.0396\n",
            "     50        \u001b[36m0.6018\u001b[0m  0.0440\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.5374\u001b[0m  0.0361\n",
            "      2        \u001b[36m2.1455\u001b[0m  0.0375\n",
            "      3        \u001b[36m1.7458\u001b[0m  0.0381\n",
            "      4        \u001b[36m1.4104\u001b[0m  0.0373\n",
            "      5        \u001b[36m1.2100\u001b[0m  0.0408\n",
            "      6        \u001b[36m1.1247\u001b[0m  0.0584\n",
            "      7        \u001b[36m1.0821\u001b[0m  0.0402\n",
            "      8        \u001b[36m1.0407\u001b[0m  0.0455\n",
            "      9        \u001b[36m1.0079\u001b[0m  0.0513\n",
            "     10        \u001b[36m0.9730\u001b[0m  0.0431\n",
            "     11        \u001b[36m0.9312\u001b[0m  0.0403\n",
            "     12        \u001b[36m0.8906\u001b[0m  0.0417\n",
            "     13        \u001b[36m0.8616\u001b[0m  0.0400\n",
            "     14        \u001b[36m0.8192\u001b[0m  0.0396\n",
            "     15        \u001b[36m0.7779\u001b[0m  0.0391\n",
            "     16        \u001b[36m0.7485\u001b[0m  0.0372\n",
            "     17        \u001b[36m0.7280\u001b[0m  0.0397\n",
            "     18        \u001b[36m0.7148\u001b[0m  0.0390\n",
            "     19        \u001b[36m0.7049\u001b[0m  0.0404\n",
            "     20        \u001b[36m0.6977\u001b[0m  0.0557\n",
            "     21        0.6983  0.0560\n",
            "     22        \u001b[36m0.6939\u001b[0m  0.0536\n",
            "     23        \u001b[36m0.6892\u001b[0m  0.0537\n",
            "     24        \u001b[36m0.6876\u001b[0m  0.0511\n",
            "     25        \u001b[36m0.6850\u001b[0m  0.0581\n",
            "     26        \u001b[36m0.6832\u001b[0m  0.0498\n",
            "     27        \u001b[36m0.6816\u001b[0m  0.0646\n",
            "     28        \u001b[36m0.6797\u001b[0m  0.0521\n",
            "     29        \u001b[36m0.6789\u001b[0m  0.0612\n",
            "     30        \u001b[36m0.6776\u001b[0m  0.0538\n",
            "     31        \u001b[36m0.6764\u001b[0m  0.0510\n",
            "     32        \u001b[36m0.6752\u001b[0m  0.0479\n",
            "     33        \u001b[36m0.6741\u001b[0m  0.0485\n",
            "     34        \u001b[36m0.6730\u001b[0m  0.0480\n",
            "     35        \u001b[36m0.6719\u001b[0m  0.0477\n",
            "     36        0.6749  0.0483\n",
            "     37        \u001b[36m0.6698\u001b[0m  0.0521\n",
            "     38        \u001b[36m0.6688\u001b[0m  0.0506\n",
            "     39        \u001b[36m0.6678\u001b[0m  0.0488\n",
            "     40        \u001b[36m0.6669\u001b[0m  0.0483\n",
            "     41        \u001b[36m0.6662\u001b[0m  0.0498\n",
            "     42        \u001b[36m0.6652\u001b[0m  0.0486\n",
            "     43        \u001b[36m0.6643\u001b[0m  0.0490\n",
            "     44        \u001b[36m0.6634\u001b[0m  0.0469\n",
            "     45        \u001b[36m0.6625\u001b[0m  0.0470\n",
            "     46        \u001b[36m0.6617\u001b[0m  0.0540\n",
            "     47        \u001b[36m0.6608\u001b[0m  0.0722\n",
            "     48        \u001b[36m0.6600\u001b[0m  0.0588\n",
            "     49        \u001b[36m0.6592\u001b[0m  0.0557\n",
            "     50        \u001b[36m0.6584\u001b[0m  0.0542\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8797\u001b[0m  0.0414\n",
            "      2        \u001b[36m0.8209\u001b[0m  0.0375\n",
            "      3        \u001b[36m0.8035\u001b[0m  0.0366\n",
            "      4        \u001b[36m0.7946\u001b[0m  0.0381\n",
            "      5        \u001b[36m0.7881\u001b[0m  0.0427\n",
            "      6        \u001b[36m0.7773\u001b[0m  0.0431\n",
            "      7        \u001b[36m0.7723\u001b[0m  0.0428\n",
            "      8        \u001b[36m0.7676\u001b[0m  0.0404\n",
            "      9        \u001b[36m0.7630\u001b[0m  0.0424\n",
            "     10        \u001b[36m0.7586\u001b[0m  0.0409\n",
            "     11        \u001b[36m0.7543\u001b[0m  0.0377\n",
            "     12        \u001b[36m0.7502\u001b[0m  0.0434\n",
            "     13        \u001b[36m0.7462\u001b[0m  0.0385\n",
            "     14        \u001b[36m0.7424\u001b[0m  0.0390\n",
            "     15        \u001b[36m0.7386\u001b[0m  0.0377\n",
            "     16        \u001b[36m0.7349\u001b[0m  0.0388\n",
            "     17        \u001b[36m0.7313\u001b[0m  0.0391\n",
            "     18        \u001b[36m0.7277\u001b[0m  0.0413\n",
            "     19        \u001b[36m0.7242\u001b[0m  0.0561\n",
            "     20        \u001b[36m0.7208\u001b[0m  0.0410\n",
            "     21        \u001b[36m0.7175\u001b[0m  0.0469\n",
            "     22        \u001b[36m0.7141\u001b[0m  0.0432\n",
            "     23        \u001b[36m0.7109\u001b[0m  0.0473\n",
            "     24        \u001b[36m0.7077\u001b[0m  0.0463\n",
            "     25        \u001b[36m0.7045\u001b[0m  0.0431\n",
            "     26        \u001b[36m0.7014\u001b[0m  0.0431\n",
            "     27        \u001b[36m0.6983\u001b[0m  0.0286\n",
            "     28        \u001b[36m0.6953\u001b[0m  0.0332\n",
            "     29        \u001b[36m0.6923\u001b[0m  0.0287\n",
            "     30        \u001b[36m0.6894\u001b[0m  0.0290\n",
            "     31        \u001b[36m0.6865\u001b[0m  0.0305\n",
            "     32        \u001b[36m0.6837\u001b[0m  0.0323\n",
            "     33        \u001b[36m0.6809\u001b[0m  0.0292\n",
            "     34        \u001b[36m0.6782\u001b[0m  0.0291\n",
            "     35        \u001b[36m0.6755\u001b[0m  0.0299\n",
            "     36        \u001b[36m0.6728\u001b[0m  0.0335\n",
            "     37        \u001b[36m0.6703\u001b[0m  0.0309\n",
            "     38        \u001b[36m0.6677\u001b[0m  0.0295\n",
            "     39        \u001b[36m0.6652\u001b[0m  0.0296\n",
            "     40        \u001b[36m0.6628\u001b[0m  0.0298\n",
            "     41        \u001b[36m0.6604\u001b[0m  0.0307\n",
            "     42        \u001b[36m0.6581\u001b[0m  0.0296\n",
            "     43        \u001b[36m0.6558\u001b[0m  0.0337\n",
            "     44        \u001b[36m0.6536\u001b[0m  0.0412\n",
            "     45        \u001b[36m0.6514\u001b[0m  0.0357\n",
            "     46        \u001b[36m0.6493\u001b[0m  0.0375\n",
            "     47        \u001b[36m0.6472\u001b[0m  0.0414\n",
            "     48        \u001b[36m0.6452\u001b[0m  0.0279\n",
            "     49        \u001b[36m0.6433\u001b[0m  0.0295\n",
            "     50        \u001b[36m0.6414\u001b[0m  0.0294\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5757\u001b[0m  0.0288\n",
            "      2        \u001b[36m1.5521\u001b[0m  0.0299\n",
            "      3        \u001b[36m1.5307\u001b[0m  0.0301\n",
            "      4        \u001b[36m1.5097\u001b[0m  0.0280\n",
            "      5        \u001b[36m1.4889\u001b[0m  0.0283\n",
            "      6        \u001b[36m1.4683\u001b[0m  0.0315\n",
            "      7        \u001b[36m1.4480\u001b[0m  0.0289\n",
            "      8        \u001b[36m1.4279\u001b[0m  0.0304\n",
            "      9        \u001b[36m1.4080\u001b[0m  0.0308\n",
            "     10        \u001b[36m1.3884\u001b[0m  0.0288\n",
            "     11        \u001b[36m1.3691\u001b[0m  0.0315\n",
            "     12        \u001b[36m1.3500\u001b[0m  0.0296\n",
            "     13        \u001b[36m1.3312\u001b[0m  0.0326\n",
            "     14        \u001b[36m1.3127\u001b[0m  0.0297\n",
            "     15        \u001b[36m1.2944\u001b[0m  0.0288\n",
            "     16        \u001b[36m1.2765\u001b[0m  0.0299\n",
            "     17        \u001b[36m1.2588\u001b[0m  0.0291\n",
            "     18        \u001b[36m1.2414\u001b[0m  0.0285\n",
            "     19        \u001b[36m1.2243\u001b[0m  0.0289\n",
            "     20        \u001b[36m1.2076\u001b[0m  0.0301\n",
            "     21        \u001b[36m1.1911\u001b[0m  0.0296\n",
            "     22        \u001b[36m1.1750\u001b[0m  0.0299\n",
            "     23        \u001b[36m1.1592\u001b[0m  0.0283\n",
            "     24        \u001b[36m1.1438\u001b[0m  0.0373\n",
            "     25        \u001b[36m1.1287\u001b[0m  0.0353\n",
            "     26        \u001b[36m1.1140\u001b[0m  0.0368\n",
            "     27        \u001b[36m1.0996\u001b[0m  0.0336\n",
            "     28        \u001b[36m1.0855\u001b[0m  0.0404\n",
            "     29        \u001b[36m1.0719\u001b[0m  0.0278\n",
            "     30        \u001b[36m1.0586\u001b[0m  0.0293\n",
            "     31        \u001b[36m1.0457\u001b[0m  0.0292\n",
            "     32        \u001b[36m1.0332\u001b[0m  0.0312\n",
            "     33        \u001b[36m1.0211\u001b[0m  0.0279\n",
            "     34        \u001b[36m1.0093\u001b[0m  0.0285\n",
            "     35        \u001b[36m0.9979\u001b[0m  0.0298\n",
            "     36        \u001b[36m0.9869\u001b[0m  0.0281\n",
            "     37        \u001b[36m0.9763\u001b[0m  0.0298\n",
            "     38        \u001b[36m0.9661\u001b[0m  0.0303\n",
            "     39        \u001b[36m0.9562\u001b[0m  0.0305\n",
            "     40        \u001b[36m0.9468\u001b[0m  0.0338\n",
            "     41        \u001b[36m0.9377\u001b[0m  0.0298\n",
            "     42        \u001b[36m0.9289\u001b[0m  0.0308\n",
            "     43        \u001b[36m0.9205\u001b[0m  0.0290\n",
            "     44        \u001b[36m0.9125\u001b[0m  0.0291\n",
            "     45        \u001b[36m0.9042\u001b[0m  0.0288\n",
            "     46        \u001b[36m0.8967\u001b[0m  0.0333\n",
            "     47        \u001b[36m0.8897\u001b[0m  0.0299\n",
            "     48        \u001b[36m0.8830\u001b[0m  0.0288\n",
            "     49        \u001b[36m0.8766\u001b[0m  0.0357\n",
            "     50        \u001b[36m0.8706\u001b[0m  0.0316\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9882\u001b[0m  0.0374\n",
            "      2        \u001b[36m1.6034\u001b[0m  0.0381\n",
            "      3        \u001b[36m1.2802\u001b[0m  0.0503\n",
            "      4        \u001b[36m1.0126\u001b[0m  0.0522\n",
            "      5        \u001b[36m0.8221\u001b[0m  0.0456\n",
            "      6        \u001b[36m0.7129\u001b[0m  0.0457\n",
            "      7        \u001b[36m0.6620\u001b[0m  0.0459\n",
            "      8        \u001b[36m0.6388\u001b[0m  0.0405\n",
            "      9        \u001b[36m0.6193\u001b[0m  0.0431\n",
            "     10        0.6210  0.0401\n",
            "     11        \u001b[36m0.6143\u001b[0m  0.0406\n",
            "     12        \u001b[36m0.6045\u001b[0m  0.0450\n",
            "     13        \u001b[36m0.5902\u001b[0m  0.0407\n",
            "     14        0.5909  0.0405\n",
            "     15        \u001b[36m0.5848\u001b[0m  0.0387\n",
            "     16        \u001b[36m0.5814\u001b[0m  0.0382\n",
            "     17        \u001b[36m0.5784\u001b[0m  0.0392\n",
            "     18        \u001b[36m0.5767\u001b[0m  0.0392\n",
            "     19        \u001b[36m0.5740\u001b[0m  0.0409\n",
            "     20        \u001b[36m0.5697\u001b[0m  0.0432\n",
            "     21        0.5706  0.0405\n",
            "     22        \u001b[36m0.5669\u001b[0m  0.0405\n",
            "     23        \u001b[36m0.5629\u001b[0m  0.0411\n",
            "     24        \u001b[36m0.5547\u001b[0m  0.0387\n",
            "     25        \u001b[36m0.5528\u001b[0m  0.0388\n",
            "     26        \u001b[36m0.5499\u001b[0m  0.0529\n",
            "     27        \u001b[36m0.5430\u001b[0m  0.0521\n",
            "     28        0.5471  0.0421\n",
            "     29        0.5448  0.0395\n",
            "     30        \u001b[36m0.5426\u001b[0m  0.0481\n",
            "     31        \u001b[36m0.5417\u001b[0m  0.0376\n",
            "     32        \u001b[36m0.5401\u001b[0m  0.0410\n",
            "     33        \u001b[36m0.5353\u001b[0m  0.0393\n",
            "     34        0.5423  0.0443\n",
            "     35        \u001b[36m0.5316\u001b[0m  0.0395\n",
            "     36        0.5322  0.0394\n",
            "     37        \u001b[36m0.5300\u001b[0m  0.0398\n",
            "     38        \u001b[36m0.5223\u001b[0m  0.0409\n",
            "     39        0.5287  0.0389\n",
            "     40        0.5262  0.0383\n",
            "     41        0.5236  0.0464\n",
            "     42        \u001b[36m0.5210\u001b[0m  0.0401\n",
            "     43        \u001b[36m0.5195\u001b[0m  0.0401\n",
            "     44        \u001b[36m0.5180\u001b[0m  0.0398\n",
            "     45        \u001b[36m0.5166\u001b[0m  0.0401\n",
            "     46        \u001b[36m0.5151\u001b[0m  0.0405\n",
            "     47        \u001b[36m0.5107\u001b[0m  0.0403\n",
            "     48        \u001b[36m0.5102\u001b[0m  0.0453\n",
            "     49        \u001b[36m0.5090\u001b[0m  0.0543\n",
            "     50        \u001b[36m0.5079\u001b[0m  0.0470\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2631\u001b[0m  0.0363\n",
            "      2        \u001b[36m1.0827\u001b[0m  0.0392\n",
            "      3        \u001b[36m0.9914\u001b[0m  0.0449\n",
            "      4        \u001b[36m0.9163\u001b[0m  0.0514\n",
            "      5        \u001b[36m0.8503\u001b[0m  0.0448\n",
            "      6        \u001b[36m0.8180\u001b[0m  0.0449\n",
            "      7        \u001b[36m0.7794\u001b[0m  0.0457\n",
            "      8        \u001b[36m0.7519\u001b[0m  0.0391\n",
            "      9        \u001b[36m0.7286\u001b[0m  0.0396\n",
            "     10        \u001b[36m0.7085\u001b[0m  0.0425\n",
            "     11        \u001b[36m0.6917\u001b[0m  0.0380\n",
            "     12        \u001b[36m0.6763\u001b[0m  0.0409\n",
            "     13        \u001b[36m0.6572\u001b[0m  0.0407\n",
            "     14        \u001b[36m0.6482\u001b[0m  0.0384\n",
            "     15        \u001b[36m0.6361\u001b[0m  0.0404\n",
            "     16        \u001b[36m0.6203\u001b[0m  0.0430\n",
            "     17        \u001b[36m0.6098\u001b[0m  0.0383\n",
            "     18        \u001b[36m0.5987\u001b[0m  0.0408\n",
            "     19        0.6077  0.0394\n",
            "     20        \u001b[36m0.5977\u001b[0m  0.0401\n",
            "     21        \u001b[36m0.5713\u001b[0m  0.0478\n",
            "     22        \u001b[36m0.5651\u001b[0m  0.0557\n",
            "     23        \u001b[36m0.5609\u001b[0m  0.0410\n",
            "     24        \u001b[36m0.5555\u001b[0m  0.0409\n",
            "     25        \u001b[36m0.5506\u001b[0m  0.0384\n",
            "     26        \u001b[36m0.5464\u001b[0m  0.0372\n",
            "     27        \u001b[36m0.5418\u001b[0m  0.0508\n",
            "     28        \u001b[36m0.5379\u001b[0m  0.0388\n",
            "     29        \u001b[36m0.5343\u001b[0m  0.0382\n",
            "     30        \u001b[36m0.5339\u001b[0m  0.0416\n",
            "     31        0.5365  0.0387\n",
            "     32        \u001b[36m0.5337\u001b[0m  0.0423\n",
            "     33        \u001b[36m0.5307\u001b[0m  0.0400\n",
            "     34        \u001b[36m0.5280\u001b[0m  0.0388\n",
            "     35        \u001b[36m0.5261\u001b[0m  0.0385\n",
            "     36        \u001b[36m0.5244\u001b[0m  0.0407\n",
            "     37        \u001b[36m0.5226\u001b[0m  0.0402\n",
            "     38        0.5245  0.0390\n",
            "     39        \u001b[36m0.5121\u001b[0m  0.0402\n",
            "     40        0.5189  0.0407\n",
            "     41        0.5194  0.0415\n",
            "     42        0.5168  0.0385\n",
            "     43        0.5178  0.0409\n",
            "     44        0.5166  0.0490\n",
            "     45        0.5156  0.0499\n",
            "     46        0.5145  0.0450\n",
            "     47        0.5135  0.0400\n",
            "     48        0.5125  0.0407\n",
            "     49        \u001b[36m0.5115\u001b[0m  0.0400\n",
            "     50        \u001b[36m0.5106\u001b[0m  0.0400\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4839\u001b[0m  0.0327\n",
            "      2        \u001b[36m1.5643\u001b[0m  0.0293\n",
            "      3        \u001b[36m1.4429\u001b[0m  0.0305\n",
            "      4        \u001b[36m1.3248\u001b[0m  0.0323\n",
            "      5        \u001b[36m1.2121\u001b[0m  0.0302\n",
            "      6        \u001b[36m1.1092\u001b[0m  0.0326\n",
            "      7        \u001b[36m1.0209\u001b[0m  0.0297\n",
            "      8        \u001b[36m0.9506\u001b[0m  0.0287\n",
            "      9        \u001b[36m0.8976\u001b[0m  0.0284\n",
            "     10        \u001b[36m0.8586\u001b[0m  0.0321\n",
            "     11        \u001b[36m0.8296\u001b[0m  0.0331\n",
            "     12        \u001b[36m0.8073\u001b[0m  0.0301\n",
            "     13        \u001b[36m0.7896\u001b[0m  0.0304\n",
            "     14        \u001b[36m0.7751\u001b[0m  0.0305\n",
            "     15        \u001b[36m0.7628\u001b[0m  0.0328\n",
            "     16        \u001b[36m0.7523\u001b[0m  0.0290\n",
            "     17        \u001b[36m0.7431\u001b[0m  0.0305\n",
            "     18        \u001b[36m0.7350\u001b[0m  0.0311\n",
            "     19        \u001b[36m0.7278\u001b[0m  0.0314\n",
            "     20        \u001b[36m0.7214\u001b[0m  0.0301\n",
            "     21        \u001b[36m0.7156\u001b[0m  0.0357\n",
            "     22        \u001b[36m0.7105\u001b[0m  0.0379\n",
            "     23        \u001b[36m0.7058\u001b[0m  0.0413\n",
            "     24        \u001b[36m0.7016\u001b[0m  0.0398\n",
            "     25        \u001b[36m0.6978\u001b[0m  0.0317\n",
            "     26        \u001b[36m0.6943\u001b[0m  0.0355\n",
            "     27        \u001b[36m0.6911\u001b[0m  0.0321\n",
            "     28        \u001b[36m0.6882\u001b[0m  0.0350\n",
            "     29        \u001b[36m0.6856\u001b[0m  0.0307\n",
            "     30        \u001b[36m0.6832\u001b[0m  0.0425\n",
            "     31        \u001b[36m0.6810\u001b[0m  0.0294\n",
            "     32        \u001b[36m0.6789\u001b[0m  0.0296\n",
            "     33        \u001b[36m0.6771\u001b[0m  0.0320\n",
            "     34        \u001b[36m0.6753\u001b[0m  0.0353\n",
            "     35        \u001b[36m0.6737\u001b[0m  0.0344\n",
            "     36        \u001b[36m0.6722\u001b[0m  0.0322\n",
            "     37        \u001b[36m0.6708\u001b[0m  0.0341\n",
            "     38        \u001b[36m0.6695\u001b[0m  0.0324\n",
            "     39        \u001b[36m0.6683\u001b[0m  0.0327\n",
            "     40        \u001b[36m0.6672\u001b[0m  0.0299\n",
            "     41        \u001b[36m0.6661\u001b[0m  0.0285\n",
            "     42        \u001b[36m0.6651\u001b[0m  0.0287\n",
            "     43        \u001b[36m0.6641\u001b[0m  0.0290\n",
            "     44        \u001b[36m0.6632\u001b[0m  0.0320\n",
            "     45        \u001b[36m0.6624\u001b[0m  0.0300\n",
            "     46        \u001b[36m0.6616\u001b[0m  0.0329\n",
            "     47        \u001b[36m0.6608\u001b[0m  0.0307\n",
            "     48        \u001b[36m0.6600\u001b[0m  0.0296\n",
            "     49        \u001b[36m0.6593\u001b[0m  0.0301\n",
            "     50        \u001b[36m0.6587\u001b[0m  0.0371\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1616\u001b[0m  0.0351\n",
            "      2        \u001b[36m1.1133\u001b[0m  0.0330\n",
            "      3        \u001b[36m1.0695\u001b[0m  0.0332\n",
            "      4        \u001b[36m0.9600\u001b[0m  0.0303\n",
            "      5        \u001b[36m0.9016\u001b[0m  0.0312\n",
            "      6        \u001b[36m0.8796\u001b[0m  0.0295\n",
            "      7        \u001b[36m0.8602\u001b[0m  0.0286\n",
            "      8        \u001b[36m0.8433\u001b[0m  0.0292\n",
            "      9        \u001b[36m0.8285\u001b[0m  0.0327\n",
            "     10        \u001b[36m0.8158\u001b[0m  0.0398\n",
            "     11        \u001b[36m0.8047\u001b[0m  0.0284\n",
            "     12        \u001b[36m0.7951\u001b[0m  0.0352\n",
            "     13        \u001b[36m0.7868\u001b[0m  0.0293\n",
            "     14        \u001b[36m0.7794\u001b[0m  0.0303\n",
            "     15        \u001b[36m0.7730\u001b[0m  0.0284\n",
            "     16        \u001b[36m0.7672\u001b[0m  0.0293\n",
            "     17        \u001b[36m0.7621\u001b[0m  0.0299\n",
            "     18        \u001b[36m0.7574\u001b[0m  0.0284\n",
            "     19        \u001b[36m0.7532\u001b[0m  0.0286\n",
            "     20        \u001b[36m0.7493\u001b[0m  0.0285\n",
            "     21        \u001b[36m0.7457\u001b[0m  0.0307\n",
            "     22        \u001b[36m0.7424\u001b[0m  0.0320\n",
            "     23        \u001b[36m0.7392\u001b[0m  0.0311\n",
            "     24        \u001b[36m0.7363\u001b[0m  0.0301\n",
            "     25        \u001b[36m0.7335\u001b[0m  0.0289\n",
            "     26        \u001b[36m0.7308\u001b[0m  0.0295\n",
            "     27        \u001b[36m0.7282\u001b[0m  0.0295\n",
            "     28        \u001b[36m0.7257\u001b[0m  0.0293\n",
            "     29        \u001b[36m0.7233\u001b[0m  0.0288\n",
            "     30        \u001b[36m0.7210\u001b[0m  0.0385\n",
            "     31        \u001b[36m0.7186\u001b[0m  0.0393\n",
            "     32        \u001b[36m0.7175\u001b[0m  0.0400\n",
            "     33        \u001b[36m0.7147\u001b[0m  0.0377\n",
            "     34        \u001b[36m0.7126\u001b[0m  0.0288\n",
            "     35        \u001b[36m0.7106\u001b[0m  0.0290\n",
            "     36        \u001b[36m0.7086\u001b[0m  0.0335\n",
            "     37        \u001b[36m0.7066\u001b[0m  0.0316\n",
            "     38        \u001b[36m0.7046\u001b[0m  0.0289\n",
            "     39        \u001b[36m0.7027\u001b[0m  0.0301\n",
            "     40        \u001b[36m0.7008\u001b[0m  0.0318\n",
            "     41        \u001b[36m0.6990\u001b[0m  0.0387\n",
            "     42        \u001b[36m0.6971\u001b[0m  0.0299\n",
            "     43        \u001b[36m0.6953\u001b[0m  0.0454\n",
            "     44        \u001b[36m0.6936\u001b[0m  0.0441\n",
            "     45        \u001b[36m0.6918\u001b[0m  0.0418\n",
            "     46        \u001b[36m0.6901\u001b[0m  0.0471\n",
            "     47        \u001b[36m0.6884\u001b[0m  0.0394\n",
            "     48        \u001b[36m0.6867\u001b[0m  0.0369\n",
            "     49        \u001b[36m0.6850\u001b[0m  0.0459\n",
            "     50        \u001b[36m0.6834\u001b[0m  0.0392\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0530\n",
            "      2       37.3239  0.0494\n",
            "      3       37.3239  0.0527\n",
            "      4       37.3239  0.0529\n",
            "      5       37.3239  0.0503\n",
            "      6       37.3239  0.0479\n",
            "      7       37.3239  0.0476\n",
            "      8       37.3239  0.0484\n",
            "      9       37.3239  0.0485\n",
            "     10       37.3239  0.0562\n",
            "     11       37.3239  0.0587\n",
            "     12       37.3239  0.0482\n",
            "     13       37.3239  0.0472\n",
            "     14       37.3239  0.0480\n",
            "     15       37.3239  0.0586\n",
            "     16       37.3239  0.0453\n",
            "     17       37.3239  0.0455\n",
            "     18       37.3239  0.0450\n",
            "     19       37.3239  0.0467\n",
            "     20       37.3239  0.0481\n",
            "     21       37.3239  0.0545\n",
            "     22       37.3239  0.0628\n",
            "     23       37.3239  0.0537\n",
            "     24       37.3239  0.0495\n",
            "     25       37.3239  0.0553\n",
            "     26       37.3239  0.0545\n",
            "     27       37.3239  0.0559\n",
            "     28       37.3239  0.0586\n",
            "     29       37.3239  0.0581\n",
            "     30       37.3239  0.0604\n",
            "     31       37.3239  0.0537\n",
            "     32       37.3239  0.0545\n",
            "     33       37.3239  0.0534\n",
            "     34       37.3239  0.0529\n",
            "     35       37.3239  0.0666\n",
            "     36       37.3239  0.0583\n",
            "     37       37.3239  0.0557\n",
            "     38       37.3239  0.0613\n",
            "     39       37.3239  0.0630\n",
            "     40       37.3239  0.0567\n",
            "     41       37.3239  0.0397\n",
            "     42       37.3239  0.0391\n",
            "     43       37.3239  0.0362\n",
            "     44       37.3239  0.0393\n",
            "     45       37.3239  0.0386\n",
            "     46       37.3239  0.0410\n",
            "     47       37.3239  0.0375\n",
            "     48       37.3239  0.0379\n",
            "     49       37.3239  0.0512\n",
            "     50       37.3239  0.0386\n",
            "     51       37.3239  0.0371\n",
            "     52       37.3239  0.0366\n",
            "     53       37.3239  0.0437\n",
            "     54       37.3239  0.0410\n",
            "     55       37.3239  0.0399\n",
            "     56       37.3239  0.0390\n",
            "     57       37.3239  0.0388\n",
            "     58       37.3239  0.0376\n",
            "     59       37.3239  0.0366\n",
            "     60       37.3239  0.0391\n",
            "     61       37.3239  0.0441\n",
            "     62       37.3239  0.0486\n",
            "     63       37.3239  0.0473\n",
            "     64       \u001b[36m24.9553\u001b[0m  0.0382\n",
            "     65        \u001b[36m0.6287\u001b[0m  0.0424\n",
            "     66        \u001b[36m0.6234\u001b[0m  0.0402\n",
            "     67        \u001b[36m0.6218\u001b[0m  0.0436\n",
            "     68        \u001b[36m0.6207\u001b[0m  0.0401\n",
            "     69        \u001b[36m0.6199\u001b[0m  0.0404\n",
            "     70        \u001b[36m0.6191\u001b[0m  0.0395\n",
            "     71        \u001b[36m0.6185\u001b[0m  0.0408\n",
            "     72        \u001b[36m0.6180\u001b[0m  0.0434\n",
            "     73        \u001b[36m0.6176\u001b[0m  0.0473\n",
            "     74        \u001b[36m0.6172\u001b[0m  0.0366\n",
            "     75        \u001b[36m0.6168\u001b[0m  0.0412\n",
            "     76        \u001b[36m0.6165\u001b[0m  0.0398\n",
            "     77        \u001b[36m0.6162\u001b[0m  0.0381\n",
            "     78        \u001b[36m0.6160\u001b[0m  0.0406\n",
            "     79        \u001b[36m0.6157\u001b[0m  0.0396\n",
            "     80        \u001b[36m0.6155\u001b[0m  0.0404\n",
            "     81        \u001b[36m0.6153\u001b[0m  0.0392\n",
            "     82        \u001b[36m0.6151\u001b[0m  0.0398\n",
            "     83        \u001b[36m0.6150\u001b[0m  0.0381\n",
            "     84        \u001b[36m0.6148\u001b[0m  0.0504\n",
            "     85        \u001b[36m0.6147\u001b[0m  0.0496\n",
            "     86        \u001b[36m0.6145\u001b[0m  0.0513\n",
            "     87        \u001b[36m0.6144\u001b[0m  0.0393\n",
            "     88        \u001b[36m0.6143\u001b[0m  0.0385\n",
            "     89        \u001b[36m0.6142\u001b[0m  0.0405\n",
            "     90        \u001b[36m0.6141\u001b[0m  0.0378\n",
            "     91        \u001b[36m0.6140\u001b[0m  0.0394\n",
            "     92        \u001b[36m0.6139\u001b[0m  0.0431\n",
            "     93        \u001b[36m0.6138\u001b[0m  0.0405\n",
            "     94        \u001b[36m0.6137\u001b[0m  0.0394\n",
            "     95        \u001b[36m0.6136\u001b[0m  0.0376\n",
            "     96        \u001b[36m0.6136\u001b[0m  0.0400\n",
            "     97        \u001b[36m0.6135\u001b[0m  0.0491\n",
            "     98        \u001b[36m0.6134\u001b[0m  0.0369\n",
            "     99        \u001b[36m0.6134\u001b[0m  0.0389\n",
            "    100        \u001b[36m0.6133\u001b[0m  0.0398\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0444\n",
            "      2       37.1930  0.0399\n",
            "      3       37.1930  0.0382\n",
            "      4       37.1930  0.0382\n",
            "      5       37.1930  0.0370\n",
            "      6       37.1930  0.0376\n",
            "      7       37.1930  0.0438\n",
            "      8       37.1930  0.0492\n",
            "      9       37.1930  0.0461\n",
            "     10       37.1930  0.0388\n",
            "     11       37.1930  0.0397\n",
            "     12       37.1930  0.0395\n",
            "     13       37.1930  0.0372\n",
            "     14       37.1930  0.0376\n",
            "     15       37.1930  0.0423\n",
            "     16       37.1930  0.0406\n",
            "     17       37.1930  0.0399\n",
            "     18       37.1930  0.0401\n",
            "     19       37.1930  0.0401\n",
            "     20       37.1930  0.0401\n",
            "     21       37.1930  0.0455\n",
            "     22       37.1930  0.0400\n",
            "     23       37.1930  0.0400\n",
            "     24       37.1930  0.0435\n",
            "     25       37.1930  0.0397\n",
            "     26       37.1930  0.0378\n",
            "     27       37.1930  0.0399\n",
            "     28       37.1930  0.0387\n",
            "     29       37.1930  0.0381\n",
            "     30       37.1930  0.0400\n",
            "     31       37.1930  0.0509\n",
            "     32       37.1930  0.0466\n",
            "     33       37.1930  0.0417\n",
            "     34       37.1930  0.0379\n",
            "     35       37.1930  0.0386\n",
            "     36       37.1930  0.0405\n",
            "     37       37.1930  0.0419\n",
            "     38       \u001b[36m30.8813\u001b[0m  0.0405\n",
            "     39        \u001b[36m0.5905\u001b[0m  0.0421\n",
            "     40        0.8529  0.0396\n",
            "     41        \u001b[36m0.5823\u001b[0m  0.0417\n",
            "     42        \u001b[36m0.5180\u001b[0m  0.0402\n",
            "     43        0.5196  0.0442\n",
            "     44        \u001b[36m0.4851\u001b[0m  0.0392\n",
            "     45        0.5080  0.0485\n",
            "     46        \u001b[36m0.4441\u001b[0m  0.0392\n",
            "     47        0.4481  0.0410\n",
            "     48        \u001b[36m0.4148\u001b[0m  0.0378\n",
            "     49        0.4156  0.0403\n",
            "     50        \u001b[36m0.4068\u001b[0m  0.0388\n",
            "     51        \u001b[36m0.3813\u001b[0m  0.0434\n",
            "     52        \u001b[36m0.3678\u001b[0m  0.0390\n",
            "     53        \u001b[36m0.3588\u001b[0m  0.0386\n",
            "     54        \u001b[36m0.3490\u001b[0m  0.0446\n",
            "     55        \u001b[36m0.3402\u001b[0m  0.0496\n",
            "     56        \u001b[36m0.3326\u001b[0m  0.0486\n",
            "     57        \u001b[36m0.3241\u001b[0m  0.0403\n",
            "     58        \u001b[36m0.3137\u001b[0m  0.0394\n",
            "     59        \u001b[36m0.3116\u001b[0m  0.0389\n",
            "     60        \u001b[36m0.3042\u001b[0m  0.0383\n",
            "     61        \u001b[36m0.2998\u001b[0m  0.0391\n",
            "     62        \u001b[36m0.2935\u001b[0m  0.0418\n",
            "     63        \u001b[36m0.2879\u001b[0m  0.0439\n",
            "     64        \u001b[36m0.2811\u001b[0m  0.0388\n",
            "     65        \u001b[36m0.2759\u001b[0m  0.0406\n",
            "     66        \u001b[36m0.2696\u001b[0m  0.0440\n",
            "     67        \u001b[36m0.2650\u001b[0m  0.0455\n",
            "     68        \u001b[36m0.2604\u001b[0m  0.0432\n",
            "     69        \u001b[36m0.2558\u001b[0m  0.0498\n",
            "     70        \u001b[36m0.2479\u001b[0m  0.0414\n",
            "     71        \u001b[36m0.2462\u001b[0m  0.0404\n",
            "     72        \u001b[36m0.2413\u001b[0m  0.0383\n",
            "     73        \u001b[36m0.2348\u001b[0m  0.0411\n",
            "     74        \u001b[36m0.2312\u001b[0m  0.0388\n",
            "     75        \u001b[36m0.2287\u001b[0m  0.0399\n",
            "     76        \u001b[36m0.2248\u001b[0m  0.0399\n",
            "     77        \u001b[36m0.2228\u001b[0m  0.0488\n",
            "     78        \u001b[36m0.2183\u001b[0m  0.0496\n",
            "     79        \u001b[36m0.2173\u001b[0m  0.0450\n",
            "     80        \u001b[36m0.2128\u001b[0m  0.0391\n",
            "     81        \u001b[36m0.2114\u001b[0m  0.0434\n",
            "     82        \u001b[36m0.2068\u001b[0m  0.0418\n",
            "     83        \u001b[36m0.2062\u001b[0m  0.0372\n",
            "     84        \u001b[36m0.2038\u001b[0m  0.0403\n",
            "     85        \u001b[36m0.2024\u001b[0m  0.0419\n",
            "     86        \u001b[36m0.2000\u001b[0m  0.0503\n",
            "     87        \u001b[36m0.1959\u001b[0m  0.0414\n",
            "     88        \u001b[36m0.1959\u001b[0m  0.0404\n",
            "     89        \u001b[36m0.1949\u001b[0m  0.0409\n",
            "     90        \u001b[36m0.1909\u001b[0m  0.0380\n",
            "     91        \u001b[36m0.1883\u001b[0m  0.0398\n",
            "     92        \u001b[36m0.1837\u001b[0m  0.0497\n",
            "     93        0.1950  0.0424\n",
            "     94        0.1945  0.0427\n",
            "     95        0.1903  0.0417\n",
            "     96        0.1860  0.0382\n",
            "     97        \u001b[36m0.1830\u001b[0m  0.0398\n",
            "     98        \u001b[36m0.1793\u001b[0m  0.0398\n",
            "     99        \u001b[36m0.1772\u001b[0m  0.0435\n",
            "    100        \u001b[36m0.1764\u001b[0m  0.0493\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0333\n",
            "      2       37.3239  0.0285\n",
            "      3       37.3239  0.0309\n",
            "      4       37.3239  0.0299\n",
            "      5       37.3239  0.0306\n",
            "      6       37.3239  0.0302\n",
            "      7       37.3239  0.0328\n",
            "      8       37.3239  0.0305\n",
            "      9       37.3239  0.0300\n",
            "     10       37.3239  0.0287\n",
            "     11       37.3239  0.0303\n",
            "     12       37.3239  0.0305\n",
            "     13       37.3239  0.0279\n",
            "     14       37.3239  0.0294\n",
            "     15       37.3239  0.0300\n",
            "     16       37.3239  0.0327\n",
            "     17       37.3239  0.0315\n",
            "     18       37.3239  0.0322\n",
            "     19       37.3239  0.0318\n",
            "     20       37.3239  0.0381\n",
            "     21       37.3239  0.0294\n",
            "     22       37.3239  0.0285\n",
            "     23       37.3239  0.0287\n",
            "     24       37.3239  0.0278\n",
            "     25       37.3239  0.0326\n",
            "     26       37.3239  0.0288\n",
            "     27       37.3239  0.0309\n",
            "     28       37.3239  0.0291\n",
            "     29       37.3239  0.0295\n",
            "     30       37.3239  0.0400\n",
            "     31       37.3239  0.0390\n",
            "     32       37.3239  0.0350\n",
            "     33       37.3239  0.0388\n",
            "     34       37.3239  0.0333\n",
            "     35       37.3239  0.0300\n",
            "     36       37.3239  0.0284\n",
            "     37       37.3239  0.0290\n",
            "     38       37.3239  0.0321\n",
            "     39       37.3239  0.0394\n",
            "     40       37.3239  0.0364\n",
            "     41       37.3239  0.0328\n",
            "     42       37.3239  0.0300\n",
            "     43       37.3239  0.0287\n",
            "     44       37.3239  0.0317\n",
            "     45       37.3239  0.0294\n",
            "     46       37.3239  0.0324\n",
            "     47       37.3239  0.0299\n",
            "     48       37.3239  0.0304\n",
            "     49       37.3239  0.0298\n",
            "     50       37.3239  0.0321\n",
            "     51       37.3239  0.0338\n",
            "     52       37.3239  0.0278\n",
            "     53       37.3239  0.0313\n",
            "     54       37.3239  0.0299\n",
            "     55       37.3239  0.0308\n",
            "     56       37.3239  0.0310\n",
            "     57       37.3239  0.0313\n",
            "     58       37.3239  0.0308\n",
            "     59       37.3239  0.0382\n",
            "     60       37.3239  0.0416\n",
            "     61       37.3239  0.0361\n",
            "     62       37.3239  0.0373\n",
            "     63       37.3239  0.0293\n",
            "     64       37.3239  0.0300\n",
            "     65       37.3239  0.0291\n",
            "     66       37.3239  0.0289\n",
            "     67       37.3239  0.0296\n",
            "     68       37.3239  0.0321\n",
            "     69       37.3239  0.0311\n",
            "     70       37.3239  0.0321\n",
            "     71       37.3239  0.0308\n",
            "     72       37.3239  0.0329\n",
            "     73       37.3239  0.0288\n",
            "     74       37.3239  0.0286\n",
            "     75       37.3239  0.0290\n",
            "     76       37.3239  0.0316\n",
            "     77       37.3239  0.0286\n",
            "     78       37.3239  0.0282\n",
            "     79       37.3239  0.0295\n",
            "     80       37.3239  0.0316\n",
            "     81       37.3239  0.0314\n",
            "     82       37.3239  0.0393\n",
            "     83       37.3239  0.0313\n",
            "     84       37.3239  0.0287\n",
            "     85       37.3239  0.0300\n",
            "     86       37.3239  0.0280\n",
            "     87       37.3239  0.0282\n",
            "     88       37.3239  0.0306\n",
            "     89       37.3239  0.0299\n",
            "     90       37.3239  0.0386\n",
            "     91       37.3239  0.0362\n",
            "     92       37.3239  0.0370\n",
            "     93       37.3239  0.0420\n",
            "     94       37.3239  0.0415\n",
            "     95       37.3239  0.0426\n",
            "     96       37.3239  0.0394\n",
            "     97       37.3239  0.0385\n",
            "     98       37.3239  0.0394\n",
            "     99       37.3239  0.0449\n",
            "    100       37.3239  0.0422\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0432\n",
            "      2       37.1930  0.0362\n",
            "      3       37.1930  0.0334\n",
            "      4       37.1930  0.0392\n",
            "      5       37.1930  0.0357\n",
            "      6       37.1930  0.0383\n",
            "      7       37.1930  0.0417\n",
            "      8       37.1930  0.0373\n",
            "      9       37.1930  0.0365\n",
            "     10       37.1930  0.0348\n",
            "     11       37.1930  0.0343\n",
            "     12       37.1930  0.0349\n",
            "     13       37.1930  0.0389\n",
            "     14       37.1930  0.0378\n",
            "     15       37.1930  0.0393\n",
            "     16       37.1930  0.0440\n",
            "     17       37.1930  0.0440\n",
            "     18       37.1930  0.0367\n",
            "     19       37.1930  0.0344\n",
            "     20       37.1930  0.0342\n",
            "     21       37.1930  0.0410\n",
            "     22       37.1930  0.0380\n",
            "     23       37.1930  0.0379\n",
            "     24       37.1930  0.0373\n",
            "     25       37.1930  0.0358\n",
            "     26       37.1930  0.0374\n",
            "     27       37.1930  0.0361\n",
            "     28       37.1930  0.0366\n",
            "     29       37.1930  0.0366\n",
            "     30       37.1930  0.0413\n",
            "     31       37.1930  0.0397\n",
            "     32       37.1930  0.0399\n",
            "     33       37.1930  0.0487\n",
            "     34       37.1930  0.0457\n",
            "     35       37.1930  0.0353\n",
            "     36       37.1930  0.0396\n",
            "     37       37.1930  0.0453\n",
            "     38       37.1930  0.0414\n",
            "     39       37.1930  0.0427\n",
            "     40       37.1930  0.0455\n",
            "     41       37.1930  0.0469\n",
            "     42       37.1930  0.0489\n",
            "     43       37.1930  0.0379\n",
            "     44       37.1930  0.0457\n",
            "     45       37.1930  0.0428\n",
            "     46       37.1930  0.0418\n",
            "     47       37.1930  0.0386\n",
            "     48       37.1930  0.0412\n",
            "     49       37.1930  0.0405\n",
            "     50       37.1930  0.0385\n",
            "     51       37.1930  0.0377\n",
            "     52       37.1930  0.0457\n",
            "     53       37.1930  0.0433\n",
            "     54       37.1930  0.0395\n",
            "     55       37.1930  0.0391\n",
            "     56       37.1930  0.0505\n",
            "     57       37.1930  0.0416\n",
            "     58       37.1930  0.0443\n",
            "     59       37.1930  0.0437\n",
            "     60       37.1930  0.0439\n",
            "     61       37.1930  0.0474\n",
            "     62       37.1930  0.0296\n",
            "     63       37.1930  0.0314\n",
            "     64       37.1930  0.0283\n",
            "     65       37.1930  0.0283\n",
            "     66       37.1930  0.0287\n",
            "     67       37.1930  0.0303\n",
            "     68       37.1930  0.0325\n",
            "     69       37.1930  0.0287\n",
            "     70       37.1930  0.0320\n",
            "     71       37.1930  0.0290\n",
            "     72       37.1930  0.0313\n",
            "     73       37.1930  0.0290\n",
            "     74       37.1930  0.0276\n",
            "     75       37.1930  0.0310\n",
            "     76       37.1930  0.0286\n",
            "     77       37.1930  0.0311\n",
            "     78       37.1930  0.0303\n",
            "     79       37.1930  0.0293\n",
            "     80       37.1930  0.0314\n",
            "     81       37.1930  0.0288\n",
            "     82       37.1930  0.0310\n",
            "     83       37.1930  0.0295\n",
            "     84       37.1930  0.0296\n",
            "     85       37.1930  0.0315\n",
            "     86       37.1930  0.0356\n",
            "     87       37.1930  0.0273\n",
            "     88       37.1930  0.0383\n",
            "     89       37.1930  0.0362\n",
            "     90       37.1930  0.0385\n",
            "     91       37.1930  0.0373\n",
            "     92       37.1930  0.0311\n",
            "     93       37.1930  0.0294\n",
            "     94       37.1930  0.0297\n",
            "     95       37.1930  0.0304\n",
            "     96       37.1930  0.0309\n",
            "     97       37.1930  0.0304\n",
            "     98       37.1930  0.0309\n",
            "     99       37.1930  0.0337\n",
            "    100       37.1930  0.0324\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0364\n",
            "      2       37.3239  0.0364\n",
            "      3       37.3239  0.0411\n",
            "      4       37.3239  0.0382\n",
            "      5       37.3239  0.0381\n",
            "      6       37.3239  0.0388\n",
            "      7       37.3239  0.0415\n",
            "      8       37.3239  0.0396\n",
            "      9       37.3239  0.0394\n",
            "     10       37.3239  0.0400\n",
            "     11       37.3239  0.0389\n",
            "     12       37.3239  0.0379\n",
            "     13       37.3239  0.0532\n",
            "     14       37.3239  0.0475\n",
            "     15       37.3239  0.0474\n",
            "     16       37.3239  0.0378\n",
            "     17       37.3239  0.0405\n",
            "     18       37.3239  0.0385\n",
            "     19       37.3239  0.0378\n",
            "     20       37.3239  0.0386\n",
            "     21       37.3239  0.0421\n",
            "     22       37.3239  0.0391\n",
            "     23       37.3239  0.0382\n",
            "     24       37.3239  0.0430\n",
            "     25       37.3239  0.0387\n",
            "     26       37.3239  0.0376\n",
            "     27       37.3239  0.0395\n",
            "     28       37.3239  0.0429\n",
            "     29       37.3239  0.0383\n",
            "     30       37.3239  0.0381\n",
            "     31       37.3239  0.0444\n",
            "     32       37.3239  0.0441\n",
            "     33       37.3239  0.0382\n",
            "     34       37.3239  0.0391\n",
            "     35       37.3239  0.0412\n",
            "     36       37.3239  0.0384\n",
            "     37       37.3239  0.0587\n",
            "     38       37.3239  0.0481\n",
            "     39       37.3239  0.0415\n",
            "     40       37.3239  0.0402\n",
            "     41       37.3239  0.0396\n",
            "     42       37.3239  0.0381\n",
            "     43       37.3239  0.0374\n",
            "     44       37.3239  0.0397\n",
            "     45       37.3239  0.0387\n",
            "     46       37.3239  0.0371\n",
            "     47       37.3239  0.0405\n",
            "     48       37.3239  0.0424\n",
            "     49       37.3239  0.0383\n",
            "     50       37.3239  0.0378\n",
            "     51       37.3239  0.0398\n",
            "     52       37.3239  0.0394\n",
            "     53       37.3239  0.0386\n",
            "     54       37.3239  0.0383\n",
            "     55       37.3239  0.0420\n",
            "     56       37.3239  0.0383\n",
            "     57       37.3239  0.0382\n",
            "     58       37.3239  0.0384\n",
            "     59       37.3239  0.0392\n",
            "     60       37.3239  0.0392\n",
            "     61       37.3239  0.0477\n",
            "     62       37.3239  0.0525\n",
            "     63       37.3239  0.0506\n",
            "     64       37.3239  0.0389\n",
            "     65       37.3239  0.0386\n",
            "     66       37.3239  0.0433\n",
            "     67       37.3239  0.0389\n",
            "     68       37.3239  0.0396\n",
            "     69       37.3239  0.0467\n",
            "     70       37.3239  0.0410\n",
            "     71       37.3239  0.0407\n",
            "     72       37.3239  0.0393\n",
            "     73       37.3239  0.0435\n",
            "     74       37.3239  0.0406\n",
            "     75       37.3239  0.0428\n",
            "     76       37.3239  0.0435\n",
            "     77       37.3239  0.0393\n",
            "     78       37.3239  0.0400\n",
            "     79       37.3239  0.0387\n",
            "     80       37.3239  0.0401\n",
            "     81       37.3239  0.0393\n",
            "     82       37.3239  0.0423\n",
            "     83       37.3239  0.0399\n",
            "     84       37.3239  0.0489\n",
            "     85       37.3239  0.0564\n",
            "     86       37.3239  0.0392\n",
            "     87       37.3239  0.0385\n",
            "     88       37.3239  0.0385\n",
            "     89       37.3239  0.0405\n",
            "     90       37.3239  0.0408\n",
            "     91       37.3239  0.0397\n",
            "     92       37.3239  0.0413\n",
            "     93       37.3239  0.0397\n",
            "     94       37.3239  0.0418\n",
            "     95       37.3239  0.0393\n",
            "     96       37.3239  0.0416\n",
            "     97       37.3239  0.0393\n",
            "     98       37.3239  0.0409\n",
            "     99       37.3239  0.0392\n",
            "    100       37.3239  0.0411\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0383\n",
            "      2       37.1930  0.0396\n",
            "      3       37.1930  0.0412\n",
            "      4       37.1930  0.0387\n",
            "      5       37.1930  0.0432\n",
            "      6       37.1930  0.0410\n",
            "      7       37.1930  0.0509\n",
            "      8       37.1930  0.0499\n",
            "      9       37.1930  0.0523\n",
            "     10       37.1930  0.0409\n",
            "     11       37.1930  0.0404\n",
            "     12       37.1930  0.0389\n",
            "     13       37.1930  0.0412\n",
            "     14       37.1930  0.0378\n",
            "     15       37.1930  0.0388\n",
            "     16       37.1930  0.0406\n",
            "     17       37.1930  0.0393\n",
            "     18       37.1930  0.0410\n",
            "     19       37.1930  0.0395\n",
            "     20       37.1930  0.0434\n",
            "     21       37.1930  0.0384\n",
            "     22       37.1930  0.0410\n",
            "     23       37.1930  0.0411\n",
            "     24       37.1930  0.0379\n",
            "     25       37.1930  0.0373\n",
            "     26       37.1930  0.0422\n",
            "     27       37.1930  0.0372\n",
            "     28       37.1930  0.0376\n",
            "     29       37.1930  0.0393\n",
            "     30       37.1930  0.0433\n",
            "     31       37.1930  0.0490\n",
            "     32       37.1930  0.0476\n",
            "     33       37.1930  0.0526\n",
            "     34       37.1930  0.0386\n",
            "     35       37.1930  0.0377\n",
            "     36       37.1930  0.0381\n",
            "     37       37.1930  0.0392\n",
            "     38       37.1930  0.0377\n",
            "     39       37.1930  0.0401\n",
            "     40       37.1930  0.0427\n",
            "     41       37.1930  0.0411\n",
            "     42       37.1930  0.0394\n",
            "     43       37.1930  0.0417\n",
            "     44       37.1930  0.0444\n",
            "     45       \u001b[36m31.4244\u001b[0m  0.0415\n",
            "     46        \u001b[36m1.8086\u001b[0m  0.0387\n",
            "     47        \u001b[36m0.6406\u001b[0m  0.0399\n",
            "     48        \u001b[36m0.6065\u001b[0m  0.0387\n",
            "     49        \u001b[36m0.5953\u001b[0m  0.0381\n",
            "     50        \u001b[36m0.5844\u001b[0m  0.0425\n",
            "     51        \u001b[36m0.5728\u001b[0m  0.0455\n",
            "     52        \u001b[36m0.5621\u001b[0m  0.0375\n",
            "     53        \u001b[36m0.5542\u001b[0m  0.0424\n",
            "     54        \u001b[36m0.5450\u001b[0m  0.0495\n",
            "     55        \u001b[36m0.5362\u001b[0m  0.0471\n",
            "     56        \u001b[36m0.5281\u001b[0m  0.0412\n",
            "     57        \u001b[36m0.5187\u001b[0m  0.0512\n",
            "     58        \u001b[36m0.5088\u001b[0m  0.0397\n",
            "     59        \u001b[36m0.4980\u001b[0m  0.0405\n",
            "     60        \u001b[36m0.4896\u001b[0m  0.0420\n",
            "     61        \u001b[36m0.4809\u001b[0m  0.0386\n",
            "     62        \u001b[36m0.4516\u001b[0m  0.0391\n",
            "     63        0.5173  0.0414\n",
            "     64        \u001b[36m0.4348\u001b[0m  0.0433\n",
            "     65        0.4555  0.0405\n",
            "     66        \u001b[36m0.4274\u001b[0m  0.0408\n",
            "     67        \u001b[36m0.4245\u001b[0m  0.0398\n",
            "     68        0.4259  0.0395\n",
            "     69        \u001b[36m0.3958\u001b[0m  0.0382\n",
            "     70        0.4459  0.0389\n",
            "     71        \u001b[36m0.3704\u001b[0m  0.0450\n",
            "     72        0.4087  0.0393\n",
            "     73        0.3831  0.0406\n",
            "     74        0.3780  0.0387\n",
            "     75        \u001b[36m0.3702\u001b[0m  0.0389\n",
            "     76        \u001b[36m0.3645\u001b[0m  0.0391\n",
            "     77        \u001b[36m0.3547\u001b[0m  0.0531\n",
            "     78        \u001b[36m0.3495\u001b[0m  0.0497\n",
            "     79        \u001b[36m0.3433\u001b[0m  0.0387\n",
            "     80        \u001b[36m0.3380\u001b[0m  0.0418\n",
            "     81        \u001b[36m0.3314\u001b[0m  0.0485\n",
            "     82        \u001b[36m0.3251\u001b[0m  0.0380\n",
            "     83        \u001b[36m0.3199\u001b[0m  0.0387\n",
            "     84        \u001b[36m0.3184\u001b[0m  0.0391\n",
            "     85        0.3189  0.0394\n",
            "     86        \u001b[36m0.3122\u001b[0m  0.0394\n",
            "     87        \u001b[36m0.3036\u001b[0m  0.0410\n",
            "     88        \u001b[36m0.2983\u001b[0m  0.0502\n",
            "     89        \u001b[36m0.2948\u001b[0m  0.0374\n",
            "     90        \u001b[36m0.2875\u001b[0m  0.0416\n",
            "     91        \u001b[36m0.2844\u001b[0m  0.0394\n",
            "     92        \u001b[36m0.2836\u001b[0m  0.0427\n",
            "     93        \u001b[36m0.2788\u001b[0m  0.0406\n",
            "     94        \u001b[36m0.2780\u001b[0m  0.0418\n",
            "     95        \u001b[36m0.2724\u001b[0m  0.0376\n",
            "     96        \u001b[36m0.2666\u001b[0m  0.0404\n",
            "     97        \u001b[36m0.2614\u001b[0m  0.0449\n",
            "     98        \u001b[36m0.2610\u001b[0m  0.0404\n",
            "     99        \u001b[36m0.2561\u001b[0m  0.0412\n",
            "    100        0.2572  0.0535\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0309\n",
            "      2       37.3239  0.0278\n",
            "      3       37.3239  0.0305\n",
            "      4       37.3239  0.0437\n",
            "      5       37.3239  0.0539\n",
            "      6       37.3239  0.0425\n",
            "      7       37.3239  0.0409\n",
            "      8       37.3239  0.0390\n",
            "      9       37.3239  0.0378\n",
            "     10       37.3239  0.0451\n",
            "     11       37.3239  0.0390\n",
            "     12       37.3239  0.0397\n",
            "     13       37.3239  0.0438\n",
            "     14       37.3239  0.0364\n",
            "     15       37.3239  0.0368\n",
            "     16       37.3239  0.0391\n",
            "     17       37.3239  0.0392\n",
            "     18       37.3239  0.0453\n",
            "     19       37.3239  0.0462\n",
            "     20       37.3239  0.0386\n",
            "     21       37.3239  0.0367\n",
            "     22       37.3239  0.0527\n",
            "     23       37.3239  0.0468\n",
            "     24       37.3239  0.0476\n",
            "     25       37.3239  0.0418\n",
            "     26       37.3239  0.0406\n",
            "     27       37.3239  0.0389\n",
            "     28       37.3239  0.0419\n",
            "     29       37.3239  0.0363\n",
            "     30       37.3239  0.0358\n",
            "     31       37.3239  0.0378\n",
            "     32       37.3239  0.0380\n",
            "     33       37.3239  0.0375\n",
            "     34       37.3239  0.0379\n",
            "     35       37.3239  0.0357\n",
            "     36       37.3239  0.0402\n",
            "     37       37.3239  0.0358\n",
            "     38       37.3239  0.0358\n",
            "     39       37.3239  0.0379\n",
            "     40       37.3239  0.0399\n",
            "     41       37.3239  0.0461\n",
            "     42       37.3239  0.0444\n",
            "     43       37.3239  0.0425\n",
            "     44       37.3239  0.0448\n",
            "     45       37.3239  0.0580\n",
            "     46       37.3239  0.0501\n",
            "     47       37.3239  0.0439\n",
            "     48       37.3239  0.0430\n",
            "     49       37.3239  0.0479\n",
            "     50       37.3239  0.0492\n",
            "     51       37.3239  0.0445\n",
            "     52       37.3239  0.0484\n",
            "     53       37.3239  0.0442\n",
            "     54       37.3239  0.0431\n",
            "     55       37.3239  0.0453\n",
            "     56       37.3239  0.0409\n",
            "     57       37.3239  0.0421\n",
            "     58       37.3239  0.0428\n",
            "     59       37.3239  0.0418\n",
            "     60       37.3239  0.0390\n",
            "     61       37.3239  0.0397\n",
            "     62       37.3239  0.0411\n",
            "     63       37.3239  0.0398\n",
            "     64       37.3239  0.0382\n",
            "     65       37.3239  0.0390\n",
            "     66       37.3239  0.0460\n",
            "     67       37.3239  0.0448\n",
            "     68       37.3239  0.0419\n",
            "     69       37.3239  0.0427\n",
            "     70       37.3239  0.0474\n",
            "     71       37.3239  0.0421\n",
            "     72       37.3239  0.0301\n",
            "     73       37.3239  0.0288\n",
            "     74       37.3239  0.0296\n",
            "     75       37.3239  0.0374\n",
            "     76       37.3239  0.0299\n",
            "     77       37.3239  0.0307\n",
            "     78       37.3239  0.0305\n",
            "     79       37.3239  0.0331\n",
            "     80       37.3239  0.0333\n",
            "     81       37.3239  0.0317\n",
            "     82       37.3239  0.0302\n",
            "     83       37.3239  0.0278\n",
            "     84       37.3239  0.0282\n",
            "     85       37.3239  0.0292\n",
            "     86       37.3239  0.0281\n",
            "     87       37.3239  0.0314\n",
            "     88       37.3239  0.0286\n",
            "     89       37.3239  0.0310\n",
            "     90       37.3239  0.0309\n",
            "     91       37.3239  0.0288\n",
            "     92       37.3239  0.0297\n",
            "     93       37.3239  0.0295\n",
            "     94       37.3239  0.0377\n",
            "     95       37.3239  0.0378\n",
            "     96       37.3239  0.0379\n",
            "     97       37.3239  0.0372\n",
            "     98       37.3239  0.0285\n",
            "     99       37.3239  0.0298\n",
            "    100       37.3239  0.0288\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0267\n",
            "      2       37.1930  0.0293\n",
            "      3       37.1930  0.0283\n",
            "      4       37.1930  0.0279\n",
            "      5       37.1930  0.0358\n",
            "      6       37.1930  0.0392\n",
            "      7       37.1930  0.0300\n",
            "      8       37.1930  0.0301\n",
            "      9       37.1930  0.0304\n",
            "     10       37.1930  0.0284\n",
            "     11       37.1930  0.0289\n",
            "     12       37.1930  0.0336\n",
            "     13       37.1930  0.0293\n",
            "     14       37.1930  0.0297\n",
            "     15       37.1930  0.0324\n",
            "     16       37.1930  0.0313\n",
            "     17       37.1930  0.0316\n",
            "     18       37.1930  0.0301\n",
            "     19       37.1930  0.0282\n",
            "     20       37.1930  0.0307\n",
            "     21       37.1930  0.0309\n",
            "     22       37.1930  0.0289\n",
            "     23       37.1930  0.0310\n",
            "     24       37.1930  0.0381\n",
            "     25       37.1930  0.0399\n",
            "     26       37.1930  0.0375\n",
            "     27       37.1930  0.0356\n",
            "     28       37.1930  0.0365\n",
            "     29       37.1930  0.0341\n",
            "     30       37.1930  0.0326\n",
            "     31       37.1930  0.0338\n",
            "     32       37.1930  0.0332\n",
            "     33       37.1930  0.0310\n",
            "     34       37.1930  0.0314\n",
            "     35       37.1930  0.0325\n",
            "     36       37.1930  0.0425\n",
            "     37       37.1930  0.0308\n",
            "     38       37.1930  0.0319\n",
            "     39       37.1930  0.0312\n",
            "     40       37.1930  0.0298\n",
            "     41       37.1930  0.0370\n",
            "     42       37.1930  0.0298\n",
            "     43       37.1930  0.0321\n",
            "     44       37.1930  0.0345\n",
            "     45       37.1930  0.0310\n",
            "     46       37.1930  0.0302\n",
            "     47       37.1930  0.0309\n",
            "     48       37.1930  0.0301\n",
            "     49       37.1930  0.0328\n",
            "     50       37.1930  0.0290\n",
            "     51       37.1930  0.0321\n",
            "     52       37.1930  0.0306\n",
            "     53       37.1930  0.0361\n",
            "     54       37.1930  0.0384\n",
            "     55       37.1930  0.0366\n",
            "     56       37.1930  0.0303\n",
            "     57       37.1930  0.0345\n",
            "     58       37.1930  0.0283\n",
            "     59       37.1930  0.0300\n",
            "     60       37.1930  0.0307\n",
            "     61       37.1930  0.0296\n",
            "     62       37.1930  0.0299\n",
            "     63       37.1930  0.0310\n",
            "     64       37.1930  0.0304\n",
            "     65       37.1930  0.0307\n",
            "     66       37.1930  0.0495\n",
            "     67       37.1930  0.0315\n",
            "     68       37.1930  0.0324\n",
            "     69       37.1930  0.0299\n",
            "     70       37.1930  0.0320\n",
            "     71       37.1930  0.0331\n",
            "     72       37.1930  0.0291\n",
            "     73       37.1930  0.0298\n",
            "     74       37.1930  0.0330\n",
            "     75       37.1930  0.0317\n",
            "     76       37.1930  0.0292\n",
            "     77       37.1930  0.0284\n",
            "     78       37.1930  0.0295\n",
            "     79       37.1930  0.0305\n",
            "     80       37.1930  0.0289\n",
            "     81       37.1930  0.0296\n",
            "     82       37.1930  0.0355\n",
            "     83       37.1930  0.0376\n",
            "     84       37.1930  0.0375\n",
            "     85       37.1930  0.0395\n",
            "     86       37.1930  0.0325\n",
            "     87       37.1930  0.0295\n",
            "     88       37.1930  0.0292\n",
            "     89       37.1930  0.0321\n",
            "     90       37.1930  0.0289\n",
            "     91       37.1930  0.0305\n",
            "     92       37.1930  0.0314\n",
            "     93       37.1930  0.0376\n",
            "     94       37.1930  0.0276\n",
            "     95       37.1930  0.0304\n",
            "     96       37.1930  0.0287\n",
            "     97       37.1930  0.0392\n",
            "     98       37.1930  0.0316\n",
            "     99       37.1930  0.0298\n",
            "    100       37.1930  0.0281\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m38.6253\u001b[0m  0.0393\n",
            "      2       \u001b[36m38.1440\u001b[0m  0.0386\n",
            "      3       \u001b[36m37.6783\u001b[0m  0.0379\n",
            "      4       \u001b[36m37.6782\u001b[0m  0.0447\n",
            "      5       \u001b[36m37.3261\u001b[0m  0.0404\n",
            "      6       \u001b[36m37.2814\u001b[0m  0.0415\n",
            "      7       \u001b[36m37.2647\u001b[0m  0.0428\n",
            "      8       \u001b[36m37.2486\u001b[0m  0.0457\n",
            "      9       \u001b[36m37.2331\u001b[0m  0.0477\n",
            "     10       \u001b[36m37.2183\u001b[0m  0.0484\n",
            "     11       \u001b[36m37.2040\u001b[0m  0.0440\n",
            "     12       \u001b[36m37.1904\u001b[0m  0.0388\n",
            "     13       \u001b[36m37.1774\u001b[0m  0.0390\n",
            "     14       \u001b[36m37.1650\u001b[0m  0.0450\n",
            "     15       \u001b[36m37.1531\u001b[0m  0.0392\n",
            "     16       \u001b[36m37.1419\u001b[0m  0.0401\n",
            "     17       \u001b[36m37.1312\u001b[0m  0.0403\n",
            "     18       37.2576  0.0387\n",
            "     19       \u001b[36m37.1112\u001b[0m  0.0410\n",
            "     20       \u001b[36m37.0945\u001b[0m  0.0397\n",
            "     21       \u001b[36m36.9736\u001b[0m  0.0464\n",
            "     22       \u001b[36m36.9736\u001b[0m  0.0443\n",
            "     23       \u001b[36m36.9736\u001b[0m  0.0396\n",
            "     24       \u001b[36m36.9735\u001b[0m  0.0393\n",
            "     25       \u001b[36m36.9735\u001b[0m  0.0403\n",
            "     26       \u001b[36m36.9735\u001b[0m  0.0393\n",
            "     27       \u001b[36m36.9735\u001b[0m  0.0384\n",
            "     28       \u001b[36m36.9735\u001b[0m  0.0373\n",
            "     29       \u001b[36m36.9734\u001b[0m  0.0402\n",
            "     30       \u001b[36m36.9734\u001b[0m  0.0368\n",
            "     31       \u001b[36m36.9734\u001b[0m  0.0395\n",
            "     32       \u001b[36m36.9734\u001b[0m  0.0420\n",
            "     33       \u001b[36m36.9734\u001b[0m  0.0471\n",
            "     34       \u001b[36m36.9733\u001b[0m  0.0467\n",
            "     35       \u001b[36m36.9733\u001b[0m  0.0374\n",
            "     36       \u001b[36m36.9733\u001b[0m  0.0376\n",
            "     37       \u001b[36m36.9733\u001b[0m  0.0403\n",
            "     38       \u001b[36m36.9733\u001b[0m  0.0405\n",
            "     39       \u001b[36m36.9732\u001b[0m  0.0377\n",
            "     40       \u001b[36m36.9732\u001b[0m  0.0383\n",
            "     41       \u001b[36m36.9732\u001b[0m  0.0361\n",
            "     42       \u001b[36m36.9732\u001b[0m  0.0368\n",
            "     43       \u001b[36m36.9732\u001b[0m  0.0383\n",
            "     44       \u001b[36m36.9732\u001b[0m  0.0392\n",
            "     45       \u001b[36m36.9731\u001b[0m  0.0374\n",
            "     46       \u001b[36m36.6504\u001b[0m  0.0527\n",
            "     47       37.3239  0.0406\n",
            "     48       37.3239  0.0391\n",
            "     49       37.3239  0.0384\n",
            "     50       37.3239  0.0444\n",
            "     51       37.3239  0.0442\n",
            "     52       37.3239  0.0381\n",
            "     53       37.3239  0.0404\n",
            "     54       37.3239  0.0376\n",
            "     55       37.3239  0.0387\n",
            "     56       37.3239  0.0468\n",
            "     57       37.3239  0.0487\n",
            "     58       37.3239  0.0502\n",
            "     59       37.3239  0.0405\n",
            "     60       37.3239  0.0399\n",
            "     61       37.3239  0.0387\n",
            "     62       37.3239  0.0389\n",
            "     63       37.3239  0.0386\n",
            "     64       37.3239  0.0372\n",
            "     65       37.3239  0.0391\n",
            "     66       37.3239  0.0386\n",
            "     67       37.3239  0.0413\n",
            "     68       37.3239  0.0428\n",
            "     69       37.3239  0.0400\n",
            "     70       37.3239  0.0501\n",
            "     71       37.3239  0.0402\n",
            "     72       37.3239  0.0380\n",
            "     73       37.3239  0.0378\n",
            "     74       37.3239  0.0421\n",
            "     75       37.3239  0.0371\n",
            "     76       37.3239  0.0364\n",
            "     77       37.3239  0.0386\n",
            "     78       37.3239  0.0385\n",
            "     79       37.3239  0.0379\n",
            "     80       37.3239  0.0509\n",
            "     81       37.3239  0.0492\n",
            "     82       37.3239  0.0426\n",
            "     83       37.3239  0.0377\n",
            "     84       37.3239  0.0377\n",
            "     85       37.3239  0.0381\n",
            "     86       37.3239  0.0374\n",
            "     87       37.3239  0.0383\n",
            "     88       37.3239  0.0455\n",
            "     89       37.3239  0.0378\n",
            "     90       37.3239  0.0395\n",
            "     91       37.3239  0.0388\n",
            "     92       37.3239  0.0383\n",
            "     93       37.3239  0.0376\n",
            "     94       37.3239  0.0422\n",
            "     95       37.3239  0.0473\n",
            "     96       37.3239  0.0375\n",
            "     97       37.3239  0.0399\n",
            "     98       37.3239  0.0387\n",
            "     99       37.3239  0.0390\n",
            "    100       37.3239  0.0385\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m48.9033\u001b[0m  0.0374\n",
            "      2       49.4431  0.0369\n",
            "      3       49.1228  0.0378\n",
            "      4       49.1228  0.0523\n",
            "      5       \u001b[36m48.7719\u001b[0m  0.0473\n",
            "      6       \u001b[36m48.4211\u001b[0m  0.0418\n",
            "      7       48.4211  0.0415\n",
            "      8       \u001b[36m48.0702\u001b[0m  0.0402\n",
            "      9       48.0702  0.0363\n",
            "     10       \u001b[36m47.7193\u001b[0m  0.0375\n",
            "     11       47.7193  0.0383\n",
            "     12       47.7193  0.0371\n",
            "     13       47.7193  0.0366\n",
            "     14       47.7193  0.0415\n",
            "     15       47.7193  0.0377\n",
            "     16       \u001b[36m47.6392\u001b[0m  0.0396\n",
            "     17       \u001b[36m47.5212\u001b[0m  0.0416\n",
            "     18       47.5707  0.0397\n",
            "     19       47.7201  0.0498\n",
            "     20       47.7193  0.0391\n",
            "     21       47.7193  0.0370\n",
            "     22       47.7193  0.0372\n",
            "     23       47.7193  0.0411\n",
            "     24       47.7193  0.0382\n",
            "     25       47.7193  0.0381\n",
            "     26       47.7193  0.0385\n",
            "     27       47.7193  0.0371\n",
            "     28       47.7193  0.0494\n",
            "     29       47.7193  0.0495\n",
            "     30       47.7193  0.0375\n",
            "     31       47.7193  0.0407\n",
            "     32       47.7193  0.0377\n",
            "     33       47.7193  0.0376\n",
            "     34       47.7193  0.0375\n",
            "     35       47.7193  0.0572\n",
            "     36       47.7193  0.0549\n",
            "     37       47.7193  0.0539\n",
            "     38       47.7193  0.0532\n",
            "     39       47.7193  0.0648\n",
            "     40       47.7193  0.0529\n",
            "     41       47.7193  0.0607\n",
            "     42       47.7193  0.0477\n",
            "     43       47.7193  0.0505\n",
            "     44       47.7193  0.0530\n",
            "     45       47.7193  0.0497\n",
            "     46       47.7193  0.0481\n",
            "     47       47.7193  0.0663\n",
            "     48       47.7193  0.0615\n",
            "     49       47.7193  0.0521\n",
            "     50       47.7193  0.0470\n",
            "     51       47.7193  0.0516\n",
            "     52       47.7193  0.0489\n",
            "     53       47.7193  0.0495\n",
            "     54       47.7193  0.0502\n",
            "     55       47.7193  0.0488\n",
            "     56       47.7193  0.0498\n",
            "     57       47.7193  0.0464\n",
            "     58       47.7193  0.0492\n",
            "     59       47.7193  0.0490\n",
            "     60       47.7193  0.0583\n",
            "     61       47.7193  0.0610\n",
            "     62       47.7193  0.0514\n",
            "     63       47.7193  0.0554\n",
            "     64       47.7193  0.0552\n",
            "     65       47.7193  0.0608\n",
            "     66       47.7193  0.0581\n",
            "     67       47.7193  0.0509\n",
            "     68       47.7193  0.0530\n",
            "     69       47.7193  0.0556\n",
            "     70       47.7193  0.0587\n",
            "     71       47.7193  0.0543\n",
            "     72       47.7193  0.0674\n",
            "     73       47.7193  0.0601\n",
            "     74       47.7193  0.0520\n",
            "     75       47.7193  0.0571\n",
            "     76       47.7193  0.0521\n",
            "     77       47.7193  0.0559\n",
            "     78       47.7193  0.0653\n",
            "     79       47.7193  0.0524\n",
            "     80       47.7193  0.0530\n",
            "     81       47.7193  0.0525\n",
            "     82       47.7193  0.0656\n",
            "     83       47.7193  0.0555\n",
            "     84       47.7193  0.0552\n",
            "     85       47.7193  0.0551\n",
            "     86       47.7193  0.0578\n",
            "     87       47.7193  0.0427\n",
            "     88       47.7193  0.0404\n",
            "     89       47.7193  0.0377\n",
            "     90       47.7193  0.0402\n",
            "     91       47.7193  0.0438\n",
            "     92       47.7193  0.0407\n",
            "     93       47.7193  0.0395\n",
            "     94       47.7193  0.0403\n",
            "     95       47.7193  0.0374\n",
            "     96       47.7193  0.0405\n",
            "     97       47.7193  0.0448\n",
            "     98       47.7193  0.0478\n",
            "     99       47.7193  0.0543\n",
            "    100       47.7193  0.0460\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m35.6394\u001b[0m  0.0261\n",
            "      2       37.3239  0.0298\n",
            "      3       37.3239  0.0384\n",
            "      4       37.3239  0.0341\n",
            "      5       37.3239  0.0370\n",
            "      6       37.3239  0.0304\n",
            "      7       37.3239  0.0290\n",
            "      8       37.3239  0.0293\n",
            "      9       37.3239  0.0305\n",
            "     10       37.3239  0.0276\n",
            "     11       37.3239  0.0302\n",
            "     12       37.3239  0.0295\n",
            "     13       37.3239  0.0297\n",
            "     14       37.3239  0.0304\n",
            "     15       37.3239  0.0316\n",
            "     16       37.3239  0.0306\n",
            "     17       37.3239  0.0308\n",
            "     18       37.3239  0.0287\n",
            "     19       37.3239  0.0334\n",
            "     20       37.3239  0.0298\n",
            "     21       37.3239  0.0299\n",
            "     22       37.3239  0.0312\n",
            "     23       37.3239  0.0306\n",
            "     24       37.3239  0.0299\n",
            "     25       37.3239  0.0373\n",
            "     26       37.3239  0.0289\n",
            "     27       37.3239  0.0292\n",
            "     28       37.3239  0.0289\n",
            "     29       37.3239  0.0307\n",
            "     30       37.3239  0.0365\n",
            "     31       37.3239  0.0294\n",
            "     32       37.3239  0.0287\n",
            "     33       37.3239  0.0335\n",
            "     34       37.3239  0.0390\n",
            "     35       37.3239  0.0374\n",
            "     36       37.3239  0.0343\n",
            "     37       37.3239  0.0354\n",
            "     38       37.3239  0.0293\n",
            "     39       37.3239  0.0294\n",
            "     40       37.3239  0.0295\n",
            "     41       37.3239  0.0288\n",
            "     42       37.3239  0.0305\n",
            "     43       37.3239  0.0293\n",
            "     44       37.3239  0.0322\n",
            "     45       37.3239  0.0317\n",
            "     46       37.3239  0.0291\n",
            "     47       37.3239  0.0291\n",
            "     48       37.3239  0.0304\n",
            "     49       37.3239  0.0285\n",
            "     50       37.3239  0.0300\n",
            "     51       37.3239  0.0295\n",
            "     52       37.3239  0.0290\n",
            "     53       37.3239  0.0351\n",
            "     54       37.3239  0.0310\n",
            "     55       37.3239  0.0305\n",
            "     56       37.3239  0.0304\n",
            "     57       37.3239  0.0289\n",
            "     58       37.3239  0.0288\n",
            "     59       37.3239  0.0311\n",
            "     60       37.3239  0.0293\n",
            "     61       37.3239  0.0401\n",
            "     62       37.3239  0.0322\n",
            "     63       37.3239  0.0296\n",
            "     64       37.3239  0.0382\n",
            "     65       37.3239  0.0358\n",
            "     66       37.3239  0.0387\n",
            "     67       37.3239  0.0381\n",
            "     68       37.3239  0.0297\n",
            "     69       37.3239  0.0293\n",
            "     70       37.3239  0.0323\n",
            "     71       37.3239  0.0306\n",
            "     72       37.3239  0.0333\n",
            "     73       37.3239  0.0304\n",
            "     74       37.3239  0.0309\n",
            "     75       37.3239  0.0335\n",
            "     76       37.3239  0.0317\n",
            "     77       37.3239  0.0310\n",
            "     78       37.3239  0.0323\n",
            "     79       37.3239  0.0298\n",
            "     80       37.3239  0.0317\n",
            "     81       37.3239  0.0322\n",
            "     82       37.3239  0.0296\n",
            "     83       37.3239  0.0329\n",
            "     84       37.3239  0.0337\n",
            "     85       37.3239  0.0308\n",
            "     86       37.3239  0.0323\n",
            "     87       37.3239  0.0299\n",
            "     88       37.3239  0.0327\n",
            "     89       37.3239  0.0332\n",
            "     90       37.3239  0.0304\n",
            "     91       37.3239  0.0380\n",
            "     92       37.3239  0.0317\n",
            "     93       37.3239  0.0462\n",
            "     94       37.3239  0.0390\n",
            "     95       37.3239  0.0371\n",
            "     96       37.3239  0.0361\n",
            "     97       37.3239  0.0346\n",
            "     98       37.3239  0.0312\n",
            "     99       37.3239  0.0301\n",
            "    100       37.3239  0.0333\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m49.4737\u001b[0m  0.0283\n",
            "      2       49.4737  0.0319\n",
            "      3       49.4737  0.0295\n",
            "      4       49.4737  0.0296\n",
            "      5       49.4737  0.0346\n",
            "      6       49.4737  0.0310\n",
            "      7       49.4737  0.0297\n",
            "      8       49.4737  0.0315\n",
            "      9       49.4737  0.0300\n",
            "     10       49.4737  0.0295\n",
            "     11       49.4737  0.0328\n",
            "     12       49.4737  0.0305\n",
            "     13       49.4737  0.0306\n",
            "     14       49.4737  0.0287\n",
            "     15       49.4737  0.0328\n",
            "     16       49.4737  0.0318\n",
            "     17       49.4737  0.0327\n",
            "     18       49.4737  0.0323\n",
            "     19       49.4737  0.0305\n",
            "     20       49.4737  0.0301\n",
            "     21       49.4737  0.0380\n",
            "     22       49.4737  0.0361\n",
            "     23       49.4737  0.0363\n",
            "     24       49.4737  0.0368\n",
            "     25       49.4737  0.0317\n",
            "     26       49.4737  0.0303\n",
            "     27       49.4737  0.0296\n",
            "     28       49.4737  0.0304\n",
            "     29       49.4737  0.0311\n",
            "     30       49.4737  0.0305\n",
            "     31       49.4737  0.0303\n",
            "     32       49.4737  0.0299\n",
            "     33       49.4737  0.0292\n",
            "     34       49.4737  0.0282\n",
            "     35       49.4737  0.0334\n",
            "     36       49.4737  0.0293\n",
            "     37       49.4737  0.0302\n",
            "     38       49.4737  0.0284\n",
            "     39       49.4737  0.0281\n",
            "     40       49.4737  0.0298\n",
            "     41       49.4737  0.0288\n",
            "     42       49.4737  0.0351\n",
            "     43       49.4737  0.0317\n",
            "     44       49.4737  0.0333\n",
            "     45       49.4737  0.0333\n",
            "     46       49.4737  0.0341\n",
            "     47       49.4737  0.0339\n",
            "     48       49.4737  0.0288\n",
            "     49       49.4737  0.0321\n",
            "     50       49.4737  0.0288\n",
            "     51       49.4737  0.0317\n",
            "     52       49.4737  0.0428\n",
            "     53       49.4737  0.0351\n",
            "     54       49.4737  0.0382\n",
            "     55       49.4737  0.0356\n",
            "     56       49.4737  0.0332\n",
            "     57       49.4737  0.0291\n",
            "     58       49.4737  0.0288\n",
            "     59       49.4737  0.0293\n",
            "     60       49.4737  0.0283\n",
            "     61       49.4737  0.0288\n",
            "     62       49.4737  0.0352\n",
            "     63       49.4737  0.0298\n",
            "     64       49.4737  0.0289\n",
            "     65       49.4737  0.0303\n",
            "     66       49.4737  0.0295\n",
            "     67       49.4737  0.0294\n",
            "     68       49.4737  0.0307\n",
            "     69       49.4737  0.0309\n",
            "     70       49.4737  0.0314\n",
            "     71       49.4737  0.0325\n",
            "     72       49.4737  0.0323\n",
            "     73       49.4737  0.0306\n",
            "     74       49.4737  0.0302\n",
            "     75       49.4737  0.0276\n",
            "     76       49.4737  0.0285\n",
            "     77       49.4737  0.0286\n",
            "     78       49.4737  0.0288\n",
            "     79       49.4737  0.0307\n",
            "     80       49.4737  0.0297\n",
            "     81       49.4737  0.0280\n",
            "     82       49.4737  0.0303\n",
            "     83       49.4737  0.0345\n",
            "     84       49.4737  0.0394\n",
            "     85       49.4737  0.0366\n",
            "     86       49.4737  0.0359\n",
            "     87       49.4737  0.0323\n",
            "     88       49.4737  0.0350\n",
            "     89       49.4737  0.0299\n",
            "     90       49.4737  0.0286\n",
            "     91       49.4737  0.0282\n",
            "     92       49.4737  0.0302\n",
            "     93       49.4737  0.0296\n",
            "     94       49.4737  0.0299\n",
            "     95       49.4737  0.0306\n",
            "     96       49.4737  0.0293\n",
            "     97       49.4737  0.0300\n",
            "     98       49.4737  0.0299\n",
            "     99       49.4737  0.0287\n",
            "    100       49.4737  0.0315\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m55.2817\u001b[0m  0.0365\n",
            "      2       55.2817  0.0420\n",
            "      3       55.2817  0.0386\n",
            "      4       55.6338  0.0397\n",
            "      5       55.6338  0.0381\n",
            "      6       55.6338  0.0406\n",
            "      7       55.6338  0.0415\n",
            "      8       55.6338  0.0375\n",
            "      9       55.9859  0.0386\n",
            "     10       56.3380  0.0409\n",
            "     11       56.6901  0.0525\n",
            "     12       56.0809  0.0514\n",
            "     13       \u001b[36m52.8169\u001b[0m  0.0407\n",
            "     14       \u001b[36m52.1127\u001b[0m  0.0398\n",
            "     15       52.1127  0.0372\n",
            "     16       \u001b[36m50.0385\u001b[0m  0.0377\n",
            "     17       \u001b[36m38.4303\u001b[0m  0.0404\n",
            "     18       38.6815  0.0380\n",
            "     19       \u001b[36m37.7493\u001b[0m  0.0382\n",
            "     20       37.8074  0.0425\n",
            "     21       37.8057  0.0374\n",
            "     22       37.7981  0.0406\n",
            "     23       37.7555  0.0378\n",
            "     24       \u001b[36m37.3239\u001b[0m  0.0384\n",
            "     25       \u001b[36m37.2609\u001b[0m  0.0394\n",
            "     26       \u001b[36m37.2353\u001b[0m  0.0439\n",
            "     27       \u001b[36m37.2184\u001b[0m  0.0443\n",
            "     28       \u001b[36m37.2071\u001b[0m  0.0403\n",
            "     29       \u001b[36m37.2006\u001b[0m  0.0372\n",
            "     30       \u001b[36m37.1983\u001b[0m  0.0388\n",
            "     31       37.1994  0.0379\n",
            "     32       37.2035  0.0373\n",
            "     33       37.2099  0.0388\n",
            "     34       37.2183  0.0433\n",
            "     35       37.2282  0.0498\n",
            "     36       37.2392  0.0555\n",
            "     37       37.2511  0.0410\n",
            "     38       37.2634  0.0386\n",
            "     39       37.2761  0.0375\n",
            "     40       37.3239  0.0387\n",
            "     41       37.3239  0.0397\n",
            "     42       37.3239  0.0391\n",
            "     43       37.3239  0.0422\n",
            "     44       37.3239  0.0396\n",
            "     45       37.3239  0.0384\n",
            "     46       37.3239  0.0395\n",
            "     47       37.3239  0.0399\n",
            "     48       37.3239  0.0396\n",
            "     49       37.3239  0.0375\n",
            "     50       37.3239  0.0416\n",
            "     51       37.3239  0.0415\n",
            "     52       37.3239  0.0387\n",
            "     53       37.3239  0.0395\n",
            "     54       37.3239  0.0377\n",
            "     55       37.3239  0.0397\n",
            "     56       37.3239  0.0388\n",
            "     57       37.3239  0.0439\n",
            "     58       37.3239  0.0519\n",
            "     59       37.3239  0.0488\n",
            "     60       37.3239  0.0531\n",
            "     61       37.3239  0.0377\n",
            "     62       37.3239  0.0370\n",
            "     63       37.3239  0.0396\n",
            "     64       37.3239  0.0412\n",
            "     65       37.3239  0.0589\n",
            "     66       37.3239  0.0527\n",
            "     67       37.3239  0.0542\n",
            "     68       37.3239  0.0544\n",
            "     69       37.3239  0.0495\n",
            "     70       37.3239  0.0596\n",
            "     71       37.3239  0.0535\n",
            "     72       37.3239  0.0556\n",
            "     73       37.3239  0.0520\n",
            "     74       37.3239  0.0522\n",
            "     75       37.3239  0.0492\n",
            "     76       37.3239  0.0576\n",
            "     77       37.3239  0.0798\n",
            "     78       37.3239  0.0541\n",
            "     79       37.3239  0.0529\n",
            "     80       37.3239  0.0499\n",
            "     81       37.3239  0.0561\n",
            "     82       37.3239  0.0475\n",
            "     83       37.3239  0.0473\n",
            "     84       37.3239  0.0467\n",
            "     85       37.3239  0.0459\n",
            "     86       37.3239  0.0488\n",
            "     87       37.3239  0.0467\n",
            "     88       37.3239  0.0471\n",
            "     89       37.3239  0.0535\n",
            "     90       37.3239  0.0473\n",
            "     91       37.3239  0.0487\n",
            "     92       37.3239  0.0532\n",
            "     93       37.3239  0.0564\n",
            "     94       37.3239  0.0578\n",
            "     95       37.3239  0.0581\n",
            "     96       37.3239  0.0607\n",
            "     97       37.3239  0.0503\n",
            "     98       37.3239  0.0636\n",
            "     99       37.2842  0.0617\n",
            "    100       37.3239  0.0563\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m44.2105\u001b[0m  0.0552\n",
            "      2       \u001b[36m40.2520\u001b[0m  0.0613\n",
            "      3       40.5001  0.0536\n",
            "      4       40.8435  0.0585\n",
            "      5       \u001b[36m38.5965\u001b[0m  0.0587\n",
            "      6       38.9474  0.0529\n",
            "      7       38.8301  0.0542\n",
            "      8       40.3509  0.0528\n",
            "      9       42.1712  0.0526\n",
            "     10       38.9474  0.0522\n",
            "     11       \u001b[36m38.2456\u001b[0m  0.0759\n",
            "     12       38.2456  0.0569\n",
            "     13       38.2456  0.0551\n",
            "     14       38.2456  0.0568\n",
            "     15       38.2456  0.0531\n",
            "     16       38.2456  0.0395\n",
            "     17       38.2456  0.0396\n",
            "     18       38.2456  0.0406\n",
            "     19       38.2561  0.0387\n",
            "     20       \u001b[36m37.8947\u001b[0m  0.0427\n",
            "     21       37.8947  0.0384\n",
            "     22       37.8947  0.0387\n",
            "     23       37.8947  0.0394\n",
            "     24       37.8947  0.0373\n",
            "     25       37.8947  0.0419\n",
            "     26       37.8947  0.0372\n",
            "     27       37.8947  0.0397\n",
            "     28       37.8947  0.0424\n",
            "     29       37.8947  0.0372\n",
            "     30       37.8947  0.0407\n",
            "     31       37.8947  0.0389\n",
            "     32       37.8947  0.0393\n",
            "     33       37.8947  0.0528\n",
            "     34       37.8947  0.0504\n",
            "     35       37.8947  0.0382\n",
            "     36       37.8947  0.0406\n",
            "     37       37.8947  0.0445\n",
            "     38       37.8947  0.0455\n",
            "     39       37.8947  0.0446\n",
            "     40       37.8947  0.0442\n",
            "     41       37.8947  0.0389\n",
            "     42       37.8947  0.0396\n",
            "     43       37.8947  0.0393\n",
            "     44       37.8947  0.0386\n",
            "     45       37.8947  0.0383\n",
            "     46       37.8947  0.0392\n",
            "     47       37.8947  0.0406\n",
            "     48       37.8947  0.0425\n",
            "     49       37.8947  0.0395\n",
            "     50       37.8947  0.0363\n",
            "     51       37.8947  0.0414\n",
            "     52       37.8947  0.0400\n",
            "     53       37.8947  0.0389\n",
            "     54       37.8947  0.0452\n",
            "     55       37.8947  0.0388\n",
            "     56       37.8947  0.0512\n",
            "     57       37.8947  0.0484\n",
            "     58       37.8947  0.0435\n",
            "     59       37.8947  0.0427\n",
            "     60       37.8947  0.0435\n",
            "     61       37.8947  0.0375\n",
            "     62       37.8947  0.0392\n",
            "     63       37.8947  0.0484\n",
            "     64       37.8947  0.0376\n",
            "     65       37.8947  0.0432\n",
            "     66       37.8947  0.0414\n",
            "     67       37.8947  0.0391\n",
            "     68       37.8947  0.0377\n",
            "     69       37.8947  0.0397\n",
            "     70       37.8947  0.0408\n",
            "     71       37.8947  0.0386\n",
            "     72       37.8947  0.0424\n",
            "     73       37.8947  0.0415\n",
            "     74       37.8947  0.0399\n",
            "     75       37.8947  0.0412\n",
            "     76       37.8947  0.0398\n",
            "     77       37.8947  0.0394\n",
            "     78       37.8947  0.0377\n",
            "     79       37.8947  0.0499\n",
            "     80       \u001b[36m37.2304\u001b[0m  0.0497\n",
            "     81       \u001b[36m37.1930\u001b[0m  0.0473\n",
            "     82       37.1930  0.0383\n",
            "     83       37.1930  0.0413\n",
            "     84       37.1930  0.0393\n",
            "     85       37.1930  0.0382\n",
            "     86       37.1930  0.0460\n",
            "     87       37.1930  0.0457\n",
            "     88       37.1930  0.0392\n",
            "     89       37.1930  0.0416\n",
            "     90       37.1930  0.0422\n",
            "     91       37.1930  0.0391\n",
            "     92       37.1930  0.0392\n",
            "     93       37.1930  0.0388\n",
            "     94       37.1930  0.0416\n",
            "     95       37.1930  0.0415\n",
            "     96       37.1930  0.0406\n",
            "     97       37.1930  0.0411\n",
            "     98       37.1930  0.0420\n",
            "     99       37.1930  0.0404\n",
            "    100       37.1930  0.0390\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.9445\u001b[0m  0.0286\n",
            "      2       54.2254  0.0373\n",
            "      3       54.2254  0.0379\n",
            "      4       54.2254  0.0356\n",
            "      5       54.2254  0.0272\n",
            "      6       54.2254  0.0322\n",
            "      7       54.2254  0.0276\n",
            "      8       54.2254  0.0279\n",
            "      9       54.2254  0.0318\n",
            "     10       54.2254  0.0305\n",
            "     11       54.2254  0.0289\n",
            "     12       54.2254  0.0303\n",
            "     13       54.2254  0.0320\n",
            "     14       54.2254  0.0355\n",
            "     15       54.2254  0.0285\n",
            "     16       54.2254  0.0283\n",
            "     17       54.2254  0.0306\n",
            "     18       54.2254  0.0276\n",
            "     19       54.2254  0.0285\n",
            "     20       54.2254  0.0299\n",
            "     21       54.2254  0.0270\n",
            "     22       54.2254  0.0272\n",
            "     23       54.2254  0.0313\n",
            "     24       54.2254  0.0366\n",
            "     25       54.2254  0.0310\n",
            "     26       54.2254  0.0314\n",
            "     27       54.2254  0.0295\n",
            "     28       54.2254  0.0319\n",
            "     29       54.2254  0.0310\n",
            "     30       54.2254  0.0296\n",
            "     31       54.2254  0.0296\n",
            "     32       54.2254  0.0296\n",
            "     33       54.2254  0.0369\n",
            "     34       54.2254  0.0369\n",
            "     35       54.2254  0.0389\n",
            "     36       54.2254  0.0361\n",
            "     37       54.2254  0.0294\n",
            "     38       54.2254  0.0299\n",
            "     39       54.2254  0.0322\n",
            "     40       54.2254  0.0291\n",
            "     41       54.2254  0.0296\n",
            "     42       54.2254  0.0328\n",
            "     43       54.2254  0.0336\n",
            "     44       54.2254  0.0343\n",
            "     45       54.2254  0.0397\n",
            "     46       54.2254  0.0317\n",
            "     47       54.2254  0.0349\n",
            "     48       54.2254  0.0302\n",
            "     49       54.2254  0.0304\n",
            "     50       54.2254  0.0287\n",
            "     51       54.2254  0.0309\n",
            "     52       54.2254  0.0317\n",
            "     53       54.2254  0.0295\n",
            "     54       54.2254  0.0347\n",
            "     55       54.2254  0.0290\n",
            "     56       54.2254  0.0319\n",
            "     57       54.2254  0.0281\n",
            "     58       54.2254  0.0321\n",
            "     59       54.2254  0.0301\n",
            "     60       54.2254  0.0302\n",
            "     61       54.2254  0.0302\n",
            "     62       54.2254  0.0291\n",
            "     63       54.2254  0.0412\n",
            "     64       54.2254  0.0365\n",
            "     65       54.2254  0.0376\n",
            "     66       54.2254  0.0352\n",
            "     67       54.2254  0.0290\n",
            "     68       54.2254  0.0291\n",
            "     69       54.2254  0.0294\n",
            "     70       54.2254  0.0314\n",
            "     71       54.2254  0.0299\n",
            "     72       54.2254  0.0318\n",
            "     73       54.2254  0.0338\n",
            "     74       54.2254  0.0306\n",
            "     75       54.2254  0.0375\n",
            "     76       54.2254  0.0335\n",
            "     77       54.2254  0.0335\n",
            "     78       54.2254  0.0304\n",
            "     79       54.2254  0.0292\n",
            "     80       54.2254  0.0294\n",
            "     81       54.2254  0.0315\n",
            "     82       54.2254  0.0291\n",
            "     83       54.2254  0.0315\n",
            "     84       54.2254  0.0321\n",
            "     85       54.2254  0.0326\n",
            "     86       54.2254  0.0282\n",
            "     87       54.2254  0.0308\n",
            "     88       54.2254  0.0307\n",
            "     89       54.2254  0.0309\n",
            "     90       54.2254  0.0321\n",
            "     91       54.2254  0.0299\n",
            "     92       54.2254  0.0310\n",
            "     93       54.2254  0.0377\n",
            "     94       54.2254  0.0373\n",
            "     95       54.2254  0.0384\n",
            "     96       54.2254  0.0306\n",
            "     97       54.2254  0.0336\n",
            "     98       54.2254  0.0297\n",
            "     99       54.2254  0.0317\n",
            "    100       54.2254  0.0287\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0282\n",
            "      2       37.1930  0.0326\n",
            "      3       37.1930  0.0315\n",
            "      4       37.1930  0.0356\n",
            "      5       37.1930  0.0390\n",
            "      6       37.1930  0.0341\n",
            "      7       37.1930  0.0306\n",
            "      8       37.1930  0.0292\n",
            "      9       37.1930  0.0296\n",
            "     10       37.1930  0.0283\n",
            "     11       37.1930  0.0301\n",
            "     12       37.1930  0.0278\n",
            "     13       37.1930  0.0346\n",
            "     14       37.1930  0.0305\n",
            "     15       37.1930  0.0273\n",
            "     16       37.1930  0.0298\n",
            "     17       37.1930  0.0284\n",
            "     18       37.1930  0.0304\n",
            "     19       37.1930  0.0304\n",
            "     20       37.1930  0.0282\n",
            "     21       37.1930  0.0285\n",
            "     22       37.1930  0.0381\n",
            "     23       37.1930  0.0359\n",
            "     24       37.1930  0.0381\n",
            "     25       37.1930  0.0344\n",
            "     26       37.1930  0.0296\n",
            "     27       37.1930  0.0285\n",
            "     28       37.1930  0.0299\n",
            "     29       37.1930  0.0280\n",
            "     30       37.1930  0.0289\n",
            "     31       37.1930  0.0299\n",
            "     32       37.1930  0.0315\n",
            "     33       37.1930  0.0365\n",
            "     34       37.1930  0.0300\n",
            "     35       37.1930  0.0320\n",
            "     36       37.1930  0.0288\n",
            "     37       37.1930  0.0396\n",
            "     38       37.1930  0.0283\n",
            "     39       37.1930  0.0283\n",
            "     40       37.1930  0.0323\n",
            "     41       37.1930  0.0310\n",
            "     42       37.1930  0.0294\n",
            "     43       37.1930  0.0316\n",
            "     44       37.1930  0.0314\n",
            "     45       37.1930  0.0273\n",
            "     46       37.1930  0.0301\n",
            "     47       37.1930  0.0291\n",
            "     48       37.1930  0.0299\n",
            "     49       37.1930  0.0333\n",
            "     50       37.1930  0.0285\n",
            "     51       37.1930  0.0299\n",
            "     52       37.1930  0.0335\n",
            "     53       37.1930  0.0396\n",
            "     54       37.1930  0.0388\n",
            "     55       37.1930  0.0370\n",
            "     56       37.1930  0.0353\n",
            "     57       37.1930  0.0323\n",
            "     58       37.1930  0.0368\n",
            "     59       37.1930  0.0357\n",
            "     60       37.1930  0.0331\n",
            "     61       37.1930  0.0353\n",
            "     62       37.1930  0.0335\n",
            "     63       37.1930  0.0318\n",
            "     64       37.1930  0.0355\n",
            "     65       37.1930  0.0331\n",
            "     66       37.1930  0.0339\n",
            "     67       37.1930  0.0418\n",
            "     68       37.1930  0.0320\n",
            "     69       37.1930  0.0309\n",
            "     70       37.1930  0.0299\n",
            "     71       37.1930  0.0312\n",
            "     72       37.1930  0.0314\n",
            "     73       37.1930  0.0370\n",
            "     74       37.1930  0.0311\n",
            "     75       37.1930  0.0325\n",
            "     76       37.1930  0.0311\n",
            "     77       37.1930  0.0318\n",
            "     78       37.1930  0.0336\n",
            "     79       37.1930  0.0298\n",
            "     80       37.1930  0.0296\n",
            "     81       37.1930  0.0327\n",
            "     82       37.1930  0.0380\n",
            "     83       37.1930  0.0370\n",
            "     84       37.1930  0.0354\n",
            "     85       37.1930  0.0300\n",
            "     86       37.1930  0.0294\n",
            "     87       37.1930  0.0322\n",
            "     88       37.1930  0.0320\n",
            "     89       37.1930  0.0339\n",
            "     90       37.1930  0.0474\n",
            "     91       37.1930  0.0432\n",
            "     92       37.1930  0.0406\n",
            "     93       37.1930  0.0427\n",
            "     94       37.1930  0.0422\n",
            "     95       37.1930  0.0439\n",
            "     96       37.1930  0.0454\n",
            "     97       37.1930  0.0456\n",
            "     98       37.1930  0.0403\n",
            "     99       37.1930  0.0494\n",
            "    100       37.1930  0.0367\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8697\u001b[0m  0.0512\n",
            "      2        \u001b[36m1.8033\u001b[0m  0.0535\n",
            "      3        \u001b[36m1.7339\u001b[0m  0.0517\n",
            "      4        \u001b[36m1.6617\u001b[0m  0.0749\n",
            "      5        \u001b[36m1.5852\u001b[0m  0.0554\n",
            "      6        \u001b[36m1.4989\u001b[0m  0.0537\n",
            "      7        \u001b[36m1.3896\u001b[0m  0.0497\n",
            "      8        \u001b[36m1.2336\u001b[0m  0.0488\n",
            "      9        \u001b[36m1.0247\u001b[0m  0.0514\n",
            "     10        \u001b[36m0.8284\u001b[0m  0.0515\n",
            "     11        \u001b[36m0.7211\u001b[0m  0.0514\n",
            "     12        \u001b[36m0.6852\u001b[0m  0.0654\n",
            "     13        \u001b[36m0.6747\u001b[0m  0.0482\n",
            "     14        \u001b[36m0.6716\u001b[0m  0.0505\n",
            "     15        \u001b[36m0.6704\u001b[0m  0.0556\n",
            "     16        \u001b[36m0.6698\u001b[0m  0.0492\n",
            "     17        \u001b[36m0.6694\u001b[0m  0.0498\n",
            "     18        \u001b[36m0.6691\u001b[0m  0.0520\n",
            "     19        \u001b[36m0.6689\u001b[0m  0.0575\n",
            "     20        \u001b[36m0.6688\u001b[0m  0.0692\n",
            "     21        \u001b[36m0.6686\u001b[0m  0.0679\n",
            "     22        \u001b[36m0.6685\u001b[0m  0.0663\n",
            "     23        \u001b[36m0.6684\u001b[0m  0.0534\n",
            "     24        \u001b[36m0.6683\u001b[0m  0.0489\n",
            "     25        \u001b[36m0.6683\u001b[0m  0.0510\n",
            "     26        \u001b[36m0.6682\u001b[0m  0.0568\n",
            "     27        \u001b[36m0.6681\u001b[0m  0.0584\n",
            "     28        \u001b[36m0.6681\u001b[0m  0.0513\n",
            "     29        \u001b[36m0.6680\u001b[0m  0.0526\n",
            "     30        \u001b[36m0.6680\u001b[0m  0.0602\n",
            "     31        \u001b[36m0.6680\u001b[0m  0.0522\n",
            "     32        \u001b[36m0.6679\u001b[0m  0.0598\n",
            "     33        \u001b[36m0.6679\u001b[0m  0.0577\n",
            "     34        \u001b[36m0.6679\u001b[0m  0.0521\n",
            "     35        0.6679  0.0605\n",
            "     36        \u001b[36m0.6678\u001b[0m  0.0551\n",
            "     37        \u001b[36m0.6678\u001b[0m  0.0543\n",
            "     38        \u001b[36m0.6677\u001b[0m  0.0759\n",
            "     39        \u001b[36m0.6677\u001b[0m  0.0552\n",
            "     40        \u001b[36m0.6677\u001b[0m  0.0595\n",
            "     41        \u001b[36m0.6677\u001b[0m  0.2298\n",
            "     42        0.6677  0.0395\n",
            "     43        \u001b[36m0.6676\u001b[0m  0.0384\n",
            "     44        \u001b[36m0.6676\u001b[0m  0.0446\n",
            "     45        \u001b[36m0.6676\u001b[0m  0.0402\n",
            "     46        \u001b[36m0.6676\u001b[0m  0.0389\n",
            "     47        \u001b[36m0.6676\u001b[0m  0.0384\n",
            "     48        \u001b[36m0.6675\u001b[0m  0.0418\n",
            "     49        \u001b[36m0.6675\u001b[0m  0.0462\n",
            "     50        \u001b[36m0.6675\u001b[0m  0.0410\n",
            "     51        \u001b[36m0.6675\u001b[0m  0.0403\n",
            "     52        \u001b[36m0.6511\u001b[0m  0.0414\n",
            "     53        0.7138  0.0403\n",
            "     54        0.6867  0.0439\n",
            "     55        0.6760  0.0520\n",
            "     56        0.6726  0.0454\n",
            "     57        0.6714  0.0393\n",
            "     58        0.6710  0.0413\n",
            "     59        0.6707  0.0409\n",
            "     60        0.6705  0.0393\n",
            "     61        0.6704  0.0394\n",
            "     62        0.6702  0.0399\n",
            "     63        0.6701  0.0427\n",
            "     64        0.6700  0.0393\n",
            "     65        0.6699  0.0443\n",
            "     66        0.6698  0.0396\n",
            "     67        0.6601  0.0385\n",
            "     68        0.6767  0.0387\n",
            "     69        0.6717  0.0376\n",
            "     70        0.6690  0.0416\n",
            "     71        0.6674  0.0415\n",
            "     72        0.6664  0.0420\n",
            "     73        0.6656  0.0503\n",
            "     74        0.6648  0.0411\n",
            "     75        0.6641  0.0394\n",
            "     76        0.6633  0.0405\n",
            "     77        0.6626  0.0414\n",
            "     78        0.6619  0.0484\n",
            "     79        0.6612  0.0481\n",
            "     80        0.6606  0.0454\n",
            "     81        0.6600  0.0416\n",
            "     82        0.6595  0.0397\n",
            "     83        0.6590  0.0384\n",
            "     84        0.6586  0.0384\n",
            "     85        0.6581  0.0411\n",
            "     86        0.6577  0.0406\n",
            "     87        0.6573  0.0396\n",
            "     88        0.6570  0.0406\n",
            "     89        0.6566  0.0382\n",
            "     90        0.6563  0.0390\n",
            "     91        0.6560  0.0403\n",
            "     92        0.6556  0.0413\n",
            "     93        0.6553  0.0382\n",
            "     94        0.6550  0.0402\n",
            "     95        0.6548  0.0400\n",
            "     96        0.6545  0.0380\n",
            "     97        0.6542  0.0524\n",
            "     98        0.6539  0.0373\n",
            "     99        0.6537  0.0377\n",
            "    100        0.6534  0.0422\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3199\u001b[0m  0.0442\n",
            "      2        \u001b[36m1.2579\u001b[0m  0.0466\n",
            "      3        \u001b[36m1.1982\u001b[0m  0.0415\n",
            "      4        \u001b[36m1.1382\u001b[0m  0.0383\n",
            "      5        \u001b[36m1.0779\u001b[0m  0.0368\n",
            "      6        \u001b[36m1.0158\u001b[0m  0.0424\n",
            "      7        \u001b[36m0.9487\u001b[0m  0.0372\n",
            "      8        \u001b[36m0.8733\u001b[0m  0.0377\n",
            "      9        \u001b[36m0.7941\u001b[0m  0.0392\n",
            "     10        \u001b[36m0.7297\u001b[0m  0.0386\n",
            "     11        \u001b[36m0.6928\u001b[0m  0.0384\n",
            "     12        \u001b[36m0.6768\u001b[0m  0.0375\n",
            "     13        \u001b[36m0.6706\u001b[0m  0.0395\n",
            "     14        \u001b[36m0.6680\u001b[0m  0.0405\n",
            "     15        \u001b[36m0.6669\u001b[0m  0.0405\n",
            "     16        \u001b[36m0.6663\u001b[0m  0.0507\n",
            "     17        \u001b[36m0.6659\u001b[0m  0.0418\n",
            "     18        \u001b[36m0.6657\u001b[0m  0.0381\n",
            "     19        \u001b[36m0.6655\u001b[0m  0.0446\n",
            "     20        \u001b[36m0.6654\u001b[0m  0.0398\n",
            "     21        \u001b[36m0.6653\u001b[0m  0.0481\n",
            "     22        \u001b[36m0.6652\u001b[0m  0.0384\n",
            "     23        \u001b[36m0.6652\u001b[0m  0.0367\n",
            "     24        \u001b[36m0.6651\u001b[0m  0.0411\n",
            "     25        \u001b[36m0.6651\u001b[0m  0.0500\n",
            "     26        \u001b[36m0.6650\u001b[0m  0.0514\n",
            "     27        \u001b[36m0.6650\u001b[0m  0.0396\n",
            "     28        \u001b[36m0.6650\u001b[0m  0.0377\n",
            "     29        \u001b[36m0.6649\u001b[0m  0.0384\n",
            "     30        \u001b[36m0.6649\u001b[0m  0.0368\n",
            "     31        \u001b[36m0.6649\u001b[0m  0.0374\n",
            "     32        \u001b[36m0.6649\u001b[0m  0.0376\n",
            "     33        \u001b[36m0.6648\u001b[0m  0.0420\n",
            "     34        \u001b[36m0.6648\u001b[0m  0.0374\n",
            "     35        \u001b[36m0.6647\u001b[0m  0.0380\n",
            "     36        \u001b[36m0.6640\u001b[0m  0.0405\n",
            "     37        \u001b[36m0.6605\u001b[0m  0.0383\n",
            "     38        0.6658  0.0376\n",
            "     39        0.6654  0.0392\n",
            "     40        0.6652  0.0435\n",
            "     41        0.6648  0.0395\n",
            "     42        0.6636  0.0394\n",
            "     43        0.6650  0.0392\n",
            "     44        0.6689  0.0415\n",
            "     45        0.6742  0.0452\n",
            "     46        0.6642  0.0390\n",
            "     47        0.6643  0.0393\n",
            "     48        0.6643  0.0391\n",
            "     49        0.6644  0.0557\n",
            "     50        0.6644  0.0515\n",
            "     51        0.6644  0.0384\n",
            "     52        0.6642  0.0416\n",
            "     53        0.6607  0.0376\n",
            "     54        \u001b[36m0.6560\u001b[0m  0.0394\n",
            "     55        \u001b[36m0.6521\u001b[0m  0.0392\n",
            "     56        0.6608  0.0406\n",
            "     57        0.6551  0.0418\n",
            "     58        0.6548  0.0419\n",
            "     59        0.6545  0.0411\n",
            "     60        0.6542  0.0440\n",
            "     61        0.6538  0.0409\n",
            "     62        0.6534  0.0403\n",
            "     63        0.6530  0.0393\n",
            "     64        0.6526  0.0398\n",
            "     65        0.6522  0.0405\n",
            "     66        \u001b[36m0.6518\u001b[0m  0.0420\n",
            "     67        \u001b[36m0.6514\u001b[0m  0.0394\n",
            "     68        \u001b[36m0.6510\u001b[0m  0.0395\n",
            "     69        \u001b[36m0.6506\u001b[0m  0.0491\n",
            "     70        \u001b[36m0.6502\u001b[0m  0.0391\n",
            "     71        \u001b[36m0.6499\u001b[0m  0.0406\n",
            "     72        \u001b[36m0.6495\u001b[0m  0.0549\n",
            "     73        \u001b[36m0.6491\u001b[0m  0.0517\n",
            "     74        \u001b[36m0.6488\u001b[0m  0.0397\n",
            "     75        \u001b[36m0.6484\u001b[0m  0.0398\n",
            "     76        \u001b[36m0.6481\u001b[0m  0.0383\n",
            "     77        \u001b[36m0.6477\u001b[0m  0.0388\n",
            "     78        \u001b[36m0.6474\u001b[0m  0.0393\n",
            "     79        \u001b[36m0.6471\u001b[0m  0.0393\n",
            "     80        \u001b[36m0.6468\u001b[0m  0.0436\n",
            "     81        \u001b[36m0.6465\u001b[0m  0.0450\n",
            "     82        \u001b[36m0.6462\u001b[0m  0.0373\n",
            "     83        \u001b[36m0.6459\u001b[0m  0.0411\n",
            "     84        \u001b[36m0.6457\u001b[0m  0.0386\n",
            "     85        \u001b[36m0.6454\u001b[0m  0.0375\n",
            "     86        \u001b[36m0.6452\u001b[0m  0.0385\n",
            "     87        \u001b[36m0.6449\u001b[0m  0.0395\n",
            "     88        \u001b[36m0.6447\u001b[0m  0.0416\n",
            "     89        \u001b[36m0.6444\u001b[0m  0.0414\n",
            "     90        \u001b[36m0.6442\u001b[0m  0.0387\n",
            "     91        \u001b[36m0.6440\u001b[0m  0.0413\n",
            "     92        \u001b[36m0.6438\u001b[0m  0.0379\n",
            "     93        \u001b[36m0.6436\u001b[0m  0.0480\n",
            "     94        \u001b[36m0.6433\u001b[0m  0.0375\n",
            "     95        \u001b[36m0.6431\u001b[0m  0.0470\n",
            "     96        \u001b[36m0.6429\u001b[0m  0.0544\n",
            "     97        \u001b[36m0.6427\u001b[0m  0.0419\n",
            "     98        \u001b[36m0.6426\u001b[0m  0.0427\n",
            "     99        \u001b[36m0.6424\u001b[0m  0.0385\n",
            "    100        \u001b[36m0.6422\u001b[0m  0.0380\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8167\u001b[0m  0.0262\n",
            "      2        \u001b[36m1.7813\u001b[0m  0.0305\n",
            "      3        \u001b[36m1.7460\u001b[0m  0.0331\n",
            "      4        \u001b[36m1.7109\u001b[0m  0.0286\n",
            "      5        \u001b[36m1.6760\u001b[0m  0.0276\n",
            "      6        \u001b[36m1.6413\u001b[0m  0.0313\n",
            "      7        \u001b[36m1.6069\u001b[0m  0.0296\n",
            "      8        \u001b[36m1.5727\u001b[0m  0.0320\n",
            "      9        \u001b[36m1.5387\u001b[0m  0.0290\n",
            "     10        \u001b[36m1.5051\u001b[0m  0.0302\n",
            "     11        \u001b[36m1.4717\u001b[0m  0.0283\n",
            "     12        \u001b[36m1.4387\u001b[0m  0.0288\n",
            "     13        \u001b[36m1.4061\u001b[0m  0.0356\n",
            "     14        \u001b[36m1.3739\u001b[0m  0.0291\n",
            "     15        \u001b[36m1.3421\u001b[0m  0.0336\n",
            "     16        \u001b[36m1.3108\u001b[0m  0.0295\n",
            "     17        \u001b[36m1.2800\u001b[0m  0.0299\n",
            "     18        \u001b[36m1.2498\u001b[0m  0.0310\n",
            "     19        \u001b[36m1.2201\u001b[0m  0.0296\n",
            "     20        \u001b[36m1.1910\u001b[0m  0.0331\n",
            "     21        \u001b[36m1.1626\u001b[0m  0.0298\n",
            "     22        \u001b[36m1.1348\u001b[0m  0.0381\n",
            "     23        \u001b[36m1.1078\u001b[0m  0.0378\n",
            "     24        \u001b[36m1.0815\u001b[0m  0.0360\n",
            "     25        \u001b[36m1.0560\u001b[0m  0.0385\n",
            "     26        \u001b[36m1.0314\u001b[0m  0.0345\n",
            "     27        \u001b[36m1.0076\u001b[0m  0.0293\n",
            "     28        \u001b[36m0.9846\u001b[0m  0.0303\n",
            "     29        \u001b[36m0.9626\u001b[0m  0.0322\n",
            "     30        \u001b[36m0.9415\u001b[0m  0.0300\n",
            "     31        \u001b[36m0.9214\u001b[0m  0.0291\n",
            "     32        \u001b[36m0.9021\u001b[0m  0.0299\n",
            "     33        \u001b[36m0.8839\u001b[0m  0.0327\n",
            "     34        \u001b[36m0.8666\u001b[0m  0.0312\n",
            "     35        \u001b[36m0.8502\u001b[0m  0.0310\n",
            "     36        \u001b[36m0.8349\u001b[0m  0.0309\n",
            "     37        \u001b[36m0.8204\u001b[0m  0.0321\n",
            "     38        \u001b[36m0.8069\u001b[0m  0.0303\n",
            "     39        \u001b[36m0.7942\u001b[0m  0.0295\n",
            "     40        \u001b[36m0.7824\u001b[0m  0.0334\n",
            "     41        \u001b[36m0.7715\u001b[0m  0.0293\n",
            "     42        \u001b[36m0.7614\u001b[0m  0.0342\n",
            "     43        \u001b[36m0.7520\u001b[0m  0.0325\n",
            "     44        \u001b[36m0.7434\u001b[0m  0.0286\n",
            "     45        \u001b[36m0.7354\u001b[0m  0.0417\n",
            "     46        \u001b[36m0.7282\u001b[0m  0.0290\n",
            "     47        \u001b[36m0.7215\u001b[0m  0.0312\n",
            "     48        \u001b[36m0.7154\u001b[0m  0.0321\n",
            "     49        \u001b[36m0.7099\u001b[0m  0.0321\n",
            "     50        \u001b[36m0.7049\u001b[0m  0.0319\n",
            "     51        \u001b[36m0.7003\u001b[0m  0.0289\n",
            "     52        \u001b[36m0.6962\u001b[0m  0.0426\n",
            "     53        \u001b[36m0.6925\u001b[0m  0.0401\n",
            "     54        \u001b[36m0.6891\u001b[0m  0.0382\n",
            "     55        \u001b[36m0.6860\u001b[0m  0.0378\n",
            "     56        \u001b[36m0.6833\u001b[0m  0.0379\n",
            "     57        \u001b[36m0.6809\u001b[0m  0.0305\n",
            "     58        \u001b[36m0.6787\u001b[0m  0.0339\n",
            "     59        \u001b[36m0.6767\u001b[0m  0.0311\n",
            "     60        \u001b[36m0.6749\u001b[0m  0.0311\n",
            "     61        \u001b[36m0.6733\u001b[0m  0.0307\n",
            "     62        \u001b[36m0.6719\u001b[0m  0.0323\n",
            "     63        \u001b[36m0.6707\u001b[0m  0.0298\n",
            "     64        \u001b[36m0.6695\u001b[0m  0.0286\n",
            "     65        \u001b[36m0.6685\u001b[0m  0.0314\n",
            "     66        \u001b[36m0.6677\u001b[0m  0.0321\n",
            "     67        \u001b[36m0.6669\u001b[0m  0.0306\n",
            "     68        \u001b[36m0.6662\u001b[0m  0.0309\n",
            "     69        \u001b[36m0.6656\u001b[0m  0.0292\n",
            "     70        \u001b[36m0.6650\u001b[0m  0.0312\n",
            "     71        \u001b[36m0.6645\u001b[0m  0.0292\n",
            "     72        \u001b[36m0.6641\u001b[0m  0.0292\n",
            "     73        \u001b[36m0.6637\u001b[0m  0.0307\n",
            "     74        \u001b[36m0.6634\u001b[0m  0.0297\n",
            "     75        \u001b[36m0.6631\u001b[0m  0.0309\n",
            "     76        \u001b[36m0.6628\u001b[0m  0.0333\n",
            "     77        \u001b[36m0.6626\u001b[0m  0.0329\n",
            "     78        \u001b[36m0.6624\u001b[0m  0.0318\n",
            "     79        \u001b[36m0.6622\u001b[0m  0.0310\n",
            "     80        \u001b[36m0.6621\u001b[0m  0.0308\n",
            "     81        \u001b[36m0.6619\u001b[0m  0.0285\n",
            "     82        \u001b[36m0.6618\u001b[0m  0.0427\n",
            "     83        \u001b[36m0.6617\u001b[0m  0.0396\n",
            "     84        \u001b[36m0.6616\u001b[0m  0.0347\n",
            "     85        \u001b[36m0.6615\u001b[0m  0.0382\n",
            "     86        \u001b[36m0.6615\u001b[0m  0.0336\n",
            "     87        \u001b[36m0.6614\u001b[0m  0.0311\n",
            "     88        \u001b[36m0.6613\u001b[0m  0.0313\n",
            "     89        \u001b[36m0.6613\u001b[0m  0.0315\n",
            "     90        \u001b[36m0.6613\u001b[0m  0.0313\n",
            "     91        \u001b[36m0.6612\u001b[0m  0.0436\n",
            "     92        \u001b[36m0.6612\u001b[0m  0.0404\n",
            "     93        \u001b[36m0.6612\u001b[0m  0.0430\n",
            "     94        \u001b[36m0.6612\u001b[0m  0.0434\n",
            "     95        \u001b[36m0.6611\u001b[0m  0.0451\n",
            "     96        \u001b[36m0.6611\u001b[0m  0.0393\n",
            "     97        \u001b[36m0.6611\u001b[0m  0.0394\n",
            "     98        \u001b[36m0.6611\u001b[0m  0.0415\n",
            "     99        \u001b[36m0.6611\u001b[0m  0.0405\n",
            "    100        \u001b[36m0.6611\u001b[0m  0.0392\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3884\u001b[0m  0.0346\n",
            "      2        \u001b[36m1.3579\u001b[0m  0.0397\n",
            "      3        \u001b[36m1.3278\u001b[0m  0.0418\n",
            "      4        \u001b[36m1.2981\u001b[0m  0.0365\n",
            "      5        \u001b[36m1.2689\u001b[0m  0.0374\n",
            "      6        \u001b[36m1.2402\u001b[0m  0.0455\n",
            "      7        \u001b[36m1.2120\u001b[0m  0.0503\n",
            "      8        \u001b[36m1.1845\u001b[0m  0.0459\n",
            "      9        \u001b[36m1.1575\u001b[0m  0.0375\n",
            "     10        \u001b[36m1.1312\u001b[0m  0.0375\n",
            "     11        \u001b[36m1.1055\u001b[0m  0.0371\n",
            "     12        \u001b[36m1.0805\u001b[0m  0.0369\n",
            "     13        \u001b[36m1.0563\u001b[0m  0.0365\n",
            "     14        \u001b[36m1.0328\u001b[0m  0.0397\n",
            "     15        \u001b[36m1.0102\u001b[0m  0.0354\n",
            "     16        \u001b[36m0.9883\u001b[0m  0.0366\n",
            "     17        \u001b[36m0.9672\u001b[0m  0.0360\n",
            "     18        \u001b[36m0.9470\u001b[0m  0.0345\n",
            "     19        \u001b[36m0.9277\u001b[0m  0.0367\n",
            "     20        \u001b[36m0.9092\u001b[0m  0.0392\n",
            "     21        \u001b[36m0.8916\u001b[0m  0.0391\n",
            "     22        \u001b[36m0.8748\u001b[0m  0.0379\n",
            "     23        \u001b[36m0.8590\u001b[0m  0.0343\n",
            "     24        \u001b[36m0.8440\u001b[0m  0.0376\n",
            "     25        \u001b[36m0.8299\u001b[0m  0.0339\n",
            "     26        \u001b[36m0.8166\u001b[0m  0.0360\n",
            "     27        \u001b[36m0.8041\u001b[0m  0.0359\n",
            "     28        \u001b[36m0.7924\u001b[0m  0.0355\n",
            "     29        \u001b[36m0.7815\u001b[0m  0.0435\n",
            "     30        \u001b[36m0.7714\u001b[0m  0.0449\n",
            "     31        \u001b[36m0.7619\u001b[0m  0.0492\n",
            "     32        \u001b[36m0.7532\u001b[0m  0.0457\n",
            "     33        \u001b[36m0.7451\u001b[0m  0.0506\n",
            "     34        \u001b[36m0.7377\u001b[0m  0.0387\n",
            "     35        \u001b[36m0.7308\u001b[0m  0.0408\n",
            "     36        \u001b[36m0.7245\u001b[0m  0.0366\n",
            "     37        \u001b[36m0.7186\u001b[0m  0.0360\n",
            "     38        \u001b[36m0.7133\u001b[0m  0.0432\n",
            "     39        \u001b[36m0.7085\u001b[0m  0.0389\n",
            "     40        \u001b[36m0.7040\u001b[0m  0.0508\n",
            "     41        \u001b[36m0.7000\u001b[0m  0.0409\n",
            "     42        \u001b[36m0.6963\u001b[0m  0.0400\n",
            "     43        \u001b[36m0.6929\u001b[0m  0.0364\n",
            "     44        \u001b[36m0.6898\u001b[0m  0.0394\n",
            "     45        \u001b[36m0.6871\u001b[0m  0.0400\n",
            "     46        \u001b[36m0.6846\u001b[0m  0.0391\n",
            "     47        \u001b[36m0.6823\u001b[0m  0.0402\n",
            "     48        \u001b[36m0.6802\u001b[0m  0.0442\n",
            "     49        \u001b[36m0.6783\u001b[0m  0.0445\n",
            "     50        \u001b[36m0.6766\u001b[0m  0.0415\n",
            "     51        \u001b[36m0.6751\u001b[0m  0.0405\n",
            "     52        \u001b[36m0.6737\u001b[0m  0.0494\n",
            "     53        \u001b[36m0.6725\u001b[0m  0.0422\n",
            "     54        \u001b[36m0.6714\u001b[0m  0.0516\n",
            "     55        \u001b[36m0.6703\u001b[0m  0.0403\n",
            "     56        \u001b[36m0.6694\u001b[0m  0.0469\n",
            "     57        \u001b[36m0.6686\u001b[0m  0.0432\n",
            "     58        \u001b[36m0.6678\u001b[0m  0.0435\n",
            "     59        \u001b[36m0.6672\u001b[0m  0.0438\n",
            "     60        \u001b[36m0.6666\u001b[0m  0.0445\n",
            "     61        \u001b[36m0.6660\u001b[0m  0.0415\n",
            "     62        \u001b[36m0.6655\u001b[0m  0.0317\n",
            "     63        \u001b[36m0.6651\u001b[0m  0.0296\n",
            "     64        \u001b[36m0.6647\u001b[0m  0.0282\n",
            "     65        \u001b[36m0.6643\u001b[0m  0.0293\n",
            "     66        \u001b[36m0.6640\u001b[0m  0.0288\n",
            "     67        \u001b[36m0.6637\u001b[0m  0.0279\n",
            "     68        \u001b[36m0.6634\u001b[0m  0.0291\n",
            "     69        \u001b[36m0.6631\u001b[0m  0.0310\n",
            "     70        \u001b[36m0.6629\u001b[0m  0.0295\n",
            "     71        \u001b[36m0.6627\u001b[0m  0.0302\n",
            "     72        \u001b[36m0.6625\u001b[0m  0.0330\n",
            "     73        \u001b[36m0.6624\u001b[0m  0.0275\n",
            "     74        \u001b[36m0.6622\u001b[0m  0.0302\n",
            "     75        \u001b[36m0.6621\u001b[0m  0.0289\n",
            "     76        \u001b[36m0.6620\u001b[0m  0.0317\n",
            "     77        \u001b[36m0.6619\u001b[0m  0.0310\n",
            "     78        \u001b[36m0.6617\u001b[0m  0.0287\n",
            "     79        \u001b[36m0.6617\u001b[0m  0.0372\n",
            "     80        \u001b[36m0.6616\u001b[0m  0.0368\n",
            "     81        \u001b[36m0.6615\u001b[0m  0.0374\n",
            "     82        \u001b[36m0.6614\u001b[0m  0.0350\n",
            "     83        \u001b[36m0.6614\u001b[0m  0.0317\n",
            "     84        \u001b[36m0.6613\u001b[0m  0.0297\n",
            "     85        \u001b[36m0.6612\u001b[0m  0.0288\n",
            "     86        \u001b[36m0.6612\u001b[0m  0.0353\n",
            "     87        \u001b[36m0.6612\u001b[0m  0.0304\n",
            "     88        \u001b[36m0.6611\u001b[0m  0.0295\n",
            "     89        \u001b[36m0.6611\u001b[0m  0.0302\n",
            "     90        \u001b[36m0.6610\u001b[0m  0.0283\n",
            "     91        \u001b[36m0.6610\u001b[0m  0.0300\n",
            "     92        \u001b[36m0.6610\u001b[0m  0.0340\n",
            "     93        \u001b[36m0.6609\u001b[0m  0.0322\n",
            "     94        \u001b[36m0.6609\u001b[0m  0.0297\n",
            "     95        \u001b[36m0.6609\u001b[0m  0.0323\n",
            "     96        \u001b[36m0.6609\u001b[0m  0.0284\n",
            "     97        \u001b[36m0.6609\u001b[0m  0.0312\n",
            "     98        \u001b[36m0.6608\u001b[0m  0.0309\n",
            "     99        \u001b[36m0.6608\u001b[0m  0.0302\n",
            "    100        \u001b[36m0.6608\u001b[0m  0.0293\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.0041\u001b[0m  0.0376\n",
            "      2        \u001b[36m1.8798\u001b[0m  0.0425\n",
            "      3        \u001b[36m1.7518\u001b[0m  0.0428\n",
            "      4        \u001b[36m1.6226\u001b[0m  0.0407\n",
            "      5        \u001b[36m1.4944\u001b[0m  0.0423\n",
            "      6        \u001b[36m1.3668\u001b[0m  0.0405\n",
            "      7        \u001b[36m1.2260\u001b[0m  0.0561\n",
            "      8        \u001b[36m1.0295\u001b[0m  0.0513\n",
            "      9        \u001b[36m0.8162\u001b[0m  0.0382\n",
            "     10        \u001b[36m0.7109\u001b[0m  0.0406\n",
            "     11        \u001b[36m0.6805\u001b[0m  0.0396\n",
            "     12        \u001b[36m0.6754\u001b[0m  0.0385\n",
            "     13        \u001b[36m0.6743\u001b[0m  0.0529\n",
            "     14        \u001b[36m0.6736\u001b[0m  0.0417\n",
            "     15        \u001b[36m0.6731\u001b[0m  0.0427\n",
            "     16        \u001b[36m0.6727\u001b[0m  0.0407\n",
            "     17        \u001b[36m0.6724\u001b[0m  0.0426\n",
            "     18        \u001b[36m0.6722\u001b[0m  0.0403\n",
            "     19        \u001b[36m0.6720\u001b[0m  0.0395\n",
            "     20        \u001b[36m0.6719\u001b[0m  0.0404\n",
            "     21        \u001b[36m0.6718\u001b[0m  0.0415\n",
            "     22        \u001b[36m0.6716\u001b[0m  0.0391\n",
            "     23        \u001b[36m0.6715\u001b[0m  0.0402\n",
            "     24        \u001b[36m0.6715\u001b[0m  0.0418\n",
            "     25        \u001b[36m0.6714\u001b[0m  0.0405\n",
            "     26        \u001b[36m0.6713\u001b[0m  0.0425\n",
            "     27        \u001b[36m0.6712\u001b[0m  0.0406\n",
            "     28        \u001b[36m0.6710\u001b[0m  0.0388\n",
            "     29        \u001b[36m0.6709\u001b[0m  0.0418\n",
            "     30        \u001b[36m0.6708\u001b[0m  0.0535\n",
            "     31        \u001b[36m0.6708\u001b[0m  0.0450\n",
            "     32        \u001b[36m0.6707\u001b[0m  0.0391\n",
            "     33        \u001b[36m0.6707\u001b[0m  0.0401\n",
            "     34        0.6755  0.0388\n",
            "     35        0.6764  0.0418\n",
            "     36        \u001b[36m0.6690\u001b[0m  0.0380\n",
            "     37        \u001b[36m0.6631\u001b[0m  0.0490\n",
            "     38        0.6685  0.0411\n",
            "     39        0.6664  0.0393\n",
            "     40        0.6660  0.0426\n",
            "     41        0.6658  0.0410\n",
            "     42        0.6656  0.0410\n",
            "     43        0.6655  0.0384\n",
            "     44        0.6654  0.0404\n",
            "     45        0.6653  0.0386\n",
            "     46        0.6652  0.0417\n",
            "     47        \u001b[36m0.6605\u001b[0m  0.0418\n",
            "     48        0.6674  0.0412\n",
            "     49        0.6680  0.0375\n",
            "     50        0.6651  0.0409\n",
            "     51        0.6647  0.0408\n",
            "     52        0.6664  0.0415\n",
            "     53        0.6645  0.0558\n",
            "     54        0.6623  0.0520\n",
            "     55        0.6659  0.0397\n",
            "     56        0.6642  0.0402\n",
            "     57        0.6642  0.0416\n",
            "     58        0.6642  0.0427\n",
            "     59        0.6642  0.0416\n",
            "     60        0.6647  0.0510\n",
            "     61        0.6643  0.0415\n",
            "     62        0.6642  0.0432\n",
            "     63        0.6637  0.0404\n",
            "     64        0.6629  0.0407\n",
            "     65        0.6621  0.0434\n",
            "     66        \u001b[36m0.6449\u001b[0m  0.0429\n",
            "     67        0.6730  0.0430\n",
            "     68        0.6630  0.0392\n",
            "     69        0.6592  0.0428\n",
            "     70        0.6552  0.0399\n",
            "     71        0.6534  0.0398\n",
            "     72        0.6535  0.0404\n",
            "     73        0.6526  0.0428\n",
            "     74        \u001b[36m0.6251\u001b[0m  0.0412\n",
            "     75        0.6500  0.0550\n",
            "     76        0.6468  0.0563\n",
            "     77        0.6465  0.0488\n",
            "     78        0.6462  0.0404\n",
            "     79        0.6457  0.0420\n",
            "     80        0.6451  0.0402\n",
            "     81        0.6445  0.0415\n",
            "     82        0.6440  0.0407\n",
            "     83        0.6435  0.0499\n",
            "     84        0.6431  0.0392\n",
            "     85        0.6426  0.0405\n",
            "     86        0.6423  0.0409\n",
            "     87        0.6419  0.0427\n",
            "     88        0.6416  0.0405\n",
            "     89        0.6412  0.0397\n",
            "     90        0.6409  0.0401\n",
            "     91        0.6407  0.0401\n",
            "     92        0.6404  0.0394\n",
            "     93        0.6401  0.0441\n",
            "     94        0.6399  0.0381\n",
            "     95        0.6396  0.0443\n",
            "     96        0.6394  0.0428\n",
            "     97        0.6392  0.0641\n",
            "     98        0.6390  0.0491\n",
            "     99        0.6388  0.0463\n",
            "    100        0.6386  0.0407\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4929\u001b[0m  0.0364\n",
            "      2        \u001b[36m2.3622\u001b[0m  0.0375\n",
            "      3        \u001b[36m2.2327\u001b[0m  0.0397\n",
            "      4        \u001b[36m2.1007\u001b[0m  0.0401\n",
            "      5        \u001b[36m1.9677\u001b[0m  0.0442\n",
            "      6        \u001b[36m1.8336\u001b[0m  0.0517\n",
            "      7        \u001b[36m1.6914\u001b[0m  0.0450\n",
            "      8        \u001b[36m1.5011\u001b[0m  0.0408\n",
            "      9        \u001b[36m1.2059\u001b[0m  0.0390\n",
            "     10        \u001b[36m0.8482\u001b[0m  0.0391\n",
            "     11        \u001b[36m0.6960\u001b[0m  0.0383\n",
            "     12        \u001b[36m0.6723\u001b[0m  0.0422\n",
            "     13        \u001b[36m0.6696\u001b[0m  0.0412\n",
            "     14        \u001b[36m0.6693\u001b[0m  0.0430\n",
            "     15        \u001b[36m0.6690\u001b[0m  0.0383\n",
            "     16        \u001b[36m0.6688\u001b[0m  0.0401\n",
            "     17        \u001b[36m0.6686\u001b[0m  0.0425\n",
            "     18        \u001b[36m0.6685\u001b[0m  0.0396\n",
            "     19        \u001b[36m0.6684\u001b[0m  0.0415\n",
            "     20        \u001b[36m0.6683\u001b[0m  0.0525\n",
            "     21        \u001b[36m0.6682\u001b[0m  0.0492\n",
            "     22        \u001b[36m0.6663\u001b[0m  0.0375\n",
            "     23        0.6865  0.0413\n",
            "     24        0.6690  0.0376\n",
            "     25        0.6684  0.0395\n",
            "     26        0.6680  0.0386\n",
            "     27        0.6676  0.0411\n",
            "     28        0.6674  0.0406\n",
            "     29        \u001b[36m0.6652\u001b[0m  0.0430\n",
            "     30        \u001b[36m0.6638\u001b[0m  0.0433\n",
            "     31        \u001b[36m0.6617\u001b[0m  0.0417\n",
            "     32        \u001b[36m0.6601\u001b[0m  0.0386\n",
            "     33        \u001b[36m0.6591\u001b[0m  0.0394\n",
            "     34        \u001b[36m0.6584\u001b[0m  0.0405\n",
            "     35        \u001b[36m0.6578\u001b[0m  0.0447\n",
            "     36        \u001b[36m0.6572\u001b[0m  0.0377\n",
            "     37        \u001b[36m0.6567\u001b[0m  0.0384\n",
            "     38        \u001b[36m0.6563\u001b[0m  0.0397\n",
            "     39        \u001b[36m0.6558\u001b[0m  0.0394\n",
            "     40        \u001b[36m0.6554\u001b[0m  0.0416\n",
            "     41        \u001b[36m0.6550\u001b[0m  0.0381\n",
            "     42        \u001b[36m0.6547\u001b[0m  0.0387\n",
            "     43        \u001b[36m0.6543\u001b[0m  0.0477\n",
            "     44        \u001b[36m0.6540\u001b[0m  0.0535\n",
            "     45        \u001b[36m0.6536\u001b[0m  0.0472\n",
            "     46        \u001b[36m0.6532\u001b[0m  0.0417\n",
            "     47        \u001b[36m0.6529\u001b[0m  0.0391\n",
            "     48        \u001b[36m0.6525\u001b[0m  0.0400\n",
            "     49        \u001b[36m0.6521\u001b[0m  0.0382\n",
            "     50        \u001b[36m0.6518\u001b[0m  0.0414\n",
            "     51        \u001b[36m0.6514\u001b[0m  0.0392\n",
            "     52        \u001b[36m0.6511\u001b[0m  0.0437\n",
            "     53        \u001b[36m0.6507\u001b[0m  0.0440\n",
            "     54        \u001b[36m0.6336\u001b[0m  0.0418\n",
            "     55        0.6681  0.0390\n",
            "     56        0.6575  0.0395\n",
            "     57        0.6536  0.0411\n",
            "     58        0.6522  0.0399\n",
            "     59        0.6516  0.0400\n",
            "     60        0.6512  0.0381\n",
            "     61        0.6512  0.0393\n",
            "     62        0.6507  0.0396\n",
            "     63        \u001b[36m0.5863\u001b[0m  0.0374\n",
            "     64        0.7443  0.0413\n",
            "     65        0.6724  0.0401\n",
            "     66        0.6532  0.0459\n",
            "     67        0.6233  0.0531\n",
            "     68        0.6189  0.0397\n",
            "     69        0.6772  0.0410\n",
            "     70        0.6450  0.0378\n",
            "     71        0.5874  0.0394\n",
            "     72        0.6437  0.0376\n",
            "     73        0.5987  0.0389\n",
            "     74        0.5882  0.0387\n",
            "     75        0.6039  0.0395\n",
            "     76        0.6153  0.0396\n",
            "     77        0.5995  0.0400\n",
            "     78        \u001b[36m0.5811\u001b[0m  0.0505\n",
            "     79        0.6690  0.0383\n",
            "     80        0.6347  0.0383\n",
            "     81        0.6259  0.0405\n",
            "     82        0.6233  0.0370\n",
            "     83        0.6218  0.0398\n",
            "     84        0.6207  0.0411\n",
            "     85        0.6198  0.0387\n",
            "     86        0.6191  0.0388\n",
            "     87        0.6184  0.0375\n",
            "     88        0.6178  0.0424\n",
            "     89        0.6175  0.0372\n",
            "     90        0.6077  0.0477\n",
            "     91        0.5889  0.0494\n",
            "     92        \u001b[36m0.5801\u001b[0m  0.0424\n",
            "     93        \u001b[36m0.5691\u001b[0m  0.0395\n",
            "     94        0.6210  0.0396\n",
            "     95        0.5832  0.0396\n",
            "     96        0.5804  0.0376\n",
            "     97        0.5825  0.0408\n",
            "     98        0.5842  0.0386\n",
            "     99        0.5795  0.0391\n",
            "    100        0.5832  0.0370\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.3162\u001b[0m  0.0423\n",
            "      2        \u001b[36m3.2462\u001b[0m  0.0465\n",
            "      3        \u001b[36m3.1762\u001b[0m  0.0483\n",
            "      4        \u001b[36m3.1061\u001b[0m  0.0487\n",
            "      5        \u001b[36m3.0361\u001b[0m  0.0445\n",
            "      6        \u001b[36m2.9661\u001b[0m  0.0422\n",
            "      7        \u001b[36m2.8961\u001b[0m  0.0415\n",
            "      8        \u001b[36m2.8262\u001b[0m  0.0370\n",
            "      9        \u001b[36m2.7563\u001b[0m  0.0375\n",
            "     10        \u001b[36m2.6864\u001b[0m  0.0385\n",
            "     11        \u001b[36m2.6166\u001b[0m  0.0362\n",
            "     12        \u001b[36m2.5469\u001b[0m  0.0421\n",
            "     13        \u001b[36m2.4772\u001b[0m  0.0464\n",
            "     14        \u001b[36m2.4076\u001b[0m  0.0422\n",
            "     15        \u001b[36m2.3382\u001b[0m  0.0406\n",
            "     16        \u001b[36m2.2688\u001b[0m  0.0403\n",
            "     17        \u001b[36m2.1997\u001b[0m  0.0379\n",
            "     18        \u001b[36m2.1307\u001b[0m  0.0398\n",
            "     19        \u001b[36m2.0619\u001b[0m  0.0363\n",
            "     20        \u001b[36m1.9935\u001b[0m  0.0365\n",
            "     21        \u001b[36m1.9253\u001b[0m  0.0379\n",
            "     22        \u001b[36m1.8576\u001b[0m  0.0376\n",
            "     23        \u001b[36m1.7904\u001b[0m  0.0392\n",
            "     24        \u001b[36m1.7237\u001b[0m  0.0404\n",
            "     25        \u001b[36m1.6576\u001b[0m  0.0527\n",
            "     26        \u001b[36m1.5924\u001b[0m  0.0363\n",
            "     27        \u001b[36m1.5281\u001b[0m  0.0357\n",
            "     28        \u001b[36m1.4649\u001b[0m  0.0358\n",
            "     29        \u001b[36m1.4029\u001b[0m  0.0345\n",
            "     30        \u001b[36m1.3424\u001b[0m  0.0350\n",
            "     31        \u001b[36m1.2836\u001b[0m  0.0352\n",
            "     32        \u001b[36m1.2268\u001b[0m  0.0386\n",
            "     33        \u001b[36m1.1721\u001b[0m  0.0354\n",
            "     34        \u001b[36m1.1198\u001b[0m  0.0383\n",
            "     35        \u001b[36m1.0702\u001b[0m  0.0386\n",
            "     36        \u001b[36m1.0234\u001b[0m  0.0434\n",
            "     37        \u001b[36m0.9798\u001b[0m  0.0475\n",
            "     38        \u001b[36m0.9394\u001b[0m  0.0453\n",
            "     39        \u001b[36m0.9023\u001b[0m  0.0480\n",
            "     40        \u001b[36m0.8687\u001b[0m  0.0412\n",
            "     41        \u001b[36m0.8386\u001b[0m  0.0412\n",
            "     42        \u001b[36m0.8117\u001b[0m  0.0393\n",
            "     43        \u001b[36m0.7881\u001b[0m  0.0415\n",
            "     44        \u001b[36m0.7675\u001b[0m  0.0370\n",
            "     45        \u001b[36m0.7497\u001b[0m  0.0387\n",
            "     46        \u001b[36m0.7345\u001b[0m  0.0409\n",
            "     47        \u001b[36m0.7216\u001b[0m  0.0423\n",
            "     48        \u001b[36m0.7107\u001b[0m  0.0411\n",
            "     49        \u001b[36m0.7017\u001b[0m  0.0474\n",
            "     50        \u001b[36m0.6941\u001b[0m  0.0393\n",
            "     51        \u001b[36m0.6879\u001b[0m  0.0418\n",
            "     52        \u001b[36m0.6828\u001b[0m  0.0524\n",
            "     53        \u001b[36m0.6786\u001b[0m  0.0537\n",
            "     54        \u001b[36m0.6752\u001b[0m  0.0433\n",
            "     55        \u001b[36m0.6724\u001b[0m  0.0385\n",
            "     56        \u001b[36m0.6702\u001b[0m  0.0418\n",
            "     57        \u001b[36m0.6684\u001b[0m  0.0454\n",
            "     58        \u001b[36m0.6670\u001b[0m  0.0449\n",
            "     59        \u001b[36m0.6658\u001b[0m  0.0436\n",
            "     60        \u001b[36m0.6649\u001b[0m  0.0417\n",
            "     61        \u001b[36m0.6641\u001b[0m  0.0375\n",
            "     62        \u001b[36m0.6636\u001b[0m  0.0429\n",
            "     63        \u001b[36m0.6631\u001b[0m  0.0394\n",
            "     64        \u001b[36m0.6627\u001b[0m  0.0417\n",
            "     65        \u001b[36m0.6624\u001b[0m  0.0423\n",
            "     66        \u001b[36m0.6622\u001b[0m  0.0426\n",
            "     67        \u001b[36m0.6620\u001b[0m  0.0408\n",
            "     68        \u001b[36m0.6619\u001b[0m  0.0395\n",
            "     69        \u001b[36m0.6618\u001b[0m  0.0299\n",
            "     70        \u001b[36m0.6617\u001b[0m  0.0288\n",
            "     71        \u001b[36m0.6616\u001b[0m  0.0297\n",
            "     72        \u001b[36m0.6615\u001b[0m  0.0318\n",
            "     73        \u001b[36m0.6615\u001b[0m  0.0361\n",
            "     74        \u001b[36m0.6615\u001b[0m  0.0344\n",
            "     75        \u001b[36m0.6614\u001b[0m  0.0290\n",
            "     76        \u001b[36m0.6614\u001b[0m  0.0293\n",
            "     77        \u001b[36m0.6614\u001b[0m  0.0300\n",
            "     78        \u001b[36m0.6614\u001b[0m  0.0300\n",
            "     79        \u001b[36m0.6614\u001b[0m  0.0290\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0302\n",
            "     81        \u001b[36m0.6614\u001b[0m  0.0319\n",
            "     82        \u001b[36m0.6614\u001b[0m  0.0318\n",
            "     83        \u001b[36m0.6614\u001b[0m  0.0307\n",
            "     84        \u001b[36m0.6614\u001b[0m  0.0375\n",
            "     85        \u001b[36m0.6614\u001b[0m  0.0398\n",
            "     86        \u001b[36m0.6614\u001b[0m  0.0338\n",
            "     87        \u001b[36m0.6614\u001b[0m  0.0315\n",
            "     88        \u001b[36m0.6614\u001b[0m  0.0292\n",
            "     89        0.6614  0.0306\n",
            "     90        0.6614  0.0304\n",
            "     91        0.6614  0.0304\n",
            "     92        0.6614  0.0311\n",
            "     93        0.6614  0.0325\n",
            "     94        0.6614  0.0323\n",
            "     95        0.6614  0.0310\n",
            "     96        0.6614  0.0305\n",
            "     97        0.6614  0.0309\n",
            "     98        0.6614  0.0314\n",
            "     99        0.6614  0.0314\n",
            "    100        0.6614  0.0304\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.5141\u001b[0m  0.0265\n",
            "      2        \u001b[36m2.4475\u001b[0m  0.0305\n",
            "      3        \u001b[36m2.3811\u001b[0m  0.0462\n",
            "      4        \u001b[36m2.3147\u001b[0m  0.0293\n",
            "      5        \u001b[36m2.2485\u001b[0m  0.0309\n",
            "      6        \u001b[36m2.1824\u001b[0m  0.0287\n",
            "      7        \u001b[36m2.1166\u001b[0m  0.0330\n",
            "      8        \u001b[36m2.0509\u001b[0m  0.0297\n",
            "      9        \u001b[36m1.9855\u001b[0m  0.0288\n",
            "     10        \u001b[36m1.9204\u001b[0m  0.0307\n",
            "     11        \u001b[36m1.8557\u001b[0m  0.0295\n",
            "     12        \u001b[36m1.7915\u001b[0m  0.0346\n",
            "     13        \u001b[36m1.7277\u001b[0m  0.0409\n",
            "     14        \u001b[36m1.6646\u001b[0m  0.0365\n",
            "     15        \u001b[36m1.6022\u001b[0m  0.0382\n",
            "     16        \u001b[36m1.5406\u001b[0m  0.0453\n",
            "     17        \u001b[36m1.4800\u001b[0m  0.0300\n",
            "     18        \u001b[36m1.4205\u001b[0m  0.0313\n",
            "     19        \u001b[36m1.3624\u001b[0m  0.0304\n",
            "     20        \u001b[36m1.3057\u001b[0m  0.0322\n",
            "     21        \u001b[36m1.2508\u001b[0m  0.0315\n",
            "     22        \u001b[36m1.1977\u001b[0m  0.0329\n",
            "     23        \u001b[36m1.1468\u001b[0m  0.0317\n",
            "     24        \u001b[36m1.0982\u001b[0m  0.0331\n",
            "     25        \u001b[36m1.0521\u001b[0m  0.0327\n",
            "     26        \u001b[36m1.0088\u001b[0m  0.0317\n",
            "     27        \u001b[36m0.9684\u001b[0m  0.0329\n",
            "     28        \u001b[36m0.9310\u001b[0m  0.0301\n",
            "     29        \u001b[36m0.8967\u001b[0m  0.0297\n",
            "     30        \u001b[36m0.8655\u001b[0m  0.0327\n",
            "     31        \u001b[36m0.8374\u001b[0m  0.0295\n",
            "     32        \u001b[36m0.8124\u001b[0m  0.0367\n",
            "     33        \u001b[36m0.7902\u001b[0m  0.0374\n",
            "     34        \u001b[36m0.7707\u001b[0m  0.0330\n",
            "     35        \u001b[36m0.7538\u001b[0m  0.0315\n",
            "     36        \u001b[36m0.7392\u001b[0m  0.0324\n",
            "     37        \u001b[36m0.7267\u001b[0m  0.0297\n",
            "     38        \u001b[36m0.7160\u001b[0m  0.0322\n",
            "     39        \u001b[36m0.7069\u001b[0m  0.0302\n",
            "     40        \u001b[36m0.6993\u001b[0m  0.0326\n",
            "     41        \u001b[36m0.6929\u001b[0m  0.0336\n",
            "     42        \u001b[36m0.6876\u001b[0m  0.0407\n",
            "     43        \u001b[36m0.6831\u001b[0m  0.0403\n",
            "     44        \u001b[36m0.6794\u001b[0m  0.0363\n",
            "     45        \u001b[36m0.6763\u001b[0m  0.0302\n",
            "     46        \u001b[36m0.6738\u001b[0m  0.0322\n",
            "     47        \u001b[36m0.6717\u001b[0m  0.0342\n",
            "     48        \u001b[36m0.6699\u001b[0m  0.0322\n",
            "     49        \u001b[36m0.6685\u001b[0m  0.0365\n",
            "     50        \u001b[36m0.6673\u001b[0m  0.0359\n",
            "     51        \u001b[36m0.6663\u001b[0m  0.0331\n",
            "     52        \u001b[36m0.6655\u001b[0m  0.0321\n",
            "     53        \u001b[36m0.6648\u001b[0m  0.0351\n",
            "     54        \u001b[36m0.6642\u001b[0m  0.0302\n",
            "     55        \u001b[36m0.6637\u001b[0m  0.0311\n",
            "     56        \u001b[36m0.6633\u001b[0m  0.0318\n",
            "     57        \u001b[36m0.6630\u001b[0m  0.0309\n",
            "     58        \u001b[36m0.6627\u001b[0m  0.0344\n",
            "     59        \u001b[36m0.6625\u001b[0m  0.0299\n",
            "     60        \u001b[36m0.6623\u001b[0m  0.0340\n",
            "     61        \u001b[36m0.6621\u001b[0m  0.0305\n",
            "     62        \u001b[36m0.6620\u001b[0m  0.0424\n",
            "     63        \u001b[36m0.6618\u001b[0m  0.0292\n",
            "     64        \u001b[36m0.6617\u001b[0m  0.0314\n",
            "     65        \u001b[36m0.6617\u001b[0m  0.0319\n",
            "     66        \u001b[36m0.6616\u001b[0m  0.0296\n",
            "     67        \u001b[36m0.6615\u001b[0m  0.0330\n",
            "     68        \u001b[36m0.6615\u001b[0m  0.0295\n",
            "     69        \u001b[36m0.6614\u001b[0m  0.0338\n",
            "     70        \u001b[36m0.6614\u001b[0m  0.0373\n",
            "     71        \u001b[36m0.6613\u001b[0m  0.0399\n",
            "     72        \u001b[36m0.6613\u001b[0m  0.0382\n",
            "     73        \u001b[36m0.6613\u001b[0m  0.0351\n",
            "     74        \u001b[36m0.6612\u001b[0m  0.0298\n",
            "     75        \u001b[36m0.6612\u001b[0m  0.0305\n",
            "     76        \u001b[36m0.6612\u001b[0m  0.0295\n",
            "     77        \u001b[36m0.6612\u001b[0m  0.0318\n",
            "     78        \u001b[36m0.6612\u001b[0m  0.0281\n",
            "     79        \u001b[36m0.6612\u001b[0m  0.0315\n",
            "     80        \u001b[36m0.6611\u001b[0m  0.0301\n",
            "     81        \u001b[36m0.6611\u001b[0m  0.0318\n",
            "     82        \u001b[36m0.6611\u001b[0m  0.0310\n",
            "     83        \u001b[36m0.6611\u001b[0m  0.0304\n",
            "     84        \u001b[36m0.6611\u001b[0m  0.0281\n",
            "     85        \u001b[36m0.6611\u001b[0m  0.0302\n",
            "     86        \u001b[36m0.6611\u001b[0m  0.0283\n",
            "     87        \u001b[36m0.6611\u001b[0m  0.0307\n",
            "     88        \u001b[36m0.6611\u001b[0m  0.0292\n",
            "     89        \u001b[36m0.6611\u001b[0m  0.0310\n",
            "     90        \u001b[36m0.6611\u001b[0m  0.0300\n",
            "     91        \u001b[36m0.6611\u001b[0m  0.0308\n",
            "     92        \u001b[36m0.6611\u001b[0m  0.0288\n",
            "     93        \u001b[36m0.6611\u001b[0m  0.0390\n",
            "     94        \u001b[36m0.6611\u001b[0m  0.0287\n",
            "     95        \u001b[36m0.6611\u001b[0m  0.0310\n",
            "     96        \u001b[36m0.6611\u001b[0m  0.0290\n",
            "     97        \u001b[36m0.6611\u001b[0m  0.0332\n",
            "     98        \u001b[36m0.6611\u001b[0m  0.0284\n",
            "     99        \u001b[36m0.6611\u001b[0m  0.0314\n",
            "    100        \u001b[36m0.6611\u001b[0m  0.0366\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7767\u001b[0m  0.0461\n",
            "      2        \u001b[36m0.7599\u001b[0m  0.0452\n",
            "      3        \u001b[36m0.7452\u001b[0m  0.0396\n",
            "      4        \u001b[36m0.7326\u001b[0m  0.0425\n",
            "      5        \u001b[36m0.7225\u001b[0m  0.0391\n",
            "      6        \u001b[36m0.7059\u001b[0m  0.0412\n",
            "      7        \u001b[36m0.7029\u001b[0m  0.0399\n",
            "      8        \u001b[36m0.6911\u001b[0m  0.0401\n",
            "      9        \u001b[36m0.6836\u001b[0m  0.0397\n",
            "     10        \u001b[36m0.6737\u001b[0m  0.0400\n",
            "     11        \u001b[36m0.6639\u001b[0m  0.0400\n",
            "     12        \u001b[36m0.6554\u001b[0m  0.0421\n",
            "     13        \u001b[36m0.6492\u001b[0m  0.0386\n",
            "     14        \u001b[36m0.6410\u001b[0m  0.0400\n",
            "     15        \u001b[36m0.6315\u001b[0m  0.0386\n",
            "     16        \u001b[36m0.6250\u001b[0m  0.0392\n",
            "     17        \u001b[36m0.6186\u001b[0m  0.0375\n",
            "     18        \u001b[36m0.6138\u001b[0m  0.0505\n",
            "     19        \u001b[36m0.6087\u001b[0m  0.0401\n",
            "     20        \u001b[36m0.6050\u001b[0m  0.0392\n",
            "     21        \u001b[36m0.6037\u001b[0m  0.0403\n",
            "     22        \u001b[36m0.5983\u001b[0m  0.0389\n",
            "     23        \u001b[36m0.5962\u001b[0m  0.0468\n",
            "     24        0.5965  0.0503\n",
            "     25        \u001b[36m0.5941\u001b[0m  0.0393\n",
            "     26        \u001b[36m0.5923\u001b[0m  0.0399\n",
            "     27        \u001b[36m0.5909\u001b[0m  0.0396\n",
            "     28        \u001b[36m0.5890\u001b[0m  0.0440\n",
            "     29        \u001b[36m0.5872\u001b[0m  0.0403\n",
            "     30        \u001b[36m0.5855\u001b[0m  0.0410\n",
            "     31        \u001b[36m0.5853\u001b[0m  0.0380\n",
            "     32        \u001b[36m0.5837\u001b[0m  0.0403\n",
            "     33        \u001b[36m0.5806\u001b[0m  0.0389\n",
            "     34        \u001b[36m0.5797\u001b[0m  0.0430\n",
            "     35        0.5817  0.0410\n",
            "     36        \u001b[36m0.5755\u001b[0m  0.0373\n",
            "     37        \u001b[36m0.5738\u001b[0m  0.0422\n",
            "     38        \u001b[36m0.5727\u001b[0m  0.0452\n",
            "     39        \u001b[36m0.5717\u001b[0m  0.0444\n",
            "     40        \u001b[36m0.5707\u001b[0m  0.0385\n",
            "     41        \u001b[36m0.5697\u001b[0m  0.0386\n",
            "     42        \u001b[36m0.5689\u001b[0m  0.0478\n",
            "     43        \u001b[36m0.5667\u001b[0m  0.0397\n",
            "     44        \u001b[36m0.5658\u001b[0m  0.0384\n",
            "     45        0.5661  0.0402\n",
            "     46        \u001b[36m0.5655\u001b[0m  0.0452\n",
            "     47        \u001b[36m0.5648\u001b[0m  0.0530\n",
            "     48        \u001b[36m0.5642\u001b[0m  0.0463\n",
            "     49        \u001b[36m0.5640\u001b[0m  0.0399\n",
            "     50        \u001b[36m0.5620\u001b[0m  0.0385\n",
            "     51        \u001b[36m0.5614\u001b[0m  0.0407\n",
            "     52        \u001b[36m0.5605\u001b[0m  0.0381\n",
            "     53        \u001b[36m0.5596\u001b[0m  0.0406\n",
            "     54        \u001b[36m0.5581\u001b[0m  0.0392\n",
            "     55        \u001b[36m0.5574\u001b[0m  0.0394\n",
            "     56        \u001b[36m0.5568\u001b[0m  0.0393\n",
            "     57        \u001b[36m0.5562\u001b[0m  0.0390\n",
            "     58        \u001b[36m0.5555\u001b[0m  0.0393\n",
            "     59        \u001b[36m0.5549\u001b[0m  0.0391\n",
            "     60        \u001b[36m0.5527\u001b[0m  0.0368\n",
            "     61        \u001b[36m0.5515\u001b[0m  0.0427\n",
            "     62        \u001b[36m0.5510\u001b[0m  0.0381\n",
            "     63        \u001b[36m0.5505\u001b[0m  0.0483\n",
            "     64        \u001b[36m0.5500\u001b[0m  0.0513\n",
            "     65        \u001b[36m0.5496\u001b[0m  0.0434\n",
            "     66        \u001b[36m0.5491\u001b[0m  0.0437\n",
            "     67        \u001b[36m0.5487\u001b[0m  0.0424\n",
            "     68        \u001b[36m0.5483\u001b[0m  0.0383\n",
            "     69        \u001b[36m0.5479\u001b[0m  0.0481\n",
            "     70        \u001b[36m0.5475\u001b[0m  0.0505\n",
            "     71        \u001b[36m0.5471\u001b[0m  0.0453\n",
            "     72        \u001b[36m0.5467\u001b[0m  0.0384\n",
            "     73        \u001b[36m0.5463\u001b[0m  0.0405\n",
            "     74        \u001b[36m0.5459\u001b[0m  0.0398\n",
            "     75        \u001b[36m0.5456\u001b[0m  0.0412\n",
            "     76        \u001b[36m0.5452\u001b[0m  0.0397\n",
            "     77        \u001b[36m0.5449\u001b[0m  0.0383\n",
            "     78        \u001b[36m0.5445\u001b[0m  0.0421\n",
            "     79        \u001b[36m0.5442\u001b[0m  0.0396\n",
            "     80        \u001b[36m0.5439\u001b[0m  0.0402\n",
            "     81        \u001b[36m0.5436\u001b[0m  0.0411\n",
            "     82        \u001b[36m0.5432\u001b[0m  0.0387\n",
            "     83        0.5443  0.0401\n",
            "     84        \u001b[36m0.5426\u001b[0m  0.0410\n",
            "     85        0.5437  0.0383\n",
            "     86        0.5434  0.0394\n",
            "     87        0.5431  0.0410\n",
            "     88        0.5428  0.0405\n",
            "     89        \u001b[36m0.5426\u001b[0m  0.0459\n",
            "     90        \u001b[36m0.5423\u001b[0m  0.0388\n",
            "     91        \u001b[36m0.5420\u001b[0m  0.0393\n",
            "     92        \u001b[36m0.5417\u001b[0m  0.0463\n",
            "     93        \u001b[36m0.5415\u001b[0m  0.0489\n",
            "     94        \u001b[36m0.5410\u001b[0m  0.0460\n",
            "     95        \u001b[36m0.5390\u001b[0m  0.0386\n",
            "     96        \u001b[36m0.5346\u001b[0m  0.0399\n",
            "     97        0.5387  0.0385\n",
            "     98        0.5384  0.0389\n",
            "     99        0.5381  0.0383\n",
            "    100        0.5378  0.0445\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6906\u001b[0m  0.0352\n",
            "      2        \u001b[36m0.6742\u001b[0m  0.0416\n",
            "      3        \u001b[36m0.6688\u001b[0m  0.0379\n",
            "      4        \u001b[36m0.6599\u001b[0m  0.0409\n",
            "      5        \u001b[36m0.6556\u001b[0m  0.0380\n",
            "      6        \u001b[36m0.6519\u001b[0m  0.0386\n",
            "      7        \u001b[36m0.6486\u001b[0m  0.0385\n",
            "      8        \u001b[36m0.6457\u001b[0m  0.0417\n",
            "      9        0.6458  0.0380\n",
            "     10        \u001b[36m0.6421\u001b[0m  0.0400\n",
            "     11        \u001b[36m0.6382\u001b[0m  0.0373\n",
            "     12        \u001b[36m0.6364\u001b[0m  0.0407\n",
            "     13        \u001b[36m0.6350\u001b[0m  0.0472\n",
            "     14        \u001b[36m0.6336\u001b[0m  0.0385\n",
            "     15        0.6350  0.0384\n",
            "     16        0.6393  0.0511\n",
            "     17        0.6393  0.0486\n",
            "     18        0.6380  0.0373\n",
            "     19        0.6368  0.0399\n",
            "     20        0.6370  0.0403\n",
            "     21        0.6393  0.0406\n",
            "     22        0.6375  0.0397\n",
            "     23        0.6360  0.0412\n",
            "     24        0.6361  0.0383\n",
            "     25        0.6340  0.0391\n",
            "     26        \u001b[36m0.6332\u001b[0m  0.0398\n",
            "     27        \u001b[36m0.6317\u001b[0m  0.0507\n",
            "     28        \u001b[36m0.6283\u001b[0m  0.0596\n",
            "     29        \u001b[36m0.6276\u001b[0m  0.0582\n",
            "     30        \u001b[36m0.6270\u001b[0m  0.0540\n",
            "     31        \u001b[36m0.6264\u001b[0m  0.0512\n",
            "     32        \u001b[36m0.6258\u001b[0m  0.0585\n",
            "     33        \u001b[36m0.6253\u001b[0m  0.0514\n",
            "     34        \u001b[36m0.6248\u001b[0m  0.0641\n",
            "     35        \u001b[36m0.6243\u001b[0m  0.0500\n",
            "     36        \u001b[36m0.6224\u001b[0m  0.0631\n",
            "     37        \u001b[36m0.6214\u001b[0m  0.0585\n",
            "     38        \u001b[36m0.6209\u001b[0m  0.0625\n",
            "     39        \u001b[36m0.6204\u001b[0m  0.0487\n",
            "     40        \u001b[36m0.6200\u001b[0m  0.0522\n",
            "     41        \u001b[36m0.6196\u001b[0m  0.0501\n",
            "     42        \u001b[36m0.6193\u001b[0m  0.0488\n",
            "     43        \u001b[36m0.6187\u001b[0m  0.0500\n",
            "     44        0.6191  0.0584\n",
            "     45        0.6201  0.0526\n",
            "     46        0.6199  0.0489\n",
            "     47        0.6196  0.0528\n",
            "     48        0.6193  0.0509\n",
            "     49        0.6190  0.0508\n",
            "     50        0.6188  0.0486\n",
            "     51        \u001b[36m0.6185\u001b[0m  0.0477\n",
            "     52        \u001b[36m0.6182\u001b[0m  0.0521\n",
            "     53        \u001b[36m0.6179\u001b[0m  0.0622\n",
            "     54        \u001b[36m0.6177\u001b[0m  0.0560\n",
            "     55        \u001b[36m0.6174\u001b[0m  0.0623\n",
            "     56        \u001b[36m0.6171\u001b[0m  0.0577\n",
            "     57        \u001b[36m0.6169\u001b[0m  0.0523\n",
            "     58        \u001b[36m0.6166\u001b[0m  0.0532\n",
            "     59        \u001b[36m0.6163\u001b[0m  0.0517\n",
            "     60        \u001b[36m0.6161\u001b[0m  0.0482\n",
            "     61        \u001b[36m0.6158\u001b[0m  0.0532\n",
            "     62        \u001b[36m0.6155\u001b[0m  0.0553\n",
            "     63        \u001b[36m0.6153\u001b[0m  0.0578\n",
            "     64        \u001b[36m0.6150\u001b[0m  0.0515\n",
            "     65        \u001b[36m0.6147\u001b[0m  0.0572\n",
            "     66        \u001b[36m0.6145\u001b[0m  0.0564\n",
            "     67        \u001b[36m0.6142\u001b[0m  0.0565\n",
            "     68        \u001b[36m0.6140\u001b[0m  0.0539\n",
            "     69        \u001b[36m0.6137\u001b[0m  0.0519\n",
            "     70        \u001b[36m0.6135\u001b[0m  0.0509\n",
            "     71        \u001b[36m0.6132\u001b[0m  0.0815\n",
            "     72        \u001b[36m0.6130\u001b[0m  0.0538\n",
            "     73        \u001b[36m0.6127\u001b[0m  0.0593\n",
            "     74        \u001b[36m0.6125\u001b[0m  0.0579\n",
            "     75        \u001b[36m0.6122\u001b[0m  0.0606\n",
            "     76        \u001b[36m0.6119\u001b[0m  0.0426\n",
            "     77        \u001b[36m0.6116\u001b[0m  0.0388\n",
            "     78        \u001b[36m0.6114\u001b[0m  0.0395\n",
            "     79        \u001b[36m0.6111\u001b[0m  0.0412\n",
            "     80        \u001b[36m0.6103\u001b[0m  0.0412\n",
            "     81        \u001b[36m0.6022\u001b[0m  0.0442\n",
            "     82        0.6111  0.0395\n",
            "     83        0.6063  0.0413\n",
            "     84        0.6058  0.0394\n",
            "     85        0.6055  0.0399\n",
            "     86        0.6053  0.0396\n",
            "     87        0.6050  0.0394\n",
            "     88        0.6048  0.0414\n",
            "     89        0.6045  0.0429\n",
            "     90        0.6043  0.0412\n",
            "     91        0.6041  0.0518\n",
            "     92        0.6039  0.0648\n",
            "     93        0.6038  0.0484\n",
            "     94        0.6036  0.0404\n",
            "     95        0.6034  0.0412\n",
            "     96        0.6032  0.0398\n",
            "     97        0.6031  0.0389\n",
            "     98        0.6029  0.0409\n",
            "     99        0.6028  0.0427\n",
            "    100        0.6026  0.0403\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9342\u001b[0m  0.0274\n",
            "      2        \u001b[36m0.9176\u001b[0m  0.0295\n",
            "      3        \u001b[36m0.9032\u001b[0m  0.0327\n",
            "      4        \u001b[36m0.8897\u001b[0m  0.0288\n",
            "      5        \u001b[36m0.8771\u001b[0m  0.0302\n",
            "      6        \u001b[36m0.8654\u001b[0m  0.0287\n",
            "      7        \u001b[36m0.8544\u001b[0m  0.0303\n",
            "      8        \u001b[36m0.8442\u001b[0m  0.0302\n",
            "      9        \u001b[36m0.8346\u001b[0m  0.0313\n",
            "     10        \u001b[36m0.8257\u001b[0m  0.0292\n",
            "     11        \u001b[36m0.8173\u001b[0m  0.0339\n",
            "     12        \u001b[36m0.8095\u001b[0m  0.0332\n",
            "     13        \u001b[36m0.8023\u001b[0m  0.0320\n",
            "     14        \u001b[36m0.7955\u001b[0m  0.0307\n",
            "     15        \u001b[36m0.7891\u001b[0m  0.0308\n",
            "     16        \u001b[36m0.7831\u001b[0m  0.0296\n",
            "     17        \u001b[36m0.7775\u001b[0m  0.0363\n",
            "     18        \u001b[36m0.7723\u001b[0m  0.0405\n",
            "     19        \u001b[36m0.7674\u001b[0m  0.0393\n",
            "     20        \u001b[36m0.7628\u001b[0m  0.0429\n",
            "     21        \u001b[36m0.7584\u001b[0m  0.0292\n",
            "     22        \u001b[36m0.7543\u001b[0m  0.0303\n",
            "     23        \u001b[36m0.7504\u001b[0m  0.0297\n",
            "     24        \u001b[36m0.7468\u001b[0m  0.0318\n",
            "     25        \u001b[36m0.7433\u001b[0m  0.0307\n",
            "     26        \u001b[36m0.7400\u001b[0m  0.0303\n",
            "     27        \u001b[36m0.7369\u001b[0m  0.0310\n",
            "     28        \u001b[36m0.7350\u001b[0m  0.0304\n",
            "     29        \u001b[36m0.7321\u001b[0m  0.0330\n",
            "     30        \u001b[36m0.7292\u001b[0m  0.0289\n",
            "     31        \u001b[36m0.7266\u001b[0m  0.0315\n",
            "     32        \u001b[36m0.7240\u001b[0m  0.0285\n",
            "     33        \u001b[36m0.7215\u001b[0m  0.0302\n",
            "     34        \u001b[36m0.7192\u001b[0m  0.0287\n",
            "     35        \u001b[36m0.7169\u001b[0m  0.0290\n",
            "     36        \u001b[36m0.7148\u001b[0m  0.0308\n",
            "     37        \u001b[36m0.7127\u001b[0m  0.0300\n",
            "     38        \u001b[36m0.7107\u001b[0m  0.0339\n",
            "     39        \u001b[36m0.7087\u001b[0m  0.0328\n",
            "     40        \u001b[36m0.7069\u001b[0m  0.0301\n",
            "     41        \u001b[36m0.7051\u001b[0m  0.0298\n",
            "     42        \u001b[36m0.7033\u001b[0m  0.0282\n",
            "     43        \u001b[36m0.7016\u001b[0m  0.0310\n",
            "     44        \u001b[36m0.7000\u001b[0m  0.0287\n",
            "     45        \u001b[36m0.6984\u001b[0m  0.0311\n",
            "     46        \u001b[36m0.6968\u001b[0m  0.0286\n",
            "     47        \u001b[36m0.6953\u001b[0m  0.0333\n",
            "     48        \u001b[36m0.6939\u001b[0m  0.0377\n",
            "     49        \u001b[36m0.6925\u001b[0m  0.0414\n",
            "     50        \u001b[36m0.6911\u001b[0m  0.0381\n",
            "     51        \u001b[36m0.6897\u001b[0m  0.0388\n",
            "     52        \u001b[36m0.6884\u001b[0m  0.0298\n",
            "     53        \u001b[36m0.6871\u001b[0m  0.0298\n",
            "     54        \u001b[36m0.6859\u001b[0m  0.0296\n",
            "     55        \u001b[36m0.6846\u001b[0m  0.0311\n",
            "     56        \u001b[36m0.6834\u001b[0m  0.0326\n",
            "     57        \u001b[36m0.6823\u001b[0m  0.0310\n",
            "     58        \u001b[36m0.6811\u001b[0m  0.0317\n",
            "     59        \u001b[36m0.6800\u001b[0m  0.0311\n",
            "     60        \u001b[36m0.6789\u001b[0m  0.0313\n",
            "     61        \u001b[36m0.6778\u001b[0m  0.0319\n",
            "     62        \u001b[36m0.6768\u001b[0m  0.0304\n",
            "     63        \u001b[36m0.6757\u001b[0m  0.0343\n",
            "     64        \u001b[36m0.6747\u001b[0m  0.0291\n",
            "     65        \u001b[36m0.6737\u001b[0m  0.0325\n",
            "     66        \u001b[36m0.6727\u001b[0m  0.0325\n",
            "     67        \u001b[36m0.6718\u001b[0m  0.0294\n",
            "     68        \u001b[36m0.6708\u001b[0m  0.0331\n",
            "     69        \u001b[36m0.6699\u001b[0m  0.0310\n",
            "     70        \u001b[36m0.6690\u001b[0m  0.0326\n",
            "     71        \u001b[36m0.6681\u001b[0m  0.0290\n",
            "     72        \u001b[36m0.6672\u001b[0m  0.0311\n",
            "     73        \u001b[36m0.6664\u001b[0m  0.0300\n",
            "     74        \u001b[36m0.6655\u001b[0m  0.0320\n",
            "     75        \u001b[36m0.6647\u001b[0m  0.0287\n",
            "     76        \u001b[36m0.6639\u001b[0m  0.0293\n",
            "     77        \u001b[36m0.6631\u001b[0m  0.0370\n",
            "     78        \u001b[36m0.6623\u001b[0m  0.0375\n",
            "     79        \u001b[36m0.6615\u001b[0m  0.0370\n",
            "     80        \u001b[36m0.6608\u001b[0m  0.0352\n",
            "     81        \u001b[36m0.6600\u001b[0m  0.0410\n",
            "     82        \u001b[36m0.6593\u001b[0m  0.0280\n",
            "     83        \u001b[36m0.6586\u001b[0m  0.0300\n",
            "     84        \u001b[36m0.6579\u001b[0m  0.0288\n",
            "     85        \u001b[36m0.6572\u001b[0m  0.0301\n",
            "     86        \u001b[36m0.6565\u001b[0m  0.0302\n",
            "     87        \u001b[36m0.6558\u001b[0m  0.0295\n",
            "     88        \u001b[36m0.6552\u001b[0m  0.0320\n",
            "     89        \u001b[36m0.6545\u001b[0m  0.0290\n",
            "     90        \u001b[36m0.6539\u001b[0m  0.0293\n",
            "     91        \u001b[36m0.6533\u001b[0m  0.0289\n",
            "     92        \u001b[36m0.6527\u001b[0m  0.0330\n",
            "     93        \u001b[36m0.6521\u001b[0m  0.0311\n",
            "     94        \u001b[36m0.6515\u001b[0m  0.0313\n",
            "     95        \u001b[36m0.6509\u001b[0m  0.0309\n",
            "     96        \u001b[36m0.6503\u001b[0m  0.0315\n",
            "     97        \u001b[36m0.6498\u001b[0m  0.0327\n",
            "     98        \u001b[36m0.6492\u001b[0m  0.0312\n",
            "     99        \u001b[36m0.6487\u001b[0m  0.0310\n",
            "    100        \u001b[36m0.6481\u001b[0m  0.0290\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8353\u001b[0m  0.0261\n",
            "      2        \u001b[36m0.8145\u001b[0m  0.0307\n",
            "      3        \u001b[36m0.8025\u001b[0m  0.0308\n",
            "      4        \u001b[36m0.7938\u001b[0m  0.0296\n",
            "      5        \u001b[36m0.7875\u001b[0m  0.0304\n",
            "      6        \u001b[36m0.7829\u001b[0m  0.0290\n",
            "      7        \u001b[36m0.7796\u001b[0m  0.0415\n",
            "      8        \u001b[36m0.7771\u001b[0m  0.0377\n",
            "      9        \u001b[36m0.7751\u001b[0m  0.0383\n",
            "     10        \u001b[36m0.7735\u001b[0m  0.0301\n",
            "     11        \u001b[36m0.7721\u001b[0m  0.0352\n",
            "     12        \u001b[36m0.7709\u001b[0m  0.0365\n",
            "     13        \u001b[36m0.7698\u001b[0m  0.0324\n",
            "     14        \u001b[36m0.7688\u001b[0m  0.0297\n",
            "     15        \u001b[36m0.7677\u001b[0m  0.0313\n",
            "     16        \u001b[36m0.7667\u001b[0m  0.0292\n",
            "     17        \u001b[36m0.7657\u001b[0m  0.0314\n",
            "     18        \u001b[36m0.7648\u001b[0m  0.0304\n",
            "     19        \u001b[36m0.7638\u001b[0m  0.0316\n",
            "     20        \u001b[36m0.7628\u001b[0m  0.0297\n",
            "     21        \u001b[36m0.7611\u001b[0m  0.0316\n",
            "     22        0.7635  0.0288\n",
            "     23        0.7622  0.0311\n",
            "     24        0.7612  0.0288\n",
            "     25        \u001b[36m0.7602\u001b[0m  0.0315\n",
            "     26        \u001b[36m0.7592\u001b[0m  0.0300\n",
            "     27        \u001b[36m0.7582\u001b[0m  0.0365\n",
            "     28        \u001b[36m0.7572\u001b[0m  0.0300\n",
            "     29        \u001b[36m0.7562\u001b[0m  0.0327\n",
            "     30        \u001b[36m0.7552\u001b[0m  0.0292\n",
            "     31        \u001b[36m0.7543\u001b[0m  0.0306\n",
            "     32        \u001b[36m0.7533\u001b[0m  0.0299\n",
            "     33        \u001b[36m0.7524\u001b[0m  0.0301\n",
            "     34        \u001b[36m0.7514\u001b[0m  0.0310\n",
            "     35        \u001b[36m0.7505\u001b[0m  0.0293\n",
            "     36        \u001b[36m0.7496\u001b[0m  0.0330\n",
            "     37        \u001b[36m0.7487\u001b[0m  0.0385\n",
            "     38        \u001b[36m0.7478\u001b[0m  0.0427\n",
            "     39        \u001b[36m0.7469\u001b[0m  0.0365\n",
            "     40        \u001b[36m0.7460\u001b[0m  0.0304\n",
            "     41        \u001b[36m0.7451\u001b[0m  0.0295\n",
            "     42        \u001b[36m0.7443\u001b[0m  0.0366\n",
            "     43        \u001b[36m0.7434\u001b[0m  0.0310\n",
            "     44        \u001b[36m0.7426\u001b[0m  0.0314\n",
            "     45        \u001b[36m0.7418\u001b[0m  0.0310\n",
            "     46        \u001b[36m0.7409\u001b[0m  0.0336\n",
            "     47        \u001b[36m0.7401\u001b[0m  0.0322\n",
            "     48        \u001b[36m0.7393\u001b[0m  0.0285\n",
            "     49        \u001b[36m0.7385\u001b[0m  0.0298\n",
            "     50        \u001b[36m0.7378\u001b[0m  0.0293\n",
            "     51        \u001b[36m0.7370\u001b[0m  0.0309\n",
            "     52        \u001b[36m0.7362\u001b[0m  0.0302\n",
            "     53        \u001b[36m0.7355\u001b[0m  0.0299\n",
            "     54        \u001b[36m0.7347\u001b[0m  0.0332\n",
            "     55        \u001b[36m0.7340\u001b[0m  0.0309\n",
            "     56        \u001b[36m0.7332\u001b[0m  0.0322\n",
            "     57        \u001b[36m0.7325\u001b[0m  0.0306\n",
            "     58        \u001b[36m0.7318\u001b[0m  0.0293\n",
            "     59        \u001b[36m0.7311\u001b[0m  0.0322\n",
            "     60        \u001b[36m0.7304\u001b[0m  0.0292\n",
            "     61        \u001b[36m0.7297\u001b[0m  0.0305\n",
            "     62        \u001b[36m0.7290\u001b[0m  0.0307\n",
            "     63        \u001b[36m0.7283\u001b[0m  0.0307\n",
            "     64        \u001b[36m0.7277\u001b[0m  0.0295\n",
            "     65        \u001b[36m0.7270\u001b[0m  0.0297\n",
            "     66        \u001b[36m0.7263\u001b[0m  0.0335\n",
            "     67        \u001b[36m0.7257\u001b[0m  0.0389\n",
            "     68        \u001b[36m0.7250\u001b[0m  0.0371\n",
            "     69        \u001b[36m0.7244\u001b[0m  0.0406\n",
            "     70        \u001b[36m0.7238\u001b[0m  0.0312\n",
            "     71        \u001b[36m0.7232\u001b[0m  0.0333\n",
            "     72        \u001b[36m0.7226\u001b[0m  0.0302\n",
            "     73        \u001b[36m0.7219\u001b[0m  0.0399\n",
            "     74        \u001b[36m0.7213\u001b[0m  0.0294\n",
            "     75        \u001b[36m0.7208\u001b[0m  0.0315\n",
            "     76        \u001b[36m0.7202\u001b[0m  0.0303\n",
            "     77        \u001b[36m0.7196\u001b[0m  0.0326\n",
            "     78        \u001b[36m0.7190\u001b[0m  0.0324\n",
            "     79        \u001b[36m0.7184\u001b[0m  0.0297\n",
            "     80        \u001b[36m0.7179\u001b[0m  0.0307\n",
            "     81        \u001b[36m0.7173\u001b[0m  0.0335\n",
            "     82        \u001b[36m0.7168\u001b[0m  0.0354\n",
            "     83        \u001b[36m0.7162\u001b[0m  0.0293\n",
            "     84        \u001b[36m0.7157\u001b[0m  0.0320\n",
            "     85        \u001b[36m0.7152\u001b[0m  0.0288\n",
            "     86        \u001b[36m0.7146\u001b[0m  0.0317\n",
            "     87        \u001b[36m0.7141\u001b[0m  0.0296\n",
            "     88        \u001b[36m0.7136\u001b[0m  0.0311\n",
            "     89        \u001b[36m0.7131\u001b[0m  0.0288\n",
            "     90        \u001b[36m0.7126\u001b[0m  0.0334\n",
            "     91        \u001b[36m0.7121\u001b[0m  0.0295\n",
            "     92        \u001b[36m0.7116\u001b[0m  0.0316\n",
            "     93        \u001b[36m0.7111\u001b[0m  0.0304\n",
            "     94        \u001b[36m0.7106\u001b[0m  0.0318\n",
            "     95        \u001b[36m0.7101\u001b[0m  0.0307\n",
            "     96        \u001b[36m0.7096\u001b[0m  0.0391\n",
            "     97        \u001b[36m0.7092\u001b[0m  0.0390\n",
            "     98        \u001b[36m0.7087\u001b[0m  0.0412\n",
            "     99        \u001b[36m0.7082\u001b[0m  0.0323\n",
            "    100        \u001b[36m0.7078\u001b[0m  0.0292\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7401\u001b[0m  0.0356\n",
            "      2        \u001b[36m0.7046\u001b[0m  0.0466\n",
            "      3        \u001b[36m0.6583\u001b[0m  0.0433\n",
            "      4        \u001b[36m0.6212\u001b[0m  0.0389\n",
            "      5        \u001b[36m0.5899\u001b[0m  0.0411\n",
            "      6        \u001b[36m0.5837\u001b[0m  0.0396\n",
            "      7        \u001b[36m0.5688\u001b[0m  0.0418\n",
            "      8        \u001b[36m0.5669\u001b[0m  0.0393\n",
            "      9        \u001b[36m0.5625\u001b[0m  0.0382\n",
            "     10        \u001b[36m0.5575\u001b[0m  0.0387\n",
            "     11        0.5590  0.0390\n",
            "     12        \u001b[36m0.5573\u001b[0m  0.0402\n",
            "     13        \u001b[36m0.5545\u001b[0m  0.0411\n",
            "     14        \u001b[36m0.5502\u001b[0m  0.0414\n",
            "     15        \u001b[36m0.5495\u001b[0m  0.0410\n",
            "     16        0.5556  0.0368\n",
            "     17        0.5501  0.0410\n",
            "     18        \u001b[36m0.5476\u001b[0m  0.0389\n",
            "     19        \u001b[36m0.5428\u001b[0m  0.0394\n",
            "     20        \u001b[36m0.5414\u001b[0m  0.0520\n",
            "     21        0.5436  0.0485\n",
            "     22        \u001b[36m0.5413\u001b[0m  0.0422\n",
            "     23        \u001b[36m0.5401\u001b[0m  0.0393\n",
            "     24        \u001b[36m0.5391\u001b[0m  0.0405\n",
            "     25        \u001b[36m0.5381\u001b[0m  0.0398\n",
            "     26        \u001b[36m0.5360\u001b[0m  0.0399\n",
            "     27        \u001b[36m0.5346\u001b[0m  0.0481\n",
            "     28        \u001b[36m0.5339\u001b[0m  0.0425\n",
            "     29        \u001b[36m0.5336\u001b[0m  0.0424\n",
            "     30        \u001b[36m0.5329\u001b[0m  0.0380\n",
            "     31        \u001b[36m0.5323\u001b[0m  0.0409\n",
            "     32        \u001b[36m0.5317\u001b[0m  0.0401\n",
            "     33        \u001b[36m0.5311\u001b[0m  0.0408\n",
            "     34        \u001b[36m0.5305\u001b[0m  0.0413\n",
            "     35        \u001b[36m0.5300\u001b[0m  0.0408\n",
            "     36        \u001b[36m0.5294\u001b[0m  0.0403\n",
            "     37        \u001b[36m0.5289\u001b[0m  0.0385\n",
            "     38        \u001b[36m0.5285\u001b[0m  0.0420\n",
            "     39        \u001b[36m0.5281\u001b[0m  0.0390\n",
            "     40        0.5306  0.0414\n",
            "     41        0.5299  0.0415\n",
            "     42        0.5294  0.0398\n",
            "     43        0.5289  0.0532\n",
            "     44        0.5284  0.0495\n",
            "     45        \u001b[36m0.5280\u001b[0m  0.0464\n",
            "     46        \u001b[36m0.5277\u001b[0m  0.0406\n",
            "     47        0.5284  0.0424\n",
            "     48        0.5280  0.0412\n",
            "     49        \u001b[36m0.5276\u001b[0m  0.0421\n",
            "     50        \u001b[36m0.5273\u001b[0m  0.0537\n",
            "     51        \u001b[36m0.5272\u001b[0m  0.0577\n",
            "     52        \u001b[36m0.5269\u001b[0m  0.0578\n",
            "     53        \u001b[36m0.5266\u001b[0m  0.0623\n",
            "     54        \u001b[36m0.5263\u001b[0m  0.0577\n",
            "     55        \u001b[36m0.5260\u001b[0m  0.0657\n",
            "     56        \u001b[36m0.5248\u001b[0m  0.0509\n",
            "     57        \u001b[36m0.5246\u001b[0m  0.0576\n",
            "     58        \u001b[36m0.5242\u001b[0m  0.0517\n",
            "     59        \u001b[36m0.5240\u001b[0m  0.0600\n",
            "     60        \u001b[36m0.5238\u001b[0m  0.0531\n",
            "     61        0.5299  0.0568\n",
            "     62        0.5359  0.0637\n",
            "     63        0.5311  0.0524\n",
            "     64        0.5307  0.0498\n",
            "     65        0.5319  0.0495\n",
            "     66        0.5332  0.0480\n",
            "     67        0.5375  0.0526\n",
            "     68        0.5296  0.0596\n",
            "     69        0.5246  0.0485\n",
            "     70        0.5320  0.0496\n",
            "     71        0.5332  0.0466\n",
            "     72        0.5300  0.0485\n",
            "     73        0.5276  0.0484\n",
            "     74        0.5261  0.0516\n",
            "     75        0.5252  0.0506\n",
            "     76        0.5246  0.0466\n",
            "     77        0.5242  0.0495\n",
            "     78        \u001b[36m0.5237\u001b[0m  0.0559\n",
            "     79        0.5238  0.0589\n",
            "     80        \u001b[36m0.5233\u001b[0m  0.0673\n",
            "     81        \u001b[36m0.5228\u001b[0m  0.0565\n",
            "     82        \u001b[36m0.5224\u001b[0m  0.0508\n",
            "     83        \u001b[36m0.5220\u001b[0m  0.0491\n",
            "     84        \u001b[36m0.5216\u001b[0m  0.0541\n",
            "     85        \u001b[36m0.5213\u001b[0m  0.0553\n",
            "     86        \u001b[36m0.5210\u001b[0m  0.0656\n",
            "     87        \u001b[36m0.5207\u001b[0m  0.0568\n",
            "     88        \u001b[36m0.5204\u001b[0m  0.0562\n",
            "     89        \u001b[36m0.5180\u001b[0m  0.0519\n",
            "     90        \u001b[36m0.5177\u001b[0m  0.0567\n",
            "     91        \u001b[36m0.5174\u001b[0m  0.0559\n",
            "     92        \u001b[36m0.5171\u001b[0m  0.0525\n",
            "     93        \u001b[36m0.5168\u001b[0m  0.0510\n",
            "     94        \u001b[36m0.5165\u001b[0m  0.0520\n",
            "     95        \u001b[36m0.5160\u001b[0m  0.0566\n",
            "     96        \u001b[36m0.5151\u001b[0m  0.0571\n",
            "     97        0.5182  0.0603\n",
            "     98        0.5181  0.0568\n",
            "     99        0.5179  0.0573\n",
            "    100        0.5211  0.0591\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0435\u001b[0m  0.0550\n",
            "      2        \u001b[36m0.9116\u001b[0m  0.0415\n",
            "      3        \u001b[36m0.8474\u001b[0m  0.0389\n",
            "      4        \u001b[36m0.8072\u001b[0m  0.0510\n",
            "      5        \u001b[36m0.7864\u001b[0m  0.0451\n",
            "      6        \u001b[36m0.7699\u001b[0m  0.0417\n",
            "      7        \u001b[36m0.7575\u001b[0m  0.0396\n",
            "      8        \u001b[36m0.7363\u001b[0m  0.0388\n",
            "      9        \u001b[36m0.7276\u001b[0m  0.0403\n",
            "     10        \u001b[36m0.7202\u001b[0m  0.0380\n",
            "     11        \u001b[36m0.7137\u001b[0m  0.0381\n",
            "     12        \u001b[36m0.7054\u001b[0m  0.0385\n",
            "     13        \u001b[36m0.6948\u001b[0m  0.0390\n",
            "     14        \u001b[36m0.6869\u001b[0m  0.0385\n",
            "     15        \u001b[36m0.6824\u001b[0m  0.0398\n",
            "     16        0.6825  0.0388\n",
            "     17        \u001b[36m0.6688\u001b[0m  0.0531\n",
            "     18        \u001b[36m0.6664\u001b[0m  0.0539\n",
            "     19        \u001b[36m0.6577\u001b[0m  0.0382\n",
            "     20        \u001b[36m0.6549\u001b[0m  0.0416\n",
            "     21        \u001b[36m0.6512\u001b[0m  0.0392\n",
            "     22        0.6527  0.0397\n",
            "     23        \u001b[36m0.6383\u001b[0m  0.0381\n",
            "     24        0.6402  0.0410\n",
            "     25        0.6385  0.0385\n",
            "     26        \u001b[36m0.6304\u001b[0m  0.0388\n",
            "     27        \u001b[36m0.6284\u001b[0m  0.0395\n",
            "     28        \u001b[36m0.6262\u001b[0m  0.0513\n",
            "     29        \u001b[36m0.6241\u001b[0m  0.0397\n",
            "     30        \u001b[36m0.6219\u001b[0m  0.0401\n",
            "     31        \u001b[36m0.6090\u001b[0m  0.0401\n",
            "     32        \u001b[36m0.6070\u001b[0m  0.0384\n",
            "     33        \u001b[36m0.6059\u001b[0m  0.0384\n",
            "     34        \u001b[36m0.6041\u001b[0m  0.0425\n",
            "     35        0.6138  0.0397\n",
            "     36        0.6124  0.0410\n",
            "     37        \u001b[36m0.6000\u001b[0m  0.0407\n",
            "     38        \u001b[36m0.5972\u001b[0m  0.0415\n",
            "     39        \u001b[36m0.5959\u001b[0m  0.0400\n",
            "     40        \u001b[36m0.5946\u001b[0m  0.0503\n",
            "     41        \u001b[36m0.5934\u001b[0m  0.0528\n",
            "     42        \u001b[36m0.5922\u001b[0m  0.0421\n",
            "     43        \u001b[36m0.5911\u001b[0m  0.0453\n",
            "     44        \u001b[36m0.5899\u001b[0m  0.0379\n",
            "     45        \u001b[36m0.5865\u001b[0m  0.0384\n",
            "     46        \u001b[36m0.5836\u001b[0m  0.0380\n",
            "     47        \u001b[36m0.5777\u001b[0m  0.0443\n",
            "     48        0.7168  0.0411\n",
            "     49        0.6262  0.0386\n",
            "     50        0.6269  0.0412\n",
            "     51        0.6005  0.0401\n",
            "     52        0.5828  0.0506\n",
            "     53        0.5785  0.0375\n",
            "     54        \u001b[36m0.5765\u001b[0m  0.0389\n",
            "     55        \u001b[36m0.5749\u001b[0m  0.0406\n",
            "     56        \u001b[36m0.5736\u001b[0m  0.0410\n",
            "     57        \u001b[36m0.5725\u001b[0m  0.0382\n",
            "     58        \u001b[36m0.5715\u001b[0m  0.0400\n",
            "     59        \u001b[36m0.5705\u001b[0m  0.0378\n",
            "     60        \u001b[36m0.5696\u001b[0m  0.0402\n",
            "     61        \u001b[36m0.5687\u001b[0m  0.0410\n",
            "     62        \u001b[36m0.5678\u001b[0m  0.0409\n",
            "     63        \u001b[36m0.5670\u001b[0m  0.0462\n",
            "     64        \u001b[36m0.5663\u001b[0m  0.0527\n",
            "     65        \u001b[36m0.5655\u001b[0m  0.0444\n",
            "     66        \u001b[36m0.5224\u001b[0m  0.0414\n",
            "     67        0.8573  0.0389\n",
            "     68        0.6957  0.0410\n",
            "     69        0.6378  0.0407\n",
            "     70        0.6116  0.0430\n",
            "     71        0.5962  0.0432\n",
            "     72        0.5858  0.0400\n",
            "     73        0.5788  0.0431\n",
            "     74        0.5737  0.0389\n",
            "     75        0.5700  0.0439\n",
            "     76        0.5666  0.0402\n",
            "     77        0.5643  0.0387\n",
            "     78        0.5635  0.0394\n",
            "     79        0.5619  0.0406\n",
            "     80        0.5606  0.0381\n",
            "     81        0.5596  0.0413\n",
            "     82        0.6403  0.0395\n",
            "     83        0.5913  0.0416\n",
            "     84        0.5967  0.0402\n",
            "     85        0.5858  0.0418\n",
            "     86        0.5770  0.0463\n",
            "     87        0.5763  0.0531\n",
            "     88        0.5704  0.0466\n",
            "     89        0.5675  0.0434\n",
            "     90        0.5653  0.0391\n",
            "     91        0.5624  0.0404\n",
            "     92        0.5599  0.0392\n",
            "     93        0.5576  0.0423\n",
            "     94        0.5551  0.0399\n",
            "     95        0.5504  0.0416\n",
            "     96        0.5534  0.0389\n",
            "     97        0.5501  0.0432\n",
            "     98        0.5478  0.0441\n",
            "     99        0.5454  0.0478\n",
            "    100        0.5405  0.0426\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9545\u001b[0m  0.0259\n",
            "      2        \u001b[36m1.7860\u001b[0m  0.0294\n",
            "      3        \u001b[36m1.7243\u001b[0m  0.0304\n",
            "      4        \u001b[36m1.6616\u001b[0m  0.0308\n",
            "      5        \u001b[36m1.5977\u001b[0m  0.0301\n",
            "      6        \u001b[36m1.5325\u001b[0m  0.0296\n",
            "      7        \u001b[36m1.4663\u001b[0m  0.0277\n",
            "      8        \u001b[36m1.3997\u001b[0m  0.0304\n",
            "      9        \u001b[36m1.3335\u001b[0m  0.0292\n",
            "     10        \u001b[36m1.2688\u001b[0m  0.0298\n",
            "     11        \u001b[36m1.2071\u001b[0m  0.0325\n",
            "     12        \u001b[36m1.1498\u001b[0m  0.0376\n",
            "     13        \u001b[36m1.0984\u001b[0m  0.0366\n",
            "     14        \u001b[36m1.0535\u001b[0m  0.0329\n",
            "     15        \u001b[36m1.0153\u001b[0m  0.0306\n",
            "     16        \u001b[36m0.9831\u001b[0m  0.0334\n",
            "     17        \u001b[36m0.9562\u001b[0m  0.0305\n",
            "     18        \u001b[36m0.9334\u001b[0m  0.0294\n",
            "     19        \u001b[36m0.9139\u001b[0m  0.0271\n",
            "     20        \u001b[36m0.8971\u001b[0m  0.0328\n",
            "     21        \u001b[36m0.8822\u001b[0m  0.0335\n",
            "     22        \u001b[36m0.8690\u001b[0m  0.0338\n",
            "     23        \u001b[36m0.8571\u001b[0m  0.0286\n",
            "     24        \u001b[36m0.8463\u001b[0m  0.0311\n",
            "     25        \u001b[36m0.8365\u001b[0m  0.0289\n",
            "     26        \u001b[36m0.8275\u001b[0m  0.0312\n",
            "     27        \u001b[36m0.8192\u001b[0m  0.0301\n",
            "     28        \u001b[36m0.8114\u001b[0m  0.0306\n",
            "     29        \u001b[36m0.8043\u001b[0m  0.0342\n",
            "     30        \u001b[36m0.7976\u001b[0m  0.0349\n",
            "     31        \u001b[36m0.7913\u001b[0m  0.0322\n",
            "     32        \u001b[36m0.7854\u001b[0m  0.0314\n",
            "     33        \u001b[36m0.7799\u001b[0m  0.0302\n",
            "     34        \u001b[36m0.7747\u001b[0m  0.0300\n",
            "     35        \u001b[36m0.7697\u001b[0m  0.0305\n",
            "     36        \u001b[36m0.7650\u001b[0m  0.0298\n",
            "     37        \u001b[36m0.7605\u001b[0m  0.0305\n",
            "     38        \u001b[36m0.7563\u001b[0m  0.0309\n",
            "     39        \u001b[36m0.7522\u001b[0m  0.0294\n",
            "     40        \u001b[36m0.7483\u001b[0m  0.0343\n",
            "     41        \u001b[36m0.7446\u001b[0m  0.0385\n",
            "     42        \u001b[36m0.7410\u001b[0m  0.0375\n",
            "     43        \u001b[36m0.7376\u001b[0m  0.0387\n",
            "     44        \u001b[36m0.7342\u001b[0m  0.0369\n",
            "     45        \u001b[36m0.7310\u001b[0m  0.0352\n",
            "     46        \u001b[36m0.7280\u001b[0m  0.0312\n",
            "     47        \u001b[36m0.7250\u001b[0m  0.0310\n",
            "     48        \u001b[36m0.7221\u001b[0m  0.0313\n",
            "     49        \u001b[36m0.7193\u001b[0m  0.0308\n",
            "     50        \u001b[36m0.7166\u001b[0m  0.0297\n",
            "     51        \u001b[36m0.7140\u001b[0m  0.0298\n",
            "     52        \u001b[36m0.7114\u001b[0m  0.0315\n",
            "     53        \u001b[36m0.7090\u001b[0m  0.0335\n",
            "     54        \u001b[36m0.7066\u001b[0m  0.0277\n",
            "     55        \u001b[36m0.7042\u001b[0m  0.0327\n",
            "     56        \u001b[36m0.7020\u001b[0m  0.0301\n",
            "     57        \u001b[36m0.6998\u001b[0m  0.0335\n",
            "     58        \u001b[36m0.6976\u001b[0m  0.0318\n",
            "     59        \u001b[36m0.6956\u001b[0m  0.0314\n",
            "     60        \u001b[36m0.6935\u001b[0m  0.0405\n",
            "     61        \u001b[36m0.6915\u001b[0m  0.0303\n",
            "     62        \u001b[36m0.6896\u001b[0m  0.0341\n",
            "     63        \u001b[36m0.6877\u001b[0m  0.0303\n",
            "     64        \u001b[36m0.6859\u001b[0m  0.0315\n",
            "     65        \u001b[36m0.6841\u001b[0m  0.0325\n",
            "     66        \u001b[36m0.6823\u001b[0m  0.0299\n",
            "     67        \u001b[36m0.6806\u001b[0m  0.0302\n",
            "     68        \u001b[36m0.6789\u001b[0m  0.0332\n",
            "     69        \u001b[36m0.6773\u001b[0m  0.0309\n",
            "     70        \u001b[36m0.6757\u001b[0m  0.0326\n",
            "     71        \u001b[36m0.6741\u001b[0m  0.0369\n",
            "     72        \u001b[36m0.6726\u001b[0m  0.0376\n",
            "     73        \u001b[36m0.6711\u001b[0m  0.0404\n",
            "     74        \u001b[36m0.6696\u001b[0m  0.0342\n",
            "     75        \u001b[36m0.6682\u001b[0m  0.0342\n",
            "     76        \u001b[36m0.6668\u001b[0m  0.0317\n",
            "     77        \u001b[36m0.6654\u001b[0m  0.0326\n",
            "     78        \u001b[36m0.6641\u001b[0m  0.0332\n",
            "     79        \u001b[36m0.6628\u001b[0m  0.0321\n",
            "     80        \u001b[36m0.6615\u001b[0m  0.0332\n",
            "     81        \u001b[36m0.6602\u001b[0m  0.0316\n",
            "     82        \u001b[36m0.6589\u001b[0m  0.0352\n",
            "     83        \u001b[36m0.6577\u001b[0m  0.0323\n",
            "     84        \u001b[36m0.6565\u001b[0m  0.0333\n",
            "     85        \u001b[36m0.6553\u001b[0m  0.0321\n",
            "     86        \u001b[36m0.6542\u001b[0m  0.0338\n",
            "     87        \u001b[36m0.6531\u001b[0m  0.0301\n",
            "     88        \u001b[36m0.6519\u001b[0m  0.0309\n",
            "     89        \u001b[36m0.6508\u001b[0m  0.0332\n",
            "     90        \u001b[36m0.6498\u001b[0m  0.0357\n",
            "     91        \u001b[36m0.6487\u001b[0m  0.0294\n",
            "     92        \u001b[36m0.6477\u001b[0m  0.0315\n",
            "     93        \u001b[36m0.6467\u001b[0m  0.0308\n",
            "     94        \u001b[36m0.6457\u001b[0m  0.0326\n",
            "     95        \u001b[36m0.6447\u001b[0m  0.0297\n",
            "     96        \u001b[36m0.6437\u001b[0m  0.0298\n",
            "     97        \u001b[36m0.6428\u001b[0m  0.0306\n",
            "     98        \u001b[36m0.6418\u001b[0m  0.0302\n",
            "     99        \u001b[36m0.6409\u001b[0m  0.0315\n",
            "    100        \u001b[36m0.6400\u001b[0m  0.0405\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.4324\u001b[0m  0.0365\n",
            "      2        \u001b[36m1.3049\u001b[0m  0.0303\n",
            "      3        \u001b[36m1.2757\u001b[0m  0.0304\n",
            "      4        \u001b[36m1.2555\u001b[0m  0.0331\n",
            "      5        \u001b[36m1.2369\u001b[0m  0.0296\n",
            "      6        \u001b[36m1.2198\u001b[0m  0.0314\n",
            "      7        \u001b[36m1.2038\u001b[0m  0.0294\n",
            "      8        \u001b[36m1.1888\u001b[0m  0.0305\n",
            "      9        \u001b[36m1.1747\u001b[0m  0.0329\n",
            "     10        \u001b[36m1.1614\u001b[0m  0.0304\n",
            "     11        \u001b[36m1.1487\u001b[0m  0.0300\n",
            "     12        \u001b[36m1.1367\u001b[0m  0.0296\n",
            "     13        \u001b[36m1.1252\u001b[0m  0.0344\n",
            "     14        \u001b[36m1.1141\u001b[0m  0.0318\n",
            "     15        \u001b[36m1.1035\u001b[0m  0.0296\n",
            "     16        \u001b[36m1.0933\u001b[0m  0.0321\n",
            "     17        \u001b[36m1.0835\u001b[0m  0.0292\n",
            "     18        \u001b[36m1.0740\u001b[0m  0.0338\n",
            "     19        \u001b[36m1.0648\u001b[0m  0.0324\n",
            "     20        \u001b[36m1.0560\u001b[0m  0.0419\n",
            "     21        \u001b[36m1.0475\u001b[0m  0.0324\n",
            "     22        \u001b[36m1.0392\u001b[0m  0.0294\n",
            "     23        \u001b[36m1.0313\u001b[0m  0.0314\n",
            "     24        \u001b[36m1.0236\u001b[0m  0.0300\n",
            "     25        \u001b[36m1.0161\u001b[0m  0.0324\n",
            "     26        \u001b[36m1.0090\u001b[0m  0.0331\n",
            "     27        \u001b[36m1.0020\u001b[0m  0.0320\n",
            "     28        \u001b[36m0.9954\u001b[0m  0.0292\n",
            "     29        \u001b[36m0.9890\u001b[0m  0.0387\n",
            "     30        0.9952  0.0392\n",
            "     31        1.2417  0.0429\n",
            "     32        1.2839  0.0347\n",
            "     33        1.2350  0.0361\n",
            "     34        1.2314  0.0307\n",
            "     35        1.2216  0.0309\n",
            "     36        1.2120  0.0302\n",
            "     37        1.2028  0.0332\n",
            "     38        1.1938  0.0312\n",
            "     39        1.1851  0.0319\n",
            "     40        1.1765  0.0296\n",
            "     41        1.1681  0.0326\n",
            "     42        1.1598  0.0314\n",
            "     43        1.1517  0.0305\n",
            "     44        1.1436  0.0310\n",
            "     45        1.1357  0.0296\n",
            "     46        1.1279  0.0301\n",
            "     47        1.1201  0.0305\n",
            "     48        1.1125  0.0312\n",
            "     49        1.1049  0.0291\n",
            "     50        1.0974  0.0430\n",
            "     51        1.0900  0.0321\n",
            "     52        1.0806  0.0313\n",
            "     53        1.0734  0.0336\n",
            "     54        1.0662  0.0297\n",
            "     55        1.0590  0.0328\n",
            "     56        1.0520  0.0308\n",
            "     57        1.0450  0.0324\n",
            "     58        1.0380  0.0380\n",
            "     59        1.0311  0.0365\n",
            "     60        1.0242  0.0397\n",
            "     61        1.0174  0.0377\n",
            "     62        1.0107  0.0323\n",
            "     63        1.0040  0.0352\n",
            "     64        0.9974  0.0346\n",
            "     65        0.9908  0.0352\n",
            "     66        \u001b[36m0.9843\u001b[0m  0.0359\n",
            "     67        \u001b[36m0.9778\u001b[0m  0.0474\n",
            "     68        \u001b[36m0.9714\u001b[0m  0.0476\n",
            "     69        \u001b[36m0.9651\u001b[0m  0.0428\n",
            "     70        \u001b[36m0.9588\u001b[0m  0.0469\n",
            "     71        \u001b[36m0.9525\u001b[0m  0.0497\n",
            "     72        \u001b[36m0.9463\u001b[0m  0.0380\n",
            "     73        \u001b[36m0.9402\u001b[0m  0.0490\n",
            "     74        \u001b[36m0.9341\u001b[0m  0.0430\n",
            "     75        \u001b[36m0.9281\u001b[0m  0.0456\n",
            "     76        \u001b[36m0.9221\u001b[0m  0.0461\n",
            "     77        \u001b[36m0.9162\u001b[0m  0.0414\n",
            "     78        \u001b[36m0.9103\u001b[0m  0.0422\n",
            "     79        \u001b[36m0.9045\u001b[0m  0.0451\n",
            "     80        \u001b[36m0.8987\u001b[0m  0.0510\n",
            "     81        \u001b[36m0.8930\u001b[0m  0.0468\n",
            "     82        \u001b[36m0.8751\u001b[0m  0.0448\n",
            "     83        1.0462  0.0417\n",
            "     84        0.9588  0.0428\n",
            "     85        0.9395  0.0423\n",
            "     86        0.9223  0.0370\n",
            "     87        0.9085  0.0384\n",
            "     88        0.8861  0.0377\n",
            "     89        0.8752  0.0414\n",
            "     90        \u001b[36m0.8658\u001b[0m  0.0368\n",
            "     91        \u001b[36m0.8576\u001b[0m  0.0353\n",
            "     92        \u001b[36m0.8505\u001b[0m  0.0364\n",
            "     93        \u001b[36m0.8442\u001b[0m  0.0355\n",
            "     94        \u001b[36m0.8386\u001b[0m  0.0358\n",
            "     95        \u001b[36m0.8336\u001b[0m  0.0372\n",
            "     96        \u001b[36m0.8291\u001b[0m  0.0380\n",
            "     97        0.8508  0.0441\n",
            "     98        0.8614  0.0372\n",
            "     99        0.8536  0.0488\n",
            "    100        0.8460  0.0519\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0539\n",
            "      2        1.0000  0.0589\n",
            "      3        1.0000  0.0624\n",
            "      4        1.0000  0.0571\n",
            "      5        1.0000  0.0604\n",
            "      6        1.0000  0.0598\n",
            "      7        1.0000  0.0624\n",
            "      8        1.0000  0.0556\n",
            "      9        1.0000  0.0565\n",
            "     10        1.0000  0.0572\n",
            "     11        1.0000  0.0637\n",
            "     12        1.0000  0.0642\n",
            "     13        1.0000  0.0541\n",
            "     14        1.0000  0.0603\n",
            "     15        1.0000  0.0632\n",
            "     16        1.0000  0.0643\n",
            "     17        1.0000  0.0687\n",
            "     18        1.0000  0.0616\n",
            "     19        1.0000  0.0576\n",
            "     20        1.0000  0.0564\n",
            "     21        1.0000  0.0645\n",
            "     22        1.0000  0.0616\n",
            "     23        1.0000  0.0641\n",
            "     24        1.0000  0.0609\n",
            "     25        1.0000  0.0695\n",
            "     26        1.0000  0.0436\n",
            "     27        1.0000  0.0435\n",
            "     28        1.0000  0.0420\n",
            "     29        1.0000  0.0433\n",
            "     30        1.0000  0.0424\n",
            "     31        1.0000  0.0432\n",
            "     32        1.0000  0.0418\n",
            "     33        1.0000  0.0467\n",
            "     34        1.0000  0.0509\n",
            "     35        1.0000  0.0482\n",
            "     36        1.0000  0.0557\n",
            "     37        \u001b[36m1.0000\u001b[0m  0.0478\n",
            "     38        \u001b[36m0.9965\u001b[0m  0.0434\n",
            "     39        \u001b[36m0.4061\u001b[0m  0.0477\n",
            "     40        \u001b[36m0.3732\u001b[0m  0.0435\n",
            "     41        \u001b[36m0.3732\u001b[0m  0.0432\n",
            "     42        \u001b[36m0.3732\u001b[0m  0.0448\n",
            "     43        0.3732  0.0455\n",
            "     44        0.3732  0.0424\n",
            "     45        0.3732  0.0427\n",
            "     46        0.3732  0.0431\n",
            "     47        0.3732  0.0440\n",
            "     48        0.3732  0.0413\n",
            "     49        0.3732  0.0427\n",
            "     50        0.3732  0.0415\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0407\n",
            "      2        1.0000  0.0425\n",
            "      3        1.0000  0.0440\n",
            "      4        1.0000  0.0416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0474\n",
            "      6        1.0000  0.0558\n",
            "      7        1.0000  0.0540\n",
            "      8        1.0000  0.0503\n",
            "      9        1.0000  0.0436\n",
            "     10        1.0000  0.0441\n",
            "     11        1.0000  0.0437\n",
            "     12        1.0000  0.0406\n",
            "     13        1.0000  0.0434\n",
            "     14        1.0000  0.0444\n",
            "     15        1.0000  0.0472\n",
            "     16        1.0000  0.0415\n",
            "     17        1.0000  0.0421\n",
            "     18        1.0000  0.0431\n",
            "     19        1.0000  0.0415\n",
            "     20        1.0000  0.0453\n",
            "     21        1.0000  0.0437\n",
            "     22        1.0000  0.0432\n",
            "     23        1.0000  0.0416\n",
            "     24        1.0000  0.0428\n",
            "     25        1.0000  0.0426\n",
            "     26        1.0000  0.0442\n",
            "     27        1.0000  0.0500\n",
            "     28        1.0000  0.0574\n",
            "     29        1.0000  0.0526\n",
            "     30        1.0000  0.0454\n",
            "     31        1.0000  0.0429\n",
            "     32        1.0000  0.0423\n",
            "     33        1.0000  0.0433\n",
            "     34        1.0000  0.0426\n",
            "     35        1.0000  0.0426\n",
            "     36        1.0000  0.0422\n",
            "     37        1.0000  0.0428\n",
            "     38        1.0000  0.0404\n",
            "     39        1.0000  0.0451\n",
            "     40        \u001b[36m1.0000\u001b[0m  0.0422\n",
            "     41        \u001b[36m1.0000\u001b[0m  0.0458\n",
            "     42        \u001b[36m0.5643\u001b[0m  0.0422\n",
            "     43        \u001b[36m0.3719\u001b[0m  0.0422\n",
            "     44        \u001b[36m0.3719\u001b[0m  0.0423\n",
            "     45        0.3719  0.0418\n",
            "     46        0.3719  0.0436\n",
            "     47        0.3719  0.0439\n",
            "     48        0.3719  0.0435\n",
            "     49        0.3719  0.0441\n",
            "     50        0.3719  0.0513\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0399\n",
            "      2        1.0000  0.0323\n",
            "      3        1.0000  0.0322\n",
            "      4        1.0000  0.0328\n",
            "      5        1.0000  0.0333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0371\n",
            "      7        1.0000  0.0323\n",
            "      8        1.0000  0.0328\n",
            "      9        1.0000  0.0332\n",
            "     10        1.0000  0.0317\n",
            "     11        1.0000  0.0326\n",
            "     12        1.0000  0.0320\n",
            "     13        1.0000  0.0322\n",
            "     14        1.0000  0.0338\n",
            "     15        1.0000  0.0308\n",
            "     16        1.0000  0.0319\n",
            "     17        1.0000  0.0316\n",
            "     18        1.0000  0.0319\n",
            "     19        1.0000  0.0320\n",
            "     20        1.0000  0.0383\n",
            "     21        1.0000  0.0344\n",
            "     22        1.0000  0.0326\n",
            "     23        1.0000  0.0319\n",
            "     24        1.0000  0.0319\n",
            "     25        1.0000  0.0311\n",
            "     26        1.0000  0.0333\n",
            "     27        1.0000  0.0298\n",
            "     28        1.0000  0.0412\n",
            "     29        1.0000  0.0392\n",
            "     30        1.0000  0.0481\n",
            "     31        1.0000  0.0344\n",
            "     32        1.0000  0.0321\n",
            "     33        1.0000  0.0308\n",
            "     34        1.0000  0.0325\n",
            "     35        1.0000  0.0311\n",
            "     36        1.0000  0.0314\n",
            "     37        1.0000  0.0323\n",
            "     38        1.0000  0.0316\n",
            "     39        1.0000  0.0308\n",
            "     40        1.0000  0.0330\n",
            "     41        1.0000  0.0314\n",
            "     42        1.0000  0.0322\n",
            "     43        1.0000  0.0323\n",
            "     44        1.0000  0.0308\n",
            "     45        1.0000  0.0332\n",
            "     46        1.0000  0.0352\n",
            "     47        1.0000  0.0325\n",
            "     48        1.0000  0.0325\n",
            "     49        1.0000  0.0323\n",
            "     50        1.0000  0.0343\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0289\n",
            "      2        1.0000  0.0315\n",
            "      3        1.0000  0.0320\n",
            "      4        1.0000  0.0347\n",
            "      5        1.0000  0.0319\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0393\n",
            "      7        1.0000  0.0390\n",
            "      8        1.0000  0.0394\n",
            "      9        1.0000  0.0477\n",
            "     10        1.0000  0.0320\n",
            "     11        1.0000  0.0304\n",
            "     12        1.0000  0.0314\n",
            "     13        1.0000  0.0321\n",
            "     14        1.0000  0.0314\n",
            "     15        1.0000  0.0320\n",
            "     16        1.0000  0.0328\n",
            "     17        1.0000  0.0323\n",
            "     18        1.0000  0.0328\n",
            "     19        1.0000  0.0325\n",
            "     20        1.0000  0.0357\n",
            "     21        1.0000  0.0344\n",
            "     22        1.0000  0.0329\n",
            "     23        1.0000  0.0321\n",
            "     24        1.0000  0.0320\n",
            "     25        1.0000  0.0313\n",
            "     26        1.0000  0.0319\n",
            "     27        1.0000  0.0325\n",
            "     28        1.0000  0.0333\n",
            "     29        1.0000  0.0327\n",
            "     30        1.0000  0.0323\n",
            "     31        1.0000  0.0315\n",
            "     32        1.0000  0.0321\n",
            "     33        1.0000  0.0333\n",
            "     34        1.0000  0.0325\n",
            "     35        1.0000  0.0439\n",
            "     36        1.0000  0.0404\n",
            "     37        1.0000  0.0387\n",
            "     38        1.0000  0.0410\n",
            "     39        1.0000  0.0331\n",
            "     40        1.0000  0.0334\n",
            "     41        1.0000  0.0347\n",
            "     42        1.0000  0.0317\n",
            "     43        1.0000  0.0343\n",
            "     44        1.0000  0.0348\n",
            "     45        1.0000  0.0344\n",
            "     46        1.0000  0.0337\n",
            "     47        1.0000  0.0313\n",
            "     48        1.0000  0.0339\n",
            "     49        1.0000  0.0337\n",
            "     50        1.0000  0.0319\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0385\n",
            "      2        1.0000  0.0409\n",
            "      3        1.0000  0.0414\n",
            "      4        1.0000  0.0437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0483\n",
            "      6        1.0000  0.0423\n",
            "      7        1.0000  0.0404\n",
            "      8        1.0000  0.0412\n",
            "      9        1.0000  0.0407\n",
            "     10        1.0000  0.0541\n",
            "     11        1.0000  0.0518\n",
            "     12        1.0000  0.0416\n",
            "     13        1.0000  0.0487\n",
            "     14        1.0000  0.0437\n",
            "     15        1.0000  0.0422\n",
            "     16        1.0000  0.0418\n",
            "     17        1.0000  0.0437\n",
            "     18        1.0000  0.0430\n",
            "     19        1.0000  0.0419\n",
            "     20        1.0000  0.0406\n",
            "     21        1.0000  0.0399\n",
            "     22        1.0000  0.0411\n",
            "     23        1.0000  0.0417\n",
            "     24        1.0000  0.0466\n",
            "     25        1.0000  0.0434\n",
            "     26        1.0000  0.0411\n",
            "     27        1.0000  0.0428\n",
            "     28        1.0000  0.0430\n",
            "     29        1.0000  0.0412\n",
            "     30        1.0000  0.0415\n",
            "     31        1.0000  0.0433\n",
            "     32        1.0000  0.0530\n",
            "     33        1.0000  0.0519\n",
            "     34        1.0000  0.0444\n",
            "     35        1.0000  0.0411\n",
            "     36        1.0000  0.0526\n",
            "     37        1.0000  0.0441\n",
            "     38        1.0000  0.0429\n",
            "     39        \u001b[36m0.9326\u001b[0m  0.0430\n",
            "     40        \u001b[36m0.3732\u001b[0m  0.0433\n",
            "     41        \u001b[36m0.3732\u001b[0m  0.0424\n",
            "     42        \u001b[36m0.3732\u001b[0m  0.0416\n",
            "     43        0.3732  0.0452\n",
            "     44        0.3732  0.0412\n",
            "     45        0.3732  0.0423\n",
            "     46        0.3732  0.0424\n",
            "     47        0.3732  0.0426\n",
            "     48        0.3732  0.0433\n",
            "     49        0.3732  0.0441\n",
            "     50        0.3732  0.0430\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0399\n",
            "      2        1.0000  0.0430\n",
            "      3        1.0000  0.0493\n",
            "      4        1.0000  0.0524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0494\n",
            "      6        1.0000  0.0421\n",
            "      7        1.0000  0.0416\n",
            "      8        1.0000  0.0519\n",
            "      9        1.0000  0.0432\n",
            "     10        1.0000  0.0419\n",
            "     11        1.0000  0.0473\n",
            "     12        1.0000  0.0412\n",
            "     13        1.0000  0.0411\n",
            "     14        1.0000  0.0421\n",
            "     15        1.0000  0.0522\n",
            "     16        1.0000  0.0635\n",
            "     17        1.0000  0.0574\n",
            "     18        1.0000  0.0590\n",
            "     19        1.0000  0.0637\n",
            "     20        1.0000  0.0610\n",
            "     21        1.0000  0.0582\n",
            "     22        1.0000  0.0581\n",
            "     23        1.0000  0.0702\n",
            "     24        1.0000  0.0533\n",
            "     25        1.0000  0.0524\n",
            "     26        1.0000  0.0567\n",
            "     27        1.0000  0.0611\n",
            "     28        1.0000  0.0559\n",
            "     29        1.0000  0.0545\n",
            "     30        1.0000  0.0532\n",
            "     31        1.0000  0.0580\n",
            "     32        1.0000  0.0520\n",
            "     33        1.0000  0.0524\n",
            "     34        1.0000  0.0546\n",
            "     35        1.0000  0.0508\n",
            "     36        1.0000  0.0515\n",
            "     37        1.0000  0.0519\n",
            "     38        1.0000  0.0524\n",
            "     39        1.0000  0.0551\n",
            "     40        \u001b[36m0.9777\u001b[0m  0.0772\n",
            "     41        \u001b[36m0.3719\u001b[0m  0.0601\n",
            "     42        \u001b[36m0.3719\u001b[0m  0.0667\n",
            "     43        \u001b[36m0.3719\u001b[0m  0.0605\n",
            "     44        0.3719  0.0660\n",
            "     45        0.3719  0.0558\n",
            "     46        0.3719  0.0629\n",
            "     47        0.3719  0.0640\n",
            "     48        0.3719  0.0638\n",
            "     49        0.3719  0.0566\n",
            "     50        0.3719  0.0625\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0447\n",
            "      2        1.0000  0.0448\n",
            "      3        1.0000  0.0443\n",
            "      4        1.0000  0.0446\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0489\n",
            "      6        1.0000  0.0460\n",
            "      7        1.0000  0.0603\n",
            "      8        1.0000  0.0474\n",
            "      9        1.0000  0.0446\n",
            "     10        1.0000  0.0455\n",
            "     11        1.0000  0.0476\n",
            "     12        1.0000  0.0519\n",
            "     13        1.0000  0.0567\n",
            "     14        1.0000  0.0436\n",
            "     15        1.0000  0.0439\n",
            "     16        1.0000  0.0457\n",
            "     17        1.0000  0.0444\n",
            "     18        1.0000  0.0458\n",
            "     19        1.0000  0.0467\n",
            "     20        1.0000  0.0432\n",
            "     21        1.0000  0.0311\n",
            "     22        1.0000  0.0346\n",
            "     23        1.0000  0.0333\n",
            "     24        1.0000  0.0330\n",
            "     25        1.0000  0.0318\n",
            "     26        1.0000  0.0377\n",
            "     27        1.0000  0.0375\n",
            "     28        1.0000  0.0422\n",
            "     29        1.0000  0.0452\n",
            "     30        1.0000  0.0389\n",
            "     31        1.0000  0.0376\n",
            "     32        1.0000  0.0350\n",
            "     33        1.0000  0.0352\n",
            "     34        1.0000  0.0324\n",
            "     35        1.0000  0.0359\n",
            "     36        1.0000  0.0329\n",
            "     37        1.0000  0.0323\n",
            "     38        1.0000  0.0370\n",
            "     39        1.0000  0.0390\n",
            "     40        1.0000  0.0349\n",
            "     41        1.0000  0.0337\n",
            "     42        1.0000  0.0329\n",
            "     43        1.0000  0.0330\n",
            "     44        1.0000  0.0326\n",
            "     45        1.0000  0.0361\n",
            "     46        1.0000  0.0347\n",
            "     47        1.0000  0.0364\n",
            "     48        1.0000  0.0408\n",
            "     49        1.0000  0.0395\n",
            "     50        1.0000  0.0400\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0311\n",
            "      2        1.0000  0.0345\n",
            "      3        1.0000  0.0409\n",
            "      4        1.0000  0.0424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0410\n",
            "      6        1.0000  0.0362\n",
            "      7        1.0000  0.0330\n",
            "      8        1.0000  0.0345\n",
            "      9        1.0000  0.0341\n",
            "     10        1.0000  0.0334\n",
            "     11        1.0000  0.0353\n",
            "     12        1.0000  0.0340\n",
            "     13        1.0000  0.0341\n",
            "     14        1.0000  0.0331\n",
            "     15        1.0000  0.0389\n",
            "     16        1.0000  0.0365\n",
            "     17        1.0000  0.0349\n",
            "     18        1.0000  0.0344\n",
            "     19        1.0000  0.0340\n",
            "     20        1.0000  0.0327\n",
            "     21        1.0000  0.0327\n",
            "     22        1.0000  0.0327\n",
            "     23        1.0000  0.0319\n",
            "     24        1.0000  0.0328\n",
            "     25        1.0000  0.0343\n",
            "     26        1.0000  0.0338\n",
            "     27        1.0000  0.0343\n",
            "     28        1.0000  0.0333\n",
            "     29        1.0000  0.0339\n",
            "     30        1.0000  0.0379\n",
            "     31        1.0000  0.0411\n",
            "     32        1.0000  0.0415\n",
            "     33        1.0000  0.0399\n",
            "     34        1.0000  0.0342\n",
            "     35        1.0000  0.0327\n",
            "     36        1.0000  0.0323\n",
            "     37        1.0000  0.0326\n",
            "     38        1.0000  0.0317\n",
            "     39        1.0000  0.0346\n",
            "     40        1.0000  0.0340\n",
            "     41        1.0000  0.0319\n",
            "     42        1.0000  0.0323\n",
            "     43        1.0000  0.0315\n",
            "     44        1.0000  0.0409\n",
            "     45        1.0000  0.0332\n",
            "     46        1.0000  0.0328\n",
            "     47        1.0000  0.0316\n",
            "     48        1.0000  0.0339\n",
            "     49        1.0000  0.0330\n",
            "     50        1.0000  0.0331\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8627\u001b[0m  0.0416\n",
            "      2        \u001b[36m0.8627\u001b[0m  0.0414\n",
            "      3        \u001b[36m0.8451\u001b[0m  0.0444\n",
            "      4        \u001b[36m0.8205\u001b[0m  0.0429\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.7747\u001b[0m  0.0454\n",
            "      6        \u001b[36m0.7236\u001b[0m  0.0498\n",
            "      7        \u001b[36m0.6761\u001b[0m  0.0514\n",
            "      8        \u001b[36m0.6725\u001b[0m  0.0498\n",
            "      9        \u001b[36m0.6619\u001b[0m  0.0409\n",
            "     10        \u001b[36m0.6549\u001b[0m  0.0422\n",
            "     11        \u001b[36m0.6549\u001b[0m  0.0423\n",
            "     12        0.6549  0.0425\n",
            "     13        0.6549  0.0454\n",
            "     14        0.6549  0.0456\n",
            "     15        0.6549  0.0441\n",
            "     16        0.6549  0.0427\n",
            "     17        0.6549  0.0491\n",
            "     18        0.6549  0.0433\n",
            "     19        \u001b[36m0.6549\u001b[0m  0.0418\n",
            "     20        0.6549  0.0423\n",
            "     21        0.6549  0.0437\n",
            "     22        0.6549  0.0430\n",
            "     23        0.6549  0.0414\n",
            "     24        0.6549  0.0414\n",
            "     25        0.6549  0.0434\n",
            "     26        0.6549  0.0418\n",
            "     27        0.6549  0.0422\n",
            "     28        \u001b[36m0.6549\u001b[0m  0.0502\n",
            "     29        \u001b[36m0.6446\u001b[0m  0.0509\n",
            "     30        \u001b[36m0.5313\u001b[0m  0.0440\n",
            "     31        \u001b[36m0.4600\u001b[0m  0.0421\n",
            "     32        \u001b[36m0.4111\u001b[0m  0.0408\n",
            "     33        \u001b[36m0.4049\u001b[0m  0.0415\n",
            "     34        0.4049  0.0447\n",
            "     35        0.4049  0.0430\n",
            "     36        0.4049  0.0415\n",
            "     37        0.4049  0.0401\n",
            "     38        0.4049  0.0434\n",
            "     39        0.4049  0.0425\n",
            "     40        0.4049  0.0502\n",
            "     41        0.4049  0.0431\n",
            "     42        0.4049  0.0442\n",
            "     43        0.4049  0.0417\n",
            "     44        0.4049  0.0411\n",
            "     45        0.4049  0.0418\n",
            "     46        0.4049  0.0408\n",
            "     47        0.4049  0.0433\n",
            "     48        0.4049  0.0424\n",
            "     49        0.4049  0.0422\n",
            "     50        0.4049  0.0482\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4035\u001b[0m  0.0514\n",
            "      2        0.4035  0.0454\n",
            "      3        \u001b[36m0.3930\u001b[0m  0.0419\n",
            "      4        \u001b[36m0.3930\u001b[0m  0.0425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.3825\u001b[0m  0.0454\n",
            "      6        0.3825  0.0401\n",
            "      7        0.3825  0.0471\n",
            "      8        0.3825  0.0412\n",
            "      9        0.3825  0.0417\n",
            "     10        0.3825  0.0416\n",
            "     11        0.3825  0.0440\n",
            "     12        0.3825  0.0454\n",
            "     13        0.3825  0.0465\n",
            "     14        0.3825  0.0404\n",
            "     15        0.3825  0.0431\n",
            "     16        0.3825  0.0407\n",
            "     17        0.3825  0.0436\n",
            "     18        0.3825  0.0430\n",
            "     19        0.3825  0.0426\n",
            "     20        0.3825  0.0410\n",
            "     21        0.3825  0.0428\n",
            "     22        0.3825  0.0518\n",
            "     23        0.3825  0.0573\n",
            "     24        0.3825  0.0423\n",
            "     25        0.3825  0.0413\n",
            "     26        \u001b[36m0.3755\u001b[0m  0.0415\n",
            "     27        \u001b[36m0.3754\u001b[0m  0.0410\n",
            "     28        0.3754  0.0415\n",
            "     29        0.3754  0.0456\n",
            "     30        0.3754  0.0452\n",
            "     31        0.3754  0.0443\n",
            "     32        0.3754  0.0420\n",
            "     33        0.3754  0.0427\n",
            "     34        0.3754  0.0425\n",
            "     35        0.3754  0.0522\n",
            "     36        0.3754  0.0414\n",
            "     37        0.3754  0.0461\n",
            "     38        0.3754  0.0433\n",
            "     39        0.3754  0.0410\n",
            "     40        0.3754  0.0424\n",
            "     41        0.3754  0.0431\n",
            "     42        0.3754  0.0424\n",
            "     43        0.3754  0.0418\n",
            "     44        0.3754  0.0537\n",
            "     45        0.3754  0.0547\n",
            "     46        0.3754  0.0438\n",
            "     47        0.3754  0.0433\n",
            "     48        0.3754  0.0437\n",
            "     49        0.3754  0.0423\n",
            "     50        0.3754  0.0426\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0319\n",
            "      2        0.3732  0.0327\n",
            "      3        0.3732  0.0324\n",
            "      4        0.3732  0.0323\n",
            "      5        0.3732  0.0323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.3732  0.0357\n",
            "      7        0.3732  0.0350\n",
            "      8        0.3732  0.0332\n",
            "      9        0.3732  0.0435\n",
            "     10        0.3732  0.0316\n",
            "     11        0.3732  0.0324\n",
            "     12        0.3732  0.0328\n",
            "     13        0.3732  0.0329\n",
            "     14        0.3732  0.0322\n",
            "     15        0.3732  0.0316\n",
            "     16        0.3732  0.0340\n",
            "     17        0.3732  0.0308\n",
            "     18        0.3732  0.0314\n",
            "     19        0.3732  0.0323\n",
            "     20        0.3732  0.0410\n",
            "     21        0.3732  0.0376\n",
            "     22        0.3732  0.0391\n",
            "     23        0.3732  0.0376\n",
            "     24        0.3732  0.0312\n",
            "     25        0.3732  0.0342\n",
            "     26        0.3732  0.0308\n",
            "     27        0.3732  0.0322\n",
            "     28        0.3732  0.0321\n",
            "     29        0.3732  0.0368\n",
            "     30        0.3732  0.0341\n",
            "     31        0.3732  0.0349\n",
            "     32        0.3732  0.0315\n",
            "     33        0.3732  0.0334\n",
            "     34        0.3732  0.0329\n",
            "     35        0.3732  0.0328\n",
            "     36        0.3732  0.0342\n",
            "     37        0.3732  0.0321\n",
            "     38        0.3732  0.0444\n",
            "     39        0.3732  0.0333\n",
            "     40        0.3732  0.0335\n",
            "     41        0.3732  0.0324\n",
            "     42        0.3732  0.0350\n",
            "     43        0.3732  0.0335\n",
            "     44        0.3732  0.0329\n",
            "     45        0.3732  0.0323\n",
            "     46        0.3732  0.0362\n",
            "     47        0.3732  0.0351\n",
            "     48        0.3732  0.0424\n",
            "     49        0.3732  0.0395\n",
            "     50        0.3732  0.0397\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5086\u001b[0m  0.0304\n",
            "      2        \u001b[36m0.4772\u001b[0m  0.0327\n",
            "      3        0.4772  0.0328\n",
            "      4        0.4772  0.0341\n",
            "      5        0.4772  0.0314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.4772  0.0364\n",
            "      7        0.4772  0.0347\n",
            "      8        0.4772  0.0320\n",
            "      9        0.4772  0.0328\n",
            "     10        0.4772  0.0324\n",
            "     11        0.4772  0.0331\n",
            "     12        0.4772  0.0345\n",
            "     13        0.4772  0.0320\n",
            "     14        0.4772  0.0327\n",
            "     15        0.4772  0.0342\n",
            "     16        0.4772  0.0429\n",
            "     17        0.4772  0.0346\n",
            "     18        0.4772  0.0426\n",
            "     19        0.4772  0.0480\n",
            "     20        0.4772  0.0440\n",
            "     21        0.4772  0.0419\n",
            "     22        0.4772  0.0427\n",
            "     23        0.4772  0.0568\n",
            "     24        0.4772  0.0555\n",
            "     25        0.4772  0.0437\n",
            "     26        0.4772  0.0426\n",
            "     27        0.4772  0.0403\n",
            "     28        0.4772  0.0401\n",
            "     29        0.4772  0.0440\n",
            "     30        0.4772  0.0411\n",
            "     31        0.4772  0.0389\n",
            "     32        0.4772  0.0421\n",
            "     33        0.4772  0.0388\n",
            "     34        0.4772  0.0388\n",
            "     35        0.4772  0.0390\n",
            "     36        0.4772  0.0408\n",
            "     37        0.4772  0.0405\n",
            "     38        0.4772  0.0387\n",
            "     39        0.4772  0.0458\n",
            "     40        0.4772  0.0432\n",
            "     41        0.4772  0.0408\n",
            "     42        0.4772  0.0408\n",
            "     43        0.4772  0.0380\n",
            "     44        0.4772  0.0395\n",
            "     45        0.4772  0.0434\n",
            "     46        0.4772  0.0446\n",
            "     47        0.4772  0.0451\n",
            "     48        0.4772  0.0405\n",
            "     49        0.4772  0.0401\n",
            "     50        0.4772  0.0391\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3979\u001b[0m  0.0524\n",
            "      2        0.3979  0.0572\n",
            "      3        0.3979  0.0614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4        0.3979  0.0713\n",
            "      5        0.3979  0.0601\n",
            "      6        0.3979  0.0563\n",
            "      7        0.3979  0.0517\n",
            "      8        0.3979  0.0605\n",
            "      9        0.3979  0.0763\n",
            "     10        0.3979  0.0597\n",
            "     11        0.3979  0.0604\n",
            "     12        0.3979  0.0700\n",
            "     13        0.3979  0.0728\n",
            "     14        0.3979  0.0651\n",
            "     15        0.3979  0.0570\n",
            "     16        0.3979  0.0570\n",
            "     17        0.3979  0.0720\n",
            "     18        0.3979  0.0586\n",
            "     19        0.3979  0.0605\n",
            "     20        0.3979  0.0677\n",
            "     21        0.3979  0.0488\n",
            "     22        0.3979  0.0408\n",
            "     23        0.3979  0.0449\n",
            "     24        0.3979  0.0423\n",
            "     25        0.3979  0.0404\n",
            "     26        0.3979  0.0505\n",
            "     27        0.3979  0.0406\n",
            "     28        0.3979  0.0423\n",
            "     29        0.3979  0.0434\n",
            "     30        0.3979  0.0579\n",
            "     31        0.3979  0.0468\n",
            "     32        0.3979  0.0424\n",
            "     33        0.3979  0.0424\n",
            "     34        0.3979  0.0408\n",
            "     35        0.3979  0.0415\n",
            "     36        0.3979  0.0417\n",
            "     37        0.3979  0.0430\n",
            "     38        0.3979  0.0443\n",
            "     39        0.3979  0.0431\n",
            "     40        0.3979  0.0422\n",
            "     41        0.3979  0.0420\n",
            "     42        \u001b[36m0.3803\u001b[0m  0.0417\n",
            "     43        \u001b[36m0.3732\u001b[0m  0.0444\n",
            "     44        0.3732  0.0436\n",
            "     45        0.3732  0.0422\n",
            "     46        0.3732  0.0425\n",
            "     47        0.3732  0.0455\n",
            "     48        0.3732  0.0472\n",
            "     49        0.3732  0.0431\n",
            "     50        0.3732  0.0408\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3965\u001b[0m  0.0433\n",
            "      2        \u001b[36m0.3895\u001b[0m  0.0522\n",
            "      3        0.3895  0.0475\n",
            "      4        0.3895  0.0412\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.3895\u001b[0m  0.0436\n",
            "      6        \u001b[36m0.3754\u001b[0m  0.0403\n",
            "      7        0.3754  0.0403\n",
            "      8        0.3754  0.0428\n",
            "      9        0.3754  0.0421\n",
            "     10        0.3754  0.0436\n",
            "     11        0.3754  0.0416\n",
            "     12        0.3754  0.0403\n",
            "     13        0.3754  0.0430\n",
            "     14        0.3860  0.0441\n",
            "     15        0.3930  0.0459\n",
            "     16        0.3965  0.0412\n",
            "     17        0.3930  0.0418\n",
            "     18        0.4000  0.0416\n",
            "     19        0.4035  0.0405\n",
            "     20        0.4070  0.0405\n",
            "     21        0.4000  0.0485\n",
            "     22        \u001b[36m0.3719\u001b[0m  0.0401\n",
            "     23        0.3719  0.0426\n",
            "     24        0.3719  0.0704\n",
            "     25        0.3719  0.0610\n",
            "     26        0.3719  0.0480\n",
            "     27        0.3719  0.0405\n",
            "     28        0.3719  0.0410\n",
            "     29        0.3719  0.0416\n",
            "     30        0.3719  0.0425\n",
            "     31        0.3719  0.0451\n",
            "     32        0.3719  0.0416\n",
            "     33        0.3719  0.0402\n",
            "     34        0.3719  0.0411\n",
            "     35        0.3719  0.0442\n",
            "     36        0.3719  0.0420\n",
            "     37        0.3719  0.0427\n",
            "     38        0.3719  0.0413\n",
            "     39        0.3719  0.0440\n",
            "     40        0.3719  0.0423\n",
            "     41        0.3719  0.0410\n",
            "     42        0.3719  0.0408\n",
            "     43        0.3719  0.0480\n",
            "     44        0.3719  0.0438\n",
            "     45        0.3719  0.0461\n",
            "     46        0.3719  0.0547\n",
            "     47        0.3719  0.0463\n",
            "     48        0.3719  0.0454\n",
            "     49        0.3719  0.0406\n",
            "     50        0.3719  0.0421\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6866\u001b[0m  0.0326\n",
            "      2        0.6866  0.0397\n",
            "      3        0.6866  0.0398\n",
            "      4        0.6866  0.0348\n",
            "      5        0.6866  0.0344\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.6866  0.0409\n",
            "      7        0.6866  0.0337\n",
            "      8        0.6866  0.0346\n",
            "      9        0.6866  0.0344\n",
            "     10        0.6866  0.0376\n",
            "     11        0.6866  0.0363\n",
            "     12        0.6866  0.0340\n",
            "     13        0.6866  0.0351\n",
            "     14        0.6866  0.0342\n",
            "     15        0.6866  0.0334\n",
            "     16        0.6866  0.0348\n",
            "     17        0.6866  0.0332\n",
            "     18        0.6866  0.0419\n",
            "     19        0.6866  0.0335\n",
            "     20        0.6866  0.0418\n",
            "     21        0.6866  0.0406\n",
            "     22        0.6866  0.0421\n",
            "     23        0.6866  0.0355\n",
            "     24        0.6866  0.0335\n",
            "     25        0.6866  0.0322\n",
            "     26        0.6866  0.0330\n",
            "     27        0.6866  0.0330\n",
            "     28        0.6866  0.0337\n",
            "     29        0.6866  0.0338\n",
            "     30        0.6866  0.0354\n",
            "     31        0.6866  0.0333\n",
            "     32        0.6866  0.0337\n",
            "     33        0.6866  0.0337\n",
            "     34        0.6866  0.0390\n",
            "     35        0.6866  0.0386\n",
            "     36        0.6866  0.0359\n",
            "     37        0.6866  0.0356\n",
            "     38        0.6866  0.0350\n",
            "     39        0.6866  0.0357\n",
            "     40        0.6866  0.0358\n",
            "     41        0.6866  0.0343\n",
            "     42        0.6866  0.0341\n",
            "     43        0.6866  0.0351\n",
            "     44        0.6866  0.0330\n",
            "     45        0.6866  0.0343\n",
            "     46        0.6866  0.0466\n",
            "     47        0.6866  0.0435\n",
            "     48        0.6866  0.0437\n",
            "     49        0.6866  0.0402\n",
            "     50        0.6866  0.0403\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8667\u001b[0m  0.0309\n",
            "      2        0.8667  0.0340\n",
            "      3        0.8667  0.0341\n",
            "      4        0.8667  0.0346\n",
            "      5        0.8667  0.0345\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.8667  0.0414\n",
            "      7        0.8667  0.0340\n",
            "      8        0.8667  0.0339\n",
            "      9        0.8667  0.0336\n",
            "     10        0.8667  0.0351\n",
            "     11        0.8667  0.0338\n",
            "     12        0.8667  0.0349\n",
            "     13        0.8667  0.0344\n",
            "     14        0.8667  0.0343\n",
            "     15        0.8667  0.0402\n",
            "     16        0.8667  0.0343\n",
            "     17        0.8667  0.0342\n",
            "     18        0.8667  0.0346\n",
            "     19        0.8667  0.0346\n",
            "     20        0.8667  0.0350\n",
            "     21        0.8667  0.0346\n",
            "     22        0.8667  0.0362\n",
            "     23        0.8667  0.0494\n",
            "     24        0.8667  0.0432\n",
            "     25        0.8667  0.0352\n",
            "     26        0.8667  0.0342\n",
            "     27        0.8667  0.0337\n",
            "     28        0.8667  0.0337\n",
            "     29        0.8667  0.0336\n",
            "     30        0.8667  0.0353\n",
            "     31        0.8667  0.0373\n",
            "     32        0.8667  0.0345\n",
            "     33        0.8667  0.0361\n",
            "     34        0.8667  0.0341\n",
            "     35        0.8667  0.0351\n",
            "     36        0.8667  0.0349\n",
            "     37        0.8667  0.0347\n",
            "     38        0.8667  0.0347\n",
            "     39        0.8667  0.0376\n",
            "     40        0.8667  0.0371\n",
            "     41        0.8667  0.0366\n",
            "     42        0.8667  0.0328\n",
            "     43        0.8667  0.0342\n",
            "     44        0.8667  0.0345\n",
            "     45        0.8667  0.0350\n",
            "     46        0.8667  0.0336\n",
            "     47        0.8667  0.0342\n",
            "     48        0.8667  0.0343\n",
            "     49        0.8667  0.0390\n",
            "     50        0.8667  0.0570\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9894\u001b[0m  0.0464\n",
            "      2        \u001b[36m0.9864\u001b[0m  0.0440\n",
            "      3        \u001b[36m0.9821\u001b[0m  0.0443\n",
            "      4        \u001b[36m0.9757\u001b[0m  0.0446\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9655\u001b[0m  0.0469\n",
            "      6        \u001b[36m0.9467\u001b[0m  0.0443\n",
            "      7        \u001b[36m0.9028\u001b[0m  0.0487\n",
            "      8        \u001b[36m0.7853\u001b[0m  0.0444\n",
            "      9        \u001b[36m0.5939\u001b[0m  0.0424\n",
            "     10        \u001b[36m0.4833\u001b[0m  0.0449\n",
            "     11        \u001b[36m0.4449\u001b[0m  0.0437\n",
            "     12        \u001b[36m0.4274\u001b[0m  0.0423\n",
            "     13        \u001b[36m0.4170\u001b[0m  0.0422\n",
            "     14        \u001b[36m0.4099\u001b[0m  0.0449\n",
            "     15        \u001b[36m0.4046\u001b[0m  0.0429\n",
            "     16        \u001b[36m0.4006\u001b[0m  0.0416\n",
            "     17        \u001b[36m0.3974\u001b[0m  0.0429\n",
            "     18        \u001b[36m0.3947\u001b[0m  0.0423\n",
            "     19        \u001b[36m0.3925\u001b[0m  0.0422\n",
            "     20        \u001b[36m0.3907\u001b[0m  0.0476\n",
            "     21        \u001b[36m0.3892\u001b[0m  0.0536\n",
            "     22        \u001b[36m0.3878\u001b[0m  0.0600\n",
            "     23        \u001b[36m0.3867\u001b[0m  0.0425\n",
            "     24        \u001b[36m0.3856\u001b[0m  0.0421\n",
            "     25        \u001b[36m0.3848\u001b[0m  0.0410\n",
            "     26        \u001b[36m0.3840\u001b[0m  0.0431\n",
            "     27        \u001b[36m0.3833\u001b[0m  0.0452\n",
            "     28        \u001b[36m0.3826\u001b[0m  0.0450\n",
            "     29        \u001b[36m0.3821\u001b[0m  0.0484\n",
            "     30        \u001b[36m0.3815\u001b[0m  0.0465\n",
            "     31        \u001b[36m0.3811\u001b[0m  0.0484\n",
            "     32        \u001b[36m0.3806\u001b[0m  0.0435\n",
            "     33        \u001b[36m0.3802\u001b[0m  0.0424\n",
            "     34        \u001b[36m0.3799\u001b[0m  0.0440\n",
            "     35        \u001b[36m0.3796\u001b[0m  0.0453\n",
            "     36        \u001b[36m0.3793\u001b[0m  0.0476\n",
            "     37        \u001b[36m0.3790\u001b[0m  0.0452\n",
            "     38        \u001b[36m0.3787\u001b[0m  0.0453\n",
            "     39        \u001b[36m0.3785\u001b[0m  0.0419\n",
            "     40        \u001b[36m0.3782\u001b[0m  0.0422\n",
            "     41        \u001b[36m0.3780\u001b[0m  0.0434\n",
            "     42        \u001b[36m0.3778\u001b[0m  0.0565\n",
            "     43        \u001b[36m0.3776\u001b[0m  0.0518\n",
            "     44        \u001b[36m0.3775\u001b[0m  0.0558\n",
            "     45        \u001b[36m0.3773\u001b[0m  0.0436\n",
            "     46        \u001b[36m0.3771\u001b[0m  0.0418\n",
            "     47        \u001b[36m0.3770\u001b[0m  0.0425\n",
            "     48        \u001b[36m0.3769\u001b[0m  0.0439\n",
            "     49        \u001b[36m0.3767\u001b[0m  0.0445\n",
            "     50        \u001b[36m0.3766\u001b[0m  0.0468\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9578\u001b[0m  0.0402\n",
            "      2        \u001b[36m0.9459\u001b[0m  0.0445\n",
            "      3        \u001b[36m0.9302\u001b[0m  0.0452\n",
            "      4        \u001b[36m0.9083\u001b[0m  0.0582\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.8760\u001b[0m  0.0634\n",
            "      6        \u001b[36m0.8239\u001b[0m  0.0601\n",
            "      7        \u001b[36m0.7318\u001b[0m  0.0616\n",
            "      8        \u001b[36m0.6037\u001b[0m  0.0566\n",
            "      9        \u001b[36m0.5039\u001b[0m  0.0590\n",
            "     10        \u001b[36m0.4499\u001b[0m  0.0689\n",
            "     11        \u001b[36m0.4256\u001b[0m  0.0584\n",
            "     12        \u001b[36m0.4142\u001b[0m  0.0580\n",
            "     13        \u001b[36m0.4077\u001b[0m  0.0575\n",
            "     14        \u001b[36m0.4032\u001b[0m  0.0531\n",
            "     15        \u001b[36m0.3998\u001b[0m  0.0534\n",
            "     16        \u001b[36m0.3971\u001b[0m  0.0547\n",
            "     17        \u001b[36m0.3949\u001b[0m  0.0574\n",
            "     18        \u001b[36m0.3930\u001b[0m  0.0535\n",
            "     19        \u001b[36m0.3914\u001b[0m  0.0551\n",
            "     20        \u001b[36m0.3900\u001b[0m  0.0548\n",
            "     21        \u001b[36m0.3887\u001b[0m  0.0569\n",
            "     22        \u001b[36m0.3876\u001b[0m  0.0539\n",
            "     23        \u001b[36m0.3866\u001b[0m  0.0524\n",
            "     24        \u001b[36m0.3857\u001b[0m  0.0566\n",
            "     25        \u001b[36m0.3849\u001b[0m  0.0530\n",
            "     26        \u001b[36m0.3842\u001b[0m  0.0513\n",
            "     27        \u001b[36m0.3835\u001b[0m  0.0550\n",
            "     28        \u001b[36m0.3829\u001b[0m  0.0567\n",
            "     29        \u001b[36m0.3824\u001b[0m  0.0528\n",
            "     30        \u001b[36m0.3819\u001b[0m  0.0515\n",
            "     31        \u001b[36m0.3814\u001b[0m  0.0601\n",
            "     32        \u001b[36m0.3809\u001b[0m  0.0581\n",
            "     33        \u001b[36m0.3805\u001b[0m  0.0659\n",
            "     34        \u001b[36m0.3801\u001b[0m  0.0591\n",
            "     35        \u001b[36m0.3798\u001b[0m  0.0572\n",
            "     36        \u001b[36m0.3795\u001b[0m  0.0571\n",
            "     37        \u001b[36m0.3791\u001b[0m  0.0564\n",
            "     38        \u001b[36m0.3788\u001b[0m  0.0606\n",
            "     39        \u001b[36m0.3786\u001b[0m  0.0624\n",
            "     40        \u001b[36m0.3783\u001b[0m  0.0610\n",
            "     41        \u001b[36m0.3781\u001b[0m  0.0615\n",
            "     42        \u001b[36m0.3778\u001b[0m  0.0649\n",
            "     43        \u001b[36m0.3776\u001b[0m  0.0660\n",
            "     44        \u001b[36m0.3774\u001b[0m  0.0677\n",
            "     45        \u001b[36m0.3772\u001b[0m  0.0615\n",
            "     46        \u001b[36m0.3770\u001b[0m  0.0622\n",
            "     47        \u001b[36m0.3769\u001b[0m  0.0615\n",
            "     48        \u001b[36m0.3767\u001b[0m  0.0657\n",
            "     49        \u001b[36m0.3765\u001b[0m  0.0601\n",
            "     50        \u001b[36m0.3764\u001b[0m  0.0602\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9944\u001b[0m  0.0424\n",
            "      2        \u001b[36m0.9944\u001b[0m  0.0437\n",
            "      3        \u001b[36m0.9943\u001b[0m  0.0465\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4        \u001b[36m0.9943\u001b[0m  0.0488\n",
            "      5        \u001b[36m0.9943\u001b[0m  0.0444\n",
            "      6        \u001b[36m0.9943\u001b[0m  0.0401\n",
            "      7        \u001b[36m0.9943\u001b[0m  0.0336\n",
            "      8        \u001b[36m0.9943\u001b[0m  0.0335\n",
            "      9        \u001b[36m0.9943\u001b[0m  0.0330\n",
            "     10        \u001b[36m0.9943\u001b[0m  0.0334\n",
            "     11        \u001b[36m0.9943\u001b[0m  0.0333\n",
            "     12        \u001b[36m0.9943\u001b[0m  0.0410\n",
            "     13        \u001b[36m0.9943\u001b[0m  0.0341\n",
            "     14        \u001b[36m0.9943\u001b[0m  0.0328\n",
            "     15        \u001b[36m0.9942\u001b[0m  0.0329\n",
            "     16        \u001b[36m0.9942\u001b[0m  0.0345\n",
            "     17        \u001b[36m0.9942\u001b[0m  0.0321\n",
            "     18        \u001b[36m0.9942\u001b[0m  0.0327\n",
            "     19        \u001b[36m0.9942\u001b[0m  0.0324\n",
            "     20        \u001b[36m0.9942\u001b[0m  0.0321\n",
            "     21        \u001b[36m0.9942\u001b[0m  0.0422\n",
            "     22        \u001b[36m0.9942\u001b[0m  0.0330\n",
            "     23        \u001b[36m0.9942\u001b[0m  0.0325\n",
            "     24        \u001b[36m0.9942\u001b[0m  0.0346\n",
            "     25        \u001b[36m0.9942\u001b[0m  0.0319\n",
            "     26        \u001b[36m0.9942\u001b[0m  0.0328\n",
            "     27        \u001b[36m0.9941\u001b[0m  0.0324\n",
            "     28        \u001b[36m0.9941\u001b[0m  0.0333\n",
            "     29        \u001b[36m0.9941\u001b[0m  0.0339\n",
            "     30        \u001b[36m0.9941\u001b[0m  0.0327\n",
            "     31        \u001b[36m0.9941\u001b[0m  0.0324\n",
            "     32        \u001b[36m0.9941\u001b[0m  0.0327\n",
            "     33        \u001b[36m0.9941\u001b[0m  0.0340\n",
            "     34        \u001b[36m0.9941\u001b[0m  0.0321\n",
            "     35        \u001b[36m0.9941\u001b[0m  0.0314\n",
            "     36        \u001b[36m0.9941\u001b[0m  0.0332\n",
            "     37        \u001b[36m0.9941\u001b[0m  0.0338\n",
            "     38        \u001b[36m0.9940\u001b[0m  0.0326\n",
            "     39        \u001b[36m0.9940\u001b[0m  0.0323\n",
            "     40        \u001b[36m0.9940\u001b[0m  0.0357\n",
            "     41        \u001b[36m0.9940\u001b[0m  0.0406\n",
            "     42        \u001b[36m0.9940\u001b[0m  0.0376\n",
            "     43        \u001b[36m0.9940\u001b[0m  0.0330\n",
            "     44        \u001b[36m0.9940\u001b[0m  0.0334\n",
            "     45        \u001b[36m0.9940\u001b[0m  0.0339\n",
            "     46        \u001b[36m0.9940\u001b[0m  0.0332\n",
            "     47        \u001b[36m0.9940\u001b[0m  0.0325\n",
            "     48        \u001b[36m0.9940\u001b[0m  0.0322\n",
            "     49        \u001b[36m0.9939\u001b[0m  0.0326\n",
            "     50        \u001b[36m0.9939\u001b[0m  0.0419\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9981\u001b[0m  0.0324\n",
            "      2        \u001b[36m0.9981\u001b[0m  0.0362\n",
            "      3        \u001b[36m0.9981\u001b[0m  0.0356\n",
            "      4        \u001b[36m0.9981\u001b[0m  0.0346\n",
            "      5        \u001b[36m0.9981\u001b[0m  0.0345\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9981\u001b[0m  0.0426\n",
            "      7        \u001b[36m0.9981\u001b[0m  0.0350\n",
            "      8        \u001b[36m0.9981\u001b[0m  0.0337\n",
            "      9        \u001b[36m0.9981\u001b[0m  0.0336\n",
            "     10        \u001b[36m0.9981\u001b[0m  0.0343\n",
            "     11        \u001b[36m0.9981\u001b[0m  0.0379\n",
            "     12        \u001b[36m0.9981\u001b[0m  0.0417\n",
            "     13        \u001b[36m0.9981\u001b[0m  0.0386\n",
            "     14        \u001b[36m0.9981\u001b[0m  0.0347\n",
            "     15        \u001b[36m0.9981\u001b[0m  0.0340\n",
            "     16        \u001b[36m0.9981\u001b[0m  0.0347\n",
            "     17        \u001b[36m0.9981\u001b[0m  0.0416\n",
            "     18        \u001b[36m0.9981\u001b[0m  0.0409\n",
            "     19        \u001b[36m0.9981\u001b[0m  0.0340\n",
            "     20        \u001b[36m0.9981\u001b[0m  0.0334\n",
            "     21        \u001b[36m0.9981\u001b[0m  0.0333\n",
            "     22        \u001b[36m0.9981\u001b[0m  0.0331\n",
            "     23        \u001b[36m0.9981\u001b[0m  0.0325\n",
            "     24        \u001b[36m0.9981\u001b[0m  0.0329\n",
            "     25        \u001b[36m0.9981\u001b[0m  0.0337\n",
            "     26        \u001b[36m0.9981\u001b[0m  0.0333\n",
            "     27        \u001b[36m0.9981\u001b[0m  0.0412\n",
            "     28        \u001b[36m0.9981\u001b[0m  0.0338\n",
            "     29        \u001b[36m0.9981\u001b[0m  0.0336\n",
            "     30        \u001b[36m0.9981\u001b[0m  0.0342\n",
            "     31        \u001b[36m0.9981\u001b[0m  0.0338\n",
            "     32        \u001b[36m0.9981\u001b[0m  0.0326\n",
            "     33        \u001b[36m0.9981\u001b[0m  0.0329\n",
            "     34        \u001b[36m0.9981\u001b[0m  0.0347\n",
            "     35        \u001b[36m0.9981\u001b[0m  0.0318\n",
            "     36        \u001b[36m0.9981\u001b[0m  0.0322\n",
            "     37        \u001b[36m0.9981\u001b[0m  0.0328\n",
            "     38        \u001b[36m0.9981\u001b[0m  0.0327\n",
            "     39        \u001b[36m0.9981\u001b[0m  0.0312\n",
            "     40        \u001b[36m0.9981\u001b[0m  0.0341\n",
            "     41        \u001b[36m0.9981\u001b[0m  0.0323\n",
            "     42        \u001b[36m0.9981\u001b[0m  0.0326\n",
            "     43        \u001b[36m0.9981\u001b[0m  0.0322\n",
            "     44        \u001b[36m0.9981\u001b[0m  0.0325\n",
            "     45        \u001b[36m0.9981\u001b[0m  0.0352\n",
            "     46        \u001b[36m0.9981\u001b[0m  0.0407\n",
            "     47        \u001b[36m0.9981\u001b[0m  0.0334\n",
            "     48        \u001b[36m0.9981\u001b[0m  0.0334\n",
            "     49        \u001b[36m0.9981\u001b[0m  0.0371\n",
            "     50        \u001b[36m0.9981\u001b[0m  0.0339\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0407\n",
            "      2        \u001b[36m0.9998\u001b[0m  0.0425\n",
            "      3        \u001b[36m0.9996\u001b[0m  0.0445\n",
            "      4        \u001b[36m0.9993\u001b[0m  0.0440\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9983\u001b[0m  0.0575\n",
            "      6        \u001b[36m0.9956\u001b[0m  0.0456\n",
            "      7        \u001b[36m0.9868\u001b[0m  0.0426\n",
            "      8        \u001b[36m0.9555\u001b[0m  0.0446\n",
            "      9        \u001b[36m0.8253\u001b[0m  0.0455\n",
            "     10        \u001b[36m0.5895\u001b[0m  0.0450\n",
            "     11        \u001b[36m0.4419\u001b[0m  0.0445\n",
            "     12        \u001b[36m0.4038\u001b[0m  0.0427\n",
            "     13        \u001b[36m0.3957\u001b[0m  0.0415\n",
            "     14        \u001b[36m0.3870\u001b[0m  0.0417\n",
            "     15        \u001b[36m0.3824\u001b[0m  0.0455\n",
            "     16        \u001b[36m0.3812\u001b[0m  0.0418\n",
            "     17        \u001b[36m0.3801\u001b[0m  0.0425\n",
            "     18        \u001b[36m0.3796\u001b[0m  0.0549\n",
            "     19        \u001b[36m0.3792\u001b[0m  0.0464\n",
            "     20        \u001b[36m0.3785\u001b[0m  0.0427\n",
            "     21        \u001b[36m0.3776\u001b[0m  0.0450\n",
            "     22        \u001b[36m0.3766\u001b[0m  0.0436\n",
            "     23        \u001b[36m0.3756\u001b[0m  0.0423\n",
            "     24        \u001b[36m0.3753\u001b[0m  0.0450\n",
            "     25        \u001b[36m0.3752\u001b[0m  0.0443\n",
            "     26        \u001b[36m0.3752\u001b[0m  0.0435\n",
            "     27        \u001b[36m0.3751\u001b[0m  0.0532\n",
            "     28        \u001b[36m0.3751\u001b[0m  0.0475\n",
            "     29        \u001b[36m0.3750\u001b[0m  0.0435\n",
            "     30        \u001b[36m0.3750\u001b[0m  0.0417\n",
            "     31        \u001b[36m0.3750\u001b[0m  0.0429\n",
            "     32        \u001b[36m0.3749\u001b[0m  0.0433\n",
            "     33        \u001b[36m0.3749\u001b[0m  0.0434\n",
            "     34        \u001b[36m0.3749\u001b[0m  0.0487\n",
            "     35        \u001b[36m0.3748\u001b[0m  0.0462\n",
            "     36        \u001b[36m0.3748\u001b[0m  0.0436\n",
            "     37        \u001b[36m0.3747\u001b[0m  0.0435\n",
            "     38        \u001b[36m0.3747\u001b[0m  0.0445\n",
            "     39        \u001b[36m0.3747\u001b[0m  0.0527\n",
            "     40        \u001b[36m0.3747\u001b[0m  0.0441\n",
            "     41        \u001b[36m0.3746\u001b[0m  0.0447\n",
            "     42        \u001b[36m0.3746\u001b[0m  0.0446\n",
            "     43        \u001b[36m0.3746\u001b[0m  0.0427\n",
            "     44        \u001b[36m0.3745\u001b[0m  0.0424\n",
            "     45        \u001b[36m0.3745\u001b[0m  0.0416\n",
            "     46        \u001b[36m0.3745\u001b[0m  0.0455\n",
            "     47        \u001b[36m0.3745\u001b[0m  0.0441\n",
            "     48        \u001b[36m0.3744\u001b[0m  0.0415\n",
            "     49        \u001b[36m0.3744\u001b[0m  0.0526\n",
            "     50        \u001b[36m0.3744\u001b[0m  0.0437\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9998\u001b[0m  0.0391\n",
            "      2        \u001b[36m0.9997\u001b[0m  0.0433\n",
            "      3        \u001b[36m0.9995\u001b[0m  0.0456\n",
            "      4        \u001b[36m0.9990\u001b[0m  0.0442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9977\u001b[0m  0.0450\n",
            "      6        \u001b[36m0.9939\u001b[0m  0.0421\n",
            "      7        \u001b[36m0.9814\u001b[0m  0.0416\n",
            "      8        \u001b[36m0.9408\u001b[0m  0.0429\n",
            "      9        \u001b[36m0.8257\u001b[0m  0.0424\n",
            "     10        \u001b[36m0.6048\u001b[0m  0.0433\n",
            "     11        \u001b[36m0.4609\u001b[0m  0.0552\n",
            "     12        \u001b[36m0.4142\u001b[0m  0.0425\n",
            "     13        \u001b[36m0.3940\u001b[0m  0.0427\n",
            "     14        \u001b[36m0.3887\u001b[0m  0.0434\n",
            "     15        \u001b[36m0.3859\u001b[0m  0.0425\n",
            "     16        \u001b[36m0.3820\u001b[0m  0.0437\n",
            "     17        \u001b[36m0.3806\u001b[0m  0.0435\n",
            "     18        \u001b[36m0.3799\u001b[0m  0.0436\n",
            "     19        \u001b[36m0.3793\u001b[0m  0.0444\n",
            "     20        \u001b[36m0.3788\u001b[0m  0.0435\n",
            "     21        \u001b[36m0.3784\u001b[0m  0.0530\n",
            "     22        \u001b[36m0.3780\u001b[0m  0.0410\n",
            "     23        \u001b[36m0.3776\u001b[0m  0.0451\n",
            "     24        \u001b[36m0.3773\u001b[0m  0.0452\n",
            "     25        \u001b[36m0.3770\u001b[0m  0.0452\n",
            "     26        \u001b[36m0.3767\u001b[0m  0.0428\n",
            "     27        \u001b[36m0.3765\u001b[0m  0.0415\n",
            "     28        \u001b[36m0.3762\u001b[0m  0.0418\n",
            "     29        \u001b[36m0.3760\u001b[0m  0.0417\n",
            "     30        \u001b[36m0.3753\u001b[0m  0.0430\n",
            "     31        \u001b[36m0.3750\u001b[0m  0.0424\n",
            "     32        \u001b[36m0.3748\u001b[0m  0.0463\n",
            "     33        \u001b[36m0.3747\u001b[0m  0.0616\n",
            "     34        \u001b[36m0.3746\u001b[0m  0.0453\n",
            "     35        \u001b[36m0.3745\u001b[0m  0.0448\n",
            "     36        \u001b[36m0.3744\u001b[0m  0.0434\n",
            "     37        \u001b[36m0.3744\u001b[0m  0.0432\n",
            "     38        \u001b[36m0.3743\u001b[0m  0.0411\n",
            "     39        \u001b[36m0.3742\u001b[0m  0.0450\n",
            "     40        \u001b[36m0.3741\u001b[0m  0.0425\n",
            "     41        \u001b[36m0.3741\u001b[0m  0.0430\n",
            "     42        \u001b[36m0.3740\u001b[0m  0.0418\n",
            "     43        \u001b[36m0.3739\u001b[0m  0.0493\n",
            "     44        \u001b[36m0.3739\u001b[0m  0.0416\n",
            "     45        \u001b[36m0.3738\u001b[0m  0.0421\n",
            "     46        \u001b[36m0.3737\u001b[0m  0.0456\n",
            "     47        \u001b[36m0.3737\u001b[0m  0.0431\n",
            "     48        \u001b[36m0.3736\u001b[0m  0.0442\n",
            "     49        \u001b[36m0.3736\u001b[0m  0.0452\n",
            "     50        \u001b[36m0.3735\u001b[0m  0.0437\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9995\u001b[0m  0.0293\n",
            "      2        \u001b[36m0.9995\u001b[0m  0.0351\n",
            "      3        \u001b[36m0.9995\u001b[0m  0.0332\n",
            "      4        \u001b[36m0.9995\u001b[0m  0.0336\n",
            "      5        \u001b[36m0.9995\u001b[0m  0.0421\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9995\u001b[0m  0.0410\n",
            "      7        \u001b[36m0.9995\u001b[0m  0.0314\n",
            "      8        \u001b[36m0.9995\u001b[0m  0.0323\n",
            "      9        \u001b[36m0.9995\u001b[0m  0.0326\n",
            "     10        \u001b[36m0.9995\u001b[0m  0.0332\n",
            "     11        \u001b[36m0.9995\u001b[0m  0.0311\n",
            "     12        \u001b[36m0.9995\u001b[0m  0.0324\n",
            "     13        \u001b[36m0.9995\u001b[0m  0.0336\n",
            "     14        \u001b[36m0.9995\u001b[0m  0.0331\n",
            "     15        \u001b[36m0.9995\u001b[0m  0.0324\n",
            "     16        \u001b[36m0.9995\u001b[0m  0.0327\n",
            "     17        \u001b[36m0.9995\u001b[0m  0.0336\n",
            "     18        \u001b[36m0.9995\u001b[0m  0.0325\n",
            "     19        \u001b[36m0.9995\u001b[0m  0.0349\n",
            "     20        \u001b[36m0.9995\u001b[0m  0.0434\n",
            "     21        \u001b[36m0.9995\u001b[0m  0.0337\n",
            "     22        \u001b[36m0.9995\u001b[0m  0.0330\n",
            "     23        \u001b[36m0.9995\u001b[0m  0.0327\n",
            "     24        \u001b[36m0.9995\u001b[0m  0.0331\n",
            "     25        \u001b[36m0.9995\u001b[0m  0.0333\n",
            "     26        \u001b[36m0.9995\u001b[0m  0.0336\n",
            "     27        \u001b[36m0.9995\u001b[0m  0.0329\n",
            "     28        \u001b[36m0.9995\u001b[0m  0.0330\n",
            "     29        \u001b[36m0.9995\u001b[0m  0.0326\n",
            "     30        \u001b[36m0.9995\u001b[0m  0.0353\n",
            "     31        \u001b[36m0.9995\u001b[0m  0.0332\n",
            "     32        \u001b[36m0.9995\u001b[0m  0.0336\n",
            "     33        \u001b[36m0.9995\u001b[0m  0.0452\n",
            "     34        \u001b[36m0.9995\u001b[0m  0.0368\n",
            "     35        \u001b[36m0.9995\u001b[0m  0.0358\n",
            "     36        \u001b[36m0.9995\u001b[0m  0.0366\n",
            "     37        \u001b[36m0.9995\u001b[0m  0.0337\n",
            "     38        \u001b[36m0.9995\u001b[0m  0.0334\n",
            "     39        \u001b[36m0.9995\u001b[0m  0.0355\n",
            "     40        \u001b[36m0.9995\u001b[0m  0.0339\n",
            "     41        \u001b[36m0.9995\u001b[0m  0.0342\n",
            "     42        \u001b[36m0.9995\u001b[0m  0.0361\n",
            "     43        \u001b[36m0.9995\u001b[0m  0.0332\n",
            "     44        \u001b[36m0.9995\u001b[0m  0.0345\n",
            "     45        \u001b[36m0.9995\u001b[0m  0.0323\n",
            "     46        \u001b[36m0.9995\u001b[0m  0.0344\n",
            "     47        \u001b[36m0.9995\u001b[0m  0.0327\n",
            "     48        \u001b[36m0.9995\u001b[0m  0.0426\n",
            "     49        \u001b[36m0.9995\u001b[0m  0.0339\n",
            "     50        \u001b[36m0.9995\u001b[0m  0.0379\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0295\n",
            "      2        \u001b[36m0.9999\u001b[0m  0.0334\n",
            "      3        0.9999  0.0328\n",
            "      4        0.9999  0.0421\n",
            "      5        0.9999  0.0455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9999\u001b[0m  0.0440\n",
            "      7        \u001b[36m0.9999\u001b[0m  0.0484\n",
            "      8        0.9999  0.0498\n",
            "      9        0.9999  0.0476\n",
            "     10        0.9999  0.0416\n",
            "     11        0.9999  0.0496\n",
            "     12        \u001b[36m0.9999\u001b[0m  0.0436\n",
            "     13        \u001b[36m0.9999\u001b[0m  0.0418\n",
            "     14        0.9999  0.0440\n",
            "     15        0.9999  0.0402\n",
            "     16        0.9999  0.0473\n",
            "     17        \u001b[36m0.9999\u001b[0m  0.0405\n",
            "     18        \u001b[36m0.9999\u001b[0m  0.0447\n",
            "     19        0.9999  0.0412\n",
            "     20        0.9999  0.0430\n",
            "     21        0.9999  0.0471\n",
            "     22        \u001b[36m0.9999\u001b[0m  0.0484\n",
            "     23        \u001b[36m0.9999\u001b[0m  0.0404\n",
            "     24        0.9999  0.0403\n",
            "     25        0.9999  0.0419\n",
            "     26        0.9999  0.0461\n",
            "     27        0.9999  0.0392\n",
            "     28        \u001b[36m0.9999\u001b[0m  0.0384\n",
            "     29        0.9999  0.0430\n",
            "     30        0.9999  0.0463\n",
            "     31        0.9999  0.0435\n",
            "     32        0.9999  0.0457\n",
            "     33        \u001b[36m0.9999\u001b[0m  0.0419\n",
            "     34        0.9999  0.0461\n",
            "     35        0.9999  0.0398\n",
            "     36        0.9999  0.0401\n",
            "     37        0.9999  0.0401\n",
            "     38        \u001b[36m0.9999\u001b[0m  0.0430\n",
            "     39        \u001b[36m0.9999\u001b[0m  0.0445\n",
            "     40        0.9999  0.0502\n",
            "     41        0.9999  0.0465\n",
            "     42        0.9999  0.0512\n",
            "     43        \u001b[36m0.9999\u001b[0m  0.0508\n",
            "     44        \u001b[36m0.9999\u001b[0m  0.0446\n",
            "     45        0.9999  0.0440\n",
            "     46        0.9999  0.0461\n",
            "     47        0.9999  0.0469\n",
            "     48        0.9999  0.0511\n",
            "     49        \u001b[36m0.9999\u001b[0m  0.0442\n",
            "     50        \u001b[36m0.9999\u001b[0m  0.0620\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9677\u001b[0m  0.0624\n",
            "      2        \u001b[36m0.9629\u001b[0m  0.0606\n",
            "      3        \u001b[36m0.9570\u001b[0m  0.0547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4        \u001b[36m0.9493\u001b[0m  0.0792\n",
            "      5        \u001b[36m0.9363\u001b[0m  0.0562\n",
            "      6        \u001b[36m0.9041\u001b[0m  0.0547\n",
            "      7        \u001b[36m0.7968\u001b[0m  0.0655\n",
            "      8        \u001b[36m0.6134\u001b[0m  0.0599\n",
            "      9        \u001b[36m0.5019\u001b[0m  0.0699\n",
            "     10        \u001b[36m0.4543\u001b[0m  0.0737\n",
            "     11        \u001b[36m0.4299\u001b[0m  0.0457\n",
            "     12        \u001b[36m0.4156\u001b[0m  0.0425\n",
            "     13        \u001b[36m0.4067\u001b[0m  0.0425\n",
            "     14        \u001b[36m0.4010\u001b[0m  0.0434\n",
            "     15        \u001b[36m0.3971\u001b[0m  0.0493\n",
            "     16        \u001b[36m0.3941\u001b[0m  0.0491\n",
            "     17        \u001b[36m0.3919\u001b[0m  0.0435\n",
            "     18        \u001b[36m0.3900\u001b[0m  0.0448\n",
            "     19        \u001b[36m0.3885\u001b[0m  0.0449\n",
            "     20        \u001b[36m0.3873\u001b[0m  0.0423\n",
            "     21        \u001b[36m0.3870\u001b[0m  0.0411\n",
            "     22        \u001b[36m0.3867\u001b[0m  0.0430\n",
            "     23        \u001b[36m0.3851\u001b[0m  0.0456\n",
            "     24        \u001b[36m0.3841\u001b[0m  0.0445\n",
            "     25        \u001b[36m0.3830\u001b[0m  0.0450\n",
            "     26        \u001b[36m0.3824\u001b[0m  0.0432\n",
            "     27        \u001b[36m0.3818\u001b[0m  0.0460\n",
            "     28        \u001b[36m0.3813\u001b[0m  0.0428\n",
            "     29        \u001b[36m0.3809\u001b[0m  0.0438\n",
            "     30        \u001b[36m0.3805\u001b[0m  0.0429\n",
            "     31        \u001b[36m0.3801\u001b[0m  0.0514\n",
            "     32        \u001b[36m0.3798\u001b[0m  0.0434\n",
            "     33        \u001b[36m0.3795\u001b[0m  0.0413\n",
            "     34        \u001b[36m0.3792\u001b[0m  0.0418\n",
            "     35        \u001b[36m0.3789\u001b[0m  0.0426\n",
            "     36        \u001b[36m0.3786\u001b[0m  0.0416\n",
            "     37        \u001b[36m0.3784\u001b[0m  0.0484\n",
            "     38        \u001b[36m0.3782\u001b[0m  0.0496\n",
            "     39        \u001b[36m0.3780\u001b[0m  0.0444\n",
            "     40        \u001b[36m0.3778\u001b[0m  0.0454\n",
            "     41        \u001b[36m0.3777\u001b[0m  0.0436\n",
            "     42        \u001b[36m0.3775\u001b[0m  0.0428\n",
            "     43        \u001b[36m0.3773\u001b[0m  0.0439\n",
            "     44        \u001b[36m0.3772\u001b[0m  0.0441\n",
            "     45        \u001b[36m0.3771\u001b[0m  0.0448\n",
            "     46        \u001b[36m0.3768\u001b[0m  0.0443\n",
            "     47        \u001b[36m0.3767\u001b[0m  0.0434\n",
            "     48        \u001b[36m0.3766\u001b[0m  0.0440\n",
            "     49        \u001b[36m0.3765\u001b[0m  0.0447\n",
            "     50        \u001b[36m0.3764\u001b[0m  0.0431\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8161\u001b[0m  0.0409\n",
            "      2        \u001b[36m0.7905\u001b[0m  0.0447\n",
            "      3        \u001b[36m0.7601\u001b[0m  0.0546\n",
            "      4        \u001b[36m0.7335\u001b[0m  0.0446\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.7146\u001b[0m  0.0485\n",
            "      6        \u001b[36m0.7006\u001b[0m  0.0415\n",
            "      7        \u001b[36m0.6855\u001b[0m  0.0429\n",
            "      8        \u001b[36m0.6644\u001b[0m  0.0476\n",
            "      9        \u001b[36m0.6237\u001b[0m  0.0492\n",
            "     10        \u001b[36m0.5785\u001b[0m  0.0415\n",
            "     11        \u001b[36m0.5324\u001b[0m  0.0439\n",
            "     12        \u001b[36m0.4979\u001b[0m  0.0435\n",
            "     13        \u001b[36m0.4748\u001b[0m  0.0437\n",
            "     14        \u001b[36m0.4578\u001b[0m  0.0416\n",
            "     15        \u001b[36m0.4460\u001b[0m  0.0417\n",
            "     16        \u001b[36m0.4358\u001b[0m  0.0428\n",
            "     17        \u001b[36m0.4264\u001b[0m  0.0427\n",
            "     18        \u001b[36m0.4200\u001b[0m  0.0416\n",
            "     19        \u001b[36m0.4155\u001b[0m  0.0418\n",
            "     20        \u001b[36m0.4116\u001b[0m  0.0449\n",
            "     21        \u001b[36m0.4083\u001b[0m  0.0434\n",
            "     22        \u001b[36m0.4054\u001b[0m  0.0427\n",
            "     23        \u001b[36m0.4029\u001b[0m  0.0427\n",
            "     24        \u001b[36m0.4006\u001b[0m  0.0416\n",
            "     25        \u001b[36m0.3986\u001b[0m  0.0407\n",
            "     26        \u001b[36m0.3967\u001b[0m  0.0501\n",
            "     27        \u001b[36m0.3951\u001b[0m  0.0405\n",
            "     28        \u001b[36m0.3937\u001b[0m  0.0443\n",
            "     29        \u001b[36m0.3924\u001b[0m  0.0416\n",
            "     30        \u001b[36m0.3911\u001b[0m  0.0415\n",
            "     31        \u001b[36m0.3900\u001b[0m  0.0551\n",
            "     32        \u001b[36m0.3890\u001b[0m  0.0419\n",
            "     33        \u001b[36m0.3881\u001b[0m  0.0426\n",
            "     34        \u001b[36m0.3872\u001b[0m  0.0430\n",
            "     35        \u001b[36m0.3864\u001b[0m  0.0438\n",
            "     36        \u001b[36m0.3856\u001b[0m  0.0428\n",
            "     37        \u001b[36m0.3848\u001b[0m  0.0420\n",
            "     38        \u001b[36m0.3841\u001b[0m  0.0435\n",
            "     39        \u001b[36m0.3835\u001b[0m  0.0444\n",
            "     40        \u001b[36m0.3829\u001b[0m  0.0439\n",
            "     41        \u001b[36m0.3823\u001b[0m  0.0412\n",
            "     42        \u001b[36m0.3819\u001b[0m  0.0411\n",
            "     43        \u001b[36m0.3814\u001b[0m  0.0448\n",
            "     44        0.3817  0.0415\n",
            "     45        \u001b[36m0.3809\u001b[0m  0.0429\n",
            "     46        \u001b[36m0.3801\u001b[0m  0.0411\n",
            "     47        \u001b[36m0.3794\u001b[0m  0.0425\n",
            "     48        \u001b[36m0.3788\u001b[0m  0.0427\n",
            "     49        \u001b[36m0.3782\u001b[0m  0.0533\n",
            "     50        \u001b[36m0.3778\u001b[0m  0.0418\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5696\u001b[0m  0.0298\n",
            "      2        \u001b[36m0.5677\u001b[0m  0.0344\n",
            "      3        \u001b[36m0.5658\u001b[0m  0.0400\n",
            "      4        \u001b[36m0.5639\u001b[0m  0.0415\n",
            "      5        \u001b[36m0.5620\u001b[0m  0.0331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.5602\u001b[0m  0.0375\n",
            "      7        \u001b[36m0.5585\u001b[0m  0.0342\n",
            "      8        \u001b[36m0.5567\u001b[0m  0.0355\n",
            "      9        \u001b[36m0.5550\u001b[0m  0.0357\n",
            "     10        \u001b[36m0.5533\u001b[0m  0.0346\n",
            "     11        \u001b[36m0.5517\u001b[0m  0.0340\n",
            "     12        \u001b[36m0.5501\u001b[0m  0.0334\n",
            "     13        \u001b[36m0.5485\u001b[0m  0.0333\n",
            "     14        \u001b[36m0.5469\u001b[0m  0.0327\n",
            "     15        \u001b[36m0.5454\u001b[0m  0.0354\n",
            "     16        \u001b[36m0.5439\u001b[0m  0.0332\n",
            "     17        \u001b[36m0.5424\u001b[0m  0.0347\n",
            "     18        \u001b[36m0.5410\u001b[0m  0.0342\n",
            "     19        \u001b[36m0.5395\u001b[0m  0.0324\n",
            "     20        \u001b[36m0.5381\u001b[0m  0.0335\n",
            "     21        \u001b[36m0.5367\u001b[0m  0.0336\n",
            "     22        \u001b[36m0.5353\u001b[0m  0.0324\n",
            "     23        \u001b[36m0.5340\u001b[0m  0.0363\n",
            "     24        \u001b[36m0.5327\u001b[0m  0.0321\n",
            "     25        \u001b[36m0.5314\u001b[0m  0.0341\n",
            "     26        \u001b[36m0.5301\u001b[0m  0.0412\n",
            "     27        \u001b[36m0.5288\u001b[0m  0.0330\n",
            "     28        \u001b[36m0.5276\u001b[0m  0.0328\n",
            "     29        \u001b[36m0.5263\u001b[0m  0.0322\n",
            "     30        \u001b[36m0.5251\u001b[0m  0.0333\n",
            "     31        \u001b[36m0.5239\u001b[0m  0.0427\n",
            "     32        \u001b[36m0.5227\u001b[0m  0.0371\n",
            "     33        \u001b[36m0.5216\u001b[0m  0.0328\n",
            "     34        \u001b[36m0.5204\u001b[0m  0.0336\n",
            "     35        \u001b[36m0.5193\u001b[0m  0.0329\n",
            "     36        \u001b[36m0.5182\u001b[0m  0.0333\n",
            "     37        \u001b[36m0.5171\u001b[0m  0.0327\n",
            "     38        \u001b[36m0.5160\u001b[0m  0.0343\n",
            "     39        \u001b[36m0.5149\u001b[0m  0.0321\n",
            "     40        \u001b[36m0.5138\u001b[0m  0.0334\n",
            "     41        \u001b[36m0.5128\u001b[0m  0.0334\n",
            "     42        \u001b[36m0.5118\u001b[0m  0.0332\n",
            "     43        \u001b[36m0.5107\u001b[0m  0.0343\n",
            "     44        \u001b[36m0.5097\u001b[0m  0.0319\n",
            "     45        \u001b[36m0.5088\u001b[0m  0.0333\n",
            "     46        \u001b[36m0.5078\u001b[0m  0.0345\n",
            "     47        \u001b[36m0.5068\u001b[0m  0.0345\n",
            "     48        \u001b[36m0.5059\u001b[0m  0.0335\n",
            "     49        \u001b[36m0.5049\u001b[0m  0.0361\n",
            "     50        \u001b[36m0.5040\u001b[0m  0.0357\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4538\u001b[0m  0.0300\n",
            "      2        \u001b[36m0.4536\u001b[0m  0.0329\n",
            "      3        \u001b[36m0.4534\u001b[0m  0.0327\n",
            "      4        \u001b[36m0.4532\u001b[0m  0.0365\n",
            "      5        \u001b[36m0.4530\u001b[0m  0.0375\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.4529\u001b[0m  0.0353\n",
            "      7        \u001b[36m0.4527\u001b[0m  0.0328\n",
            "      8        \u001b[36m0.4525\u001b[0m  0.0323\n",
            "      9        \u001b[36m0.4523\u001b[0m  0.0431\n",
            "     10        \u001b[36m0.4521\u001b[0m  0.0375\n",
            "     11        \u001b[36m0.4519\u001b[0m  0.0323\n",
            "     12        \u001b[36m0.4517\u001b[0m  0.0463\n",
            "     13        \u001b[36m0.4515\u001b[0m  0.0389\n",
            "     14        \u001b[36m0.4513\u001b[0m  0.0343\n",
            "     15        \u001b[36m0.4511\u001b[0m  0.0336\n",
            "     16        \u001b[36m0.4510\u001b[0m  0.0341\n",
            "     17        \u001b[36m0.4508\u001b[0m  0.0338\n",
            "     18        \u001b[36m0.4506\u001b[0m  0.0340\n",
            "     19        \u001b[36m0.4504\u001b[0m  0.0332\n",
            "     20        \u001b[36m0.4502\u001b[0m  0.0339\n",
            "     21        \u001b[36m0.4500\u001b[0m  0.0329\n",
            "     22        \u001b[36m0.4498\u001b[0m  0.0349\n",
            "     23        \u001b[36m0.4496\u001b[0m  0.0344\n",
            "     24        \u001b[36m0.4494\u001b[0m  0.0355\n",
            "     25        \u001b[36m0.4493\u001b[0m  0.0328\n",
            "     26        \u001b[36m0.4491\u001b[0m  0.0328\n",
            "     27        \u001b[36m0.4489\u001b[0m  0.0323\n",
            "     28        \u001b[36m0.4487\u001b[0m  0.0325\n",
            "     29        \u001b[36m0.4485\u001b[0m  0.0324\n",
            "     30        \u001b[36m0.4483\u001b[0m  0.0334\n",
            "     31        \u001b[36m0.4482\u001b[0m  0.0313\n",
            "     32        \u001b[36m0.4480\u001b[0m  0.0331\n",
            "     33        \u001b[36m0.4478\u001b[0m  0.0415\n",
            "     34        \u001b[36m0.4476\u001b[0m  0.0321\n",
            "     35        \u001b[36m0.4474\u001b[0m  0.0326\n",
            "     36        \u001b[36m0.4472\u001b[0m  0.0406\n",
            "     37        \u001b[36m0.4471\u001b[0m  0.0419\n",
            "     38        \u001b[36m0.4469\u001b[0m  0.0325\n",
            "     39        \u001b[36m0.4467\u001b[0m  0.0336\n",
            "     40        \u001b[36m0.4465\u001b[0m  0.0336\n",
            "     41        \u001b[36m0.4463\u001b[0m  0.0331\n",
            "     42        \u001b[36m0.4462\u001b[0m  0.0334\n",
            "     43        \u001b[36m0.4460\u001b[0m  0.0332\n",
            "     44        \u001b[36m0.4458\u001b[0m  0.0336\n",
            "     45        \u001b[36m0.4456\u001b[0m  0.0338\n",
            "     46        \u001b[36m0.4455\u001b[0m  0.0332\n",
            "     47        \u001b[36m0.4453\u001b[0m  0.0329\n",
            "     48        \u001b[36m0.4451\u001b[0m  0.0335\n",
            "     49        \u001b[36m0.4449\u001b[0m  0.0334\n",
            "     50        \u001b[36m0.4448\u001b[0m  0.0336\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9255\u001b[0m  0.0403\n",
            "      2        \u001b[36m0.8945\u001b[0m  0.0425\n",
            "      3        \u001b[36m0.8464\u001b[0m  0.0422\n",
            "      4        \u001b[36m0.7835\u001b[0m  0.0424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.7121\u001b[0m  0.0501\n",
            "      6        \u001b[36m0.6511\u001b[0m  0.0430\n",
            "      7        \u001b[36m0.5925\u001b[0m  0.0409\n",
            "      8        \u001b[36m0.5386\u001b[0m  0.0412\n",
            "      9        \u001b[36m0.4890\u001b[0m  0.0498\n",
            "     10        \u001b[36m0.4569\u001b[0m  0.0410\n",
            "     11        \u001b[36m0.4366\u001b[0m  0.0507\n",
            "     12        \u001b[36m0.4248\u001b[0m  0.0470\n",
            "     13        \u001b[36m0.4170\u001b[0m  0.0417\n",
            "     14        \u001b[36m0.4114\u001b[0m  0.0415\n",
            "     15        \u001b[36m0.4074\u001b[0m  0.0407\n",
            "     16        \u001b[36m0.4055\u001b[0m  0.0408\n",
            "     17        \u001b[36m0.4030\u001b[0m  0.0424\n",
            "     18        \u001b[36m0.4009\u001b[0m  0.0424\n",
            "     19        \u001b[36m0.3988\u001b[0m  0.0432\n",
            "     20        \u001b[36m0.3958\u001b[0m  0.0414\n",
            "     21        \u001b[36m0.3930\u001b[0m  0.0416\n",
            "     22        \u001b[36m0.3918\u001b[0m  0.0412\n",
            "     23        \u001b[36m0.3910\u001b[0m  0.0431\n",
            "     24        \u001b[36m0.3899\u001b[0m  0.0429\n",
            "     25        \u001b[36m0.3881\u001b[0m  0.0409\n",
            "     26        \u001b[36m0.3867\u001b[0m  0.0429\n",
            "     27        \u001b[36m0.3848\u001b[0m  0.0426\n",
            "     28        \u001b[36m0.3834\u001b[0m  0.0453\n",
            "     29        \u001b[36m0.3823\u001b[0m  0.0413\n",
            "     30        \u001b[36m0.3813\u001b[0m  0.0424\n",
            "     31        \u001b[36m0.3805\u001b[0m  0.0426\n",
            "     32        \u001b[36m0.3778\u001b[0m  0.0514\n",
            "     33        \u001b[36m0.3775\u001b[0m  0.0468\n",
            "     34        \u001b[36m0.3773\u001b[0m  0.0504\n",
            "     35        \u001b[36m0.3771\u001b[0m  0.0434\n",
            "     36        \u001b[36m0.3768\u001b[0m  0.0435\n",
            "     37        \u001b[36m0.3766\u001b[0m  0.0411\n",
            "     38        \u001b[36m0.3764\u001b[0m  0.0415\n",
            "     39        \u001b[36m0.3763\u001b[0m  0.0419\n",
            "     40        \u001b[36m0.3762\u001b[0m  0.0427\n",
            "     41        \u001b[36m0.3761\u001b[0m  0.0427\n",
            "     42        \u001b[36m0.3760\u001b[0m  0.0424\n",
            "     43        \u001b[36m0.3759\u001b[0m  0.0431\n",
            "     44        \u001b[36m0.3758\u001b[0m  0.0427\n",
            "     45        \u001b[36m0.3756\u001b[0m  0.0428\n",
            "     46        \u001b[36m0.3755\u001b[0m  0.0454\n",
            "     47        \u001b[36m0.3754\u001b[0m  0.0405\n",
            "     48        \u001b[36m0.3754\u001b[0m  0.0428\n",
            "     49        0.3757  0.0438\n",
            "     50        0.3756  0.0436\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6644\u001b[0m  0.0577\n",
            "      2        \u001b[36m0.5588\u001b[0m  0.0607\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      3        \u001b[36m0.4786\u001b[0m  0.0725\n",
            "      4        \u001b[36m0.4347\u001b[0m  0.0662\n",
            "      5        \u001b[36m0.4143\u001b[0m  0.0618\n",
            "      6        \u001b[36m0.4035\u001b[0m  0.0615\n",
            "      7        \u001b[36m0.3970\u001b[0m  0.0643\n",
            "      8        \u001b[36m0.3927\u001b[0m  0.0585\n",
            "      9        \u001b[36m0.3890\u001b[0m  0.0610\n",
            "     10        \u001b[36m0.3856\u001b[0m  0.0548\n",
            "     11        \u001b[36m0.3839\u001b[0m  0.0584\n",
            "     12        \u001b[36m0.3825\u001b[0m  0.0539\n",
            "     13        \u001b[36m0.3813\u001b[0m  0.0565\n",
            "     14        \u001b[36m0.3805\u001b[0m  0.0556\n",
            "     15        \u001b[36m0.3791\u001b[0m  0.0543\n",
            "     16        \u001b[36m0.3781\u001b[0m  0.0574\n",
            "     17        \u001b[36m0.3775\u001b[0m  0.0562\n",
            "     18        \u001b[36m0.3771\u001b[0m  0.0556\n",
            "     19        \u001b[36m0.3765\u001b[0m  0.0530\n",
            "     20        \u001b[36m0.3761\u001b[0m  0.0671\n",
            "     21        \u001b[36m0.3760\u001b[0m  0.0575\n",
            "     22        \u001b[36m0.3756\u001b[0m  0.0547\n",
            "     23        \u001b[36m0.3749\u001b[0m  0.0563\n",
            "     24        \u001b[36m0.3748\u001b[0m  0.0516\n",
            "     25        \u001b[36m0.3746\u001b[0m  0.0514\n",
            "     26        \u001b[36m0.3745\u001b[0m  0.0525\n",
            "     27        \u001b[36m0.3744\u001b[0m  0.0586\n",
            "     28        \u001b[36m0.3742\u001b[0m  0.0566\n",
            "     29        \u001b[36m0.3742\u001b[0m  0.0569\n",
            "     30        0.3744  0.0599\n",
            "     31        0.3743  0.0614\n",
            "     32        \u001b[36m0.3741\u001b[0m  0.0520\n",
            "     33        \u001b[36m0.3740\u001b[0m  0.0574\n",
            "     34        \u001b[36m0.3738\u001b[0m  0.0604\n",
            "     35        \u001b[36m0.3736\u001b[0m  0.0590\n",
            "     36        \u001b[36m0.3734\u001b[0m  0.0551\n",
            "     37        \u001b[36m0.3733\u001b[0m  0.0766\n",
            "     38        \u001b[36m0.3731\u001b[0m  0.0623\n",
            "     39        \u001b[36m0.3731\u001b[0m  0.0579\n",
            "     40        \u001b[36m0.3730\u001b[0m  0.0569\n",
            "     41        0.3731  0.0575\n",
            "     42        \u001b[36m0.3730\u001b[0m  0.0579\n",
            "     43        \u001b[36m0.3729\u001b[0m  0.0593\n",
            "     44        \u001b[36m0.3729\u001b[0m  0.0561\n",
            "     45        \u001b[36m0.3728\u001b[0m  0.0612\n",
            "     46        \u001b[36m0.3728\u001b[0m  0.0648\n",
            "     47        \u001b[36m0.3727\u001b[0m  0.0689\n",
            "     48        \u001b[36m0.3727\u001b[0m  0.0610\n",
            "     49        \u001b[36m0.3727\u001b[0m  0.0613\n",
            "     50        \u001b[36m0.3727\u001b[0m  0.0426\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4775\u001b[0m  0.0312\n",
            "      2        \u001b[36m0.4762\u001b[0m  0.0339\n",
            "      3        \u001b[36m0.4749\u001b[0m  0.0414\n",
            "      4        \u001b[36m0.4737\u001b[0m  0.0357\n",
            "      5        \u001b[36m0.4724\u001b[0m  0.0334\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.4713\u001b[0m  0.0487\n",
            "      7        \u001b[36m0.4701\u001b[0m  0.0333\n",
            "      8        \u001b[36m0.4690\u001b[0m  0.0347\n",
            "      9        \u001b[36m0.4679\u001b[0m  0.0329\n",
            "     10        \u001b[36m0.4669\u001b[0m  0.0330\n",
            "     11        \u001b[36m0.4658\u001b[0m  0.0329\n",
            "     12        \u001b[36m0.4649\u001b[0m  0.0320\n",
            "     13        \u001b[36m0.4639\u001b[0m  0.0334\n",
            "     14        \u001b[36m0.4629\u001b[0m  0.0330\n",
            "     15        \u001b[36m0.4620\u001b[0m  0.0342\n",
            "     16        \u001b[36m0.4611\u001b[0m  0.0343\n",
            "     17        \u001b[36m0.4603\u001b[0m  0.0330\n",
            "     18        \u001b[36m0.4594\u001b[0m  0.0320\n",
            "     19        \u001b[36m0.4586\u001b[0m  0.0332\n",
            "     20        \u001b[36m0.4578\u001b[0m  0.0353\n",
            "     21        \u001b[36m0.4570\u001b[0m  0.0332\n",
            "     22        \u001b[36m0.4562\u001b[0m  0.0323\n",
            "     23        \u001b[36m0.4554\u001b[0m  0.0342\n",
            "     24        \u001b[36m0.4547\u001b[0m  0.0376\n",
            "     25        \u001b[36m0.4540\u001b[0m  0.0345\n",
            "     26        \u001b[36m0.4533\u001b[0m  0.0333\n",
            "     27        \u001b[36m0.4526\u001b[0m  0.0331\n",
            "     28        \u001b[36m0.4519\u001b[0m  0.0336\n",
            "     29        \u001b[36m0.4512\u001b[0m  0.0338\n",
            "     30        \u001b[36m0.4506\u001b[0m  0.0337\n",
            "     31        \u001b[36m0.4499\u001b[0m  0.0431\n",
            "     32        \u001b[36m0.4493\u001b[0m  0.0405\n",
            "     33        \u001b[36m0.4487\u001b[0m  0.0355\n",
            "     34        \u001b[36m0.4481\u001b[0m  0.0431\n",
            "     35        \u001b[36m0.4475\u001b[0m  0.0358\n",
            "     36        \u001b[36m0.4469\u001b[0m  0.0339\n",
            "     37        \u001b[36m0.4463\u001b[0m  0.0335\n",
            "     38        \u001b[36m0.4458\u001b[0m  0.0347\n",
            "     39        \u001b[36m0.4452\u001b[0m  0.0350\n",
            "     40        \u001b[36m0.4447\u001b[0m  0.0363\n",
            "     41        \u001b[36m0.4441\u001b[0m  0.0344\n",
            "     42        \u001b[36m0.4436\u001b[0m  0.0358\n",
            "     43        \u001b[36m0.4431\u001b[0m  0.0343\n",
            "     44        \u001b[36m0.4426\u001b[0m  0.0342\n",
            "     45        \u001b[36m0.4421\u001b[0m  0.0347\n",
            "     46        \u001b[36m0.4416\u001b[0m  0.0341\n",
            "     47        \u001b[36m0.4411\u001b[0m  0.0393\n",
            "     48        \u001b[36m0.4406\u001b[0m  0.0357\n",
            "     49        \u001b[36m0.4401\u001b[0m  0.0348\n",
            "     50        \u001b[36m0.4397\u001b[0m  0.0334\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4592\u001b[0m  0.0290\n",
            "      2        \u001b[36m0.4584\u001b[0m  0.0321\n",
            "      3        \u001b[36m0.4577\u001b[0m  0.0332\n",
            "      4        \u001b[36m0.4571\u001b[0m  0.0327\n",
            "      5        \u001b[36m0.4564\u001b[0m  0.0331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.4558\u001b[0m  0.0346\n",
            "      7        \u001b[36m0.4552\u001b[0m  0.0366\n",
            "      8        \u001b[36m0.4545\u001b[0m  0.0407\n",
            "      9        \u001b[36m0.4539\u001b[0m  0.0327\n",
            "     10        \u001b[36m0.4533\u001b[0m  0.0338\n",
            "     11        \u001b[36m0.4528\u001b[0m  0.0352\n",
            "     12        \u001b[36m0.4522\u001b[0m  0.0425\n",
            "     13        \u001b[36m0.4516\u001b[0m  0.0332\n",
            "     14        \u001b[36m0.4511\u001b[0m  0.0324\n",
            "     15        \u001b[36m0.4505\u001b[0m  0.0319\n",
            "     16        \u001b[36m0.4500\u001b[0m  0.0330\n",
            "     17        \u001b[36m0.4495\u001b[0m  0.0326\n",
            "     18        \u001b[36m0.4489\u001b[0m  0.0344\n",
            "     19        \u001b[36m0.4484\u001b[0m  0.0334\n",
            "     20        \u001b[36m0.4479\u001b[0m  0.0322\n",
            "     21        \u001b[36m0.4474\u001b[0m  0.0320\n",
            "     22        \u001b[36m0.4470\u001b[0m  0.0345\n",
            "     23        \u001b[36m0.4465\u001b[0m  0.0349\n",
            "     24        \u001b[36m0.4460\u001b[0m  0.0347\n",
            "     25        \u001b[36m0.4455\u001b[0m  0.0373\n",
            "     26        \u001b[36m0.4451\u001b[0m  0.0330\n",
            "     27        \u001b[36m0.4446\u001b[0m  0.0326\n",
            "     28        \u001b[36m0.4442\u001b[0m  0.0332\n",
            "     29        \u001b[36m0.4438\u001b[0m  0.0355\n",
            "     30        \u001b[36m0.4434\u001b[0m  0.0328\n",
            "     31        \u001b[36m0.4429\u001b[0m  0.0333\n",
            "     32        \u001b[36m0.4425\u001b[0m  0.0330\n",
            "     33        \u001b[36m0.4421\u001b[0m  0.0324\n",
            "     34        \u001b[36m0.4417\u001b[0m  0.0317\n",
            "     35        \u001b[36m0.4413\u001b[0m  0.0365\n",
            "     36        \u001b[36m0.4409\u001b[0m  0.0417\n",
            "     37        \u001b[36m0.4406\u001b[0m  0.0409\n",
            "     38        \u001b[36m0.4402\u001b[0m  0.0334\n",
            "     39        \u001b[36m0.4398\u001b[0m  0.0341\n",
            "     40        \u001b[36m0.4394\u001b[0m  0.0333\n",
            "     41        \u001b[36m0.4391\u001b[0m  0.0411\n",
            "     42        \u001b[36m0.4387\u001b[0m  0.0328\n",
            "     43        \u001b[36m0.4384\u001b[0m  0.0335\n",
            "     44        \u001b[36m0.4380\u001b[0m  0.0347\n",
            "     45        \u001b[36m0.4377\u001b[0m  0.0340\n",
            "     46        \u001b[36m0.4374\u001b[0m  0.0335\n",
            "     47        \u001b[36m0.4370\u001b[0m  0.0336\n",
            "     48        \u001b[36m0.4367\u001b[0m  0.0323\n",
            "     49        \u001b[36m0.4364\u001b[0m  0.0347\n",
            "     50        \u001b[36m0.4361\u001b[0m  0.0327\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0400\n",
            "      2        1.0000  0.0428\n",
            "      3        1.0000  0.0404\n",
            "      4        1.0000  0.0415\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0500\n",
            "      6        1.0000  0.0440\n",
            "      7        1.0000  0.0429\n",
            "      8        1.0000  0.0423\n",
            "      9        1.0000  0.0419\n",
            "     10        1.0000  0.0515\n",
            "     11        1.0000  0.0458\n",
            "     12        1.0000  0.0438\n",
            "     13        1.0000  0.0444\n",
            "     14        1.0000  0.0422\n",
            "     15        1.0000  0.0495\n",
            "     16        1.0000  0.0412\n",
            "     17        1.0000  0.0423\n",
            "     18        1.0000  0.0445\n",
            "     19        1.0000  0.0434\n",
            "     20        1.0000  0.0430\n",
            "     21        1.0000  0.0430\n",
            "     22        1.0000  0.0453\n",
            "     23        1.0000  0.0434\n",
            "     24        1.0000  0.0443\n",
            "     25        1.0000  0.0443\n",
            "     26        1.0000  0.0463\n",
            "     27        1.0000  0.0413\n",
            "     28        1.0000  0.0419\n",
            "     29        1.0000  0.0429\n",
            "     30        1.0000  0.0418\n",
            "     31        1.0000  0.0434\n",
            "     32        1.0000  0.0533\n",
            "     33        \u001b[36m1.0000\u001b[0m  0.0434\n",
            "     34        \u001b[36m0.5121\u001b[0m  0.0414\n",
            "     35        \u001b[36m0.3732\u001b[0m  0.0435\n",
            "     36        0.3732  0.0417\n",
            "     37        0.3732  0.0434\n",
            "     38        0.3732  0.0518\n",
            "     39        0.3732  0.0426\n",
            "     40        0.3732  0.0430\n",
            "     41        0.3732  0.0436\n",
            "     42        0.3732  0.0431\n",
            "     43        0.3732  0.0430\n",
            "     44        0.3732  0.0415\n",
            "     45        0.3732  0.0453\n",
            "     46        0.3732  0.0467\n",
            "     47        0.3732  0.0441\n",
            "     48        0.3732  0.0440\n",
            "     49        0.3732  0.0506\n",
            "     50        0.3732  0.0470\n",
            "     51        0.3732  0.0436\n",
            "     52        0.3732  0.0436\n",
            "     53        0.3732  0.0418\n",
            "     54        0.3732  0.0538\n",
            "     55        0.3732  0.0418\n",
            "     56        0.3732  0.0417\n",
            "     57        0.3732  0.0436\n",
            "     58        0.3732  0.0424\n",
            "     59        0.3732  0.0427\n",
            "     60        0.3732  0.0528\n",
            "     61        0.3732  0.0429\n",
            "     62        0.3732  0.0441\n",
            "     63        0.3732  0.0442\n",
            "     64        0.3732  0.0416\n",
            "     65        0.3732  0.0422\n",
            "     66        0.3732  0.0428\n",
            "     67        0.3732  0.0434\n",
            "     68        0.3732  0.0454\n",
            "     69        0.3732  0.0428\n",
            "     70        0.3732  0.0442\n",
            "     71        0.3732  0.0435\n",
            "     72        0.3732  0.0451\n",
            "     73        0.3732  0.0441\n",
            "     74        0.3732  0.0433\n",
            "     75        0.3732  0.0436\n",
            "     76        0.3732  0.0559\n",
            "     77        0.3732  0.0463\n",
            "     78        0.3732  0.0444\n",
            "     79        0.3732  0.0470\n",
            "     80        0.3732  0.0443\n",
            "     81        0.3732  0.0430\n",
            "     82        0.3732  0.0474\n",
            "     83        0.3732  0.0432\n",
            "     84        0.3732  0.0446\n",
            "     85        0.3732  0.0443\n",
            "     86        0.3732  0.0407\n",
            "     87        0.3732  0.0419\n",
            "     88        0.3732  0.0423\n",
            "     89        0.3732  0.0430\n",
            "     90        0.3732  0.0439\n",
            "     91        0.3732  0.0425\n",
            "     92        0.3732  0.0403\n",
            "     93        0.3732  0.0412\n",
            "     94        0.3732  0.0409\n",
            "     95        0.3732  0.0414\n",
            "     96        0.3732  0.0424\n",
            "     97        0.3732  0.0433\n",
            "     98        0.3732  0.0536\n",
            "     99        0.3732  0.0417\n",
            "    100        0.3732  0.0428\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0444\n",
            "      2        1.0000  0.0518\n",
            "      3        1.0000  0.0441\n",
            "      4        1.0000  0.0450\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0546\n",
            "      6        1.0000  0.0453\n",
            "      7        1.0000  0.0450\n",
            "      8        1.0000  0.0490\n",
            "      9        1.0000  0.0417\n",
            "     10        1.0000  0.0445\n",
            "     11        1.0000  0.0438\n",
            "     12        1.0000  0.0432\n",
            "     13        1.0000  0.0443\n",
            "     14        1.0000  0.0462\n",
            "     15        1.0000  0.0433\n",
            "     16        1.0000  0.0455\n",
            "     17        1.0000  0.0456\n",
            "     18        1.0000  0.0487\n",
            "     19        1.0000  0.0539\n",
            "     20        1.0000  0.0445\n",
            "     21        1.0000  0.0458\n",
            "     22        1.0000  0.0480\n",
            "     23        1.0000  0.0479\n",
            "     24        1.0000  0.0442\n",
            "     25        1.0000  0.0456\n",
            "     26        1.0000  0.0520\n",
            "     27        1.0000  0.0448\n",
            "     28        1.0000  0.0417\n",
            "     29        1.0000  0.0441\n",
            "     30        1.0000  0.0428\n",
            "     31        1.0000  0.0431\n",
            "     32        1.0000  0.0455\n",
            "     33        1.0000  0.0443\n",
            "     34        1.0000  0.0435\n",
            "     35        \u001b[36m1.0000\u001b[0m  0.0452\n",
            "     36        \u001b[36m0.8405\u001b[0m  0.0534\n",
            "     37        \u001b[36m0.3719\u001b[0m  0.0592\n",
            "     38        \u001b[36m0.3719\u001b[0m  0.0626\n",
            "     39        \u001b[36m0.3719\u001b[0m  0.0696\n",
            "     40        \u001b[36m0.3719\u001b[0m  0.0610\n",
            "     41        0.3719  0.0703\n",
            "     42        0.3719  0.0537\n",
            "     43        0.3719  0.0547\n",
            "     44        0.3719  0.0569\n",
            "     45        0.3719  0.0609\n",
            "     46        0.3719  0.0568\n",
            "     47        0.3719  0.0545\n",
            "     48        0.3719  0.0554\n",
            "     49        0.3719  0.0576\n",
            "     50        0.3719  0.0561\n",
            "     51        0.3719  0.0537\n",
            "     52        0.3719  0.0567\n",
            "     53        0.3719  0.0521\n",
            "     54        0.3719  0.0540\n",
            "     55        0.3719  0.0615\n",
            "     56        0.3719  0.0516\n",
            "     57        0.3719  0.0565\n",
            "     58        0.3719  0.0584\n",
            "     59        0.3719  0.0549\n",
            "     60        0.3719  0.0536\n",
            "     61        0.3719  0.0567\n",
            "     62        0.3719  0.0671\n",
            "     63        0.3719  0.0656\n",
            "     64        0.3719  0.0605\n",
            "     65        0.3719  0.0599\n",
            "     66        0.3719  0.0547\n",
            "     67        0.3719  0.0564\n",
            "     68        0.3719  0.0578\n",
            "     69        0.3719  0.0628\n",
            "     70        0.3719  0.0561\n",
            "     71        0.3719  0.0653\n",
            "     72        0.3719  0.0636\n",
            "     73        0.3719  0.0616\n",
            "     74        0.3719  0.0619\n",
            "     75        0.3719  0.0587\n",
            "     76        0.3719  0.0582\n",
            "     77        0.3719  0.0582\n",
            "     78        0.3719  0.0562\n",
            "     79        0.3719  0.0825\n",
            "     80        0.3719  0.0579\n",
            "     81        0.3719  0.0618\n",
            "     82        0.3719  0.0687\n",
            "     83        0.3719  0.0517\n",
            "     84        0.3719  0.0437\n",
            "     85        0.3719  0.0429\n",
            "     86        0.3719  0.0420\n",
            "     87        0.3719  0.0464\n",
            "     88        0.3719  0.0477\n",
            "     89        0.3719  0.0453\n",
            "     90        0.3719  0.0426\n",
            "     91        0.3719  0.0437\n",
            "     92        0.3719  0.0414\n",
            "     93        0.3719  0.0418\n",
            "     94        0.3719  0.0425\n",
            "     95        0.3719  0.0435\n",
            "     96        0.3719  0.0427\n",
            "     97        0.3719  0.0464\n",
            "     98        \u001b[36m0.3719\u001b[0m  0.0429\n",
            "     99        \u001b[36m0.3719\u001b[0m  0.0532\n",
            "    100        \u001b[36m0.3719\u001b[0m  0.0431\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0313\n",
            "      2        1.0000  0.0334\n",
            "      3        1.0000  0.0374\n",
            "      4        1.0000  0.0362\n",
            "      5        1.0000  0.0328\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0363\n",
            "      7        1.0000  0.0344\n",
            "      8        1.0000  0.0329\n",
            "      9        1.0000  0.0339\n",
            "     10        1.0000  0.0345\n",
            "     11        1.0000  0.0405\n",
            "     12        1.0000  0.0407\n",
            "     13        1.0000  0.0342\n",
            "     14        1.0000  0.0341\n",
            "     15        1.0000  0.0341\n",
            "     16        1.0000  0.0378\n",
            "     17        1.0000  0.0358\n",
            "     18        1.0000  0.0345\n",
            "     19        1.0000  0.0351\n",
            "     20        1.0000  0.0351\n",
            "     21        1.0000  0.0344\n",
            "     22        1.0000  0.0342\n",
            "     23        1.0000  0.0345\n",
            "     24        1.0000  0.0356\n",
            "     25        1.0000  0.0344\n",
            "     26        1.0000  0.0403\n",
            "     27        1.0000  0.0360\n",
            "     28        1.0000  0.0340\n",
            "     29        1.0000  0.0347\n",
            "     30        1.0000  0.0364\n",
            "     31        1.0000  0.0347\n",
            "     32        1.0000  0.0333\n",
            "     33        1.0000  0.0341\n",
            "     34        1.0000  0.0340\n",
            "     35        1.0000  0.0346\n",
            "     36        1.0000  0.0342\n",
            "     37        1.0000  0.0342\n",
            "     38        1.0000  0.0403\n",
            "     39        1.0000  0.0415\n",
            "     40        1.0000  0.0324\n",
            "     41        1.0000  0.0332\n",
            "     42        1.0000  0.0346\n",
            "     43        1.0000  0.0345\n",
            "     44        1.0000  0.0337\n",
            "     45        1.0000  0.0350\n",
            "     46        1.0000  0.0366\n",
            "     47        1.0000  0.0343\n",
            "     48        1.0000  0.0342\n",
            "     49        1.0000  0.0343\n",
            "     50        1.0000  0.0341\n",
            "     51        1.0000  0.0340\n",
            "     52        1.0000  0.0369\n",
            "     53        1.0000  0.0343\n",
            "     54        1.0000  0.0336\n",
            "     55        1.0000  0.0403\n",
            "     56        1.0000  0.0330\n",
            "     57        1.0000  0.0341\n",
            "     58        1.0000  0.0348\n",
            "     59        1.0000  0.0334\n",
            "     60        1.0000  0.0336\n",
            "     61        1.0000  0.0338\n",
            "     62        1.0000  0.0328\n",
            "     63        1.0000  0.0336\n",
            "     64        1.0000  0.0327\n",
            "     65        1.0000  0.0343\n",
            "     66        1.0000  0.0414\n",
            "     67        1.0000  0.0373\n",
            "     68        1.0000  0.0324\n",
            "     69        1.0000  0.0345\n",
            "     70        1.0000  0.0338\n",
            "     71        1.0000  0.0342\n",
            "     72        1.0000  0.0326\n",
            "     73        1.0000  0.0328\n",
            "     74        1.0000  0.0321\n",
            "     75        1.0000  0.0345\n",
            "     76        1.0000  0.0367\n",
            "     77        1.0000  0.0343\n",
            "     78        1.0000  0.0350\n",
            "     79        1.0000  0.0355\n",
            "     80        1.0000  0.0342\n",
            "     81        1.0000  0.0341\n",
            "     82        1.0000  0.0336\n",
            "     83        1.0000  0.0430\n",
            "     84        1.0000  0.0330\n",
            "     85        1.0000  0.0355\n",
            "     86        1.0000  0.0321\n",
            "     87        1.0000  0.0338\n",
            "     88        1.0000  0.0328\n",
            "     89        1.0000  0.0335\n",
            "     90        1.0000  0.0331\n",
            "     91        1.0000  0.0345\n",
            "     92        1.0000  0.0331\n",
            "     93        1.0000  0.0354\n",
            "     94        1.0000  0.0421\n",
            "     95        1.0000  0.0387\n",
            "     96        1.0000  0.0332\n",
            "     97        1.0000  0.0356\n",
            "     98        1.0000  0.0353\n",
            "     99        1.0000  0.0334\n",
            "    100        1.0000  0.0341\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0301\n",
            "      2        1.0000  0.0338\n",
            "      3        1.0000  0.0325\n",
            "      4        1.0000  0.0353\n",
            "      5        1.0000  0.0354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0370\n",
            "      7        1.0000  0.0352\n",
            "      8        1.0000  0.0331\n",
            "      9        1.0000  0.0340\n",
            "     10        1.0000  0.0370\n",
            "     11        1.0000  0.0483\n",
            "     12        1.0000  0.0360\n",
            "     13        1.0000  0.0329\n",
            "     14        1.0000  0.0330\n",
            "     15        1.0000  0.0326\n",
            "     16        1.0000  0.0322\n",
            "     17        1.0000  0.0351\n",
            "     18        1.0000  0.0338\n",
            "     19        1.0000  0.0330\n",
            "     20        1.0000  0.0370\n",
            "     21        1.0000  0.0434\n",
            "     22        1.0000  0.0327\n",
            "     23        1.0000  0.0317\n",
            "     24        1.0000  0.0336\n",
            "     25        1.0000  0.0337\n",
            "     26        1.0000  0.0330\n",
            "     27        1.0000  0.0324\n",
            "     28        1.0000  0.0351\n",
            "     29        1.0000  0.0340\n",
            "     30        1.0000  0.0335\n",
            "     31        1.0000  0.0336\n",
            "     32        1.0000  0.0344\n",
            "     33        1.0000  0.0313\n",
            "     34        1.0000  0.0332\n",
            "     35        1.0000  0.0373\n",
            "     36        1.0000  0.0344\n",
            "     37        1.0000  0.0338\n",
            "     38        1.0000  0.0324\n",
            "     39        1.0000  0.0389\n",
            "     40        1.0000  0.0365\n",
            "     41        1.0000  0.0342\n",
            "     42        1.0000  0.0333\n",
            "     43        1.0000  0.0337\n",
            "     44        1.0000  0.0336\n",
            "     45        1.0000  0.0343\n",
            "     46        1.0000  0.0351\n",
            "     47        1.0000  0.0331\n",
            "     48        1.0000  0.0380\n",
            "     49        1.0000  0.0417\n",
            "     50        1.0000  0.0335\n",
            "     51        1.0000  0.0327\n",
            "     52        1.0000  0.0342\n",
            "     53        1.0000  0.0340\n",
            "     54        1.0000  0.0335\n",
            "     55        1.0000  0.0334\n",
            "     56        1.0000  0.0337\n",
            "     57        1.0000  0.0341\n",
            "     58        1.0000  0.0329\n",
            "     59        1.0000  0.0333\n",
            "     60        1.0000  0.0349\n",
            "     61        1.0000  0.0333\n",
            "     62        1.0000  0.0343\n",
            "     63        1.0000  0.0344\n",
            "     64        1.0000  0.0343\n",
            "     65        1.0000  0.0339\n",
            "     66        1.0000  0.0365\n",
            "     67        1.0000  0.0333\n",
            "     68        1.0000  0.0445\n",
            "     69        1.0000  0.0349\n",
            "     70        1.0000  0.0324\n",
            "     71        1.0000  0.0335\n",
            "     72        1.0000  0.0330\n",
            "     73        1.0000  0.0336\n",
            "     74        1.0000  0.0332\n",
            "     75        1.0000  0.0350\n",
            "     76        1.0000  0.0418\n",
            "     77        1.0000  0.0381\n",
            "     78        1.0000  0.0340\n",
            "     79        1.0000  0.0321\n",
            "     80        1.0000  0.0336\n",
            "     81        1.0000  0.0344\n",
            "     82        1.0000  0.0336\n",
            "     83        1.0000  0.0355\n",
            "     84        1.0000  0.0338\n",
            "     85        1.0000  0.0340\n",
            "     86        1.0000  0.0327\n",
            "     87        1.0000  0.0353\n",
            "     88        1.0000  0.0353\n",
            "     89        1.0000  0.0341\n",
            "     90        1.0000  0.0346\n",
            "     91        1.0000  0.0332\n",
            "     92        1.0000  0.0346\n",
            "     93        1.0000  0.0357\n",
            "     94        1.0000  0.0353\n",
            "     95        1.0000  0.0351\n",
            "     96        1.0000  0.0435\n",
            "     97        1.0000  0.0320\n",
            "     98        1.0000  0.0327\n",
            "     99        1.0000  0.0325\n",
            "    100        1.0000  0.0348\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0392\n",
            "      2        1.0000  0.0455\n",
            "      3        1.0000  0.0516\n",
            "      4        1.0000  0.0423\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0465\n",
            "      6        1.0000  0.0468\n",
            "      7        1.0000  0.0424\n",
            "      8        1.0000  0.0422\n",
            "      9        1.0000  0.0430\n",
            "     10        1.0000  0.0421\n",
            "     11        1.0000  0.0437\n",
            "     12        1.0000  0.0457\n",
            "     13        1.0000  0.0453\n",
            "     14        1.0000  0.0489\n",
            "     15        1.0000  0.0450\n",
            "     16        1.0000  0.0446\n",
            "     17        1.0000  0.0450\n",
            "     18        1.0000  0.0440\n",
            "     19        1.0000  0.0541\n",
            "     20        1.0000  0.0425\n",
            "     21        1.0000  0.0440\n",
            "     22        1.0000  0.0429\n",
            "     23        1.0000  0.0430\n",
            "     24        1.0000  0.0542\n",
            "     25        1.0000  0.0486\n",
            "     26        1.0000  0.0441\n",
            "     27        1.0000  0.0467\n",
            "     28        1.0000  0.0459\n",
            "     29        1.0000  0.0441\n",
            "     30        1.0000  0.0442\n",
            "     31        1.0000  0.0449\n",
            "     32        1.0000  0.0440\n",
            "     33        1.0000  0.0457\n",
            "     34        1.0000  0.0456\n",
            "     35        1.0000  0.0436\n",
            "     36        1.0000  0.0430\n",
            "     37        1.0000  0.0434\n",
            "     38        1.0000  0.0433\n",
            "     39        1.0000  0.0437\n",
            "     40        1.0000  0.0474\n",
            "     41        1.0000  0.0677\n",
            "     42        \u001b[36m1.0000\u001b[0m  0.0602\n",
            "     43        \u001b[36m1.0000\u001b[0m  0.0604\n",
            "     44        \u001b[36m0.4622\u001b[0m  0.0619\n",
            "     45        \u001b[36m0.3732\u001b[0m  0.0552\n",
            "     46        \u001b[36m0.3732\u001b[0m  0.0686\n",
            "     47        0.3732  0.0555\n",
            "     48        0.3732  0.0677\n",
            "     49        0.3732  0.0639\n",
            "     50        0.3732  0.0574\n",
            "     51        0.3732  0.0638\n",
            "     52        0.3732  0.0556\n",
            "     53        0.3732  0.0584\n",
            "     54        0.3732  0.0562\n",
            "     55        0.3732  0.0621\n",
            "     56        0.3732  0.0550\n",
            "     57        0.3732  0.0674\n",
            "     58        0.3732  0.0560\n",
            "     59        0.3732  0.0548\n",
            "     60        0.3732  0.0567\n",
            "     61        0.3732  0.0591\n",
            "     62        0.3732  0.0547\n",
            "     63        0.3732  0.0535\n",
            "     64        0.3732  0.0532\n",
            "     65        0.3732  0.0535\n",
            "     66        0.3732  0.0535\n",
            "     67        0.3732  0.0550\n",
            "     68        0.3732  0.0605\n",
            "     69        0.3732  0.0659\n",
            "     70        0.3732  0.0659\n",
            "     71        0.3732  0.0647\n",
            "     72        0.3732  0.0578\n",
            "     73        0.3732  0.0598\n",
            "     74        0.3732  0.0728\n",
            "     75        0.3732  0.0638\n",
            "     76        0.3732  0.0614\n",
            "     77        0.3732  0.0603\n",
            "     78        0.3732  0.0638\n",
            "     79        0.3732  0.0654\n",
            "     80        0.3732  0.0595\n",
            "     81        0.3732  0.0570\n",
            "     82        0.3732  0.0571\n",
            "     83        0.3732  0.0556\n",
            "     84        0.3732  0.0560\n",
            "     85        0.3732  0.0565\n",
            "     86        0.3732  0.0588\n",
            "     87        0.3732  0.0618\n",
            "     88        0.3732  0.0598\n",
            "     89        0.3732  0.0560\n",
            "     90        0.3732  0.0710\n",
            "     91        0.3732  0.0737\n",
            "     92        0.3732  0.0673\n",
            "     93        0.3732  0.0621\n",
            "     94        0.3732  0.0451\n",
            "     95        0.3732  0.0449\n",
            "     96        0.3732  0.0444\n",
            "     97        0.3732  0.0427\n",
            "     98        0.3732  0.0433\n",
            "     99        0.3732  0.0433\n",
            "    100        0.3732  0.0427\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0413\n",
            "      2        1.0000  0.0422\n",
            "      3        1.0000  0.0410\n",
            "      4        1.0000  0.0458\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0477\n",
            "      6        1.0000  0.0444\n",
            "      7        1.0000  0.0463\n",
            "      8        1.0000  0.0466\n",
            "      9        1.0000  0.0443\n",
            "     10        1.0000  0.0464\n",
            "     11        1.0000  0.0582\n",
            "     12        1.0000  0.0477\n",
            "     13        1.0000  0.0446\n",
            "     14        1.0000  0.0433\n",
            "     15        1.0000  0.0431\n",
            "     16        1.0000  0.0433\n",
            "     17        1.0000  0.0435\n",
            "     18        1.0000  0.0450\n",
            "     19        1.0000  0.0430\n",
            "     20        1.0000  0.0438\n",
            "     21        1.0000  0.0445\n",
            "     22        1.0000  0.0443\n",
            "     23        1.0000  0.0461\n",
            "     24        1.0000  0.0453\n",
            "     25        1.0000  0.0449\n",
            "     26        1.0000  0.0441\n",
            "     27        1.0000  0.0446\n",
            "     28        1.0000  0.0467\n",
            "     29        1.0000  0.0475\n",
            "     30        1.0000  0.0468\n",
            "     31        1.0000  0.0466\n",
            "     32        1.0000  0.0482\n",
            "     33        1.0000  0.0588\n",
            "     34        1.0000  0.0442\n",
            "     35        1.0000  0.0442\n",
            "     36        1.0000  0.0448\n",
            "     37        1.0000  0.0457\n",
            "     38        1.0000  0.0465\n",
            "     39        1.0000  0.0447\n",
            "     40        1.0000  0.0446\n",
            "     41        1.0000  0.0428\n",
            "     42        1.0000  0.0422\n",
            "     43        \u001b[36m1.0000\u001b[0m  0.0434\n",
            "     44        \u001b[36m0.6562\u001b[0m  0.0451\n",
            "     45        \u001b[36m0.3719\u001b[0m  0.0427\n",
            "     46        \u001b[36m0.3719\u001b[0m  0.0418\n",
            "     47        0.3719  0.0428\n",
            "     48        0.3719  0.0441\n",
            "     49        0.3719  0.0468\n",
            "     50        0.3719  0.0448\n",
            "     51        0.3719  0.0438\n",
            "     52        0.3719  0.0438\n",
            "     53        0.3719  0.0449\n",
            "     54        0.3719  0.0544\n",
            "     55        0.3719  0.0549\n",
            "     56        0.3719  0.0427\n",
            "     57        0.3719  0.0416\n",
            "     58        0.3719  0.0423\n",
            "     59        0.3719  0.0422\n",
            "     60        0.3719  0.0418\n",
            "     61        0.3719  0.0428\n",
            "     62        0.3719  0.0444\n",
            "     63        0.3719  0.0442\n",
            "     64        0.3719  0.0435\n",
            "     65        0.3719  0.0427\n",
            "     66        0.3719  0.0472\n",
            "     67        0.3719  0.0449\n",
            "     68        0.3719  0.0483\n",
            "     69        0.3719  0.0543\n",
            "     70        0.3719  0.0510\n",
            "     71        0.3719  0.0460\n",
            "     72        0.3719  0.0433\n",
            "     73        0.3719  0.0434\n",
            "     74        0.3719  0.0412\n",
            "     75        0.3719  0.0478\n",
            "     76        0.3719  0.0578\n",
            "     77        0.3719  0.0469\n",
            "     78        0.3719  0.0456\n",
            "     79        0.3719  0.0434\n",
            "     80        0.3719  0.0438\n",
            "     81        0.3719  0.0424\n",
            "     82        0.3719  0.0478\n",
            "     83        0.3719  0.0468\n",
            "     84        0.3719  0.0499\n",
            "     85        0.3719  0.0457\n",
            "     86        0.3719  0.0431\n",
            "     87        0.3719  0.0457\n",
            "     88        0.3719  0.0447\n",
            "     89        0.3719  0.0445\n",
            "     90        0.3719  0.0437\n",
            "     91        0.3719  0.0441\n",
            "     92        0.3719  0.0410\n",
            "     93        0.3719  0.0439\n",
            "     94        0.3719  0.0436\n",
            "     95        0.3719  0.0429\n",
            "     96        0.3719  0.0433\n",
            "     97        0.3719  0.0582\n",
            "     98        0.3719  0.0443\n",
            "     99        0.3719  0.0515\n",
            "    100        0.3719  0.0437\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0306\n",
            "      2        1.0000  0.0328\n",
            "      3        1.0000  0.0342\n",
            "      4        1.0000  0.0322\n",
            "      5        1.0000  0.0331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0356\n",
            "      7        1.0000  0.0365\n",
            "      8        1.0000  0.0340\n",
            "      9        1.0000  0.0318\n",
            "     10        1.0000  0.0333\n",
            "     11        1.0000  0.0327\n",
            "     12        1.0000  0.0332\n",
            "     13        1.0000  0.0348\n",
            "     14        1.0000  0.0330\n",
            "     15        1.0000  0.0342\n",
            "     16        1.0000  0.0329\n",
            "     17        1.0000  0.0375\n",
            "     18        1.0000  0.0368\n",
            "     19        1.0000  0.0348\n",
            "     20        1.0000  0.0330\n",
            "     21        1.0000  0.0352\n",
            "     22        1.0000  0.0342\n",
            "     23        1.0000  0.0420\n",
            "     24        1.0000  0.0421\n",
            "     25        1.0000  0.0335\n",
            "     26        1.0000  0.0430\n",
            "     27        1.0000  0.0326\n",
            "     28        1.0000  0.0319\n",
            "     29        1.0000  0.0350\n",
            "     30        1.0000  0.0327\n",
            "     31        1.0000  0.0344\n",
            "     32        1.0000  0.0338\n",
            "     33        1.0000  0.0335\n",
            "     34        1.0000  0.0332\n",
            "     35        1.0000  0.0329\n",
            "     36        1.0000  0.0353\n",
            "     37        1.0000  0.0339\n",
            "     38        1.0000  0.0334\n",
            "     39        1.0000  0.0342\n",
            "     40        1.0000  0.0340\n",
            "     41        1.0000  0.0336\n",
            "     42        1.0000  0.0353\n",
            "     43        1.0000  0.0351\n",
            "     44        1.0000  0.0326\n",
            "     45        1.0000  0.0333\n",
            "     46        1.0000  0.0346\n",
            "     47        1.0000  0.0334\n",
            "     48        1.0000  0.0343\n",
            "     49        1.0000  0.0334\n",
            "     50        1.0000  0.0356\n",
            "     51        1.0000  0.0424\n",
            "     52        1.0000  0.0375\n",
            "     53        1.0000  0.0348\n",
            "     54        1.0000  0.0380\n",
            "     55        1.0000  0.0386\n",
            "     56        1.0000  0.0335\n",
            "     57        1.0000  0.0336\n",
            "     58        1.0000  0.0363\n",
            "     59        1.0000  0.0323\n",
            "     60        1.0000  0.0327\n",
            "     61        1.0000  0.0339\n",
            "     62        1.0000  0.0345\n",
            "     63        1.0000  0.0361\n",
            "     64        1.0000  0.0372\n",
            "     65        1.0000  0.0338\n",
            "     66        1.0000  0.0347\n",
            "     67        1.0000  0.0332\n",
            "     68        1.0000  0.0369\n",
            "     69        1.0000  0.0339\n",
            "     70        1.0000  0.0363\n",
            "     71        1.0000  0.0341\n",
            "     72        1.0000  0.0342\n",
            "     73        1.0000  0.0395\n",
            "     74        1.0000  0.0350\n",
            "     75        1.0000  0.0344\n",
            "     76        1.0000  0.0344\n",
            "     77        1.0000  0.0340\n",
            "     78        1.0000  0.0450\n",
            "     79        1.0000  0.0365\n",
            "     80        1.0000  0.0369\n",
            "     81        1.0000  0.0338\n",
            "     82        1.0000  0.0449\n",
            "     83        1.0000  0.0337\n",
            "     84        1.0000  0.0345\n",
            "     85        1.0000  0.0331\n",
            "     86        1.0000  0.0353\n",
            "     87        1.0000  0.0352\n",
            "     88        1.0000  0.0337\n",
            "     89        1.0000  0.0347\n",
            "     90        1.0000  0.0335\n",
            "     91        1.0000  0.0333\n",
            "     92        1.0000  0.0346\n",
            "     93        1.0000  0.0337\n",
            "     94        1.0000  0.0337\n",
            "     95        1.0000  0.0328\n",
            "     96        1.0000  0.0322\n",
            "     97        1.0000  0.0332\n",
            "     98        1.0000  0.0331\n",
            "     99        1.0000  0.0365\n",
            "    100        1.0000  0.0327\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0291\n",
            "      2        1.0000  0.0341\n",
            "      3        1.0000  0.0322\n",
            "      4        1.0000  0.0311\n",
            "      5        1.0000  0.0437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        1.0000  0.0455\n",
            "      7        1.0000  0.0350\n",
            "      8        1.0000  0.0333\n",
            "      9        1.0000  0.0335\n",
            "     10        1.0000  0.0431\n",
            "     11        1.0000  0.0342\n",
            "     12        1.0000  0.0325\n",
            "     13        1.0000  0.0336\n",
            "     14        1.0000  0.0336\n",
            "     15        1.0000  0.0341\n",
            "     16        1.0000  0.0343\n",
            "     17        1.0000  0.0341\n",
            "     18        1.0000  0.0356\n",
            "     19        1.0000  0.0355\n",
            "     20        1.0000  0.0333\n",
            "     21        1.0000  0.0337\n",
            "     22        1.0000  0.0342\n",
            "     23        1.0000  0.0336\n",
            "     24        1.0000  0.0384\n",
            "     25        1.0000  0.0347\n",
            "     26        1.0000  0.0336\n",
            "     27        1.0000  0.0326\n",
            "     28        1.0000  0.0352\n",
            "     29        1.0000  0.0341\n",
            "     30        1.0000  0.0363\n",
            "     31        1.0000  0.0330\n",
            "     32        1.0000  0.0422\n",
            "     33        1.0000  0.0398\n",
            "     34        1.0000  0.0340\n",
            "     35        1.0000  0.0328\n",
            "     36        1.0000  0.0353\n",
            "     37        1.0000  0.0459\n",
            "     38        1.0000  0.0577\n",
            "     39        1.0000  0.0464\n",
            "     40        1.0000  0.0485\n",
            "     41        1.0000  0.0439\n",
            "     42        1.0000  0.0428\n",
            "     43        1.0000  0.0499\n",
            "     44        1.0000  0.0428\n",
            "     45        1.0000  0.0444\n",
            "     46        1.0000  0.0408\n",
            "     47        1.0000  0.0388\n",
            "     48        1.0000  0.0431\n",
            "     49        1.0000  0.0486\n",
            "     50        1.0000  0.0413\n",
            "     51        1.0000  0.0417\n",
            "     52        1.0000  0.0397\n",
            "     53        1.0000  0.0413\n",
            "     54        1.0000  0.0484\n",
            "     55        1.0000  0.0423\n",
            "     56        1.0000  0.0467\n",
            "     57        1.0000  0.0431\n",
            "     58        1.0000  0.0425\n",
            "     59        1.0000  0.0481\n",
            "     60        1.0000  0.0505\n",
            "     61        1.0000  0.0416\n",
            "     62        1.0000  0.0404\n",
            "     63        1.0000  0.0416\n",
            "     64        1.0000  0.0416\n",
            "     65        1.0000  0.0408\n",
            "     66        1.0000  0.0432\n",
            "     67        1.0000  0.0478\n",
            "     68        1.0000  0.0424\n",
            "     69        1.0000  0.0395\n",
            "     70        1.0000  0.0405\n",
            "     71        1.0000  0.0485\n",
            "     72        1.0000  0.0476\n",
            "     73        1.0000  0.0503\n",
            "     74        1.0000  0.0462\n",
            "     75        1.0000  0.0577\n",
            "     76        1.0000  0.0470\n",
            "     77        1.0000  0.0428\n",
            "     78        1.0000  0.0525\n",
            "     79        1.0000  0.0501\n",
            "     80        1.0000  0.0482\n",
            "     81        1.0000  0.0516\n",
            "     82        1.0000  0.0454\n",
            "     83        1.0000  0.0484\n",
            "     84        1.0000  0.0544\n",
            "     85        1.0000  0.0524\n",
            "     86        1.0000  0.0451\n",
            "     87        1.0000  0.0435\n",
            "     88        1.0000  0.0488\n",
            "     89        1.0000  0.0461\n",
            "     90        1.0000  0.0448\n",
            "     91        1.0000  0.0465\n",
            "     92        1.0000  0.0475\n",
            "     93        1.0000  0.0486\n",
            "     94        1.0000  0.0533\n",
            "     95        1.0000  0.0505\n",
            "     96        1.0000  0.0523\n",
            "     97        1.0000  0.0411\n",
            "     98        1.0000  0.0346\n",
            "     99        1.0000  0.0338\n",
            "    100        1.0000  0.0348\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0438\n",
            "      2        1.0000  0.0490\n",
            "      3        1.0000  0.0426\n",
            "      4        1.0000  0.0440\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0490\n",
            "      6        1.0000  0.0461\n",
            "      7        1.0000  0.0460\n",
            "      8        1.0000  0.0450\n",
            "      9        1.0000  0.0447\n",
            "     10        1.0000  0.0446\n",
            "     11        1.0000  0.0428\n",
            "     12        1.0000  0.0449\n",
            "     13        1.0000  0.0426\n",
            "     14        1.0000  0.0436\n",
            "     15        1.0000  0.0553\n",
            "     16        1.0000  0.0433\n",
            "     17        1.0000  0.0435\n",
            "     18        1.0000  0.0438\n",
            "     19        1.0000  0.0444\n",
            "     20        1.0000  0.0441\n",
            "     21        1.0000  0.0432\n",
            "     22        1.0000  0.0430\n",
            "     23        1.0000  0.0507\n",
            "     24        1.0000  0.0458\n",
            "     25        1.0000  0.0471\n",
            "     26        1.0000  0.0447\n",
            "     27        1.0000  0.0451\n",
            "     28        1.0000  0.0441\n",
            "     29        \u001b[36m0.9932\u001b[0m  0.0443\n",
            "     30        \u001b[36m0.9261\u001b[0m  0.0424\n",
            "     31        \u001b[36m0.9261\u001b[0m  0.0431\n",
            "     32        \u001b[36m0.9261\u001b[0m  0.0424\n",
            "     33        \u001b[36m0.9261\u001b[0m  0.0452\n",
            "     34        \u001b[36m0.9221\u001b[0m  0.0454\n",
            "     35        \u001b[36m0.8939\u001b[0m  0.0428\n",
            "     36        \u001b[36m0.8881\u001b[0m  0.0474\n",
            "     37        \u001b[36m0.8838\u001b[0m  0.0480\n",
            "     38        \u001b[36m0.8792\u001b[0m  0.0428\n",
            "     39        \u001b[36m0.8784\u001b[0m  0.0432\n",
            "     40        \u001b[36m0.8776\u001b[0m  0.0422\n",
            "     41        \u001b[36m0.8769\u001b[0m  0.0429\n",
            "     42        \u001b[36m0.8762\u001b[0m  0.0427\n",
            "     43        \u001b[36m0.8755\u001b[0m  0.0412\n",
            "     44        \u001b[36m0.8749\u001b[0m  0.0417\n",
            "     45        \u001b[36m0.8742\u001b[0m  0.0432\n",
            "     46        \u001b[36m0.8736\u001b[0m  0.0507\n",
            "     47        \u001b[36m0.8731\u001b[0m  0.0443\n",
            "     48        \u001b[36m0.8725\u001b[0m  0.0439\n",
            "     49        \u001b[36m0.8720\u001b[0m  0.0451\n",
            "     50        \u001b[36m0.8715\u001b[0m  0.0422\n",
            "     51        \u001b[36m0.8710\u001b[0m  0.0418\n",
            "     52        \u001b[36m0.8706\u001b[0m  0.0416\n",
            "     53        \u001b[36m0.8702\u001b[0m  0.0418\n",
            "     54        \u001b[36m0.8698\u001b[0m  0.0438\n",
            "     55        \u001b[36m0.8694\u001b[0m  0.0414\n",
            "     56        \u001b[36m0.8691\u001b[0m  0.0435\n",
            "     57        \u001b[36m0.8688\u001b[0m  0.0420\n",
            "     58        \u001b[36m0.8684\u001b[0m  0.0418\n",
            "     59        \u001b[36m0.8682\u001b[0m  0.0537\n",
            "     60        \u001b[36m0.8679\u001b[0m  0.0446\n",
            "     61        \u001b[36m0.8676\u001b[0m  0.0416\n",
            "     62        \u001b[36m0.8674\u001b[0m  0.0413\n",
            "     63        \u001b[36m0.8672\u001b[0m  0.0413\n",
            "     64        \u001b[36m0.8669\u001b[0m  0.0436\n",
            "     65        \u001b[36m0.8667\u001b[0m  0.0428\n",
            "     66        \u001b[36m0.8666\u001b[0m  0.0421\n",
            "     67        \u001b[36m0.8664\u001b[0m  0.0420\n",
            "     68        \u001b[36m0.8662\u001b[0m  0.0432\n",
            "     69        0.8680  0.0534\n",
            "     70        \u001b[36m0.8658\u001b[0m  0.0453\n",
            "     71        \u001b[36m0.8656\u001b[0m  0.0435\n",
            "     72        \u001b[36m0.8655\u001b[0m  0.0438\n",
            "     73        \u001b[36m0.8654\u001b[0m  0.0458\n",
            "     74        \u001b[36m0.8654\u001b[0m  0.0445\n",
            "     75        \u001b[36m0.8653\u001b[0m  0.0451\n",
            "     76        \u001b[36m0.8652\u001b[0m  0.0448\n",
            "     77        \u001b[36m0.8547\u001b[0m  0.0452\n",
            "     78        \u001b[36m0.3754\u001b[0m  0.0469\n",
            "     79        \u001b[36m0.3753\u001b[0m  0.0457\n",
            "     80        \u001b[36m0.3753\u001b[0m  0.0501\n",
            "     81        \u001b[36m0.3752\u001b[0m  0.0488\n",
            "     82        \u001b[36m0.3752\u001b[0m  0.0467\n",
            "     83        \u001b[36m0.3751\u001b[0m  0.0447\n",
            "     84        \u001b[36m0.3751\u001b[0m  0.0448\n",
            "     85        \u001b[36m0.3751\u001b[0m  0.0440\n",
            "     86        \u001b[36m0.3750\u001b[0m  0.0455\n",
            "     87        \u001b[36m0.3750\u001b[0m  0.0447\n",
            "     88        \u001b[36m0.3750\u001b[0m  0.0458\n",
            "     89        \u001b[36m0.3749\u001b[0m  0.0455\n",
            "     90        \u001b[36m0.3749\u001b[0m  0.0492\n",
            "     91        \u001b[36m0.3749\u001b[0m  0.0432\n",
            "     92        \u001b[36m0.3749\u001b[0m  0.0432\n",
            "     93        \u001b[36m0.3748\u001b[0m  0.0438\n",
            "     94        \u001b[36m0.3748\u001b[0m  0.0443\n",
            "     95        \u001b[36m0.3748\u001b[0m  0.0423\n",
            "     96        \u001b[36m0.3747\u001b[0m  0.0432\n",
            "     97        \u001b[36m0.3747\u001b[0m  0.0426\n",
            "     98        \u001b[36m0.3747\u001b[0m  0.0423\n",
            "     99        \u001b[36m0.3747\u001b[0m  0.0430\n",
            "    100        \u001b[36m0.3746\u001b[0m  0.0463\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9053\u001b[0m  0.0429\n",
            "      2        0.9053  0.0505\n",
            "      3        \u001b[36m0.8982\u001b[0m  0.0440\n",
            "      4        0.8982  0.0433\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        0.8982  0.0484\n",
            "      6        0.8982  0.0417\n",
            "      7        0.8982  0.0437\n",
            "      8        0.8982  0.0429\n",
            "      9        0.8982  0.0445\n",
            "     10        0.8982  0.0424\n",
            "     11        \u001b[36m0.8957\u001b[0m  0.0445\n",
            "     12        \u001b[36m0.8912\u001b[0m  0.0460\n",
            "     13        \u001b[36m0.8877\u001b[0m  0.0451\n",
            "     14        \u001b[36m0.8807\u001b[0m  0.0428\n",
            "     15        0.8807  0.0435\n",
            "     16        \u001b[36m0.8807\u001b[0m  0.0435\n",
            "     17        \u001b[36m0.8737\u001b[0m  0.0460\n",
            "     18        \u001b[36m0.8737\u001b[0m  0.0436\n",
            "     19        \u001b[36m0.8714\u001b[0m  0.0422\n",
            "     20        \u001b[36m0.6803\u001b[0m  0.0440\n",
            "     21        \u001b[36m0.6154\u001b[0m  0.0461\n",
            "     22        \u001b[36m0.6070\u001b[0m  0.0447\n",
            "     23        \u001b[36m0.6035\u001b[0m  0.0515\n",
            "     24        0.6035  0.0469\n",
            "     25        0.6035  0.0436\n",
            "     26        0.6035  0.0447\n",
            "     27        0.6035  0.0453\n",
            "     28        0.6035  0.0444\n",
            "     29        0.6035  0.0451\n",
            "     30        0.6035  0.0463\n",
            "     31        0.6035  0.0444\n",
            "     32        0.6035  0.0465\n",
            "     33        0.6035  0.0433\n",
            "     34        \u001b[36m0.6035\u001b[0m  0.0480\n",
            "     35        0.6035  0.0501\n",
            "     36        0.6035  0.0454\n",
            "     37        0.6035  0.0444\n",
            "     38        0.6035  0.0448\n",
            "     39        0.6035  0.0452\n",
            "     40        0.6035  0.0428\n",
            "     41        \u001b[36m0.6035\u001b[0m  0.0447\n",
            "     42        0.6035  0.0448\n",
            "     43        0.6035  0.0447\n",
            "     44        0.6035  0.0483\n",
            "     45        0.6035  0.0501\n",
            "     46        0.6035  0.0452\n",
            "     47        0.6035  0.0453\n",
            "     48        0.6035  0.0448\n",
            "     49        0.6035  0.0438\n",
            "     50        0.6035  0.0450\n",
            "     51        0.6035  0.0459\n",
            "     52        0.6035  0.0502\n",
            "     53        0.6035  0.0452\n",
            "     54        0.6035  0.0479\n",
            "     55        0.6035  0.0446\n",
            "     56        0.6035  0.0496\n",
            "     57        0.6035  0.0428\n",
            "     58        0.6035  0.0430\n",
            "     59        0.6035  0.0440\n",
            "     60        0.6035  0.0445\n",
            "     61        0.6035  0.0454\n",
            "     62        0.6035  0.0433\n",
            "     63        0.6035  0.0425\n",
            "     64        0.6035  0.0440\n",
            "     65        0.6035  0.0527\n",
            "     66        0.6035  0.0497\n",
            "     67        0.6035  0.0442\n",
            "     68        0.6035  0.0456\n",
            "     69        0.6035  0.0434\n",
            "     70        0.6035  0.0437\n",
            "     71        0.6035  0.0462\n",
            "     72        0.6035  0.0425\n",
            "     73        0.6035  0.0451\n",
            "     74        0.6035  0.0437\n",
            "     75        0.6035  0.0426\n",
            "     76        0.6035  0.0446\n",
            "     77        0.6035  0.0446\n",
            "     78        0.6035  0.0496\n",
            "     79        0.6035  0.0439\n",
            "     80        0.6035  0.0454\n",
            "     81        0.6035  0.0441\n",
            "     82        0.6035  0.0414\n",
            "     83        0.6035  0.0419\n",
            "     84        0.6035  0.0436\n",
            "     85        0.6035  0.0461\n",
            "     86        0.6035  0.0425\n",
            "     87        0.6035  0.0525\n",
            "     88        0.6035  0.0438\n",
            "     89        0.6035  0.0428\n",
            "     90        0.6035  0.0430\n",
            "     91        0.6035  0.0433\n",
            "     92        0.6035  0.0423\n",
            "     93        0.6035  0.0454\n",
            "     94        0.6035  0.0440\n",
            "     95        0.6035  0.0444\n",
            "     96        0.6035  0.0457\n",
            "     97        0.6035  0.0448\n",
            "     98        \u001b[36m0.6035\u001b[0m  0.0434\n",
            "     99        \u001b[36m0.5615\u001b[0m  0.0433\n",
            "    100        \u001b[36m0.3719\u001b[0m  0.0422\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7746\u001b[0m  0.0319\n",
            "      2        \u001b[36m0.7746\u001b[0m  0.0326\n",
            "      3        \u001b[36m0.7746\u001b[0m  0.0337\n",
            "      4        \u001b[36m0.7746\u001b[0m  0.0339\n",
            "      5        \u001b[36m0.7746\u001b[0m  0.0329\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.7746\u001b[0m  0.0355\n",
            "      7        \u001b[36m0.7746\u001b[0m  0.0328\n",
            "      8        \u001b[36m0.7746\u001b[0m  0.0345\n",
            "      9        \u001b[36m0.7746\u001b[0m  0.0342\n",
            "     10        \u001b[36m0.7746\u001b[0m  0.0320\n",
            "     11        \u001b[36m0.7746\u001b[0m  0.0431\n",
            "     12        \u001b[36m0.7746\u001b[0m  0.0375\n",
            "     13        \u001b[36m0.7711\u001b[0m  0.0334\n",
            "     14        \u001b[36m0.7711\u001b[0m  0.0340\n",
            "     15        \u001b[36m0.7711\u001b[0m  0.0336\n",
            "     16        \u001b[36m0.7711\u001b[0m  0.0410\n",
            "     17        \u001b[36m0.7711\u001b[0m  0.0439\n",
            "     18        \u001b[36m0.7711\u001b[0m  0.0437\n",
            "     19        \u001b[36m0.7711\u001b[0m  0.0438\n",
            "     20        \u001b[36m0.7711\u001b[0m  0.0476\n",
            "     21        \u001b[36m0.7711\u001b[0m  0.0425\n",
            "     22        0.7711  0.0427\n",
            "     23        \u001b[36m0.7711\u001b[0m  0.0460\n",
            "     24        \u001b[36m0.7711\u001b[0m  0.0463\n",
            "     25        0.7711  0.0442\n",
            "     26        0.7711  0.0427\n",
            "     27        0.7711  0.0388\n",
            "     28        \u001b[36m0.7711\u001b[0m  0.0399\n",
            "     29        \u001b[36m0.7711\u001b[0m  0.0404\n",
            "     30        0.7711  0.0403\n",
            "     31        0.7711  0.0400\n",
            "     32        0.7711  0.0425\n",
            "     33        0.7711  0.0416\n",
            "     34        0.7711  0.0558\n",
            "     35        0.7711  0.0401\n",
            "     36        0.7711  0.0392\n",
            "     37        0.7711  0.0390\n",
            "     38        \u001b[36m0.7711\u001b[0m  0.0393\n",
            "     39        0.7711  0.0396\n",
            "     40        0.7711  0.0427\n",
            "     41        0.7711  0.0395\n",
            "     42        0.7711  0.0395\n",
            "     43        \u001b[36m0.7711\u001b[0m  0.0392\n",
            "     44        0.7711  0.0391\n",
            "     45        0.7711  0.0404\n",
            "     46        0.7711  0.0397\n",
            "     47        0.7711  0.0396\n",
            "     48        0.7711  0.0400\n",
            "     49        0.7711  0.0400\n",
            "     50        0.7711  0.0481\n",
            "     51        0.7711  0.0422\n",
            "     52        0.7711  0.0404\n",
            "     53        0.7711  0.0396\n",
            "     54        0.7711  0.0402\n",
            "     55        0.7711  0.0452\n",
            "     56        0.7711  0.0473\n",
            "     57        0.7711  0.0540\n",
            "     58        0.7711  0.0506\n",
            "     59        0.7711  0.0460\n",
            "     60        0.7711  0.0483\n",
            "     61        0.7711  0.0473\n",
            "     62        0.7711  0.0444\n",
            "     63        0.7711  0.0488\n",
            "     64        0.7711  0.0434\n",
            "     65        0.7711  0.0425\n",
            "     66        0.7711  0.0465\n",
            "     67        0.7711  0.0466\n",
            "     68        0.7711  0.0454\n",
            "     69        0.7711  0.0446\n",
            "     70        0.7711  0.0436\n",
            "     71        0.7711  0.0438\n",
            "     72        0.7711  0.0501\n",
            "     73        0.7711  0.0488\n",
            "     74        0.7711  0.0452\n",
            "     75        0.7711  0.0441\n",
            "     76        0.7711  0.0565\n",
            "     77        0.7711  0.0489\n",
            "     78        \u001b[36m0.7711\u001b[0m  0.0489\n",
            "     79        0.7711  0.0487\n",
            "     80        0.7711  0.0455\n",
            "     81        0.7711  0.0434\n",
            "     82        0.7711  0.0454\n",
            "     83        0.7711  0.0455\n",
            "     84        0.7711  0.0444\n",
            "     85        0.7711  0.0383\n",
            "     86        0.7711  0.0340\n",
            "     87        0.7711  0.0343\n",
            "     88        0.7711  0.0350\n",
            "     89        0.7711  0.0336\n",
            "     90        0.7711  0.0343\n",
            "     91        0.7711  0.0323\n",
            "     92        0.7711  0.0331\n",
            "     93        0.7711  0.0334\n",
            "     94        0.7711  0.0337\n",
            "     95        0.7711  0.0347\n",
            "     96        0.7711  0.0389\n",
            "     97        0.7711  0.0331\n",
            "     98        0.7711  0.0325\n",
            "     99        0.7711  0.0337\n",
            "    100        0.7711  0.0390\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4842\u001b[0m  0.0300\n",
            "      2        0.4842  0.0337\n",
            "      3        0.4842  0.0330\n",
            "      4        0.4842  0.0332\n",
            "      5        0.4842  0.0327\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.4842  0.0379\n",
            "      7        0.4842  0.0330\n",
            "      8        0.4842  0.0338\n",
            "      9        0.4842  0.0338\n",
            "     10        0.4842  0.0344\n",
            "     11        0.4842  0.0436\n",
            "     12        0.4842  0.0437\n",
            "     13        0.4842  0.0324\n",
            "     14        0.4842  0.0339\n",
            "     15        0.4842  0.0328\n",
            "     16        0.4842  0.0326\n",
            "     17        0.4842  0.0335\n",
            "     18        0.4842  0.0324\n",
            "     19        0.4842  0.0331\n",
            "     20        0.4842  0.0344\n",
            "     21        0.4842  0.0330\n",
            "     22        0.4842  0.0330\n",
            "     23        0.4842  0.0344\n",
            "     24        0.4842  0.0419\n",
            "     25        0.4842  0.0334\n",
            "     26        0.4842  0.0359\n",
            "     27        0.4842  0.0399\n",
            "     28        0.4842  0.0394\n",
            "     29        0.4842  0.0323\n",
            "     30        0.4842  0.0334\n",
            "     31        0.4842  0.0339\n",
            "     32        0.4842  0.0351\n",
            "     33        0.4842  0.0339\n",
            "     34        0.4842  0.0335\n",
            "     35        0.4842  0.0350\n",
            "     36        0.4842  0.0337\n",
            "     37        0.4842  0.0359\n",
            "     38        0.4842  0.0335\n",
            "     39        0.4842  0.0346\n",
            "     40        0.4842  0.0341\n",
            "     41        0.4842  0.0349\n",
            "     42        0.4842  0.0337\n",
            "     43        0.4842  0.0352\n",
            "     44        0.4842  0.0330\n",
            "     45        0.4842  0.0329\n",
            "     46        0.4842  0.0306\n",
            "     47        0.4842  0.0321\n",
            "     48        0.4842  0.0339\n",
            "     49        0.4842  0.0321\n",
            "     50        0.4842  0.0318\n",
            "     51        0.4842  0.0319\n",
            "     52        0.4842  0.0365\n",
            "     53        0.4842  0.0363\n",
            "     54        0.4842  0.0343\n",
            "     55        0.4842  0.0389\n",
            "     56        0.4842  0.0396\n",
            "     57        0.4842  0.0352\n",
            "     58        0.4842  0.0325\n",
            "     59        0.4842  0.0331\n",
            "     60        0.4842  0.0330\n",
            "     61        0.4842  0.0341\n",
            "     62        0.4842  0.0328\n",
            "     63        0.4842  0.0346\n",
            "     64        0.4842  0.0326\n",
            "     65        0.4842  0.0335\n",
            "     66        0.4842  0.0365\n",
            "     67        0.4842  0.0337\n",
            "     68        0.4842  0.0327\n",
            "     69        0.4842  0.0334\n",
            "     70        0.4842  0.0342\n",
            "     71        0.4842  0.0339\n",
            "     72        0.4842  0.0336\n",
            "     73        0.4842  0.0333\n",
            "     74        0.4842  0.0350\n",
            "     75        0.4842  0.0370\n",
            "     76        0.4842  0.0364\n",
            "     77        0.4842  0.0347\n",
            "     78        0.4842  0.0353\n",
            "     79        0.4842  0.0338\n",
            "     80        0.4842  0.0336\n",
            "     81        0.4842  0.0426\n",
            "     82        0.4842  0.0369\n",
            "     83        0.4842  0.0417\n",
            "     84        0.4842  0.0367\n",
            "     85        0.4842  0.0354\n",
            "     86        0.4842  0.0343\n",
            "     87        0.4842  0.0335\n",
            "     88        0.4842  0.0345\n",
            "     89        0.4842  0.0341\n",
            "     90        0.4842  0.0348\n",
            "     91        0.4842  0.0371\n",
            "     92        0.4842  0.0344\n",
            "     93        0.4842  0.0338\n",
            "     94        0.4842  0.0360\n",
            "     95        0.4842  0.0328\n",
            "     96        0.4842  0.0341\n",
            "     97        0.4842  0.0343\n",
            "     98        0.4842  0.0333\n",
            "     99        0.4842  0.0332\n",
            "    100        0.4842  0.0347\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9542\u001b[0m  0.0398\n",
            "      2        \u001b[36m0.9296\u001b[0m  0.0433\n",
            "      3        \u001b[36m0.9225\u001b[0m  0.0429\n",
            "      4        0.9225  0.0470\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        0.9225  0.0517\n",
            "      6        \u001b[36m0.9155\u001b[0m  0.0447\n",
            "      7        \u001b[36m0.9155\u001b[0m  0.0637\n",
            "      8        \u001b[36m0.8893\u001b[0m  0.0502\n",
            "      9        \u001b[36m0.8697\u001b[0m  0.0455\n",
            "     10        0.8697  0.0434\n",
            "     11        0.8697  0.0440\n",
            "     12        0.8697  0.0439\n",
            "     13        0.8697  0.0454\n",
            "     14        0.8697  0.0426\n",
            "     15        0.8697  0.0439\n",
            "     16        0.8697  0.0451\n",
            "     17        0.8697  0.0426\n",
            "     18        0.8697  0.0434\n",
            "     19        0.8697  0.0453\n",
            "     20        0.8697  0.0421\n",
            "     21        0.8697  0.0434\n",
            "     22        0.8697  0.0443\n",
            "     23        0.8697  0.0434\n",
            "     24        0.8697  0.0418\n",
            "     25        0.8697  0.0422\n",
            "     26        0.8697  0.0448\n",
            "     27        0.8697  0.0435\n",
            "     28        0.8697  0.0432\n",
            "     29        0.8697  0.0637\n",
            "     30        0.8697  0.0446\n",
            "     31        0.8697  0.0432\n",
            "     32        0.8697  0.0435\n",
            "     33        0.8697  0.0469\n",
            "     34        0.8697  0.0436\n",
            "     35        0.8697  0.0443\n",
            "     36        0.8697  0.0439\n",
            "     37        0.8697  0.0440\n",
            "     38        0.8697  0.0473\n",
            "     39        0.8697  0.0452\n",
            "     40        0.8697  0.0454\n",
            "     41        0.8697  0.0456\n",
            "     42        \u001b[36m0.8627\u001b[0m  0.0430\n",
            "     43        0.8627  0.0427\n",
            "     44        0.8627  0.0435\n",
            "     45        0.8627  0.0451\n",
            "     46        \u001b[36m0.8592\u001b[0m  0.0425\n",
            "     47        \u001b[36m0.8556\u001b[0m  0.0431\n",
            "     48        0.8556  0.0453\n",
            "     49        0.8556  0.0429\n",
            "     50        0.8556  0.0471\n",
            "     51        0.8556  0.0587\n",
            "     52        \u001b[36m0.8486\u001b[0m  0.0426\n",
            "     53        0.8486  0.0439\n",
            "     54        \u001b[36m0.8415\u001b[0m  0.0427\n",
            "     55        0.8415  0.0425\n",
            "     56        0.8415  0.0425\n",
            "     57        0.8415  0.0436\n",
            "     58        0.8451  0.0427\n",
            "     59        \u001b[36m0.8415\u001b[0m  0.0431\n",
            "     60        \u001b[36m0.8380\u001b[0m  0.0454\n",
            "     61        0.8380  0.0428\n",
            "     62        \u001b[36m0.8310\u001b[0m  0.0441\n",
            "     63        0.8310  0.0446\n",
            "     64        0.8310  0.0425\n",
            "     65        0.8310  0.0423\n",
            "     66        \u001b[36m0.8239\u001b[0m  0.0426\n",
            "     67        0.8239  0.0422\n",
            "     68        0.8239  0.0434\n",
            "     69        0.8239  0.0412\n",
            "     70        0.8239  0.0417\n",
            "     71        0.8239  0.0418\n",
            "     72        0.8239  0.0432\n",
            "     73        0.8239  0.0555\n",
            "     74        0.8275  0.0567\n",
            "     75        0.8310  0.0426\n",
            "     76        0.8310  0.0421\n",
            "     77        0.8310  0.0432\n",
            "     78        0.8275  0.0445\n",
            "     79        0.8310  0.0460\n",
            "     80        0.8310  0.0456\n",
            "     81        0.8275  0.0439\n",
            "     82        0.8310  0.0424\n",
            "     83        0.8310  0.0445\n",
            "     84        0.8310  0.0448\n",
            "     85        0.8310  0.0441\n",
            "     86        0.8310  0.0470\n",
            "     87        0.8345  0.0433\n",
            "     88        0.8345  0.0436\n",
            "     89        0.8345  0.0438\n",
            "     90        0.8345  0.0431\n",
            "     91        0.8345  0.0436\n",
            "     92        0.8345  0.0433\n",
            "     93        0.8345  0.0474\n",
            "     94        0.8345  0.0508\n",
            "     95        0.8345  0.0478\n",
            "     96        0.8345  0.0556\n",
            "     97        0.8345  0.0446\n",
            "     98        0.8345  0.0451\n",
            "     99        0.8345  0.0450\n",
            "    100        0.8345  0.0461\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0421\n",
            "      2        1.0000  0.0451\n",
            "      3        1.0000  0.0443\n",
            "      4        1.0000  0.0470\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        1.0000  0.0499\n",
            "      6        1.0000  0.0451\n",
            "      7        1.0000  0.0453\n",
            "      8        1.0000  0.0461\n",
            "      9        1.0000  0.0459\n",
            "     10        1.0000  0.0466\n",
            "     11        1.0000  0.0443\n",
            "     12        1.0000  0.0453\n",
            "     13        1.0000  0.0463\n",
            "     14        1.0000  0.0482\n",
            "     15        1.0000  0.0517\n",
            "     16        1.0000  0.0440\n",
            "     17        1.0000  0.0541\n",
            "     18        1.0000  0.0464\n",
            "     19        1.0000  0.0432\n",
            "     20        1.0000  0.0433\n",
            "     21        1.0000  0.0456\n",
            "     22        1.0000  0.0436\n",
            "     23        1.0000  0.0442\n",
            "     24        1.0000  0.0501\n",
            "     25        1.0000  0.0594\n",
            "     26        1.0000  0.0603\n",
            "     27        1.0000  0.0605\n",
            "     28        1.0000  0.0560\n",
            "     29        1.0000  0.0648\n",
            "     30        1.0000  0.0588\n",
            "     31        1.0000  0.0527\n",
            "     32        1.0000  0.0544\n",
            "     33        1.0000  0.0694\n",
            "     34        1.0000  0.0644\n",
            "     35        1.0000  0.0724\n",
            "     36        1.0000  0.0611\n",
            "     37        1.0000  0.0557\n",
            "     38        \u001b[36m1.0000\u001b[0m  0.0648\n",
            "     39        \u001b[36m0.9747\u001b[0m  0.0611\n",
            "     40        \u001b[36m0.6676\u001b[0m  0.0579\n",
            "     41        \u001b[36m0.3965\u001b[0m  0.0596\n",
            "     42        0.3965  0.0617\n",
            "     43        0.3965  0.0554\n",
            "     44        0.3965  0.0624\n",
            "     45        \u001b[36m0.3930\u001b[0m  0.0607\n",
            "     46        0.3930  0.0558\n",
            "     47        0.3930  0.0574\n",
            "     48        0.3930  0.0668\n",
            "     49        \u001b[36m0.3895\u001b[0m  0.0678\n",
            "     50        0.3895  0.0621\n",
            "     51        0.3895  0.0609\n",
            "     52        0.3895  0.0640\n",
            "     53        0.3895  0.0602\n",
            "     54        0.3895  0.0631\n",
            "     55        \u001b[36m0.3860\u001b[0m  0.0663\n",
            "     56        \u001b[36m0.3754\u001b[0m  0.0594\n",
            "     57        \u001b[36m0.3719\u001b[0m  0.0644\n",
            "     58        0.3719  0.0639\n",
            "     59        0.3719  0.0650\n",
            "     60        0.3719  0.0680\n",
            "     61        0.3719  0.0600\n",
            "     62        0.3719  0.0590\n",
            "     63        0.3719  0.0609\n",
            "     64        0.3719  0.0680\n",
            "     65        0.3719  0.0683\n",
            "     66        0.3719  0.0663\n",
            "     67        0.3719  0.0730\n",
            "     68        0.3719  0.0711\n",
            "     69        0.3719  0.0651\n",
            "     70        0.3719  0.0470\n",
            "     71        0.3719  0.0441\n",
            "     72        0.3719  0.0452\n",
            "     73        0.3719  0.0442\n",
            "     74        0.3719  0.0448\n",
            "     75        0.3719  0.0429\n",
            "     76        0.3719  0.0417\n",
            "     77        0.3719  0.0417\n",
            "     78        0.3719  0.0430\n",
            "     79        0.3719  0.0417\n",
            "     80        0.3719  0.0435\n",
            "     81        0.3719  0.0436\n",
            "     82        0.3719  0.0506\n",
            "     83        0.3719  0.0463\n",
            "     84        0.3719  0.0427\n",
            "     85        0.3719  0.0424\n",
            "     86        0.3719  0.0421\n",
            "     87        0.3719  0.0442\n",
            "     88        0.3719  0.0469\n",
            "     89        0.3719  0.0508\n",
            "     90        0.3719  0.0442\n",
            "     91        0.3719  0.0427\n",
            "     92        0.3719  0.0453\n",
            "     93        0.3719  0.0454\n",
            "     94        0.3719  0.0439\n",
            "     95        0.3719  0.0470\n",
            "     96        0.3719  0.0437\n",
            "     97        0.3719  0.0439\n",
            "     98        0.3719  0.0436\n",
            "     99        0.3719  0.0435\n",
            "    100        0.3719  0.0451\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5634\u001b[0m  0.0302\n",
            "      2        0.5634  0.0344\n",
            "      3        0.5634  0.0372\n",
            "      4        0.5634  0.0420\n",
            "      5        \u001b[36m0.5634\u001b[0m  0.0342\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.5634  0.0405\n",
            "      7        0.5634  0.0333\n",
            "      8        0.5634  0.0328\n",
            "      9        0.5634  0.0356\n",
            "     10        0.5634  0.0336\n",
            "     11        0.5634  0.0331\n",
            "     12        0.5634  0.0341\n",
            "     13        0.5634  0.0430\n",
            "     14        0.5634  0.0367\n",
            "     15        0.5634  0.0341\n",
            "     16        0.5634  0.0336\n",
            "     17        0.5634  0.0356\n",
            "     18        0.5634  0.0344\n",
            "     19        0.5634  0.0322\n",
            "     20        0.5634  0.0338\n",
            "     21        0.5634  0.0336\n",
            "     22        0.5634  0.0334\n",
            "     23        0.5634  0.0357\n",
            "     24        0.5634  0.0338\n",
            "     25        0.5634  0.0324\n",
            "     26        0.5634  0.0327\n",
            "     27        0.5634  0.0331\n",
            "     28        0.5634  0.0339\n",
            "     29        0.5634  0.0349\n",
            "     30        0.5634  0.0332\n",
            "     31        0.5634  0.0349\n",
            "     32        0.5634  0.0404\n",
            "     33        0.5634  0.0447\n",
            "     34        0.5634  0.0352\n",
            "     35        0.5634  0.0345\n",
            "     36        0.5634  0.0347\n",
            "     37        0.5634  0.0342\n",
            "     38        0.5634  0.0364\n",
            "     39        0.5634  0.0390\n",
            "     40        0.5634  0.0416\n",
            "     41        0.5634  0.0485\n",
            "     42        0.5634  0.0344\n",
            "     43        0.5634  0.0348\n",
            "     44        0.5634  0.0350\n",
            "     45        0.5634  0.0336\n",
            "     46        0.5634  0.0349\n",
            "     47        0.5634  0.0348\n",
            "     48        0.5634  0.0340\n",
            "     49        0.5634  0.0327\n",
            "     50        0.5634  0.0374\n",
            "     51        0.5634  0.0344\n",
            "     52        0.5634  0.0336\n",
            "     53        0.5634  0.0332\n",
            "     54        0.5634  0.0343\n",
            "     55        0.5634  0.0368\n",
            "     56        0.5634  0.0345\n",
            "     57        0.5634  0.0342\n",
            "     58        0.5634  0.0441\n",
            "     59        0.5634  0.0345\n",
            "     60        0.5634  0.0349\n",
            "     61        0.5634  0.0366\n",
            "     62        0.5634  0.0347\n",
            "     63        0.5634  0.0349\n",
            "     64        0.5634  0.0348\n",
            "     65        0.5634  0.0340\n",
            "     66        0.5634  0.0352\n",
            "     67        0.5634  0.0351\n",
            "     68        0.5634  0.0332\n",
            "     69        0.5634  0.0422\n",
            "     70        0.5634  0.0335\n",
            "     71        0.5634  0.0345\n",
            "     72        0.5634  0.0338\n",
            "     73        0.5634  0.0341\n",
            "     74        0.5634  0.0353\n",
            "     75        0.5634  0.0382\n",
            "     76        0.5634  0.0345\n",
            "     77        0.5634  0.0340\n",
            "     78        0.5634  0.0342\n",
            "     79        0.5634  0.0338\n",
            "     80        0.5634  0.0337\n",
            "     81        0.5634  0.0385\n",
            "     82        0.5634  0.0330\n",
            "     83        0.5634  0.0342\n",
            "     84        0.5634  0.0346\n",
            "     85        0.5634  0.0457\n",
            "     86        0.5634  0.0361\n",
            "     87        0.5634  0.0348\n",
            "     88        0.5634  0.0358\n",
            "     89        0.5634  0.0336\n",
            "     90        0.5634  0.0374\n",
            "     91        0.5634  0.0345\n",
            "     92        0.5634  0.0327\n",
            "     93        0.5634  0.0327\n",
            "     94        0.5634  0.0377\n",
            "     95        0.5634  0.0346\n",
            "     96        0.5634  0.0339\n",
            "     97        0.5634  0.0446\n",
            "     98        0.5634  0.0349\n",
            "     99        0.5634  0.0344\n",
            "    100        0.5634  0.0342\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4807\u001b[0m  0.0316\n",
            "      2        0.4807  0.0337\n",
            "      3        0.4807  0.0332\n",
            "      4        0.4807  0.0325\n",
            "      5        0.4807  0.0358\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        0.4807  0.0362\n",
            "      7        0.4807  0.0332\n",
            "      8        0.4807  0.0319\n",
            "      9        0.4807  0.0331\n",
            "     10        0.4807  0.0327\n",
            "     11        0.4807  0.0329\n",
            "     12        0.4807  0.0420\n",
            "     13        0.4807  0.0369\n",
            "     14        0.4807  0.0343\n",
            "     15        0.4807  0.0353\n",
            "     16        0.4807  0.0359\n",
            "     17        0.4807  0.0338\n",
            "     18        0.4807  0.0327\n",
            "     19        0.4807  0.0322\n",
            "     20        0.4807  0.0313\n",
            "     21        0.4807  0.0329\n",
            "     22        0.4807  0.0337\n",
            "     23        0.4807  0.0321\n",
            "     24        0.4807  0.0331\n",
            "     25        0.4807  0.0410\n",
            "     26        0.4807  0.0328\n",
            "     27        0.4807  0.0359\n",
            "     28        0.4807  0.0342\n",
            "     29        0.4807  0.0356\n",
            "     30        0.4807  0.0340\n",
            "     31        0.4807  0.0332\n",
            "     32        0.4807  0.0329\n",
            "     33        0.4807  0.0334\n",
            "     34        0.4807  0.0374\n",
            "     35        0.4807  0.0350\n",
            "     36        0.4807  0.0340\n",
            "     37        0.4807  0.0327\n",
            "     38        0.4807  0.0345\n",
            "     39        0.4807  0.0350\n",
            "     40        0.4807  0.0435\n",
            "     41        0.4807  0.0375\n",
            "     42        0.4807  0.0334\n",
            "     43        0.4807  0.0351\n",
            "     44        0.4807  0.0322\n",
            "     45        0.4807  0.0337\n",
            "     46        0.4807  0.0332\n",
            "     47        0.4807  0.0336\n",
            "     48        0.4807  0.0327\n",
            "     49        0.4807  0.0353\n",
            "     50        0.4807  0.0335\n",
            "     51        0.4807  0.0354\n",
            "     52        0.4807  0.0364\n",
            "     53        0.4807  0.0429\n",
            "     54        0.4807  0.0337\n",
            "     55        0.4807  0.0337\n",
            "     56        0.4807  0.0356\n",
            "     57        0.4807  0.0345\n",
            "     58        0.4807  0.0335\n",
            "     59        0.4807  0.0332\n",
            "     60        0.4807  0.0354\n",
            "     61        0.4807  0.0317\n",
            "     62        0.4807  0.0331\n",
            "     63        0.4807  0.0338\n",
            "     64        0.4807  0.0339\n",
            "     65        0.4807  0.0348\n",
            "     66        0.4807  0.0321\n",
            "     67        0.4807  0.0367\n",
            "     68        0.4807  0.0426\n",
            "     69        0.4807  0.0372\n",
            "     70        0.4807  0.0334\n",
            "     71        0.4807  0.0386\n",
            "     72        0.4807  0.0332\n",
            "     73        0.4807  0.0348\n",
            "     74        0.4807  0.0331\n",
            "     75        0.4807  0.0341\n",
            "     76        0.4807  0.0337\n",
            "     77        0.4807  0.0351\n",
            "     78        0.4807  0.0334\n",
            "     79        0.4807  0.0344\n",
            "     80        0.4807  0.0326\n",
            "     81        0.4807  0.0391\n",
            "     82        0.4807  0.0392\n",
            "     83        0.4807  0.0355\n",
            "     84        0.4807  0.0351\n",
            "     85        0.4807  0.0343\n",
            "     86        0.4807  0.0355\n",
            "     87        0.4807  0.0346\n",
            "     88        0.4807  0.0351\n",
            "     89        0.4807  0.0330\n",
            "     90        0.4807  0.0339\n",
            "     91        0.4807  0.0331\n",
            "     92        0.4807  0.0346\n",
            "     93        0.4807  0.0326\n",
            "     94        0.4807  0.0354\n",
            "     95        0.4807  0.0421\n",
            "     96        0.4807  0.0350\n",
            "     97        0.4807  0.0340\n",
            "     98        0.4807  0.0374\n",
            "     99        0.4807  0.0343\n",
            "    100        0.4807  0.0344\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9879\u001b[0m  0.0386\n",
            "      2        \u001b[36m0.9842\u001b[0m  0.0448\n",
            "      3        \u001b[36m0.9784\u001b[0m  0.0455\n",
            "      4        \u001b[36m0.9675\u001b[0m  0.0456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9414\u001b[0m  0.0451\n",
            "      6        \u001b[36m0.8643\u001b[0m  0.0427\n",
            "      7        \u001b[36m0.6937\u001b[0m  0.0525\n",
            "      8        \u001b[36m0.5286\u001b[0m  0.0450\n",
            "      9        \u001b[36m0.4517\u001b[0m  0.0454\n",
            "     10        \u001b[36m0.4212\u001b[0m  0.0430\n",
            "     11        \u001b[36m0.4078\u001b[0m  0.0450\n",
            "     12        \u001b[36m0.4002\u001b[0m  0.0419\n",
            "     13        \u001b[36m0.3948\u001b[0m  0.0428\n",
            "     14        \u001b[36m0.3912\u001b[0m  0.0438\n",
            "     15        \u001b[36m0.3890\u001b[0m  0.0429\n",
            "     16        \u001b[36m0.3874\u001b[0m  0.0428\n",
            "     17        \u001b[36m0.3862\u001b[0m  0.0517\n",
            "     18        \u001b[36m0.3852\u001b[0m  0.0464\n",
            "     19        \u001b[36m0.3843\u001b[0m  0.0416\n",
            "     20        \u001b[36m0.3835\u001b[0m  0.0431\n",
            "     21        \u001b[36m0.3829\u001b[0m  0.0420\n",
            "     22        \u001b[36m0.3823\u001b[0m  0.0442\n",
            "     23        \u001b[36m0.3817\u001b[0m  0.0433\n",
            "     24        \u001b[36m0.3812\u001b[0m  0.0430\n",
            "     25        \u001b[36m0.3808\u001b[0m  0.0449\n",
            "     26        \u001b[36m0.3804\u001b[0m  0.0446\n",
            "     27        \u001b[36m0.3800\u001b[0m  0.0440\n",
            "     28        \u001b[36m0.3797\u001b[0m  0.0593\n",
            "     29        \u001b[36m0.3794\u001b[0m  0.0669\n",
            "     30        \u001b[36m0.3791\u001b[0m  0.0635\n",
            "     31        \u001b[36m0.3788\u001b[0m  0.0653\n",
            "     32        \u001b[36m0.3786\u001b[0m  0.0548\n",
            "     33        \u001b[36m0.3783\u001b[0m  0.0616\n",
            "     34        \u001b[36m0.3781\u001b[0m  0.0533\n",
            "     35        \u001b[36m0.3779\u001b[0m  0.0575\n",
            "     36        \u001b[36m0.3777\u001b[0m  0.0569\n",
            "     37        \u001b[36m0.3776\u001b[0m  0.0572\n",
            "     38        \u001b[36m0.3774\u001b[0m  0.0567\n",
            "     39        \u001b[36m0.3772\u001b[0m  0.0536\n",
            "     40        \u001b[36m0.3771\u001b[0m  0.0531\n",
            "     41        \u001b[36m0.3769\u001b[0m  0.0531\n",
            "     42        \u001b[36m0.3768\u001b[0m  0.0575\n",
            "     43        \u001b[36m0.3767\u001b[0m  0.0539\n",
            "     44        \u001b[36m0.3766\u001b[0m  0.0523\n",
            "     45        \u001b[36m0.3765\u001b[0m  0.0530\n",
            "     46        \u001b[36m0.3764\u001b[0m  0.0563\n",
            "     47        \u001b[36m0.3763\u001b[0m  0.0632\n",
            "     48        \u001b[36m0.3762\u001b[0m  0.0537\n",
            "     49        \u001b[36m0.3761\u001b[0m  0.0499\n",
            "     50        \u001b[36m0.3760\u001b[0m  0.0517\n",
            "     51        \u001b[36m0.3759\u001b[0m  0.0521\n",
            "     52        \u001b[36m0.3758\u001b[0m  0.0523\n",
            "     53        \u001b[36m0.3757\u001b[0m  0.0560\n",
            "     54        \u001b[36m0.3757\u001b[0m  0.0525\n",
            "     55        \u001b[36m0.3756\u001b[0m  0.0559\n",
            "     56        \u001b[36m0.3755\u001b[0m  0.0572\n",
            "     57        \u001b[36m0.3755\u001b[0m  0.0581\n",
            "     58        \u001b[36m0.3754\u001b[0m  0.0619\n",
            "     59        \u001b[36m0.3753\u001b[0m  0.0593\n",
            "     60        \u001b[36m0.3753\u001b[0m  0.0552\n",
            "     61        \u001b[36m0.3752\u001b[0m  0.0545\n",
            "     62        \u001b[36m0.3752\u001b[0m  0.0568\n",
            "     63        \u001b[36m0.3751\u001b[0m  0.0597\n",
            "     64        \u001b[36m0.3751\u001b[0m  0.0628\n",
            "     65        \u001b[36m0.3750\u001b[0m  0.0650\n",
            "     66        \u001b[36m0.3750\u001b[0m  0.0581\n",
            "     67        \u001b[36m0.3749\u001b[0m  0.0618\n",
            "     68        \u001b[36m0.3749\u001b[0m  0.0645\n",
            "     69        \u001b[36m0.3749\u001b[0m  0.0591\n",
            "     70        \u001b[36m0.3748\u001b[0m  0.0646\n",
            "     71        \u001b[36m0.3748\u001b[0m  0.0544\n",
            "     72        \u001b[36m0.3747\u001b[0m  0.0569\n",
            "     73        \u001b[36m0.3747\u001b[0m  0.0566\n",
            "     74        \u001b[36m0.3747\u001b[0m  0.0633\n",
            "     75        \u001b[36m0.3746\u001b[0m  0.0600\n",
            "     76        \u001b[36m0.3746\u001b[0m  0.0567\n",
            "     77        \u001b[36m0.3746\u001b[0m  0.0548\n",
            "     78        \u001b[36m0.3745\u001b[0m  0.0552\n",
            "     79        \u001b[36m0.3745\u001b[0m  0.0587\n",
            "     80        \u001b[36m0.3745\u001b[0m  0.0592\n",
            "     81        \u001b[36m0.3745\u001b[0m  0.0642\n",
            "     82        \u001b[36m0.3744\u001b[0m  0.0544\n",
            "     83        \u001b[36m0.3744\u001b[0m  0.0428\n",
            "     84        \u001b[36m0.3744\u001b[0m  0.0426\n",
            "     85        \u001b[36m0.3744\u001b[0m  0.0415\n",
            "     86        \u001b[36m0.3743\u001b[0m  0.0472\n",
            "     87        \u001b[36m0.3743\u001b[0m  0.0472\n",
            "     88        \u001b[36m0.3743\u001b[0m  0.0438\n",
            "     89        \u001b[36m0.3743\u001b[0m  0.0424\n",
            "     90        \u001b[36m0.3742\u001b[0m  0.0473\n",
            "     91        \u001b[36m0.3742\u001b[0m  0.0411\n",
            "     92        \u001b[36m0.3742\u001b[0m  0.0432\n",
            "     93        \u001b[36m0.3742\u001b[0m  0.0425\n",
            "     94        \u001b[36m0.3742\u001b[0m  0.0485\n",
            "     95        \u001b[36m0.3742\u001b[0m  0.0426\n",
            "     96        \u001b[36m0.3741\u001b[0m  0.0424\n",
            "     97        \u001b[36m0.3741\u001b[0m  0.0418\n",
            "     98        \u001b[36m0.3741\u001b[0m  0.0431\n",
            "     99        \u001b[36m0.3741\u001b[0m  0.0462\n",
            "    100        \u001b[36m0.3741\u001b[0m  0.0445\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9948\u001b[0m  0.0413\n",
            "      2        \u001b[36m0.9931\u001b[0m  0.0439\n",
            "      3        \u001b[36m0.9907\u001b[0m  0.0491\n",
            "      4        \u001b[36m0.9869\u001b[0m  0.0430\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9795\u001b[0m  0.0488\n",
            "      6        \u001b[36m0.9593\u001b[0m  0.0439\n",
            "      7        \u001b[36m0.8823\u001b[0m  0.0447\n",
            "      8        \u001b[36m0.6881\u001b[0m  0.0551\n",
            "      9        \u001b[36m0.5243\u001b[0m  0.0452\n",
            "     10        \u001b[36m0.4573\u001b[0m  0.0441\n",
            "     11        \u001b[36m0.4297\u001b[0m  0.0446\n",
            "     12        \u001b[36m0.4146\u001b[0m  0.0450\n",
            "     13        \u001b[36m0.4033\u001b[0m  0.0444\n",
            "     14        \u001b[36m0.3955\u001b[0m  0.0444\n",
            "     15        \u001b[36m0.3914\u001b[0m  0.0434\n",
            "     16        \u001b[36m0.3890\u001b[0m  0.0461\n",
            "     17        \u001b[36m0.3872\u001b[0m  0.0431\n",
            "     18        \u001b[36m0.3857\u001b[0m  0.0430\n",
            "     19        \u001b[36m0.3845\u001b[0m  0.0447\n",
            "     20        \u001b[36m0.3834\u001b[0m  0.0435\n",
            "     21        \u001b[36m0.3826\u001b[0m  0.0446\n",
            "     22        \u001b[36m0.3818\u001b[0m  0.0420\n",
            "     23        \u001b[36m0.3811\u001b[0m  0.0417\n",
            "     24        \u001b[36m0.3805\u001b[0m  0.0438\n",
            "     25        \u001b[36m0.3799\u001b[0m  0.0471\n",
            "     26        \u001b[36m0.3794\u001b[0m  0.0467\n",
            "     27        \u001b[36m0.3790\u001b[0m  0.0417\n",
            "     28        \u001b[36m0.3786\u001b[0m  0.0416\n",
            "     29        \u001b[36m0.3782\u001b[0m  0.0490\n",
            "     30        \u001b[36m0.3779\u001b[0m  0.0486\n",
            "     31        \u001b[36m0.3776\u001b[0m  0.0438\n",
            "     32        \u001b[36m0.3773\u001b[0m  0.0428\n",
            "     33        \u001b[36m0.3770\u001b[0m  0.0423\n",
            "     34        \u001b[36m0.3768\u001b[0m  0.0439\n",
            "     35        \u001b[36m0.3766\u001b[0m  0.0444\n",
            "     36        \u001b[36m0.3763\u001b[0m  0.0425\n",
            "     37        \u001b[36m0.3762\u001b[0m  0.0437\n",
            "     38        \u001b[36m0.3760\u001b[0m  0.0444\n",
            "     39        \u001b[36m0.3758\u001b[0m  0.0437\n",
            "     40        \u001b[36m0.3756\u001b[0m  0.0430\n",
            "     41        \u001b[36m0.3755\u001b[0m  0.0451\n",
            "     42        \u001b[36m0.3754\u001b[0m  0.0433\n",
            "     43        \u001b[36m0.3752\u001b[0m  0.0455\n",
            "     44        \u001b[36m0.3751\u001b[0m  0.0446\n",
            "     45        \u001b[36m0.3750\u001b[0m  0.0438\n",
            "     46        \u001b[36m0.3749\u001b[0m  0.0430\n",
            "     47        \u001b[36m0.3748\u001b[0m  0.0448\n",
            "     48        \u001b[36m0.3747\u001b[0m  0.0532\n",
            "     49        \u001b[36m0.3746\u001b[0m  0.0424\n",
            "     50        \u001b[36m0.3745\u001b[0m  0.0426\n",
            "     51        \u001b[36m0.3744\u001b[0m  0.0517\n",
            "     52        \u001b[36m0.3743\u001b[0m  0.0464\n",
            "     53        \u001b[36m0.3742\u001b[0m  0.0454\n",
            "     54        \u001b[36m0.3742\u001b[0m  0.0437\n",
            "     55        \u001b[36m0.3741\u001b[0m  0.0438\n",
            "     56        \u001b[36m0.3740\u001b[0m  0.0431\n",
            "     57        \u001b[36m0.3740\u001b[0m  0.0425\n",
            "     58        \u001b[36m0.3739\u001b[0m  0.0434\n",
            "     59        \u001b[36m0.3739\u001b[0m  0.0478\n",
            "     60        \u001b[36m0.3738\u001b[0m  0.0447\n",
            "     61        \u001b[36m0.3737\u001b[0m  0.0429\n",
            "     62        \u001b[36m0.3737\u001b[0m  0.0434\n",
            "     63        \u001b[36m0.3736\u001b[0m  0.0449\n",
            "     64        \u001b[36m0.3736\u001b[0m  0.0438\n",
            "     65        \u001b[36m0.3736\u001b[0m  0.0445\n",
            "     66        \u001b[36m0.3735\u001b[0m  0.0442\n",
            "     67        \u001b[36m0.3735\u001b[0m  0.0445\n",
            "     68        \u001b[36m0.3734\u001b[0m  0.0440\n",
            "     69        \u001b[36m0.3734\u001b[0m  0.0434\n",
            "     70        \u001b[36m0.3734\u001b[0m  0.0523\n",
            "     71        \u001b[36m0.3733\u001b[0m  0.0433\n",
            "     72        \u001b[36m0.3733\u001b[0m  0.0455\n",
            "     73        \u001b[36m0.3732\u001b[0m  0.0512\n",
            "     74        \u001b[36m0.3732\u001b[0m  0.0436\n",
            "     75        \u001b[36m0.3732\u001b[0m  0.0439\n",
            "     76        \u001b[36m0.3732\u001b[0m  0.0459\n",
            "     77        \u001b[36m0.3731\u001b[0m  0.0452\n",
            "     78        \u001b[36m0.3731\u001b[0m  0.0439\n",
            "     79        \u001b[36m0.3731\u001b[0m  0.0424\n",
            "     80        \u001b[36m0.3730\u001b[0m  0.0441\n",
            "     81        \u001b[36m0.3730\u001b[0m  0.0452\n",
            "     82        \u001b[36m0.3730\u001b[0m  0.0443\n",
            "     83        \u001b[36m0.3730\u001b[0m  0.0476\n",
            "     84        \u001b[36m0.3729\u001b[0m  0.0589\n",
            "     85        \u001b[36m0.3729\u001b[0m  0.0501\n",
            "     86        \u001b[36m0.3729\u001b[0m  0.0440\n",
            "     87        \u001b[36m0.3729\u001b[0m  0.0432\n",
            "     88        \u001b[36m0.3729\u001b[0m  0.0433\n",
            "     89        \u001b[36m0.3728\u001b[0m  0.0428\n",
            "     90        \u001b[36m0.3728\u001b[0m  0.0437\n",
            "     91        \u001b[36m0.3728\u001b[0m  0.0466\n",
            "     92        \u001b[36m0.3728\u001b[0m  0.0535\n",
            "     93        \u001b[36m0.3728\u001b[0m  0.0445\n",
            "     94        \u001b[36m0.3728\u001b[0m  0.0508\n",
            "     95        \u001b[36m0.3727\u001b[0m  0.0429\n",
            "     96        \u001b[36m0.3727\u001b[0m  0.0454\n",
            "     97        \u001b[36m0.3727\u001b[0m  0.0424\n",
            "     98        \u001b[36m0.3727\u001b[0m  0.0445\n",
            "     99        \u001b[36m0.3727\u001b[0m  0.0420\n",
            "    100        \u001b[36m0.3727\u001b[0m  0.0429\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9951\u001b[0m  0.0314\n",
            "      2        \u001b[36m0.9951\u001b[0m  0.0360\n",
            "      3        \u001b[36m0.9951\u001b[0m  0.0351\n",
            "      4        \u001b[36m0.9951\u001b[0m  0.0344\n",
            "      5        \u001b[36m0.9951\u001b[0m  0.0361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9951\u001b[0m  0.0390\n",
            "      7        \u001b[36m0.9951\u001b[0m  0.0333\n",
            "      8        \u001b[36m0.9951\u001b[0m  0.0342\n",
            "      9        \u001b[36m0.9951\u001b[0m  0.0341\n",
            "     10        \u001b[36m0.9951\u001b[0m  0.0354\n",
            "     11        \u001b[36m0.9951\u001b[0m  0.0343\n",
            "     12        \u001b[36m0.9950\u001b[0m  0.0354\n",
            "     13        \u001b[36m0.9950\u001b[0m  0.0330\n",
            "     14        \u001b[36m0.9950\u001b[0m  0.0328\n",
            "     15        \u001b[36m0.9950\u001b[0m  0.0343\n",
            "     16        \u001b[36m0.9950\u001b[0m  0.0350\n",
            "     17        \u001b[36m0.9950\u001b[0m  0.0444\n",
            "     18        \u001b[36m0.9950\u001b[0m  0.0355\n",
            "     19        \u001b[36m0.9950\u001b[0m  0.0419\n",
            "     20        \u001b[36m0.9950\u001b[0m  0.0363\n",
            "     21        \u001b[36m0.9950\u001b[0m  0.0328\n",
            "     22        \u001b[36m0.9950\u001b[0m  0.0327\n",
            "     23        \u001b[36m0.9950\u001b[0m  0.0341\n",
            "     24        \u001b[36m0.9950\u001b[0m  0.0340\n",
            "     25        \u001b[36m0.9950\u001b[0m  0.0351\n",
            "     26        \u001b[36m0.9950\u001b[0m  0.0339\n",
            "     27        \u001b[36m0.9949\u001b[0m  0.0359\n",
            "     28        \u001b[36m0.9949\u001b[0m  0.0342\n",
            "     29        \u001b[36m0.9949\u001b[0m  0.0348\n",
            "     30        \u001b[36m0.9949\u001b[0m  0.0341\n",
            "     31        \u001b[36m0.9949\u001b[0m  0.0323\n",
            "     32        \u001b[36m0.9949\u001b[0m  0.0349\n",
            "     33        \u001b[36m0.9949\u001b[0m  0.0331\n",
            "     34        \u001b[36m0.9949\u001b[0m  0.0346\n",
            "     35        \u001b[36m0.9949\u001b[0m  0.0354\n",
            "     36        \u001b[36m0.9949\u001b[0m  0.0342\n",
            "     37        \u001b[36m0.9949\u001b[0m  0.0334\n",
            "     38        \u001b[36m0.9949\u001b[0m  0.0329\n",
            "     39        \u001b[36m0.9949\u001b[0m  0.0337\n",
            "     40        \u001b[36m0.9949\u001b[0m  0.0335\n",
            "     41        \u001b[36m0.9949\u001b[0m  0.0338\n",
            "     42        \u001b[36m0.9948\u001b[0m  0.0318\n",
            "     43        \u001b[36m0.9948\u001b[0m  0.0334\n",
            "     44        \u001b[36m0.9948\u001b[0m  0.0333\n",
            "     45        \u001b[36m0.9948\u001b[0m  0.0354\n",
            "     46        \u001b[36m0.9948\u001b[0m  0.0436\n",
            "     47        \u001b[36m0.9948\u001b[0m  0.0416\n",
            "     48        \u001b[36m0.9948\u001b[0m  0.0393\n",
            "     49        \u001b[36m0.9948\u001b[0m  0.0330\n",
            "     50        \u001b[36m0.9948\u001b[0m  0.0331\n",
            "     51        \u001b[36m0.9948\u001b[0m  0.0348\n",
            "     52        \u001b[36m0.9948\u001b[0m  0.0329\n",
            "     53        \u001b[36m0.9948\u001b[0m  0.0345\n",
            "     54        \u001b[36m0.9948\u001b[0m  0.0326\n",
            "     55        \u001b[36m0.9948\u001b[0m  0.0325\n",
            "     56        \u001b[36m0.9948\u001b[0m  0.0337\n",
            "     57        \u001b[36m0.9947\u001b[0m  0.0359\n",
            "     58        \u001b[36m0.9947\u001b[0m  0.0336\n",
            "     59        \u001b[36m0.9947\u001b[0m  0.0320\n",
            "     60        \u001b[36m0.9947\u001b[0m  0.0327\n",
            "     61        \u001b[36m0.9947\u001b[0m  0.0348\n",
            "     62        \u001b[36m0.9947\u001b[0m  0.0335\n",
            "     63        \u001b[36m0.9947\u001b[0m  0.0335\n",
            "     64        \u001b[36m0.9947\u001b[0m  0.0352\n",
            "     65        \u001b[36m0.9947\u001b[0m  0.0341\n",
            "     66        \u001b[36m0.9947\u001b[0m  0.0340\n",
            "     67        \u001b[36m0.9947\u001b[0m  0.0345\n",
            "     68        \u001b[36m0.9947\u001b[0m  0.0371\n",
            "     69        \u001b[36m0.9947\u001b[0m  0.0345\n",
            "     70        \u001b[36m0.9947\u001b[0m  0.0340\n",
            "     71        \u001b[36m0.9946\u001b[0m  0.0352\n",
            "     72        \u001b[36m0.9946\u001b[0m  0.0358\n",
            "     73        \u001b[36m0.9946\u001b[0m  0.0346\n",
            "     74        \u001b[36m0.9946\u001b[0m  0.0439\n",
            "     75        \u001b[36m0.9946\u001b[0m  0.0396\n",
            "     76        \u001b[36m0.9946\u001b[0m  0.0339\n",
            "     77        \u001b[36m0.9946\u001b[0m  0.0345\n",
            "     78        \u001b[36m0.9946\u001b[0m  0.0327\n",
            "     79        \u001b[36m0.9946\u001b[0m  0.0327\n",
            "     80        \u001b[36m0.9946\u001b[0m  0.0323\n",
            "     81        \u001b[36m0.9946\u001b[0m  0.0347\n",
            "     82        \u001b[36m0.9946\u001b[0m  0.0331\n",
            "     83        \u001b[36m0.9946\u001b[0m  0.0323\n",
            "     84        \u001b[36m0.9945\u001b[0m  0.0333\n",
            "     85        \u001b[36m0.9945\u001b[0m  0.0341\n",
            "     86        \u001b[36m0.9945\u001b[0m  0.0368\n",
            "     87        \u001b[36m0.9945\u001b[0m  0.0318\n",
            "     88        \u001b[36m0.9945\u001b[0m  0.0321\n",
            "     89        \u001b[36m0.9945\u001b[0m  0.0339\n",
            "     90        \u001b[36m0.9945\u001b[0m  0.0349\n",
            "     91        \u001b[36m0.9945\u001b[0m  0.0335\n",
            "     92        \u001b[36m0.9945\u001b[0m  0.0349\n",
            "     93        \u001b[36m0.9945\u001b[0m  0.0339\n",
            "     94        \u001b[36m0.9945\u001b[0m  0.0379\n",
            "     95        \u001b[36m0.9945\u001b[0m  0.0337\n",
            "     96        \u001b[36m0.9945\u001b[0m  0.0329\n",
            "     97        \u001b[36m0.9944\u001b[0m  0.0328\n",
            "     98        \u001b[36m0.9944\u001b[0m  0.0322\n",
            "     99        \u001b[36m0.9944\u001b[0m  0.0359\n",
            "    100        \u001b[36m0.9944\u001b[0m  0.0325\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9848\u001b[0m  0.0306\n",
            "      2        \u001b[36m0.9847\u001b[0m  0.0458\n",
            "      3        \u001b[36m0.9847\u001b[0m  0.0422\n",
            "      4        \u001b[36m0.9846\u001b[0m  0.0328\n",
            "      5        \u001b[36m0.9846\u001b[0m  0.0330\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9845\u001b[0m  0.0380\n",
            "      7        \u001b[36m0.9845\u001b[0m  0.0335\n",
            "      8        \u001b[36m0.9844\u001b[0m  0.0342\n",
            "      9        \u001b[36m0.9843\u001b[0m  0.0336\n",
            "     10        \u001b[36m0.9843\u001b[0m  0.0349\n",
            "     11        \u001b[36m0.9842\u001b[0m  0.0338\n",
            "     12        \u001b[36m0.9841\u001b[0m  0.0339\n",
            "     13        \u001b[36m0.9841\u001b[0m  0.0341\n",
            "     14        \u001b[36m0.9840\u001b[0m  0.0331\n",
            "     15        \u001b[36m0.9840\u001b[0m  0.0344\n",
            "     16        \u001b[36m0.9839\u001b[0m  0.0350\n",
            "     17        \u001b[36m0.9838\u001b[0m  0.0329\n",
            "     18        \u001b[36m0.9838\u001b[0m  0.0336\n",
            "     19        \u001b[36m0.9837\u001b[0m  0.0331\n",
            "     20        \u001b[36m0.9836\u001b[0m  0.0338\n",
            "     21        \u001b[36m0.9836\u001b[0m  0.0362\n",
            "     22        \u001b[36m0.9835\u001b[0m  0.0334\n",
            "     23        \u001b[36m0.9834\u001b[0m  0.0333\n",
            "     24        \u001b[36m0.9834\u001b[0m  0.0401\n",
            "     25        \u001b[36m0.9833\u001b[0m  0.0478\n",
            "     26        \u001b[36m0.9832\u001b[0m  0.0453\n",
            "     27        \u001b[36m0.9832\u001b[0m  0.0441\n",
            "     28        \u001b[36m0.9831\u001b[0m  0.0503\n",
            "     29        \u001b[36m0.9830\u001b[0m  0.0525\n",
            "     30        \u001b[36m0.9829\u001b[0m  0.0567\n",
            "     31        \u001b[36m0.9829\u001b[0m  0.0491\n",
            "     32        \u001b[36m0.9828\u001b[0m  0.0462\n",
            "     33        \u001b[36m0.9827\u001b[0m  0.0410\n",
            "     34        \u001b[36m0.9826\u001b[0m  0.0398\n",
            "     35        \u001b[36m0.9826\u001b[0m  0.0463\n",
            "     36        \u001b[36m0.9825\u001b[0m  0.0422\n",
            "     37        \u001b[36m0.9824\u001b[0m  0.0442\n",
            "     38        \u001b[36m0.9823\u001b[0m  0.0457\n",
            "     39        \u001b[36m0.9823\u001b[0m  0.0458\n",
            "     40        \u001b[36m0.9822\u001b[0m  0.0464\n",
            "     41        \u001b[36m0.9821\u001b[0m  0.0484\n",
            "     42        \u001b[36m0.9820\u001b[0m  0.0393\n",
            "     43        \u001b[36m0.9820\u001b[0m  0.0392\n",
            "     44        \u001b[36m0.9819\u001b[0m  0.0442\n",
            "     45        \u001b[36m0.9818\u001b[0m  0.0390\n",
            "     46        \u001b[36m0.9817\u001b[0m  0.0392\n",
            "     47        \u001b[36m0.9816\u001b[0m  0.0394\n",
            "     48        \u001b[36m0.9815\u001b[0m  0.0384\n",
            "     49        \u001b[36m0.9815\u001b[0m  0.0459\n",
            "     50        \u001b[36m0.9814\u001b[0m  0.0517\n",
            "     51        \u001b[36m0.9813\u001b[0m  0.0463\n",
            "     52        \u001b[36m0.9812\u001b[0m  0.0414\n",
            "     53        \u001b[36m0.9811\u001b[0m  0.0389\n",
            "     54        \u001b[36m0.9810\u001b[0m  0.0401\n",
            "     55        \u001b[36m0.9809\u001b[0m  0.0459\n",
            "     56        \u001b[36m0.9808\u001b[0m  0.0394\n",
            "     57        \u001b[36m0.9808\u001b[0m  0.0463\n",
            "     58        \u001b[36m0.9807\u001b[0m  0.0420\n",
            "     59        \u001b[36m0.9806\u001b[0m  0.0443\n",
            "     60        \u001b[36m0.9805\u001b[0m  0.0456\n",
            "     61        \u001b[36m0.9804\u001b[0m  0.0468\n",
            "     62        \u001b[36m0.9803\u001b[0m  0.0486\n",
            "     63        \u001b[36m0.9802\u001b[0m  0.0387\n",
            "     64        \u001b[36m0.9801\u001b[0m  0.0496\n",
            "     65        \u001b[36m0.9800\u001b[0m  0.0436\n",
            "     66        \u001b[36m0.9799\u001b[0m  0.0459\n",
            "     67        \u001b[36m0.9798\u001b[0m  0.0462\n",
            "     68        \u001b[36m0.9797\u001b[0m  0.0401\n",
            "     69        \u001b[36m0.9796\u001b[0m  0.0452\n",
            "     70        \u001b[36m0.9795\u001b[0m  0.0447\n",
            "     71        \u001b[36m0.9794\u001b[0m  0.0518\n",
            "     72        \u001b[36m0.9793\u001b[0m  0.0455\n",
            "     73        \u001b[36m0.9792\u001b[0m  0.0475\n",
            "     74        \u001b[36m0.9791\u001b[0m  0.0492\n",
            "     75        \u001b[36m0.9790\u001b[0m  0.0446\n",
            "     76        \u001b[36m0.9789\u001b[0m  0.0457\n",
            "     77        \u001b[36m0.9788\u001b[0m  0.0410\n",
            "     78        \u001b[36m0.9786\u001b[0m  0.0564\n",
            "     79        \u001b[36m0.9785\u001b[0m  0.0425\n",
            "     80        \u001b[36m0.9784\u001b[0m  0.0443\n",
            "     81        \u001b[36m0.9783\u001b[0m  0.0450\n",
            "     82        \u001b[36m0.9782\u001b[0m  0.0453\n",
            "     83        \u001b[36m0.9781\u001b[0m  0.0523\n",
            "     84        \u001b[36m0.9780\u001b[0m  0.0453\n",
            "     85        \u001b[36m0.9778\u001b[0m  0.0439\n",
            "     86        \u001b[36m0.9777\u001b[0m  0.0310\n",
            "     87        \u001b[36m0.9776\u001b[0m  0.0327\n",
            "     88        \u001b[36m0.9775\u001b[0m  0.0330\n",
            "     89        \u001b[36m0.9773\u001b[0m  0.0329\n",
            "     90        \u001b[36m0.9772\u001b[0m  0.0346\n",
            "     91        \u001b[36m0.9771\u001b[0m  0.0399\n",
            "     92        \u001b[36m0.9770\u001b[0m  0.0356\n",
            "     93        \u001b[36m0.9768\u001b[0m  0.0336\n",
            "     94        \u001b[36m0.9767\u001b[0m  0.0331\n",
            "     95        \u001b[36m0.9766\u001b[0m  0.0332\n",
            "     96        \u001b[36m0.9764\u001b[0m  0.0335\n",
            "     97        \u001b[36m0.9763\u001b[0m  0.0325\n",
            "     98        \u001b[36m0.9762\u001b[0m  0.0472\n",
            "     99        \u001b[36m0.9760\u001b[0m  0.0328\n",
            "    100        \u001b[36m0.9759\u001b[0m  0.0319\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9992\u001b[0m  0.0409\n",
            "      2        \u001b[36m0.9987\u001b[0m  0.0434\n",
            "      3        \u001b[36m0.9976\u001b[0m  0.0421\n",
            "      4        \u001b[36m0.9952\u001b[0m  0.0424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9891\u001b[0m  0.0447\n",
            "      6        \u001b[36m0.9719\u001b[0m  0.0465\n",
            "      7        \u001b[36m0.9240\u001b[0m  0.0433\n",
            "      8        \u001b[36m0.8095\u001b[0m  0.0444\n",
            "      9        \u001b[36m0.6081\u001b[0m  0.0442\n",
            "     10        \u001b[36m0.4452\u001b[0m  0.0432\n",
            "     11        \u001b[36m0.4013\u001b[0m  0.0429\n",
            "     12        \u001b[36m0.3922\u001b[0m  0.0454\n",
            "     13        \u001b[36m0.3892\u001b[0m  0.0426\n",
            "     14        \u001b[36m0.3862\u001b[0m  0.0554\n",
            "     15        \u001b[36m0.3806\u001b[0m  0.0440\n",
            "     16        \u001b[36m0.3789\u001b[0m  0.0426\n",
            "     17        \u001b[36m0.3786\u001b[0m  0.0428\n",
            "     18        \u001b[36m0.3783\u001b[0m  0.0424\n",
            "     19        \u001b[36m0.3780\u001b[0m  0.0460\n",
            "     20        \u001b[36m0.3778\u001b[0m  0.0551\n",
            "     21        \u001b[36m0.3776\u001b[0m  0.0427\n",
            "     22        \u001b[36m0.3775\u001b[0m  0.0441\n",
            "     23        \u001b[36m0.3773\u001b[0m  0.0447\n",
            "     24        \u001b[36m0.3771\u001b[0m  0.0423\n",
            "     25        \u001b[36m0.3769\u001b[0m  0.0448\n",
            "     26        \u001b[36m0.3768\u001b[0m  0.0426\n",
            "     27        \u001b[36m0.3766\u001b[0m  0.0429\n",
            "     28        \u001b[36m0.3765\u001b[0m  0.0449\n",
            "     29        \u001b[36m0.3764\u001b[0m  0.0451\n",
            "     30        \u001b[36m0.3763\u001b[0m  0.0452\n",
            "     31        \u001b[36m0.3762\u001b[0m  0.0420\n",
            "     32        \u001b[36m0.3761\u001b[0m  0.0440\n",
            "     33        \u001b[36m0.3760\u001b[0m  0.0429\n",
            "     34        \u001b[36m0.3759\u001b[0m  0.0428\n",
            "     35        \u001b[36m0.3758\u001b[0m  0.0451\n",
            "     36        \u001b[36m0.3757\u001b[0m  0.0517\n",
            "     37        \u001b[36m0.3756\u001b[0m  0.0449\n",
            "     38        \u001b[36m0.3755\u001b[0m  0.0448\n",
            "     39        \u001b[36m0.3755\u001b[0m  0.0473\n",
            "     40        \u001b[36m0.3754\u001b[0m  0.0427\n",
            "     41        \u001b[36m0.3753\u001b[0m  0.0429\n",
            "     42        \u001b[36m0.3753\u001b[0m  0.0520\n",
            "     43        \u001b[36m0.3752\u001b[0m  0.0432\n",
            "     44        \u001b[36m0.3751\u001b[0m  0.0463\n",
            "     45        \u001b[36m0.3751\u001b[0m  0.0435\n",
            "     46        \u001b[36m0.3750\u001b[0m  0.0436\n",
            "     47        \u001b[36m0.3750\u001b[0m  0.0445\n",
            "     48        \u001b[36m0.3749\u001b[0m  0.0437\n",
            "     49        \u001b[36m0.3749\u001b[0m  0.0447\n",
            "     50        \u001b[36m0.3748\u001b[0m  0.0432\n",
            "     51        \u001b[36m0.3748\u001b[0m  0.0435\n",
            "     52        \u001b[36m0.3747\u001b[0m  0.0430\n",
            "     53        \u001b[36m0.3747\u001b[0m  0.0419\n",
            "     54        \u001b[36m0.3747\u001b[0m  0.0445\n",
            "     55        \u001b[36m0.3746\u001b[0m  0.0465\n",
            "     56        \u001b[36m0.3746\u001b[0m  0.0443\n",
            "     57        \u001b[36m0.3746\u001b[0m  0.0576\n",
            "     58        \u001b[36m0.3745\u001b[0m  0.0442\n",
            "     59        \u001b[36m0.3745\u001b[0m  0.0448\n",
            "     60        \u001b[36m0.3745\u001b[0m  0.0443\n",
            "     61        \u001b[36m0.3744\u001b[0m  0.0442\n",
            "     62        \u001b[36m0.3744\u001b[0m  0.0440\n",
            "     63        \u001b[36m0.3744\u001b[0m  0.0475\n",
            "     64        \u001b[36m0.3743\u001b[0m  0.0525\n",
            "     65        \u001b[36m0.3743\u001b[0m  0.0450\n",
            "     66        \u001b[36m0.3743\u001b[0m  0.0459\n",
            "     67        \u001b[36m0.3743\u001b[0m  0.0438\n",
            "     68        \u001b[36m0.3742\u001b[0m  0.0432\n",
            "     69        \u001b[36m0.3742\u001b[0m  0.0449\n",
            "     70        \u001b[36m0.3742\u001b[0m  0.0433\n",
            "     71        \u001b[36m0.3742\u001b[0m  0.0462\n",
            "     72        \u001b[36m0.3742\u001b[0m  0.0441\n",
            "     73        \u001b[36m0.3741\u001b[0m  0.0434\n",
            "     74        \u001b[36m0.3741\u001b[0m  0.0423\n",
            "     75        \u001b[36m0.3741\u001b[0m  0.0414\n",
            "     76        \u001b[36m0.3741\u001b[0m  0.0435\n",
            "     77        \u001b[36m0.3741\u001b[0m  0.0440\n",
            "     78        \u001b[36m0.3740\u001b[0m  0.0500\n",
            "     79        \u001b[36m0.3740\u001b[0m  0.0476\n",
            "     80        \u001b[36m0.3740\u001b[0m  0.0436\n",
            "     81        \u001b[36m0.3740\u001b[0m  0.0433\n",
            "     82        \u001b[36m0.3740\u001b[0m  0.0445\n",
            "     83        \u001b[36m0.3740\u001b[0m  0.0438\n",
            "     84        \u001b[36m0.3739\u001b[0m  0.0452\n",
            "     85        \u001b[36m0.3739\u001b[0m  0.0445\n",
            "     86        \u001b[36m0.3739\u001b[0m  0.0543\n",
            "     87        \u001b[36m0.3739\u001b[0m  0.0486\n",
            "     88        \u001b[36m0.3739\u001b[0m  0.0497\n",
            "     89        \u001b[36m0.3739\u001b[0m  0.0501\n",
            "     90        \u001b[36m0.3739\u001b[0m  0.0429\n",
            "     91        \u001b[36m0.3739\u001b[0m  0.0433\n",
            "     92        \u001b[36m0.3738\u001b[0m  0.0439\n",
            "     93        \u001b[36m0.3738\u001b[0m  0.0458\n",
            "     94        \u001b[36m0.3738\u001b[0m  0.0430\n",
            "     95        \u001b[36m0.3738\u001b[0m  0.0426\n",
            "     96        \u001b[36m0.3738\u001b[0m  0.0421\n",
            "     97        \u001b[36m0.3738\u001b[0m  0.0440\n",
            "     98        \u001b[36m0.3738\u001b[0m  0.0438\n",
            "     99        \u001b[36m0.3738\u001b[0m  0.0478\n",
            "    100        \u001b[36m0.3738\u001b[0m  0.0509\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0407\n",
            "      2        \u001b[36m0.9998\u001b[0m  0.0450\n",
            "      3        \u001b[36m0.9996\u001b[0m  0.0417\n",
            "      4        \u001b[36m0.9991\u001b[0m  0.0432\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.9979\u001b[0m  0.0468\n",
            "      6        \u001b[36m0.9943\u001b[0m  0.0443\n",
            "      7        \u001b[36m0.9828\u001b[0m  0.0427\n",
            "      8        \u001b[36m0.9450\u001b[0m  0.0558\n",
            "      9        \u001b[36m0.8389\u001b[0m  0.0428\n",
            "     10        \u001b[36m0.6482\u001b[0m  0.0431\n",
            "     11        \u001b[36m0.4896\u001b[0m  0.0426\n",
            "     12        \u001b[36m0.4276\u001b[0m  0.0431\n",
            "     13        \u001b[36m0.4054\u001b[0m  0.0445\n",
            "     14        \u001b[36m0.3943\u001b[0m  0.0435\n",
            "     15        \u001b[36m0.3907\u001b[0m  0.0425\n",
            "     16        \u001b[36m0.3882\u001b[0m  0.0442\n",
            "     17        \u001b[36m0.3864\u001b[0m  0.0423\n",
            "     18        \u001b[36m0.3848\u001b[0m  0.0426\n",
            "     19        \u001b[36m0.3836\u001b[0m  0.0443\n",
            "     20        \u001b[36m0.3825\u001b[0m  0.0438\n",
            "     21        \u001b[36m0.3816\u001b[0m  0.0544\n",
            "     22        \u001b[36m0.3808\u001b[0m  0.0454\n",
            "     23        \u001b[36m0.3801\u001b[0m  0.0441\n",
            "     24        \u001b[36m0.3795\u001b[0m  0.0442\n",
            "     25        \u001b[36m0.3789\u001b[0m  0.0459\n",
            "     26        \u001b[36m0.3777\u001b[0m  0.0440\n",
            "     27        \u001b[36m0.3760\u001b[0m  0.0449\n",
            "     28        \u001b[36m0.3757\u001b[0m  0.0449\n",
            "     29        \u001b[36m0.3751\u001b[0m  0.0453\n",
            "     30        \u001b[36m0.3745\u001b[0m  0.0555\n",
            "     31        \u001b[36m0.3744\u001b[0m  0.0487\n",
            "     32        \u001b[36m0.3743\u001b[0m  0.0483\n",
            "     33        \u001b[36m0.3742\u001b[0m  0.0434\n",
            "     34        \u001b[36m0.3742\u001b[0m  0.0427\n",
            "     35        \u001b[36m0.3741\u001b[0m  0.0434\n",
            "     36        \u001b[36m0.3740\u001b[0m  0.0428\n",
            "     37        \u001b[36m0.3740\u001b[0m  0.0434\n",
            "     38        \u001b[36m0.3739\u001b[0m  0.0450\n",
            "     39        \u001b[36m0.3739\u001b[0m  0.0430\n",
            "     40        \u001b[36m0.3738\u001b[0m  0.0424\n",
            "     41        \u001b[36m0.3738\u001b[0m  0.0444\n",
            "     42        \u001b[36m0.3737\u001b[0m  0.0527\n",
            "     43        \u001b[36m0.3737\u001b[0m  0.0523\n",
            "     44        \u001b[36m0.3736\u001b[0m  0.0457\n",
            "     45        \u001b[36m0.3736\u001b[0m  0.0440\n",
            "     46        \u001b[36m0.3736\u001b[0m  0.0421\n",
            "     47        \u001b[36m0.3735\u001b[0m  0.0441\n",
            "     48        \u001b[36m0.3735\u001b[0m  0.0432\n",
            "     49        \u001b[36m0.3734\u001b[0m  0.0461\n",
            "     50        \u001b[36m0.3734\u001b[0m  0.0442\n",
            "     51        \u001b[36m0.3734\u001b[0m  0.0434\n",
            "     52        \u001b[36m0.3733\u001b[0m  0.0535\n",
            "     53        \u001b[36m0.3733\u001b[0m  0.0450\n",
            "     54        \u001b[36m0.3733\u001b[0m  0.0429\n",
            "     55        \u001b[36m0.3732\u001b[0m  0.0429\n",
            "     56        \u001b[36m0.3732\u001b[0m  0.0430\n",
            "     57        \u001b[36m0.3732\u001b[0m  0.0431\n",
            "     58        \u001b[36m0.3732\u001b[0m  0.0431\n",
            "     59        \u001b[36m0.3731\u001b[0m  0.0445\n",
            "     60        \u001b[36m0.3731\u001b[0m  0.0428\n",
            "     61        \u001b[36m0.3731\u001b[0m  0.0430\n",
            "     62        \u001b[36m0.3730\u001b[0m  0.0446\n",
            "     63        \u001b[36m0.3730\u001b[0m  0.0435\n",
            "     64        \u001b[36m0.3730\u001b[0m  0.0549\n",
            "     65        \u001b[36m0.3730\u001b[0m  0.0441\n",
            "     66        \u001b[36m0.3730\u001b[0m  0.0450\n",
            "     67        \u001b[36m0.3729\u001b[0m  0.0441\n",
            "     68        \u001b[36m0.3729\u001b[0m  0.0440\n",
            "     69        \u001b[36m0.3729\u001b[0m  0.0426\n",
            "     70        \u001b[36m0.3729\u001b[0m  0.0432\n",
            "     71        \u001b[36m0.3728\u001b[0m  0.0466\n",
            "     72        \u001b[36m0.3728\u001b[0m  0.0438\n",
            "     73        \u001b[36m0.3728\u001b[0m  0.0463\n",
            "     74        \u001b[36m0.3728\u001b[0m  0.0550\n",
            "     75        \u001b[36m0.3728\u001b[0m  0.0442\n",
            "     76        \u001b[36m0.3728\u001b[0m  0.0440\n",
            "     77        \u001b[36m0.3727\u001b[0m  0.0473\n",
            "     78        \u001b[36m0.3727\u001b[0m  0.0431\n",
            "     79        \u001b[36m0.3727\u001b[0m  0.0455\n",
            "     80        \u001b[36m0.3727\u001b[0m  0.0409\n",
            "     81        \u001b[36m0.3727\u001b[0m  0.0416\n",
            "     82        \u001b[36m0.3727\u001b[0m  0.0424\n",
            "     83        \u001b[36m0.3727\u001b[0m  0.0431\n",
            "     84        \u001b[36m0.3726\u001b[0m  0.0421\n",
            "     85        \u001b[36m0.3726\u001b[0m  0.0491\n",
            "     86        \u001b[36m0.3726\u001b[0m  0.0505\n",
            "     87        \u001b[36m0.3726\u001b[0m  0.0437\n",
            "     88        \u001b[36m0.3726\u001b[0m  0.0459\n",
            "     89        \u001b[36m0.3726\u001b[0m  0.0443\n",
            "     90        \u001b[36m0.3726\u001b[0m  0.0439\n",
            "     91        \u001b[36m0.3726\u001b[0m  0.0430\n",
            "     92        \u001b[36m0.3725\u001b[0m  0.0468\n",
            "     93        \u001b[36m0.3725\u001b[0m  0.0450\n",
            "     94        \u001b[36m0.3725\u001b[0m  0.0429\n",
            "     95        \u001b[36m0.3725\u001b[0m  0.0448\n",
            "     96        \u001b[36m0.3725\u001b[0m  0.0527\n",
            "     97        \u001b[36m0.3725\u001b[0m  0.0451\n",
            "     98        \u001b[36m0.3725\u001b[0m  0.0471\n",
            "     99        \u001b[36m0.3725\u001b[0m  0.0456\n",
            "    100        \u001b[36m0.3725\u001b[0m  0.0450\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9998\u001b[0m  0.0303\n",
            "      2        \u001b[36m0.9998\u001b[0m  0.0329\n",
            "      3        \u001b[36m0.9998\u001b[0m  0.0336\n",
            "      4        0.9998  0.0454\n",
            "      5        0.9998  0.0436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9998\u001b[0m  0.0461\n",
            "      7        \u001b[36m0.9998\u001b[0m  0.0515\n",
            "      8        0.9998  0.0496\n",
            "      9        \u001b[36m0.9998\u001b[0m  0.0415\n",
            "     10        \u001b[36m0.9998\u001b[0m  0.0483\n",
            "     11        0.9998  0.0475\n",
            "     12        0.9998  0.0409\n",
            "     13        \u001b[36m0.9998\u001b[0m  0.0441\n",
            "     14        \u001b[36m0.9998\u001b[0m  0.0425\n",
            "     15        0.9998  0.0410\n",
            "     16        \u001b[36m0.9998\u001b[0m  0.0464\n",
            "     17        \u001b[36m0.9998\u001b[0m  0.0397\n",
            "     18        0.9998  0.0468\n",
            "     19        0.9998  0.0505\n",
            "     20        \u001b[36m0.9998\u001b[0m  0.0513\n",
            "     21        0.9998  0.0427\n",
            "     22        0.9998  0.0418\n",
            "     23        \u001b[36m0.9998\u001b[0m  0.0421\n",
            "     24        \u001b[36m0.9998\u001b[0m  0.0416\n",
            "     25        0.9998  0.0419\n",
            "     26        \u001b[36m0.9998\u001b[0m  0.0414\n",
            "     27        \u001b[36m0.9998\u001b[0m  0.0421\n",
            "     28        0.9998  0.0472\n",
            "     29        0.9998  0.0455\n",
            "     30        \u001b[36m0.9998\u001b[0m  0.0446\n",
            "     31        \u001b[36m0.9998\u001b[0m  0.0439\n",
            "     32        0.9998  0.0394\n",
            "     33        \u001b[36m0.9998\u001b[0m  0.0407\n",
            "     34        \u001b[36m0.9998\u001b[0m  0.0407\n",
            "     35        0.9998  0.0422\n",
            "     36        0.9998  0.0404\n",
            "     37        \u001b[36m0.9998\u001b[0m  0.0418\n",
            "     38        \u001b[36m0.9998\u001b[0m  0.0425\n",
            "     39        0.9998  0.0396\n",
            "     40        \u001b[36m0.9998\u001b[0m  0.0404\n",
            "     41        \u001b[36m0.9998\u001b[0m  0.0528\n",
            "     42        0.9998  0.0494\n",
            "     43        0.9998  0.0473\n",
            "     44        \u001b[36m0.9998\u001b[0m  0.0526\n",
            "     45        0.9998  0.0406\n",
            "     46        0.9998  0.0486\n",
            "     47        \u001b[36m0.9998\u001b[0m  0.0394\n",
            "     48        \u001b[36m0.9998\u001b[0m  0.0418\n",
            "     49        0.9998  0.0484\n",
            "     50        \u001b[36m0.9998\u001b[0m  0.0528\n",
            "     51        \u001b[36m0.9998\u001b[0m  0.0470\n",
            "     52        0.9998  0.0440\n",
            "     53        0.9998  0.0427\n",
            "     54        \u001b[36m0.9998\u001b[0m  0.0484\n",
            "     55        \u001b[36m0.9998\u001b[0m  0.0464\n",
            "     56        0.9998  0.0529\n",
            "     57        \u001b[36m0.9998\u001b[0m  0.0451\n",
            "     58        \u001b[36m0.9998\u001b[0m  0.0458\n",
            "     59        0.9998  0.0547\n",
            "     60        \u001b[36m0.9998\u001b[0m  0.0444\n",
            "     61        \u001b[36m0.9998\u001b[0m  0.0436\n",
            "     62        0.9998  0.0581\n",
            "     63        0.9998  0.0483\n",
            "     64        \u001b[36m0.9998\u001b[0m  0.0439\n",
            "     65        \u001b[36m0.9998\u001b[0m  0.0461\n",
            "     66        0.9998  0.0444\n",
            "     67        \u001b[36m0.9998\u001b[0m  0.0523\n",
            "     68        \u001b[36m0.9998\u001b[0m  0.0440\n",
            "     69        0.9998  0.0628\n",
            "     70        0.9998  0.0453\n",
            "     71        \u001b[36m0.9998\u001b[0m  0.0476\n",
            "     72        0.9998  0.0477\n",
            "     73        0.9998  0.0468\n",
            "     74        \u001b[36m0.9998\u001b[0m  0.0552\n",
            "     75        \u001b[36m0.9998\u001b[0m  0.0403\n",
            "     76        0.9998  0.0373\n",
            "     77        \u001b[36m0.9998\u001b[0m  0.0369\n",
            "     78        \u001b[36m0.9998\u001b[0m  0.0356\n",
            "     79        0.9998  0.0351\n",
            "     80        0.9998  0.0344\n",
            "     81        \u001b[36m0.9998\u001b[0m  0.0355\n",
            "     82        \u001b[36m0.9998\u001b[0m  0.0337\n",
            "     83        0.9998  0.0340\n",
            "     84        \u001b[36m0.9998\u001b[0m  0.0354\n",
            "     85        \u001b[36m0.9998\u001b[0m  0.0403\n",
            "     86        0.9998  0.0386\n",
            "     87        0.9998  0.0351\n",
            "     88        \u001b[36m0.9998\u001b[0m  0.0329\n",
            "     89        0.9998  0.0342\n",
            "     90        0.9998  0.0334\n",
            "     91        \u001b[36m0.9998\u001b[0m  0.0334\n",
            "     92        \u001b[36m0.9998\u001b[0m  0.0346\n",
            "     93        0.9998  0.0423\n",
            "     94        \u001b[36m0.9998\u001b[0m  0.0406\n",
            "     95        \u001b[36m0.9998\u001b[0m  0.0336\n",
            "     96        0.9998  0.0336\n",
            "     97        0.9998  0.0343\n",
            "     98        \u001b[36m0.9998\u001b[0m  0.0345\n",
            "     99        \u001b[36m0.9998\u001b[0m  0.0361\n",
            "    100        0.9998  0.0390\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9993\u001b[0m  0.0321\n",
            "      2        \u001b[36m0.9993\u001b[0m  0.0357\n",
            "      3        \u001b[36m0.9993\u001b[0m  0.0321\n",
            "      4        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "      5        \u001b[36m0.9993\u001b[0m  0.0346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.9993\u001b[0m  0.0374\n",
            "      7        \u001b[36m0.9993\u001b[0m  0.0348\n",
            "      8        \u001b[36m0.9993\u001b[0m  0.0354\n",
            "      9        \u001b[36m0.9993\u001b[0m  0.0338\n",
            "     10        \u001b[36m0.9993\u001b[0m  0.0340\n",
            "     11        \u001b[36m0.9993\u001b[0m  0.0363\n",
            "     12        \u001b[36m0.9993\u001b[0m  0.0369\n",
            "     13        \u001b[36m0.9993\u001b[0m  0.0400\n",
            "     14        \u001b[36m0.9993\u001b[0m  0.0325\n",
            "     15        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     16        \u001b[36m0.9993\u001b[0m  0.0338\n",
            "     17        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     18        \u001b[36m0.9993\u001b[0m  0.0361\n",
            "     19        \u001b[36m0.9993\u001b[0m  0.0392\n",
            "     20        \u001b[36m0.9993\u001b[0m  0.0402\n",
            "     21        \u001b[36m0.9993\u001b[0m  0.0345\n",
            "     22        \u001b[36m0.9993\u001b[0m  0.0362\n",
            "     23        \u001b[36m0.9993\u001b[0m  0.0350\n",
            "     24        \u001b[36m0.9993\u001b[0m  0.0336\n",
            "     25        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     26        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     27        \u001b[36m0.9993\u001b[0m  0.0338\n",
            "     28        \u001b[36m0.9993\u001b[0m  0.0337\n",
            "     29        \u001b[36m0.9993\u001b[0m  0.0386\n",
            "     30        \u001b[36m0.9993\u001b[0m  0.0331\n",
            "     31        \u001b[36m0.9993\u001b[0m  0.0362\n",
            "     32        \u001b[36m0.9993\u001b[0m  0.0346\n",
            "     33        \u001b[36m0.9993\u001b[0m  0.0352\n",
            "     34        \u001b[36m0.9993\u001b[0m  0.0336\n",
            "     35        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     36        \u001b[36m0.9993\u001b[0m  0.0337\n",
            "     37        \u001b[36m0.9993\u001b[0m  0.0347\n",
            "     38        \u001b[36m0.9993\u001b[0m  0.0354\n",
            "     39        \u001b[36m0.9993\u001b[0m  0.0349\n",
            "     40        \u001b[36m0.9993\u001b[0m  0.0345\n",
            "     41        \u001b[36m0.9993\u001b[0m  0.0449\n",
            "     42        \u001b[36m0.9993\u001b[0m  0.0334\n",
            "     43        \u001b[36m0.9993\u001b[0m  0.0328\n",
            "     44        \u001b[36m0.9993\u001b[0m  0.0322\n",
            "     45        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "     46        \u001b[36m0.9993\u001b[0m  0.0350\n",
            "     47        \u001b[36m0.9993\u001b[0m  0.0421\n",
            "     48        \u001b[36m0.9993\u001b[0m  0.0366\n",
            "     49        \u001b[36m0.9993\u001b[0m  0.0336\n",
            "     50        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "     51        \u001b[36m0.9993\u001b[0m  0.0334\n",
            "     52        \u001b[36m0.9993\u001b[0m  0.0348\n",
            "     53        \u001b[36m0.9993\u001b[0m  0.0339\n",
            "     54        \u001b[36m0.9993\u001b[0m  0.0347\n",
            "     55        \u001b[36m0.9993\u001b[0m  0.0361\n",
            "     56        \u001b[36m0.9993\u001b[0m  0.0337\n",
            "     57        \u001b[36m0.9993\u001b[0m  0.0355\n",
            "     58        \u001b[36m0.9993\u001b[0m  0.0346\n",
            "     59        \u001b[36m0.9993\u001b[0m  0.0374\n",
            "     60        \u001b[36m0.9993\u001b[0m  0.0345\n",
            "     61        \u001b[36m0.9993\u001b[0m  0.0336\n",
            "     62        \u001b[36m0.9993\u001b[0m  0.0332\n",
            "     63        \u001b[36m0.9993\u001b[0m  0.0327\n",
            "     64        \u001b[36m0.9993\u001b[0m  0.0337\n",
            "     65        \u001b[36m0.9993\u001b[0m  0.0329\n",
            "     66        \u001b[36m0.9993\u001b[0m  0.0381\n",
            "     67        \u001b[36m0.9993\u001b[0m  0.0334\n",
            "     68        \u001b[36m0.9993\u001b[0m  0.0334\n",
            "     69        \u001b[36m0.9993\u001b[0m  0.0426\n",
            "     70        \u001b[36m0.9993\u001b[0m  0.0322\n",
            "     71        \u001b[36m0.9993\u001b[0m  0.0328\n",
            "     72        \u001b[36m0.9993\u001b[0m  0.0341\n",
            "     73        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     74        \u001b[36m0.9993\u001b[0m  0.0399\n",
            "     75        \u001b[36m0.9993\u001b[0m  0.0365\n",
            "     76        \u001b[36m0.9993\u001b[0m  0.0333\n",
            "     77        \u001b[36m0.9993\u001b[0m  0.0349\n",
            "     78        \u001b[36m0.9993\u001b[0m  0.0336\n",
            "     79        \u001b[36m0.9993\u001b[0m  0.0329\n",
            "     80        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "     81        \u001b[36m0.9993\u001b[0m  0.0357\n",
            "     82        \u001b[36m0.9993\u001b[0m  0.0325\n",
            "     83        \u001b[36m0.9993\u001b[0m  0.0333\n",
            "     84        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "     85        \u001b[36m0.9993\u001b[0m  0.0342\n",
            "     86        \u001b[36m0.9993\u001b[0m  0.0350\n",
            "     87        \u001b[36m0.9993\u001b[0m  0.0352\n",
            "     88        \u001b[36m0.9993\u001b[0m  0.0328\n",
            "     89        \u001b[36m0.9993\u001b[0m  0.0347\n",
            "     90        \u001b[36m0.9993\u001b[0m  0.0360\n",
            "     91        \u001b[36m0.9993\u001b[0m  0.0338\n",
            "     92        \u001b[36m0.9993\u001b[0m  0.0344\n",
            "     93        \u001b[36m0.9993\u001b[0m  0.0366\n",
            "     94        \u001b[36m0.9993\u001b[0m  0.0359\n",
            "     95        \u001b[36m0.9993\u001b[0m  0.0344\n",
            "     96        \u001b[36m0.9993\u001b[0m  0.0332\n",
            "     97        \u001b[36m0.9993\u001b[0m  0.0386\n",
            "     98        \u001b[36m0.9993\u001b[0m  0.0335\n",
            "     99        \u001b[36m0.9993\u001b[0m  0.0339\n",
            "    100        \u001b[36m0.9993\u001b[0m  0.0363\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8880\u001b[0m  0.0508\n",
            "      2        \u001b[36m0.8037\u001b[0m  0.0461\n",
            "      3        \u001b[36m0.6956\u001b[0m  0.0462\n",
            "      4        \u001b[36m0.6271\u001b[0m  0.0452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.5937\u001b[0m  0.0473\n",
            "      6        \u001b[36m0.5761\u001b[0m  0.0433\n",
            "      7        \u001b[36m0.5596\u001b[0m  0.0423\n",
            "      8        \u001b[36m0.5416\u001b[0m  0.0448\n",
            "      9        \u001b[36m0.5348\u001b[0m  0.0455\n",
            "     10        \u001b[36m0.5296\u001b[0m  0.0444\n",
            "     11        \u001b[36m0.5237\u001b[0m  0.0454\n",
            "     12        \u001b[36m0.5169\u001b[0m  0.0433\n",
            "     13        \u001b[36m0.5096\u001b[0m  0.0438\n",
            "     14        \u001b[36m0.5070\u001b[0m  0.0489\n",
            "     15        \u001b[36m0.5048\u001b[0m  0.0514\n",
            "     16        \u001b[36m0.5029\u001b[0m  0.0464\n",
            "     17        \u001b[36m0.5013\u001b[0m  0.0435\n",
            "     18        \u001b[36m0.4998\u001b[0m  0.0441\n",
            "     19        \u001b[36m0.4981\u001b[0m  0.0526\n",
            "     20        \u001b[36m0.4969\u001b[0m  0.0446\n",
            "     21        \u001b[36m0.4957\u001b[0m  0.0461\n",
            "     22        \u001b[36m0.4946\u001b[0m  0.0588\n",
            "     23        \u001b[36m0.4934\u001b[0m  0.0459\n",
            "     24        \u001b[36m0.4893\u001b[0m  0.0468\n",
            "     25        \u001b[36m0.4878\u001b[0m  0.0446\n",
            "     26        \u001b[36m0.4861\u001b[0m  0.0458\n",
            "     27        \u001b[36m0.4839\u001b[0m  0.0462\n",
            "     28        \u001b[36m0.4808\u001b[0m  0.0442\n",
            "     29        \u001b[36m0.4758\u001b[0m  0.0462\n",
            "     30        \u001b[36m0.4673\u001b[0m  0.0472\n",
            "     31        \u001b[36m0.4573\u001b[0m  0.0433\n",
            "     32        \u001b[36m0.4498\u001b[0m  0.0455\n",
            "     33        \u001b[36m0.4405\u001b[0m  0.0433\n",
            "     34        \u001b[36m0.4328\u001b[0m  0.0434\n",
            "     35        \u001b[36m0.4306\u001b[0m  0.0465\n",
            "     36        \u001b[36m0.4288\u001b[0m  0.0446\n",
            "     37        \u001b[36m0.4272\u001b[0m  0.0459\n",
            "     38        \u001b[36m0.4259\u001b[0m  0.0435\n",
            "     39        \u001b[36m0.4246\u001b[0m  0.0429\n",
            "     40        \u001b[36m0.4234\u001b[0m  0.0433\n",
            "     41        0.4237  0.0532\n",
            "     42        0.4238  0.0440\n",
            "     43        \u001b[36m0.4223\u001b[0m  0.0548\n",
            "     44        \u001b[36m0.4207\u001b[0m  0.0442\n",
            "     45        \u001b[36m0.4202\u001b[0m  0.0443\n",
            "     46        \u001b[36m0.4184\u001b[0m  0.0449\n",
            "     47        \u001b[36m0.4166\u001b[0m  0.0467\n",
            "     48        \u001b[36m0.4147\u001b[0m  0.0455\n",
            "     49        \u001b[36m0.4115\u001b[0m  0.0436\n",
            "     50        \u001b[36m0.4096\u001b[0m  0.0434\n",
            "     51        \u001b[36m0.4076\u001b[0m  0.0465\n",
            "     52        \u001b[36m0.4055\u001b[0m  0.0448\n",
            "     53        \u001b[36m0.4034\u001b[0m  0.0474\n",
            "     54        \u001b[36m0.4018\u001b[0m  0.0428\n",
            "     55        \u001b[36m0.3998\u001b[0m  0.0440\n",
            "     56        \u001b[36m0.3981\u001b[0m  0.0436\n",
            "     57        \u001b[36m0.3965\u001b[0m  0.0423\n",
            "     58        \u001b[36m0.3951\u001b[0m  0.0440\n",
            "     59        \u001b[36m0.3940\u001b[0m  0.0438\n",
            "     60        \u001b[36m0.3928\u001b[0m  0.0444\n",
            "     61        \u001b[36m0.3916\u001b[0m  0.0429\n",
            "     62        \u001b[36m0.3889\u001b[0m  0.0428\n",
            "     63        \u001b[36m0.3878\u001b[0m  0.0527\n",
            "     64        \u001b[36m0.3869\u001b[0m  0.0520\n",
            "     65        \u001b[36m0.3863\u001b[0m  0.0442\n",
            "     66        \u001b[36m0.3858\u001b[0m  0.0449\n",
            "     67        \u001b[36m0.3853\u001b[0m  0.0437\n",
            "     68        \u001b[36m0.3848\u001b[0m  0.0434\n",
            "     69        \u001b[36m0.3844\u001b[0m  0.0435\n",
            "     70        \u001b[36m0.3839\u001b[0m  0.0425\n",
            "     71        \u001b[36m0.3835\u001b[0m  0.0435\n",
            "     72        \u001b[36m0.3834\u001b[0m  0.0449\n",
            "     73        \u001b[36m0.3832\u001b[0m  0.0456\n",
            "     74        \u001b[36m0.3827\u001b[0m  0.0425\n",
            "     75        \u001b[36m0.3822\u001b[0m  0.0439\n",
            "     76        \u001b[36m0.3818\u001b[0m  0.0420\n",
            "     77        \u001b[36m0.3815\u001b[0m  0.0432\n",
            "     78        \u001b[36m0.3811\u001b[0m  0.0532\n",
            "     79        \u001b[36m0.3808\u001b[0m  0.0541\n",
            "     80        \u001b[36m0.3805\u001b[0m  0.0448\n",
            "     81        \u001b[36m0.3802\u001b[0m  0.0434\n",
            "     82        \u001b[36m0.3799\u001b[0m  0.0438\n",
            "     83        \u001b[36m0.3797\u001b[0m  0.0428\n",
            "     84        \u001b[36m0.3795\u001b[0m  0.0420\n",
            "     85        \u001b[36m0.3792\u001b[0m  0.0588\n",
            "     86        \u001b[36m0.3790\u001b[0m  0.0512\n",
            "     87        \u001b[36m0.3788\u001b[0m  0.0457\n",
            "     88        \u001b[36m0.3786\u001b[0m  0.0421\n",
            "     89        \u001b[36m0.3785\u001b[0m  0.0428\n",
            "     90        \u001b[36m0.3783\u001b[0m  0.0425\n",
            "     91        \u001b[36m0.3781\u001b[0m  0.0432\n",
            "     92        \u001b[36m0.3780\u001b[0m  0.0445\n",
            "     93        \u001b[36m0.3778\u001b[0m  0.0460\n",
            "     94        \u001b[36m0.3777\u001b[0m  0.0450\n",
            "     95        \u001b[36m0.3775\u001b[0m  0.0432\n",
            "     96        \u001b[36m0.3774\u001b[0m  0.0476\n",
            "     97        \u001b[36m0.3772\u001b[0m  0.0450\n",
            "     98        \u001b[36m0.3772\u001b[0m  0.0438\n",
            "     99        0.3772  0.0442\n",
            "    100        \u001b[36m0.3771\u001b[0m  0.0441\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5466\u001b[0m  0.0412\n",
            "      2        \u001b[36m0.5328\u001b[0m  0.0448\n",
            "      3        \u001b[36m0.5161\u001b[0m  0.0423\n",
            "      4        \u001b[36m0.5086\u001b[0m  0.0442\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.5031\u001b[0m  0.0468\n",
            "      6        \u001b[36m0.4989\u001b[0m  0.0499\n",
            "      7        \u001b[36m0.4946\u001b[0m  0.0554\n",
            "      8        \u001b[36m0.4914\u001b[0m  0.0446\n",
            "      9        \u001b[36m0.4871\u001b[0m  0.0419\n",
            "     10        \u001b[36m0.4827\u001b[0m  0.0424\n",
            "     11        \u001b[36m0.4783\u001b[0m  0.0439\n",
            "     12        \u001b[36m0.4753\u001b[0m  0.0415\n",
            "     13        \u001b[36m0.4720\u001b[0m  0.0438\n",
            "     14        \u001b[36m0.4686\u001b[0m  0.0548\n",
            "     15        \u001b[36m0.4655\u001b[0m  0.0590\n",
            "     16        \u001b[36m0.4627\u001b[0m  0.0636\n",
            "     17        \u001b[36m0.4601\u001b[0m  0.0575\n",
            "     18        \u001b[36m0.4576\u001b[0m  0.0564\n",
            "     19        \u001b[36m0.4550\u001b[0m  0.0590\n",
            "     20        \u001b[36m0.4512\u001b[0m  0.0585\n",
            "     21        \u001b[36m0.4480\u001b[0m  0.0583\n",
            "     22        \u001b[36m0.4439\u001b[0m  0.0585\n",
            "     23        \u001b[36m0.4398\u001b[0m  0.0567\n",
            "     24        \u001b[36m0.4344\u001b[0m  0.0524\n",
            "     25        \u001b[36m0.4319\u001b[0m  0.0691\n",
            "     26        \u001b[36m0.4305\u001b[0m  0.0646\n",
            "     27        \u001b[36m0.4295\u001b[0m  0.0581\n",
            "     28        \u001b[36m0.4287\u001b[0m  0.0516\n",
            "     29        \u001b[36m0.4276\u001b[0m  0.0523\n",
            "     30        \u001b[36m0.4269\u001b[0m  0.0560\n",
            "     31        \u001b[36m0.4262\u001b[0m  0.0559\n",
            "     32        \u001b[36m0.4256\u001b[0m  0.0523\n",
            "     33        \u001b[36m0.4256\u001b[0m  0.0595\n",
            "     34        \u001b[36m0.4249\u001b[0m  0.0508\n",
            "     35        \u001b[36m0.4244\u001b[0m  0.0517\n",
            "     36        \u001b[36m0.4239\u001b[0m  0.0507\n",
            "     37        \u001b[36m0.4234\u001b[0m  0.0519\n",
            "     38        \u001b[36m0.4229\u001b[0m  0.0511\n",
            "     39        \u001b[36m0.4223\u001b[0m  0.0553\n",
            "     40        \u001b[36m0.4217\u001b[0m  0.0524\n",
            "     41        \u001b[36m0.4208\u001b[0m  0.0600\n",
            "     42        \u001b[36m0.4196\u001b[0m  0.0655\n",
            "     43        \u001b[36m0.4175\u001b[0m  0.0612\n",
            "     44        \u001b[36m0.4128\u001b[0m  0.0598\n",
            "     45        \u001b[36m0.4004\u001b[0m  0.0552\n",
            "     46        \u001b[36m0.3853\u001b[0m  0.0517\n",
            "     47        \u001b[36m0.3800\u001b[0m  0.0573\n",
            "     48        \u001b[36m0.3784\u001b[0m  0.0622\n",
            "     49        \u001b[36m0.3776\u001b[0m  0.0609\n",
            "     50        \u001b[36m0.3771\u001b[0m  0.0598\n",
            "     51        \u001b[36m0.3768\u001b[0m  0.0619\n",
            "     52        \u001b[36m0.3765\u001b[0m  0.0619\n",
            "     53        \u001b[36m0.3762\u001b[0m  0.0599\n",
            "     54        \u001b[36m0.3760\u001b[0m  0.0607\n",
            "     55        0.3762  0.0575\n",
            "     56        \u001b[36m0.3757\u001b[0m  0.0573\n",
            "     57        \u001b[36m0.3755\u001b[0m  0.0582\n",
            "     58        \u001b[36m0.3754\u001b[0m  0.0582\n",
            "     59        \u001b[36m0.3752\u001b[0m  0.0711\n",
            "     60        \u001b[36m0.3751\u001b[0m  0.0679\n",
            "     61        \u001b[36m0.3750\u001b[0m  0.0587\n",
            "     62        \u001b[36m0.3749\u001b[0m  0.0586\n",
            "     63        \u001b[36m0.3744\u001b[0m  0.0576\n",
            "     64        \u001b[36m0.3743\u001b[0m  0.0603\n",
            "     65        \u001b[36m0.3743\u001b[0m  0.0584\n",
            "     66        \u001b[36m0.3742\u001b[0m  0.0674\n",
            "     67        \u001b[36m0.3741\u001b[0m  0.0638\n",
            "     68        \u001b[36m0.3740\u001b[0m  0.0532\n",
            "     69        \u001b[36m0.3740\u001b[0m  0.0439\n",
            "     70        \u001b[36m0.3739\u001b[0m  0.0444\n",
            "     71        \u001b[36m0.3739\u001b[0m  0.0442\n",
            "     72        \u001b[36m0.3738\u001b[0m  0.0429\n",
            "     73        \u001b[36m0.3738\u001b[0m  0.0435\n",
            "     74        \u001b[36m0.3737\u001b[0m  0.0446\n",
            "     75        \u001b[36m0.3737\u001b[0m  0.0515\n",
            "     76        0.3740  0.0440\n",
            "     77        \u001b[36m0.3736\u001b[0m  0.0436\n",
            "     78        0.3736  0.0438\n",
            "     79        \u001b[36m0.3735\u001b[0m  0.0538\n",
            "     80        \u001b[36m0.3735\u001b[0m  0.0438\n",
            "     81        \u001b[36m0.3735\u001b[0m  0.0463\n",
            "     82        \u001b[36m0.3734\u001b[0m  0.0447\n",
            "     83        \u001b[36m0.3734\u001b[0m  0.0447\n",
            "     84        \u001b[36m0.3734\u001b[0m  0.0477\n",
            "     85        \u001b[36m0.3733\u001b[0m  0.0449\n",
            "     86        \u001b[36m0.3733\u001b[0m  0.0434\n",
            "     87        \u001b[36m0.3733\u001b[0m  0.0447\n",
            "     88        \u001b[36m0.3732\u001b[0m  0.0438\n",
            "     89        \u001b[36m0.3732\u001b[0m  0.0450\n",
            "     90        \u001b[36m0.3732\u001b[0m  0.0456\n",
            "     91        0.3732  0.0452\n",
            "     92        0.3732  0.0435\n",
            "     93        \u001b[36m0.3731\u001b[0m  0.0445\n",
            "     94        \u001b[36m0.3731\u001b[0m  0.0426\n",
            "     95        \u001b[36m0.3730\u001b[0m  0.0425\n",
            "     96        \u001b[36m0.3730\u001b[0m  0.0496\n",
            "     97        \u001b[36m0.3730\u001b[0m  0.0473\n",
            "     98        \u001b[36m0.3729\u001b[0m  0.0446\n",
            "     99        \u001b[36m0.3729\u001b[0m  0.0472\n",
            "    100        0.3733  0.0452\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6412\u001b[0m  0.0341\n",
            "      2        \u001b[36m0.6391\u001b[0m  0.0345\n",
            "      3        \u001b[36m0.6370\u001b[0m  0.0347\n",
            "      4        \u001b[36m0.6350\u001b[0m  0.0347\n",
            "      5        \u001b[36m0.6330\u001b[0m  0.0340\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.6311\u001b[0m  0.0390\n",
            "      7        \u001b[36m0.6293\u001b[0m  0.0363\n",
            "      8        \u001b[36m0.6275\u001b[0m  0.0382\n",
            "      9        \u001b[36m0.6258\u001b[0m  0.0333\n",
            "     10        \u001b[36m0.6242\u001b[0m  0.0332\n",
            "     11        \u001b[36m0.6226\u001b[0m  0.0328\n",
            "     12        \u001b[36m0.6210\u001b[0m  0.0322\n",
            "     13        \u001b[36m0.6195\u001b[0m  0.0332\n",
            "     14        \u001b[36m0.6180\u001b[0m  0.0347\n",
            "     15        \u001b[36m0.6166\u001b[0m  0.0329\n",
            "     16        \u001b[36m0.6152\u001b[0m  0.0328\n",
            "     17        \u001b[36m0.6138\u001b[0m  0.0333\n",
            "     18        \u001b[36m0.6125\u001b[0m  0.0338\n",
            "     19        \u001b[36m0.6112\u001b[0m  0.0336\n",
            "     20        \u001b[36m0.6100\u001b[0m  0.0331\n",
            "     21        \u001b[36m0.6088\u001b[0m  0.0345\n",
            "     22        \u001b[36m0.6076\u001b[0m  0.0430\n",
            "     23        \u001b[36m0.6064\u001b[0m  0.0367\n",
            "     24        \u001b[36m0.6053\u001b[0m  0.0349\n",
            "     25        \u001b[36m0.6042\u001b[0m  0.0347\n",
            "     26        \u001b[36m0.6032\u001b[0m  0.0370\n",
            "     27        \u001b[36m0.6021\u001b[0m  0.0357\n",
            "     28        \u001b[36m0.6011\u001b[0m  0.0409\n",
            "     29        \u001b[36m0.6001\u001b[0m  0.0388\n",
            "     30        \u001b[36m0.5979\u001b[0m  0.0335\n",
            "     31        \u001b[36m0.5970\u001b[0m  0.0346\n",
            "     32        \u001b[36m0.5960\u001b[0m  0.0336\n",
            "     33        \u001b[36m0.5952\u001b[0m  0.0360\n",
            "     34        \u001b[36m0.5943\u001b[0m  0.0368\n",
            "     35        \u001b[36m0.5934\u001b[0m  0.0377\n",
            "     36        \u001b[36m0.5926\u001b[0m  0.0353\n",
            "     37        \u001b[36m0.5918\u001b[0m  0.0346\n",
            "     38        \u001b[36m0.5909\u001b[0m  0.0345\n",
            "     39        \u001b[36m0.5901\u001b[0m  0.0349\n",
            "     40        \u001b[36m0.5894\u001b[0m  0.0355\n",
            "     41        \u001b[36m0.5886\u001b[0m  0.0376\n",
            "     42        \u001b[36m0.5878\u001b[0m  0.0346\n",
            "     43        \u001b[36m0.5871\u001b[0m  0.0334\n",
            "     44        \u001b[36m0.5863\u001b[0m  0.0331\n",
            "     45        \u001b[36m0.5856\u001b[0m  0.0337\n",
            "     46        \u001b[36m0.5849\u001b[0m  0.0326\n",
            "     47        \u001b[36m0.5842\u001b[0m  0.0334\n",
            "     48        \u001b[36m0.5835\u001b[0m  0.0322\n",
            "     49        \u001b[36m0.5828\u001b[0m  0.0399\n",
            "     50        \u001b[36m0.5821\u001b[0m  0.0379\n",
            "     51        \u001b[36m0.5814\u001b[0m  0.0368\n",
            "     52        \u001b[36m0.5808\u001b[0m  0.0332\n",
            "     53        \u001b[36m0.5801\u001b[0m  0.0325\n",
            "     54        \u001b[36m0.5795\u001b[0m  0.0318\n",
            "     55        \u001b[36m0.5788\u001b[0m  0.0328\n",
            "     56        \u001b[36m0.5782\u001b[0m  0.0322\n",
            "     57        \u001b[36m0.5776\u001b[0m  0.0456\n",
            "     58        \u001b[36m0.5770\u001b[0m  0.0335\n",
            "     59        \u001b[36m0.5764\u001b[0m  0.0325\n",
            "     60        \u001b[36m0.5757\u001b[0m  0.0330\n",
            "     61        \u001b[36m0.5751\u001b[0m  0.0336\n",
            "     62        \u001b[36m0.5746\u001b[0m  0.0340\n",
            "     63        \u001b[36m0.5740\u001b[0m  0.0347\n",
            "     64        \u001b[36m0.5734\u001b[0m  0.0349\n",
            "     65        \u001b[36m0.5728\u001b[0m  0.0338\n",
            "     66        \u001b[36m0.5722\u001b[0m  0.0344\n",
            "     67        \u001b[36m0.5717\u001b[0m  0.0353\n",
            "     68        \u001b[36m0.5711\u001b[0m  0.0327\n",
            "     69        \u001b[36m0.5705\u001b[0m  0.0335\n",
            "     70        \u001b[36m0.5700\u001b[0m  0.0330\n",
            "     71        \u001b[36m0.5694\u001b[0m  0.0318\n",
            "     72        \u001b[36m0.5689\u001b[0m  0.0345\n",
            "     73        \u001b[36m0.5683\u001b[0m  0.0329\n",
            "     74        \u001b[36m0.5678\u001b[0m  0.0326\n",
            "     75        \u001b[36m0.5672\u001b[0m  0.0328\n",
            "     76        \u001b[36m0.5667\u001b[0m  0.0338\n",
            "     77        \u001b[36m0.5662\u001b[0m  0.0435\n",
            "     78        \u001b[36m0.5656\u001b[0m  0.0387\n",
            "     79        \u001b[36m0.5651\u001b[0m  0.0337\n",
            "     80        \u001b[36m0.5646\u001b[0m  0.0334\n",
            "     81        \u001b[36m0.5641\u001b[0m  0.0328\n",
            "     82        \u001b[36m0.5635\u001b[0m  0.0339\n",
            "     83        \u001b[36m0.5630\u001b[0m  0.0339\n",
            "     84        \u001b[36m0.5625\u001b[0m  0.0359\n",
            "     85        \u001b[36m0.5620\u001b[0m  0.0333\n",
            "     86        \u001b[36m0.5615\u001b[0m  0.0430\n",
            "     87        \u001b[36m0.5610\u001b[0m  0.0341\n",
            "     88        \u001b[36m0.5605\u001b[0m  0.0345\n",
            "     89        \u001b[36m0.5600\u001b[0m  0.0340\n",
            "     90        \u001b[36m0.5594\u001b[0m  0.0368\n",
            "     91        \u001b[36m0.5589\u001b[0m  0.0350\n",
            "     92        \u001b[36m0.5584\u001b[0m  0.0331\n",
            "     93        \u001b[36m0.5579\u001b[0m  0.0328\n",
            "     94        \u001b[36m0.5574\u001b[0m  0.0332\n",
            "     95        \u001b[36m0.5569\u001b[0m  0.0341\n",
            "     96        \u001b[36m0.5564\u001b[0m  0.0343\n",
            "     97        \u001b[36m0.5559\u001b[0m  0.0354\n",
            "     98        \u001b[36m0.5554\u001b[0m  0.0361\n",
            "     99        \u001b[36m0.5549\u001b[0m  0.0346\n",
            "    100        \u001b[36m0.5544\u001b[0m  0.0374\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5690\u001b[0m  0.0301\n",
            "      2        \u001b[36m0.5669\u001b[0m  0.0342\n",
            "      3        \u001b[36m0.5648\u001b[0m  0.0335\n",
            "      4        \u001b[36m0.5628\u001b[0m  0.0401\n",
            "      5        \u001b[36m0.5609\u001b[0m  0.0390\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.5590\u001b[0m  0.0388\n",
            "      7        \u001b[36m0.5572\u001b[0m  0.0339\n",
            "      8        \u001b[36m0.5554\u001b[0m  0.0340\n",
            "      9        \u001b[36m0.5537\u001b[0m  0.0338\n",
            "     10        \u001b[36m0.5519\u001b[0m  0.0329\n",
            "     11        \u001b[36m0.5503\u001b[0m  0.0351\n",
            "     12        \u001b[36m0.5487\u001b[0m  0.0333\n",
            "     13        \u001b[36m0.5471\u001b[0m  0.0388\n",
            "     14        \u001b[36m0.5455\u001b[0m  0.0364\n",
            "     15        \u001b[36m0.5440\u001b[0m  0.0338\n",
            "     16        \u001b[36m0.5426\u001b[0m  0.0346\n",
            "     17        \u001b[36m0.5411\u001b[0m  0.0348\n",
            "     18        \u001b[36m0.5397\u001b[0m  0.0340\n",
            "     19        \u001b[36m0.5384\u001b[0m  0.0325\n",
            "     20        \u001b[36m0.5370\u001b[0m  0.0348\n",
            "     21        \u001b[36m0.5357\u001b[0m  0.0336\n",
            "     22        \u001b[36m0.5344\u001b[0m  0.0348\n",
            "     23        \u001b[36m0.5332\u001b[0m  0.0335\n",
            "     24        \u001b[36m0.5319\u001b[0m  0.0350\n",
            "     25        \u001b[36m0.5307\u001b[0m  0.0334\n",
            "     26        \u001b[36m0.5296\u001b[0m  0.0339\n",
            "     27        \u001b[36m0.5284\u001b[0m  0.0336\n",
            "     28        \u001b[36m0.5273\u001b[0m  0.0362\n",
            "     29        \u001b[36m0.5262\u001b[0m  0.0331\n",
            "     30        \u001b[36m0.5251\u001b[0m  0.0332\n",
            "     31        \u001b[36m0.5240\u001b[0m  0.0363\n",
            "     32        \u001b[36m0.5230\u001b[0m  0.0437\n",
            "     33        \u001b[36m0.5220\u001b[0m  0.0326\n",
            "     34        \u001b[36m0.5210\u001b[0m  0.0348\n",
            "     35        \u001b[36m0.5200\u001b[0m  0.0325\n",
            "     36        \u001b[36m0.5190\u001b[0m  0.0346\n",
            "     37        \u001b[36m0.5181\u001b[0m  0.0352\n",
            "     38        \u001b[36m0.5171\u001b[0m  0.0345\n",
            "     39        \u001b[36m0.5162\u001b[0m  0.0332\n",
            "     40        \u001b[36m0.5153\u001b[0m  0.0332\n",
            "     41        \u001b[36m0.5145\u001b[0m  0.0336\n",
            "     42        \u001b[36m0.5136\u001b[0m  0.0426\n",
            "     43        \u001b[36m0.5128\u001b[0m  0.0354\n",
            "     44        \u001b[36m0.5119\u001b[0m  0.0356\n",
            "     45        \u001b[36m0.5111\u001b[0m  0.0358\n",
            "     46        \u001b[36m0.5103\u001b[0m  0.0335\n",
            "     47        \u001b[36m0.5095\u001b[0m  0.0331\n",
            "     48        \u001b[36m0.5088\u001b[0m  0.0340\n",
            "     49        \u001b[36m0.5080\u001b[0m  0.0338\n",
            "     50        \u001b[36m0.5072\u001b[0m  0.0348\n",
            "     51        \u001b[36m0.5065\u001b[0m  0.0337\n",
            "     52        \u001b[36m0.5058\u001b[0m  0.0333\n",
            "     53        \u001b[36m0.5051\u001b[0m  0.0347\n",
            "     54        \u001b[36m0.5044\u001b[0m  0.0328\n",
            "     55        \u001b[36m0.5037\u001b[0m  0.0330\n",
            "     56        \u001b[36m0.5030\u001b[0m  0.0331\n",
            "     57        \u001b[36m0.5023\u001b[0m  0.0321\n",
            "     58        \u001b[36m0.5017\u001b[0m  0.0328\n",
            "     59        \u001b[36m0.5010\u001b[0m  0.0395\n",
            "     60        \u001b[36m0.5004\u001b[0m  0.0415\n",
            "     61        \u001b[36m0.4997\u001b[0m  0.0351\n",
            "     62        \u001b[36m0.4991\u001b[0m  0.0331\n",
            "     63        \u001b[36m0.4985\u001b[0m  0.0336\n",
            "     64        \u001b[36m0.4979\u001b[0m  0.0332\n",
            "     65        \u001b[36m0.4973\u001b[0m  0.0334\n",
            "     66        \u001b[36m0.4967\u001b[0m  0.0320\n",
            "     67        \u001b[36m0.4962\u001b[0m  0.0333\n",
            "     68        \u001b[36m0.4956\u001b[0m  0.0352\n",
            "     69        \u001b[36m0.4950\u001b[0m  0.0337\n",
            "     70        \u001b[36m0.4945\u001b[0m  0.0341\n",
            "     71        \u001b[36m0.4939\u001b[0m  0.0434\n",
            "     72        \u001b[36m0.4934\u001b[0m  0.0334\n",
            "     73        \u001b[36m0.4929\u001b[0m  0.0351\n",
            "     74        \u001b[36m0.4923\u001b[0m  0.0343\n",
            "     75        \u001b[36m0.4918\u001b[0m  0.0362\n",
            "     76        \u001b[36m0.4913\u001b[0m  0.0332\n",
            "     77        \u001b[36m0.4908\u001b[0m  0.0344\n",
            "     78        \u001b[36m0.4903\u001b[0m  0.0336\n",
            "     79        \u001b[36m0.4898\u001b[0m  0.0335\n",
            "     80        \u001b[36m0.4893\u001b[0m  0.0341\n",
            "     81        \u001b[36m0.4888\u001b[0m  0.0340\n",
            "     82        \u001b[36m0.4884\u001b[0m  0.0346\n",
            "     83        \u001b[36m0.4879\u001b[0m  0.0339\n",
            "     84        \u001b[36m0.4874\u001b[0m  0.0326\n",
            "     85        \u001b[36m0.4870\u001b[0m  0.0334\n",
            "     86        \u001b[36m0.4865\u001b[0m  0.0347\n",
            "     87        \u001b[36m0.4861\u001b[0m  0.0428\n",
            "     88        \u001b[36m0.4856\u001b[0m  0.0367\n",
            "     89        \u001b[36m0.4852\u001b[0m  0.0365\n",
            "     90        \u001b[36m0.4848\u001b[0m  0.0348\n",
            "     91        \u001b[36m0.4843\u001b[0m  0.0342\n",
            "     92        \u001b[36m0.4839\u001b[0m  0.0340\n",
            "     93        \u001b[36m0.4835\u001b[0m  0.0336\n",
            "     94        \u001b[36m0.4831\u001b[0m  0.0333\n",
            "     95        \u001b[36m0.4827\u001b[0m  0.0332\n",
            "     96        \u001b[36m0.4823\u001b[0m  0.0365\n",
            "     97        \u001b[36m0.4819\u001b[0m  0.0335\n",
            "     98        \u001b[36m0.4815\u001b[0m  0.0328\n",
            "     99        \u001b[36m0.4811\u001b[0m  0.0420\n",
            "    100        \u001b[36m0.4807\u001b[0m  0.0325\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4967\u001b[0m  0.0412\n",
            "      2        \u001b[36m0.4484\u001b[0m  0.0478\n",
            "      3        \u001b[36m0.4138\u001b[0m  0.0457\n",
            "      4        \u001b[36m0.4000\u001b[0m  0.0437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.3924\u001b[0m  0.0483\n",
            "      6        \u001b[36m0.3874\u001b[0m  0.0433\n",
            "      7        \u001b[36m0.3831\u001b[0m  0.0428\n",
            "      8        \u001b[36m0.3811\u001b[0m  0.0467\n",
            "      9        \u001b[36m0.3799\u001b[0m  0.0452\n",
            "     10        \u001b[36m0.3790\u001b[0m  0.0466\n",
            "     11        \u001b[36m0.3783\u001b[0m  0.0549\n",
            "     12        \u001b[36m0.3776\u001b[0m  0.0420\n",
            "     13        \u001b[36m0.3770\u001b[0m  0.0437\n",
            "     14        \u001b[36m0.3767\u001b[0m  0.0444\n",
            "     15        \u001b[36m0.3764\u001b[0m  0.0477\n",
            "     16        \u001b[36m0.3761\u001b[0m  0.0430\n",
            "     17        \u001b[36m0.3759\u001b[0m  0.0434\n",
            "     18        0.3761  0.0447\n",
            "     19        \u001b[36m0.3755\u001b[0m  0.0461\n",
            "     20        \u001b[36m0.3753\u001b[0m  0.0544\n",
            "     21        \u001b[36m0.3752\u001b[0m  0.0668\n",
            "     22        0.3752  0.0446\n",
            "     23        \u001b[36m0.3751\u001b[0m  0.0447\n",
            "     24        \u001b[36m0.3748\u001b[0m  0.0433\n",
            "     25        \u001b[36m0.3747\u001b[0m  0.0549\n",
            "     26        \u001b[36m0.3746\u001b[0m  0.0619\n",
            "     27        \u001b[36m0.3746\u001b[0m  0.0596\n",
            "     28        \u001b[36m0.3745\u001b[0m  0.0621\n",
            "     29        0.3745  0.0550\n",
            "     30        \u001b[36m0.3744\u001b[0m  0.0766\n",
            "     31        \u001b[36m0.3744\u001b[0m  0.0588\n",
            "     32        \u001b[36m0.3743\u001b[0m  0.0578\n",
            "     33        0.3745  0.0521\n",
            "     34        0.3744  0.0576\n",
            "     35        0.3743  0.0539\n",
            "     36        \u001b[36m0.3743\u001b[0m  0.0570\n",
            "     37        \u001b[36m0.3742\u001b[0m  0.0712\n",
            "     38        \u001b[36m0.3742\u001b[0m  0.0737\n",
            "     39        \u001b[36m0.3741\u001b[0m  0.0626\n",
            "     40        \u001b[36m0.3741\u001b[0m  0.0567\n",
            "     41        \u001b[36m0.3741\u001b[0m  0.0537\n",
            "     42        \u001b[36m0.3740\u001b[0m  0.0591\n",
            "     43        \u001b[36m0.3739\u001b[0m  0.0546\n",
            "     44        \u001b[36m0.3739\u001b[0m  0.0669\n",
            "     45        \u001b[36m0.3739\u001b[0m  0.0691\n",
            "     46        \u001b[36m0.3739\u001b[0m  0.0642\n",
            "     47        \u001b[36m0.3738\u001b[0m  0.0532\n",
            "     48        \u001b[36m0.3738\u001b[0m  0.0603\n",
            "     49        \u001b[36m0.3738\u001b[0m  0.0600\n",
            "     50        \u001b[36m0.3738\u001b[0m  0.0545\n",
            "     51        \u001b[36m0.3737\u001b[0m  0.0572\n",
            "     52        \u001b[36m0.3737\u001b[0m  0.0585\n",
            "     53        \u001b[36m0.3737\u001b[0m  0.0666\n",
            "     54        \u001b[36m0.3737\u001b[0m  0.0645\n",
            "     55        \u001b[36m0.3737\u001b[0m  0.0595\n",
            "     56        \u001b[36m0.3737\u001b[0m  0.0604\n",
            "     57        \u001b[36m0.3737\u001b[0m  0.0545\n",
            "     58        \u001b[36m0.3736\u001b[0m  0.0694\n",
            "     59        \u001b[36m0.3736\u001b[0m  0.0647\n",
            "     60        \u001b[36m0.3736\u001b[0m  0.0601\n",
            "     61        \u001b[36m0.3736\u001b[0m  0.0650\n",
            "     62        \u001b[36m0.3736\u001b[0m  0.0613\n",
            "     63        \u001b[36m0.3736\u001b[0m  0.0608\n",
            "     64        \u001b[36m0.3736\u001b[0m  0.0593\n",
            "     65        \u001b[36m0.3736\u001b[0m  0.0564\n",
            "     66        \u001b[36m0.3736\u001b[0m  0.0571\n",
            "     67        \u001b[36m0.3736\u001b[0m  0.0570\n",
            "     68        \u001b[36m0.3736\u001b[0m  0.0593\n",
            "     69        \u001b[36m0.3736\u001b[0m  0.0581\n",
            "     70        \u001b[36m0.3736\u001b[0m  0.0673\n",
            "     71        \u001b[36m0.3736\u001b[0m  0.0627\n",
            "     72        \u001b[36m0.3735\u001b[0m  0.0703\n",
            "     73        \u001b[36m0.3735\u001b[0m  0.0663\n",
            "     74        \u001b[36m0.3735\u001b[0m  0.0534\n",
            "     75        \u001b[36m0.3735\u001b[0m  0.0428\n",
            "     76        \u001b[36m0.3735\u001b[0m  0.0466\n",
            "     77        \u001b[36m0.3735\u001b[0m  0.0527\n",
            "     78        \u001b[36m0.3735\u001b[0m  0.0452\n",
            "     79        \u001b[36m0.3735\u001b[0m  0.0454\n",
            "     80        \u001b[36m0.3735\u001b[0m  0.0455\n",
            "     81        \u001b[36m0.3735\u001b[0m  0.0464\n",
            "     82        \u001b[36m0.3735\u001b[0m  0.0474\n",
            "     83        \u001b[36m0.3735\u001b[0m  0.0460\n",
            "     84        \u001b[36m0.3735\u001b[0m  0.0457\n",
            "     85        \u001b[36m0.3735\u001b[0m  0.0439\n",
            "     86        0.3735  0.0450\n",
            "     87        \u001b[36m0.3735\u001b[0m  0.0448\n",
            "     88        \u001b[36m0.3734\u001b[0m  0.0468\n",
            "     89        \u001b[36m0.3734\u001b[0m  0.0452\n",
            "     90        \u001b[36m0.3734\u001b[0m  0.0451\n",
            "     91        \u001b[36m0.3734\u001b[0m  0.0453\n",
            "     92        \u001b[36m0.3734\u001b[0m  0.0581\n",
            "     93        \u001b[36m0.3734\u001b[0m  0.0478\n",
            "     94        \u001b[36m0.3734\u001b[0m  0.0451\n",
            "     95        0.3734  0.0448\n",
            "     96        \u001b[36m0.3734\u001b[0m  0.0442\n",
            "     97        0.3734  0.0476\n",
            "     98        0.3735  0.0555\n",
            "     99        0.3734  0.0449\n",
            "    100        0.3734  0.0485\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4142\u001b[0m  0.0404\n",
            "      2        \u001b[36m0.4114\u001b[0m  0.0458\n",
            "      3        \u001b[36m0.4069\u001b[0m  0.0442\n",
            "      4        0.4074  0.0447\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.4028\u001b[0m  0.0528\n",
            "      6        \u001b[36m0.4007\u001b[0m  0.0447\n",
            "      7        \u001b[36m0.3968\u001b[0m  0.0436\n",
            "      8        \u001b[36m0.3941\u001b[0m  0.0436\n",
            "      9        \u001b[36m0.3926\u001b[0m  0.0470\n",
            "     10        \u001b[36m0.3912\u001b[0m  0.0464\n",
            "     11        \u001b[36m0.3901\u001b[0m  0.0440\n",
            "     12        \u001b[36m0.3891\u001b[0m  0.0437\n",
            "     13        \u001b[36m0.3883\u001b[0m  0.0546\n",
            "     14        \u001b[36m0.3876\u001b[0m  0.0441\n",
            "     15        \u001b[36m0.3871\u001b[0m  0.0434\n",
            "     16        \u001b[36m0.3870\u001b[0m  0.0436\n",
            "     17        \u001b[36m0.3866\u001b[0m  0.0443\n",
            "     18        \u001b[36m0.3863\u001b[0m  0.0470\n",
            "     19        \u001b[36m0.3860\u001b[0m  0.0476\n",
            "     20        \u001b[36m0.3857\u001b[0m  0.0439\n",
            "     21        \u001b[36m0.3853\u001b[0m  0.0458\n",
            "     22        \u001b[36m0.3846\u001b[0m  0.0436\n",
            "     23        \u001b[36m0.3835\u001b[0m  0.0435\n",
            "     24        \u001b[36m0.3810\u001b[0m  0.0437\n",
            "     25        \u001b[36m0.3774\u001b[0m  0.0437\n",
            "     26        \u001b[36m0.3754\u001b[0m  0.0461\n",
            "     27        \u001b[36m0.3750\u001b[0m  0.0429\n",
            "     28        \u001b[36m0.3743\u001b[0m  0.0429\n",
            "     29        \u001b[36m0.3738\u001b[0m  0.0442\n",
            "     30        \u001b[36m0.3729\u001b[0m  0.0442\n",
            "     31        \u001b[36m0.3722\u001b[0m  0.0453\n",
            "     32        \u001b[36m0.3722\u001b[0m  0.0443\n",
            "     33        0.3722  0.0458\n",
            "     34        \u001b[36m0.3722\u001b[0m  0.0448\n",
            "     35        \u001b[36m0.3722\u001b[0m  0.0558\n",
            "     36        \u001b[36m0.3722\u001b[0m  0.0437\n",
            "     37        \u001b[36m0.3721\u001b[0m  0.0447\n",
            "     38        \u001b[36m0.3721\u001b[0m  0.0426\n",
            "     39        \u001b[36m0.3721\u001b[0m  0.0437\n",
            "     40        \u001b[36m0.3721\u001b[0m  0.0544\n",
            "     41        0.3724  0.0433\n",
            "     42        0.3722  0.0445\n",
            "     43        0.3722  0.0447\n",
            "     44        0.3722  0.0447\n",
            "     45        0.3723  0.0457\n",
            "     46        0.3723  0.0444\n",
            "     47        \u001b[36m0.3721\u001b[0m  0.0446\n",
            "     48        \u001b[36m0.3721\u001b[0m  0.0440\n",
            "     49        \u001b[36m0.3721\u001b[0m  0.0441\n",
            "     50        \u001b[36m0.3720\u001b[0m  0.0469\n",
            "     51        0.3721  0.0454\n",
            "     52        0.3721  0.0467\n",
            "     53        0.3720  0.0446\n",
            "     54        \u001b[36m0.3720\u001b[0m  0.0443\n",
            "     55        \u001b[36m0.3720\u001b[0m  0.0425\n",
            "     56        \u001b[36m0.3720\u001b[0m  0.0449\n",
            "     57        \u001b[36m0.3720\u001b[0m  0.0511\n",
            "     58        \u001b[36m0.3720\u001b[0m  0.0441\n",
            "     59        0.3720  0.0430\n",
            "     60        \u001b[36m0.3720\u001b[0m  0.0432\n",
            "     61        \u001b[36m0.3720\u001b[0m  0.0505\n",
            "     62        \u001b[36m0.3720\u001b[0m  0.0490\n",
            "     63        \u001b[36m0.3720\u001b[0m  0.0436\n",
            "     64        \u001b[36m0.3720\u001b[0m  0.0460\n",
            "     65        \u001b[36m0.3720\u001b[0m  0.0430\n",
            "     66        \u001b[36m0.3720\u001b[0m  0.0439\n",
            "     67        \u001b[36m0.3720\u001b[0m  0.0442\n",
            "     68        0.3720  0.0457\n",
            "     69        0.3720  0.0455\n",
            "     70        \u001b[36m0.3720\u001b[0m  0.0453\n",
            "     71        \u001b[36m0.3720\u001b[0m  0.0450\n",
            "     72        \u001b[36m0.3720\u001b[0m  0.0443\n",
            "     73        \u001b[36m0.3720\u001b[0m  0.0442\n",
            "     74        \u001b[36m0.3720\u001b[0m  0.0461\n",
            "     75        \u001b[36m0.3720\u001b[0m  0.0467\n",
            "     76        \u001b[36m0.3720\u001b[0m  0.0420\n",
            "     77        \u001b[36m0.3720\u001b[0m  0.0441\n",
            "     78        \u001b[36m0.3720\u001b[0m  0.0462\n",
            "     79        \u001b[36m0.3720\u001b[0m  0.0533\n",
            "     80        0.3720  0.0441\n",
            "     81        \u001b[36m0.3720\u001b[0m  0.0435\n",
            "     82        \u001b[36m0.3720\u001b[0m  0.0500\n",
            "     83        \u001b[36m0.3720\u001b[0m  0.0524\n",
            "     84        \u001b[36m0.3720\u001b[0m  0.0426\n",
            "     85        \u001b[36m0.3720\u001b[0m  0.0447\n",
            "     86        0.3720  0.0446\n",
            "     87        0.3720  0.0443\n",
            "     88        \u001b[36m0.3720\u001b[0m  0.0422\n",
            "     89        0.3720  0.0420\n",
            "     90        0.3720  0.0431\n",
            "     91        0.3720  0.0452\n",
            "     92        0.3720  0.0439\n",
            "     93        0.3720  0.0437\n",
            "     94        0.3720  0.0445\n",
            "     95        0.3720  0.0440\n",
            "     96        0.3720  0.0489\n",
            "     97        0.3720  0.0444\n",
            "     98        0.3720  0.0441\n",
            "     99        0.3720  0.0449\n",
            "    100        0.3720  0.0465\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8572\u001b[0m  0.0345\n",
            "      2        \u001b[36m0.8556\u001b[0m  0.0355\n",
            "      3        \u001b[36m0.8539\u001b[0m  0.0349\n",
            "      4        \u001b[36m0.8521\u001b[0m  0.0428\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5        \u001b[36m0.8501\u001b[0m  0.0414\n",
            "      6        \u001b[36m0.8480\u001b[0m  0.0355\n",
            "      7        \u001b[36m0.8456\u001b[0m  0.0336\n",
            "      8        \u001b[36m0.8430\u001b[0m  0.0374\n",
            "      9        \u001b[36m0.8401\u001b[0m  0.0344\n",
            "     10        \u001b[36m0.8369\u001b[0m  0.0325\n",
            "     11        \u001b[36m0.8334\u001b[0m  0.0342\n",
            "     12        \u001b[36m0.8295\u001b[0m  0.0381\n",
            "     13        \u001b[36m0.8252\u001b[0m  0.0339\n",
            "     14        \u001b[36m0.8206\u001b[0m  0.0349\n",
            "     15        \u001b[36m0.8155\u001b[0m  0.0347\n",
            "     16        \u001b[36m0.8102\u001b[0m  0.0340\n",
            "     17        \u001b[36m0.8045\u001b[0m  0.0374\n",
            "     18        \u001b[36m0.7987\u001b[0m  0.0346\n",
            "     19        \u001b[36m0.7929\u001b[0m  0.0354\n",
            "     20        \u001b[36m0.7870\u001b[0m  0.0330\n",
            "     21        \u001b[36m0.7813\u001b[0m  0.0356\n",
            "     22        \u001b[36m0.7757\u001b[0m  0.0351\n",
            "     23        \u001b[36m0.7704\u001b[0m  0.0349\n",
            "     24        \u001b[36m0.7653\u001b[0m  0.0344\n",
            "     25        \u001b[36m0.7604\u001b[0m  0.0343\n",
            "     26        \u001b[36m0.7558\u001b[0m  0.0336\n",
            "     27        \u001b[36m0.7503\u001b[0m  0.0350\n",
            "     28        \u001b[36m0.7361\u001b[0m  0.0425\n",
            "     29        \u001b[36m0.7325\u001b[0m  0.0333\n",
            "     30        \u001b[36m0.7290\u001b[0m  0.0361\n",
            "     31        \u001b[36m0.7256\u001b[0m  0.0414\n",
            "     32        \u001b[36m0.7223\u001b[0m  0.0414\n",
            "     33        \u001b[36m0.7192\u001b[0m  0.0350\n",
            "     34        \u001b[36m0.7161\u001b[0m  0.0347\n",
            "     35        \u001b[36m0.7131\u001b[0m  0.0349\n",
            "     36        \u001b[36m0.7103\u001b[0m  0.0334\n",
            "     37        \u001b[36m0.7074\u001b[0m  0.0336\n",
            "     38        \u001b[36m0.7046\u001b[0m  0.0339\n",
            "     39        \u001b[36m0.7019\u001b[0m  0.0356\n",
            "     40        \u001b[36m0.6993\u001b[0m  0.0341\n",
            "     41        \u001b[36m0.6966\u001b[0m  0.0340\n",
            "     42        \u001b[36m0.6940\u001b[0m  0.0340\n",
            "     43        \u001b[36m0.6894\u001b[0m  0.0341\n",
            "     44        \u001b[36m0.6656\u001b[0m  0.0338\n",
            "     45        \u001b[36m0.6540\u001b[0m  0.0345\n",
            "     46        \u001b[36m0.6139\u001b[0m  0.0350\n",
            "     47        \u001b[36m0.6098\u001b[0m  0.0347\n",
            "     48        \u001b[36m0.6078\u001b[0m  0.0353\n",
            "     49        \u001b[36m0.6058\u001b[0m  0.0333\n",
            "     50        \u001b[36m0.6039\u001b[0m  0.0342\n",
            "     51        \u001b[36m0.6020\u001b[0m  0.0369\n",
            "     52        \u001b[36m0.6002\u001b[0m  0.0340\n",
            "     53        \u001b[36m0.5984\u001b[0m  0.0351\n",
            "     54        \u001b[36m0.5967\u001b[0m  0.0346\n",
            "     55        \u001b[36m0.5950\u001b[0m  0.0355\n",
            "     56        \u001b[36m0.5933\u001b[0m  0.0435\n",
            "     57        \u001b[36m0.5916\u001b[0m  0.0347\n",
            "     58        \u001b[36m0.5899\u001b[0m  0.0369\n",
            "     59        \u001b[36m0.5883\u001b[0m  0.0417\n",
            "     60        \u001b[36m0.5867\u001b[0m  0.0333\n",
            "     61        \u001b[36m0.5850\u001b[0m  0.0350\n",
            "     62        \u001b[36m0.5834\u001b[0m  0.0358\n",
            "     63        \u001b[36m0.5818\u001b[0m  0.0387\n",
            "     64        \u001b[36m0.5803\u001b[0m  0.0355\n",
            "     65        \u001b[36m0.5787\u001b[0m  0.0353\n",
            "     66        \u001b[36m0.5771\u001b[0m  0.0357\n",
            "     67        \u001b[36m0.5755\u001b[0m  0.0366\n",
            "     68        \u001b[36m0.5739\u001b[0m  0.0346\n",
            "     69        \u001b[36m0.5723\u001b[0m  0.0361\n",
            "     70        \u001b[36m0.5707\u001b[0m  0.0348\n",
            "     71        \u001b[36m0.5691\u001b[0m  0.0345\n",
            "     72        \u001b[36m0.5674\u001b[0m  0.0363\n",
            "     73        \u001b[36m0.5658\u001b[0m  0.0353\n",
            "     74        \u001b[36m0.5641\u001b[0m  0.0367\n",
            "     75        \u001b[36m0.5624\u001b[0m  0.0372\n",
            "     76        \u001b[36m0.5607\u001b[0m  0.0348\n",
            "     77        \u001b[36m0.5589\u001b[0m  0.0330\n",
            "     78        \u001b[36m0.5572\u001b[0m  0.0345\n",
            "     79        \u001b[36m0.5553\u001b[0m  0.0344\n",
            "     80        \u001b[36m0.5535\u001b[0m  0.0343\n",
            "     81        \u001b[36m0.5515\u001b[0m  0.0339\n",
            "     82        \u001b[36m0.5496\u001b[0m  0.0351\n",
            "     83        \u001b[36m0.5476\u001b[0m  0.0368\n",
            "     84        \u001b[36m0.5455\u001b[0m  0.0389\n",
            "     85        \u001b[36m0.5434\u001b[0m  0.0391\n",
            "     86        \u001b[36m0.5411\u001b[0m  0.0411\n",
            "     87        \u001b[36m0.5389\u001b[0m  0.0348\n",
            "     88        \u001b[36m0.5365\u001b[0m  0.0348\n",
            "     89        \u001b[36m0.5341\u001b[0m  0.0362\n",
            "     90        \u001b[36m0.5315\u001b[0m  0.0346\n",
            "     91        \u001b[36m0.5289\u001b[0m  0.0352\n",
            "     92        \u001b[36m0.5262\u001b[0m  0.0342\n",
            "     93        \u001b[36m0.5234\u001b[0m  0.0355\n",
            "     94        \u001b[36m0.5205\u001b[0m  0.0363\n",
            "     95        \u001b[36m0.5175\u001b[0m  0.0386\n",
            "     96        \u001b[36m0.5145\u001b[0m  0.0365\n",
            "     97        \u001b[36m0.5113\u001b[0m  0.0356\n",
            "     98        \u001b[36m0.5080\u001b[0m  0.0386\n",
            "     99        \u001b[36m0.5047\u001b[0m  0.0337\n",
            "    100        \u001b[36m0.5013\u001b[0m  0.0342\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7529\u001b[0m  0.0310\n",
            "      2        \u001b[36m0.7519\u001b[0m  0.0387\n",
            "      3        \u001b[36m0.7510\u001b[0m  0.0350\n",
            "      4        \u001b[36m0.7500\u001b[0m  0.0333\n",
            "      5        \u001b[36m0.7492\u001b[0m  0.0361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m0.7483\u001b[0m  0.0386\n",
            "      7        \u001b[36m0.7474\u001b[0m  0.0334\n",
            "      8        \u001b[36m0.7466\u001b[0m  0.0461\n",
            "      9        \u001b[36m0.7458\u001b[0m  0.0447\n",
            "     10        \u001b[36m0.7450\u001b[0m  0.0628\n",
            "     11        \u001b[36m0.7442\u001b[0m  0.0591\n",
            "     12        \u001b[36m0.7434\u001b[0m  0.0525\n",
            "     13        \u001b[36m0.7427\u001b[0m  0.0424\n",
            "     14        \u001b[36m0.7419\u001b[0m  0.0464\n",
            "     15        \u001b[36m0.7412\u001b[0m  0.0457\n",
            "     16        \u001b[36m0.7405\u001b[0m  0.0428\n",
            "     17        \u001b[36m0.7398\u001b[0m  0.0481\n",
            "     18        \u001b[36m0.7391\u001b[0m  0.0437\n",
            "     19        \u001b[36m0.7384\u001b[0m  0.0421\n",
            "     20        \u001b[36m0.7377\u001b[0m  0.0422\n",
            "     21        \u001b[36m0.7371\u001b[0m  0.0432\n",
            "     22        \u001b[36m0.7364\u001b[0m  0.0457\n",
            "     23        \u001b[36m0.7358\u001b[0m  0.0448\n",
            "     24        \u001b[36m0.7352\u001b[0m  0.0441\n",
            "     25        \u001b[36m0.7346\u001b[0m  0.0432\n",
            "     26        \u001b[36m0.7340\u001b[0m  0.0422\n",
            "     27        \u001b[36m0.7334\u001b[0m  0.0426\n",
            "     28        \u001b[36m0.7328\u001b[0m  0.0422\n",
            "     29        \u001b[36m0.7322\u001b[0m  0.0417\n",
            "     30        \u001b[36m0.7317\u001b[0m  0.0413\n",
            "     31        \u001b[36m0.7311\u001b[0m  0.0438\n",
            "     32        \u001b[36m0.7306\u001b[0m  0.0576\n",
            "     33        \u001b[36m0.7300\u001b[0m  0.0559\n",
            "     34        \u001b[36m0.7295\u001b[0m  0.0521\n",
            "     35        \u001b[36m0.7290\u001b[0m  0.0417\n",
            "     36        \u001b[36m0.7285\u001b[0m  0.0473\n",
            "     37        \u001b[36m0.7280\u001b[0m  0.0407\n",
            "     38        \u001b[36m0.7275\u001b[0m  0.0436\n",
            "     39        \u001b[36m0.7269\u001b[0m  0.0428\n",
            "     40        \u001b[36m0.7264\u001b[0m  0.0438\n",
            "     41        \u001b[36m0.7259\u001b[0m  0.0423\n",
            "     42        \u001b[36m0.7255\u001b[0m  0.0424\n",
            "     43        \u001b[36m0.7250\u001b[0m  0.0507\n",
            "     44        \u001b[36m0.7245\u001b[0m  0.0517\n",
            "     45        \u001b[36m0.7241\u001b[0m  0.0446\n",
            "     46        \u001b[36m0.7236\u001b[0m  0.0588\n",
            "     47        \u001b[36m0.7232\u001b[0m  0.0440\n",
            "     48        \u001b[36m0.7227\u001b[0m  0.0546\n",
            "     49        \u001b[36m0.7223\u001b[0m  0.0489\n",
            "     50        \u001b[36m0.7218\u001b[0m  0.0580\n",
            "     51        \u001b[36m0.7214\u001b[0m  0.0448\n",
            "     52        \u001b[36m0.7210\u001b[0m  0.0428\n",
            "     53        \u001b[36m0.7206\u001b[0m  0.0643\n",
            "     54        \u001b[36m0.7201\u001b[0m  0.0524\n",
            "     55        \u001b[36m0.7197\u001b[0m  0.0502\n",
            "     56        \u001b[36m0.7193\u001b[0m  0.0466\n",
            "     57        \u001b[36m0.7189\u001b[0m  0.0435\n",
            "     58        \u001b[36m0.7185\u001b[0m  0.0485\n",
            "     59        \u001b[36m0.7181\u001b[0m  0.0613\n",
            "     60        \u001b[36m0.7177\u001b[0m  0.0460\n",
            "     61        \u001b[36m0.7173\u001b[0m  0.0508\n",
            "     62        \u001b[36m0.7169\u001b[0m  0.0438\n",
            "     63        \u001b[36m0.7166\u001b[0m  0.0485\n",
            "     64        \u001b[36m0.7162\u001b[0m  0.0445\n",
            "     65        \u001b[36m0.7158\u001b[0m  0.0454\n",
            "     66        \u001b[36m0.7154\u001b[0m  0.0433\n",
            "     67        \u001b[36m0.7150\u001b[0m  0.0439\n",
            "     68        \u001b[36m0.7147\u001b[0m  0.0454\n",
            "     69        \u001b[36m0.7143\u001b[0m  0.0475\n",
            "     70        \u001b[36m0.7139\u001b[0m  0.0499\n",
            "     71        \u001b[36m0.7136\u001b[0m  0.0453\n",
            "     72        \u001b[36m0.7132\u001b[0m  0.0479\n",
            "     73        \u001b[36m0.7128\u001b[0m  0.0532\n",
            "     74        \u001b[36m0.7125\u001b[0m  0.0552\n",
            "     75        \u001b[36m0.7121\u001b[0m  0.0435\n",
            "     76        \u001b[36m0.7118\u001b[0m  0.0563\n",
            "     77        \u001b[36m0.7114\u001b[0m  0.0487\n",
            "     78        \u001b[36m0.7111\u001b[0m  0.0447\n",
            "     79        \u001b[36m0.7107\u001b[0m  0.0469\n",
            "     80        \u001b[36m0.7104\u001b[0m  0.0408\n",
            "     81        \u001b[36m0.7097\u001b[0m  0.0342\n",
            "     82        \u001b[36m0.7093\u001b[0m  0.0362\n",
            "     83        \u001b[36m0.7089\u001b[0m  0.0351\n",
            "     84        \u001b[36m0.7086\u001b[0m  0.0364\n",
            "     85        \u001b[36m0.7082\u001b[0m  0.0334\n",
            "     86        \u001b[36m0.7078\u001b[0m  0.0360\n",
            "     87        \u001b[36m0.7075\u001b[0m  0.0343\n",
            "     88        \u001b[36m0.7071\u001b[0m  0.0329\n",
            "     89        \u001b[36m0.7068\u001b[0m  0.0326\n",
            "     90        \u001b[36m0.7064\u001b[0m  0.0352\n",
            "     91        \u001b[36m0.7061\u001b[0m  0.0333\n",
            "     92        \u001b[36m0.7057\u001b[0m  0.0356\n",
            "     93        \u001b[36m0.7054\u001b[0m  0.0426\n",
            "     94        \u001b[36m0.7050\u001b[0m  0.0359\n",
            "     95        \u001b[36m0.7047\u001b[0m  0.0372\n",
            "     96        \u001b[36m0.7043\u001b[0m  0.0368\n",
            "     97        \u001b[36m0.7040\u001b[0m  0.0356\n",
            "     98        \u001b[36m0.7036\u001b[0m  0.0346\n",
            "     99        \u001b[36m0.7033\u001b[0m  0.0432\n",
            "    100        \u001b[36m0.7029\u001b[0m  0.0356\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0147\n",
            "      2       37.3239  0.0189\n",
            "      3       37.3239  0.0191\n",
            "      4       37.3239  0.0175\n",
            "      5       37.3239  0.0156\n",
            "      6       37.3239  0.0200\n",
            "      7       37.3239  0.0168\n",
            "      8       37.3239  0.0179\n",
            "      9       37.3239  0.0153\n",
            "     10       37.3239  0.0195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11       37.3239  0.0215\n",
            "     12       37.3239  0.0167\n",
            "     13       37.3239  0.0185\n",
            "     14       37.3239  0.0166\n",
            "     15       37.3239  0.0207\n",
            "     16       37.3239  0.0206\n",
            "     17       37.3239  0.0179\n",
            "     18       37.3239  0.0186\n",
            "     19       37.3239  0.0167\n",
            "     20       37.3239  0.0210\n",
            "     21       37.3239  0.0167\n",
            "     22       37.3239  0.0191\n",
            "     23       37.3239  0.0167\n",
            "     24       37.3239  0.0196\n",
            "     25       37.3239  0.0170\n",
            "     26       37.3239  0.0194\n",
            "     27       37.3239  0.0155\n",
            "     28       37.3239  0.0212\n",
            "     29       37.3239  0.0170\n",
            "     30       37.3239  0.0193\n",
            "     31       37.3239  0.0153\n",
            "     32       37.3239  0.0207\n",
            "     33       37.3239  0.0192\n",
            "     34       37.3239  0.0228\n",
            "     35       37.3239  0.0203\n",
            "     36       37.3239  0.0212\n",
            "     37       37.3239  0.0223\n",
            "     38       37.3239  0.0163\n",
            "     39       37.3239  0.0184\n",
            "     40       37.3239  0.0180\n",
            "     41       37.3239  0.0180\n",
            "     42       37.3239  0.0177\n",
            "     43       37.3239  0.0167\n",
            "     44       37.3239  0.0199\n",
            "     45       37.3239  0.0174\n",
            "     46       37.3239  0.0175\n",
            "     47       37.3239  0.0230\n",
            "     48       37.3239  0.0239\n",
            "     49       37.3239  0.0184\n",
            "     50       37.3239  0.0211\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0146\n",
            "      2       37.1930  0.0190\n",
            "      3       37.1930  0.0191\n",
            "      4       37.1930  0.0180\n",
            "      5       37.1930  0.0156\n",
            "      6       37.1930  0.0204\n",
            "      7       37.1930  0.0190\n",
            "      8       37.1930  0.0178\n",
            "      9       37.1930  0.0166\n",
            "     10       37.1930  0.0149\n",
            "     11       37.1930  0.0193\n",
            "     12       37.1930  0.0207\n",
            "     13       37.1930  0.0178\n",
            "     14       37.1930  0.0160\n",
            "     15       37.1930  0.0202\n",
            "     16       37.1930  0.0195\n",
            "     17       37.1930  0.0203\n",
            "     18       37.1930  0.0167\n",
            "     19       37.1930  0.0154\n",
            "     20       37.1930  0.0200\n",
            "     21       37.1930  0.0175\n",
            "     22       37.1930  0.0211\n",
            "     23       37.1930  0.0150\n",
            "     24       37.1930  0.0201\n",
            "     25       37.1930  0.0173\n",
            "     26       37.1930  0.0200\n",
            "     27       37.1930  0.0149\n",
            "     28       37.1930  0.0205\n",
            "     29       37.1930  0.0163\n",
            "     30       37.1930  0.0176\n",
            "     31       37.1930  0.0150\n",
            "     32       37.1930  0.0218\n",
            "     33       37.1930  0.0247\n",
            "     34       37.1930  0.0220\n",
            "     35       37.1930  0.0208\n",
            "     36       37.1930  0.0201\n",
            "     37       37.1930  0.0215\n",
            "     38       37.1930  0.0211\n",
            "     39       37.1930  0.0168\n",
            "     40       37.1930  0.0168\n",
            "     41       37.1930  0.0176\n",
            "     42       37.1930  0.0188\n",
            "     43       37.1930  0.0198\n",
            "     44       37.1930  0.0190\n",
            "     45       37.1930  0.0191\n",
            "     46       37.1930  0.0184\n",
            "     47       37.1930  0.0239\n",
            "     48       37.1930  0.0236\n",
            "     49       37.1930  0.0189\n",
            "     50       37.1930  0.0201\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0127\n",
            "      2       37.3239  0.0155\n",
            "      3       37.3239  0.0146\n",
            "      4       37.3239  0.0150\n",
            "      5       37.3239  0.0175\n",
            "      6       37.3239  0.0117\n",
            "      7       37.3239  0.0148\n",
            "      8       37.3239  0.0148\n",
            "      9       37.3239  0.0139\n",
            "     10       37.3239  0.0116\n",
            "     11       37.3239  0.0123\n",
            "     12       37.3239  0.0169\n",
            "     13       37.3239  0.0144\n",
            "     14       37.3239  0.0121\n",
            "     15       37.3239  0.0129\n",
            "     16       37.3239  0.0149\n",
            "     17       37.3239  0.0145\n",
            "     18       37.3239  0.0113\n",
            "     19       37.3239  0.0138\n",
            "     20       37.3239  0.0169\n",
            "     21       37.3239  0.0143\n",
            "     22       37.3239  0.0114\n",
            "     23       37.3239  0.0118\n",
            "     24       37.3239  0.0153\n",
            "     25       37.3239  0.0138\n",
            "     26       37.3239  0.0107\n",
            "     27       37.3239  0.0120\n",
            "     28       37.3239  0.0140\n",
            "     29       37.3239  0.0143\n",
            "     30       37.3239  0.0109\n",
            "     31       37.3239  0.0129\n",
            "     32       37.3239  0.0145\n",
            "     33       37.3239  0.0134\n",
            "     34       37.3239  0.0117\n",
            "     35       37.3239  0.0118\n",
            "     36       37.3239  0.0183\n",
            "     37       37.3239  0.0159\n",
            "     38       37.3239  0.0150\n",
            "     39       37.3239  0.0188\n",
            "     40       37.3239  0.0166\n",
            "     41       37.3239  0.0168\n",
            "     42       37.3239  0.0168\n",
            "     43       37.3239  0.0144\n",
            "     44       37.3239  0.0146\n",
            "     45       37.3239  0.0161\n",
            "     46       37.3239  0.0147\n",
            "     47       37.3239  0.0122\n",
            "     48       37.3239  0.0116\n",
            "     49       37.3239  0.0142\n",
            "     50       37.3239  0.0144\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0110\n",
            "      2       37.1930  0.0174\n",
            "      3       37.1930  0.0143\n",
            "      4       37.1930  0.0144\n",
            "      5       37.1930  0.0120\n",
            "      6       37.1930  0.0122\n",
            "      7       37.1930  0.0154\n",
            "      8       37.1930  0.0182\n",
            "      9       37.1930  0.0159\n",
            "     10       37.1930  0.0171\n",
            "     11       37.1930  0.0168\n",
            "     12       37.1930  0.0133\n",
            "     13       37.1930  0.0120\n",
            "     14       37.1930  0.0145\n",
            "     15       37.1930  0.0152\n",
            "     16       37.1930  0.0144\n",
            "     17       37.1930  0.0150\n",
            "     18       37.1930  0.0118\n",
            "     19       37.1930  0.0123\n",
            "     20       37.1930  0.0156\n",
            "     21       37.1930  0.0154\n",
            "     22       37.1930  0.0117\n",
            "     23       37.1930  0.0133\n",
            "     24       37.1930  0.0151\n",
            "     25       37.1930  0.0147\n",
            "     26       37.1930  0.0127\n",
            "     27       37.1930  0.0143\n",
            "     28       37.1930  0.0158\n",
            "     29       37.1930  0.0148\n",
            "     30       37.1930  0.0105\n",
            "     31       37.1930  0.0116\n",
            "     32       37.1930  0.0147\n",
            "     33       37.1930  0.0145\n",
            "     34       37.1930  0.0110\n",
            "     35       37.1930  0.0137\n",
            "     36       37.1930  0.0151\n",
            "     37       37.1930  0.0146\n",
            "     38       37.1930  0.0125\n",
            "     39       37.1930  0.0137\n",
            "     40       37.1930  0.0150\n",
            "     41       37.1930  0.0148\n",
            "     42       37.1930  0.0119\n",
            "     43       37.1930  0.0121\n",
            "     44       37.1930  0.0148\n",
            "     45       37.1930  0.0148\n",
            "     46       37.1930  0.0115\n",
            "     47       37.1930  0.0148\n",
            "     48       37.1930  0.0168\n",
            "     49       37.1930  0.0168\n",
            "     50       37.1930  0.0163\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0193\n",
            "      2       37.3239  0.0217\n",
            "      3       37.3239  0.0198\n",
            "      4       37.3239  0.0171\n",
            "      5       37.3239  0.0160\n",
            "      6       37.3239  0.0199\n",
            "      7       37.3239  0.0173\n",
            "      8       37.3239  0.0181\n",
            "      9       37.3239  0.0156\n",
            "     10       37.3239  0.0191\n",
            "     11       37.3239  0.0179\n",
            "     12       37.3239  0.0175\n",
            "     13       37.3239  0.0155\n",
            "     14       37.3239  0.0204\n",
            "     15       37.3239  0.0207\n",
            "     16       37.3239  0.0192\n",
            "     17       37.3239  0.0226\n",
            "     18       37.3239  0.0201\n",
            "     19       37.3239  0.0170\n",
            "     20       37.3239  0.0179\n",
            "     21       37.3239  0.0165\n",
            "     22       37.3239  0.0181\n",
            "     23       37.3239  0.0203\n",
            "     24       37.3239  0.0178\n",
            "     25       37.3239  0.0174\n",
            "     26       37.3239  0.0172\n",
            "     27       37.3239  0.0198\n",
            "     28       37.3239  0.0197\n",
            "     29       37.3239  0.0165\n",
            "     30       37.3239  0.0171\n",
            "     31       37.3239  0.0171\n",
            "     32       37.3239  0.0205\n",
            "     33       37.3239  0.0166\n",
            "     34       37.3239  0.0170\n",
            "     35       37.3239  0.0174\n",
            "     36       37.3239  0.0170\n",
            "     37       37.3239  0.0183\n",
            "     38       37.3239  0.0172\n",
            "     39       37.3239  0.0164\n",
            "     40       37.3239  0.0161\n",
            "     41       37.3239  0.0169\n",
            "     42       37.3239  0.0169\n",
            "     43       37.3239  0.0196\n",
            "     44       37.3239  0.0176\n",
            "     45       37.3239  0.0178\n",
            "     46       37.3239  0.0187\n",
            "     47       37.3239  0.0202\n",
            "     48       37.3239  0.0203\n",
            "     49       37.3239  0.0229\n",
            "     50       37.3239  0.0217\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0145\n",
            "      2       37.1930  0.0195\n",
            "      3       37.1930  0.0179\n",
            "      4       37.1930  0.0183\n",
            "      5       37.1930  0.0151\n",
            "      6       37.1930  0.0195\n",
            "      7       37.1930  0.0188\n",
            "      8       37.1930  0.0172\n",
            "      9       37.1930  0.0158\n",
            "     10       37.1930  0.0194\n",
            "     11       37.1930  0.0197\n",
            "     12       37.1930  0.0159\n",
            "     13       37.1930  0.0143\n",
            "     14       37.1930  0.0190\n",
            "     15       37.1930  0.0205\n",
            "     16       37.1930  0.0161\n",
            "     17       37.1930  0.0159\n",
            "     18       37.1930  0.0216\n",
            "     19       37.1930  0.0254\n",
            "     20       37.1930  0.0187\n",
            "     21       37.1930  0.0148\n",
            "     22       37.1930  0.0207\n",
            "     23       37.1930  0.0173\n",
            "     24       37.1930  0.0179\n",
            "     25       37.1930  0.0154\n",
            "     26       37.1930  0.0202\n",
            "     27       37.1930  0.0198\n",
            "     28       37.1930  0.0183\n",
            "     29       37.1930  0.0156\n",
            "     30       37.1930  0.0204\n",
            "     31       37.1930  0.0177\n",
            "     32       37.1930  0.0209\n",
            "     33       37.1930  0.0165\n",
            "     34       37.1930  0.0214\n",
            "     35       37.1930  0.0183\n",
            "     36       37.1930  0.0188\n",
            "     37       37.1930  0.0155\n",
            "     38       37.1930  0.0223\n",
            "     39       37.1930  0.0172\n",
            "     40       37.1930  0.0175\n",
            "     41       37.1930  0.0149\n",
            "     42       37.1930  0.0198\n",
            "     43       37.1930  0.0208\n",
            "     44       37.1930  0.0178\n",
            "     45       37.1930  0.0157\n",
            "     46       37.1930  0.0236\n",
            "     47       37.1930  0.0224\n",
            "     48       37.1930  0.0208\n",
            "     49       37.1930  0.0208\n",
            "     50       37.1930  0.0202\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0112\n",
            "      2       37.3239  0.0148\n",
            "      3       37.3239  0.0155\n",
            "      4       37.3239  0.0160\n",
            "      5       37.3239  0.0117\n",
            "      6       37.3239  0.0124\n",
            "      7       37.3239  0.0161\n",
            "      8       37.3239  0.0148\n",
            "      9       37.3239  0.0129\n",
            "     10       37.3239  0.0130\n",
            "     11       37.3239  0.0161\n",
            "     12       37.3239  0.0155\n",
            "     13       37.3239  0.0120\n",
            "     14       37.3239  0.0131\n",
            "     15       37.3239  0.0166\n",
            "     16       37.3239  0.0150\n",
            "     17       37.3239  0.0124\n",
            "     18       37.3239  0.0129\n",
            "     19       37.3239  0.0147\n",
            "     20       37.3239  0.0154\n",
            "     21       37.3239  0.0138\n",
            "     22       37.3239  0.0159\n",
            "     23       37.3239  0.0222\n",
            "     24       37.3239  0.0161\n",
            "     25       37.3239  0.0123\n",
            "     26       37.3239  0.0129\n",
            "     27       37.3239  0.0160\n",
            "     28       37.3239  0.0150\n",
            "     29       37.3239  0.0126\n",
            "     30       37.3239  0.0125\n",
            "     31       37.3239  0.0172\n",
            "     32       37.3239  0.0152\n",
            "     33       37.3239  0.0124\n",
            "     34       37.3239  0.0133\n",
            "     35       37.3239  0.0144\n",
            "     36       37.3239  0.0150\n",
            "     37       37.3239  0.0119\n",
            "     38       37.3239  0.0138\n",
            "     39       37.3239  0.0152\n",
            "     40       37.3239  0.0145\n",
            "     41       37.3239  0.0122\n",
            "     42       37.3239  0.0122\n",
            "     43       37.3239  0.0147\n",
            "     44       37.3239  0.0141\n",
            "     45       37.3239  0.0116\n",
            "     46       37.3239  0.0136\n",
            "     47       37.3239  0.0160\n",
            "     48       37.3239  0.0141\n",
            "     49       37.3239  0.0119\n",
            "     50       37.3239  0.0122\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0150\n",
            "      2       37.1930  0.0151\n",
            "      3       37.1930  0.0148\n",
            "      4       37.1930  0.0174\n",
            "      5       37.1930  0.0140\n",
            "      6       37.1930  0.0172\n",
            "      7       37.1930  0.0148\n",
            "      8       37.1930  0.0163\n",
            "      9       37.1930  0.0179\n",
            "     10       37.1930  0.0184\n",
            "     11       37.1930  0.0167\n",
            "     12       37.1930  0.0144\n",
            "     13       37.1930  0.0107\n",
            "     14       37.1930  0.0120\n",
            "     15       37.1930  0.0154\n",
            "     16       37.1930  0.0143\n",
            "     17       37.1930  0.0160\n",
            "     18       37.1930  0.0137\n",
            "     19       37.1930  0.0149\n",
            "     20       37.1930  0.0161\n",
            "     21       37.1930  0.0120\n",
            "     22       37.1930  0.0124\n",
            "     23       37.1930  0.0156\n",
            "     24       37.1930  0.0148\n",
            "     25       37.1930  0.0120\n",
            "     26       37.1930  0.0133\n",
            "     27       37.1930  0.0169\n",
            "     28       37.1930  0.0151\n",
            "     29       37.1930  0.0120\n",
            "     30       37.1930  0.0156\n",
            "     31       37.1930  0.0169\n",
            "     32       37.1930  0.0158\n",
            "     33       37.1930  0.0117\n",
            "     34       37.1930  0.0161\n",
            "     35       37.1930  0.0166\n",
            "     36       37.1930  0.0165\n",
            "     37       37.1930  0.0159\n",
            "     38       37.1930  0.0140\n",
            "     39       37.1930  0.0146\n",
            "     40       37.1930  0.0145\n",
            "     41       37.1930  0.0135\n",
            "     42       37.1930  0.0141\n",
            "     43       37.1930  0.0146\n",
            "     44       37.1930  0.0146\n",
            "     45       37.1930  0.0117\n",
            "     46       37.1930  0.0116\n",
            "     47       37.1930  0.0157\n",
            "     48       37.1930  0.0160\n",
            "     49       37.1930  0.0121\n",
            "     50       37.1930  0.0121\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m63.3803\u001b[0m  0.0183\n",
            "      2       63.3803  0.0175\n",
            "      3       63.3803  0.0178\n",
            "      4       \u001b[36m63.2878\u001b[0m  0.0186\n",
            "      5       \u001b[36m62.8305\u001b[0m  0.0150\n",
            "      6       \u001b[36m62.3239\u001b[0m  0.0203\n",
            "      7       \u001b[36m62.1307\u001b[0m  0.0169\n",
            "      8       \u001b[36m62.0420\u001b[0m  0.0175\n",
            "      9       \u001b[36m61.0377\u001b[0m  0.0147\n",
            "     10       \u001b[36m60.3038\u001b[0m  0.0208\n",
            "     11       \u001b[36m53.9289\u001b[0m  0.0192\n",
            "     12       \u001b[36m49.8747\u001b[0m  0.0204\n",
            "     13       56.3381  0.0181\n",
            "     14       56.3381  0.0210\n",
            "     15       56.3380  0.0203\n",
            "     16       56.3380  0.0185\n",
            "     17       56.3380  0.0231\n",
            "     18       56.3380  0.0167\n",
            "     19       56.3380  0.0179\n",
            "     20       56.3380  0.0174\n",
            "     21       56.3380  0.0178\n",
            "     22       56.3380  0.0191\n",
            "     23       56.3380  0.0174\n",
            "     24       56.3380  0.0176\n",
            "     25       56.3380  0.0176\n",
            "     26       56.3380  0.0181\n",
            "     27       56.2442  0.0202\n",
            "     28       55.9859  0.0174\n",
            "     29       55.9859  0.0177\n",
            "     30       55.9859  0.0177\n",
            "     31       55.9859  0.0171\n",
            "     32       55.9859  0.0201\n",
            "     33       55.9859  0.0175\n",
            "     34       55.9859  0.0183\n",
            "     35       55.9859  0.0171\n",
            "     36       55.9859  0.0175\n",
            "     37       55.9859  0.0183\n",
            "     38       55.9859  0.0182\n",
            "     39       55.7893  0.0276\n",
            "     40       54.9980  0.0184\n",
            "     41       53.8733  0.0169\n",
            "     42       53.8732  0.0189\n",
            "     43       53.8732  0.0181\n",
            "     44       53.8732  0.0190\n",
            "     45       53.8732  0.0179\n",
            "     46       53.8732  0.0207\n",
            "     47       53.8732  0.0177\n",
            "     48       53.8732  0.0182\n",
            "     49       53.8732  0.0166\n",
            "     50       53.8732  0.0181\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.6842\u001b[0m  0.0164\n",
            "      2       \u001b[36m53.3333\u001b[0m  0.0160\n",
            "      3       \u001b[36m52.8985\u001b[0m  0.0187\n",
            "      4       \u001b[36m50.9862\u001b[0m  0.0188\n",
            "      5       \u001b[36m50.7286\u001b[0m  0.0155\n",
            "      6       \u001b[36m49.7840\u001b[0m  0.0215\n",
            "      7       \u001b[36m48.8229\u001b[0m  0.0179\n",
            "      8       \u001b[36m48.3331\u001b[0m  0.0171\n",
            "      9       \u001b[36m48.0674\u001b[0m  0.0154\n",
            "     10       48.2041  0.0199\n",
            "     11       \u001b[36m47.4529\u001b[0m  0.0213\n",
            "     12       \u001b[36m47.2484\u001b[0m  0.0214\n",
            "     13       47.5549  0.0211\n",
            "     14       \u001b[36m47.1211\u001b[0m  0.0204\n",
            "     15       \u001b[36m47.0269\u001b[0m  0.0185\n",
            "     16       47.2685  0.0189\n",
            "     17       \u001b[36m46.6023\u001b[0m  0.0159\n",
            "     18       \u001b[36m46.2478\u001b[0m  0.0224\n",
            "     19       46.8646  0.0184\n",
            "     20       46.7001  0.0182\n",
            "     21       46.6048  0.0183\n",
            "     22       46.9463  0.0152\n",
            "     23       47.0176  0.0195\n",
            "     24       47.0181  0.0192\n",
            "     25       \u001b[36m45.9923\u001b[0m  0.0185\n",
            "     26       46.7657  0.0181\n",
            "     27       47.9980  0.0194\n",
            "     28       47.8091  0.0180\n",
            "     29       47.9681  0.0158\n",
            "     30       47.5252  0.0204\n",
            "     31       47.0924  0.0181\n",
            "     32       47.1813  0.0172\n",
            "     33       47.1496  0.0146\n",
            "     34       47.1383  0.0187\n",
            "     35       47.1340  0.0183\n",
            "     36       47.1312  0.0179\n",
            "     37       47.1273  0.0158\n",
            "     38       47.0545  0.0239\n",
            "     39       47.2395  0.0292\n",
            "     40       46.9419  0.0210\n",
            "     41       46.9625  0.0222\n",
            "     42       46.5485  0.0250\n",
            "     43       47.8266  0.0239\n",
            "     44       47.2238  0.0218\n",
            "     45       47.5563  0.0221\n",
            "     46       47.1850  0.0239\n",
            "     47       47.1639  0.0266\n",
            "     48       47.1424  0.0194\n",
            "     49       47.0868  0.0190\n",
            "     50       47.0175  0.0249\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m40.3122\u001b[0m  0.0153\n",
            "      2       40.3122  0.0149\n",
            "      3       40.3122  0.0148\n",
            "      4       40.3122  0.0147\n",
            "      5       40.3122  0.0190\n",
            "      6       40.3122  0.0218\n",
            "      7       40.3122  0.0208\n",
            "      8       40.3122  0.0206\n",
            "      9       40.3122  0.0194\n",
            "     10       40.3122  0.0231\n",
            "     11       40.3122  0.0190\n",
            "     12       40.3122  0.0179\n",
            "     13       40.3122  0.0170\n",
            "     14       40.3122  0.0163\n",
            "     15       40.3122  0.0165\n",
            "     16       40.3122  0.0209\n",
            "     17       40.3122  0.0178\n",
            "     18       40.3122  0.0203\n",
            "     19       40.3122  0.0206\n",
            "     20       40.3122  0.0210\n",
            "     21       40.3122  0.0230\n",
            "     22       40.3122  0.0183\n",
            "     23       40.3122  0.0198\n",
            "     24       40.3122  0.0189\n",
            "     25       40.3122  0.0169\n",
            "     26       40.3122  0.0210\n",
            "     27       40.3122  0.0227\n",
            "     28       40.3122  0.0247\n",
            "     29       40.3122  0.0201\n",
            "     30       40.3122  0.0185\n",
            "     31       40.3122  0.0151\n",
            "     32       40.3122  0.0141\n",
            "     33       40.3122  0.0188\n",
            "     34       40.3122  0.0179\n",
            "     35       40.3122  0.0169\n",
            "     36       40.3122  0.0168\n",
            "     37       40.3122  0.0162\n",
            "     38       40.3122  0.0142\n",
            "     39       40.3122  0.0141\n",
            "     40       40.3122  0.0144\n",
            "     41       40.3122  0.0143\n",
            "     42       40.3122  0.0177\n",
            "     43       40.3122  0.0153\n",
            "     44       40.3122  0.0143\n",
            "     45       40.3122  0.0157\n",
            "     46       40.3122  0.0142\n",
            "     47       40.3122  0.0145\n",
            "     48       40.3122  0.0146\n",
            "     49       40.3123  0.0145\n",
            "     50       40.3123  0.0145\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0139\n",
            "      2       37.1930  0.0149\n",
            "      3       37.1930  0.0157\n",
            "      4       37.1930  0.0170\n",
            "      5       37.1930  0.0174\n",
            "      6       37.1930  0.0165\n",
            "      7       37.1930  0.0202\n",
            "      8       37.1930  0.0188\n",
            "      9       37.1930  0.0165\n",
            "     10       37.1930  0.0174\n",
            "     11       37.1930  0.0211\n",
            "     12       37.1930  0.0216\n",
            "     13       37.1930  0.0161\n",
            "     14       37.1930  0.0146\n",
            "     15       37.1930  0.0141\n",
            "     16       37.1930  0.0140\n",
            "     17       37.1930  0.0136\n",
            "     18       37.1930  0.0142\n",
            "     19       37.1930  0.0139\n",
            "     20       37.1930  0.0139\n",
            "     21       37.1930  0.0139\n",
            "     22       37.1930  0.0147\n",
            "     23       37.1930  0.0166\n",
            "     24       37.1930  0.0162\n",
            "     25       37.1930  0.0140\n",
            "     26       37.1930  0.0157\n",
            "     27       37.1930  0.0136\n",
            "     28       37.1930  0.0140\n",
            "     29       37.1930  0.0137\n",
            "     30       37.1930  0.0136\n",
            "     31       37.1930  0.0139\n",
            "     32       37.1930  0.0147\n",
            "     33       37.1930  0.0147\n",
            "     34       37.1930  0.0141\n",
            "     35       37.1930  0.0142\n",
            "     36       37.1930  0.0135\n",
            "     37       37.1930  0.0143\n",
            "     38       37.1930  0.0145\n",
            "     39       37.1930  0.0161\n",
            "     40       37.1930  0.0149\n",
            "     41       37.1930  0.0179\n",
            "     42       37.1930  0.0188\n",
            "     43       37.1930  0.0181\n",
            "     44       37.1930  0.0176\n",
            "     45       37.1930  0.0236\n",
            "     46       37.1930  0.0146\n",
            "     47       37.1930  0.0145\n",
            "     48       37.1930  0.0148\n",
            "     49       37.1930  0.0151\n",
            "     50       37.1930  0.0147\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m54.3857\u001b[0m  0.0233\n",
            "      2       \u001b[36m54.3155\u001b[0m  0.0247\n",
            "      3       \u001b[36m53.8060\u001b[0m  0.0221\n",
            "      4       \u001b[36m53.1222\u001b[0m  0.0188\n",
            "      5       53.1466  0.0266\n",
            "      6       53.5491  0.0269\n",
            "      7       53.5211  0.0261\n",
            "      8       53.5310  0.0239\n",
            "      9       53.8269  0.0199\n",
            "     10       53.5140  0.0292\n",
            "     11       53.4176  0.0215\n",
            "     12       53.3856  0.0314\n",
            "     13       53.3773  0.0219\n",
            "     14       53.3775  0.0314\n",
            "     15       53.3808  0.0224\n",
            "     16       53.3850  0.0271\n",
            "     17       53.3897  0.0246\n",
            "     18       53.3944  0.0248\n",
            "     19       53.3990  0.0304\n",
            "     20       53.4035  0.0270\n",
            "     21       53.4079  0.0284\n",
            "     22       53.4121  0.0270\n",
            "     23       53.4161  0.0253\n",
            "     24       53.4200  0.0281\n",
            "     25       53.4602  0.0243\n",
            "     26       53.4602  0.0249\n",
            "     27       53.4602  0.0229\n",
            "     28       53.4601  0.0195\n",
            "     29       53.4601  0.0233\n",
            "     30       53.4601  0.0261\n",
            "     31       53.4600  0.0206\n",
            "     32       53.4600  0.0262\n",
            "     33       53.4600  0.0286\n",
            "     34       53.4599  0.0232\n",
            "     35       53.4599  0.0237\n",
            "     36       53.4599  0.0205\n",
            "     37       53.4598  0.0235\n",
            "     38       53.4598  0.0245\n",
            "     39       53.4597  0.0194\n",
            "     40       53.4597  0.0228\n",
            "     41       53.4596  0.0266\n",
            "     42       53.4596  0.0236\n",
            "     43       53.4595  0.0220\n",
            "     44       53.4595  0.0199\n",
            "     45       53.4594  0.0227\n",
            "     46       53.4593  0.0216\n",
            "     47       53.4593  0.0217\n",
            "     48       53.4592  0.0241\n",
            "     49       53.4591  0.0272\n",
            "     50       53.4591  0.0253\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.8070\u001b[0m  0.0187\n",
            "      2       62.8070  0.0199\n",
            "      3       62.8070  0.0207\n",
            "      4       62.8070  0.0206\n",
            "      5       62.8070  0.0210\n",
            "      6       62.8070  0.0205\n",
            "      7       62.8070  0.0202\n",
            "      8       62.8070  0.0207\n",
            "      9       62.8070  0.0201\n",
            "     10       62.8070  0.0216\n",
            "     11       62.8070  0.0200\n",
            "     12       62.8070  0.0274\n",
            "     13       62.8070  0.0207\n",
            "     14       62.8070  0.0193\n",
            "     15       62.8070  0.0197\n",
            "     16       62.8070  0.0197\n",
            "     17       62.8070  0.0232\n",
            "     18       62.8070  0.0204\n",
            "     19       62.8070  0.0238\n",
            "     20       62.8070  0.0236\n",
            "     21       62.8070  0.0234\n",
            "     22       62.8070  0.0220\n",
            "     23       62.8070  0.0211\n",
            "     24       62.8070  0.0229\n",
            "     25       62.8070  0.0203\n",
            "     26       62.8070  0.0291\n",
            "     27       62.8070  0.0252\n",
            "     28       62.8070  0.0204\n",
            "     29       62.8070  0.0279\n",
            "     30       62.8070  0.0239\n",
            "     31       62.8070  0.0256\n",
            "     32       62.8070  0.0298\n",
            "     33       \u001b[36m62.4561\u001b[0m  0.0281\n",
            "     34       62.4561  0.0246\n",
            "     35       62.4561  0.0270\n",
            "     36       62.4561  0.0315\n",
            "     37       62.4561  0.0184\n",
            "     38       62.4561  0.0171\n",
            "     39       62.4561  0.0179\n",
            "     40       62.4561  0.0189\n",
            "     41       62.4561  0.0176\n",
            "     42       62.4561  0.0180\n",
            "     43       62.4561  0.0177\n",
            "     44       62.4561  0.0183\n",
            "     45       62.4561  0.0182\n",
            "     46       62.4561  0.0191\n",
            "     47       62.4561  0.0189\n",
            "     48       62.4561  0.0187\n",
            "     49       62.4561  0.0177\n",
            "     50       62.4561  0.0166\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m56.3380\u001b[0m  0.0111\n",
            "      2       56.3380  0.0151\n",
            "      3       56.3380  0.0159\n",
            "      4       56.3380  0.0154\n",
            "      5       56.3380  0.0118\n",
            "      6       56.3380  0.0122\n",
            "      7       56.3380  0.0168\n",
            "      8       56.3380  0.0146\n",
            "      9       56.3380  0.0117\n",
            "     10       56.3380  0.0119\n",
            "     11       56.3380  0.0149\n",
            "     12       56.3380  0.0151\n",
            "     13       56.3380  0.0150\n",
            "     14       56.3380  0.0148\n",
            "     15       56.3380  0.0148\n",
            "     16       56.3380  0.0114\n",
            "     17       56.3380  0.0125\n",
            "     18       56.3380  0.0155\n",
            "     19       56.3380  0.0146\n",
            "     20       56.3380  0.0147\n",
            "     21       56.3380  0.0131\n",
            "     22       56.3380  0.0127\n",
            "     23       56.3380  0.0155\n",
            "     24       56.3380  0.0150\n",
            "     25       56.3380  0.0127\n",
            "     26       56.3380  0.0126\n",
            "     27       56.3380  0.0222\n",
            "     28       56.3380  0.0156\n",
            "     29       56.3380  0.0145\n",
            "     30       56.3380  0.0145\n",
            "     31       56.3380  0.0158\n",
            "     32       56.3380  0.0146\n",
            "     33       56.3380  0.0150\n",
            "     34       56.3380  0.0178\n",
            "     35       56.3380  0.0169\n",
            "     36       56.3380  0.0156\n",
            "     37       56.3380  0.0161\n",
            "     38       56.3380  0.0223\n",
            "     39       56.3380  0.0149\n",
            "     40       56.3380  0.0147\n",
            "     41       56.3380  0.0122\n",
            "     42       56.3380  0.0125\n",
            "     43       56.3380  0.0150\n",
            "     44       56.3380  0.0149\n",
            "     45       56.3380  0.0153\n",
            "     46       56.3380  0.0142\n",
            "     47       56.3380  0.0154\n",
            "     48       56.3380  0.0149\n",
            "     49       56.3380  0.0118\n",
            "     50       56.3380  0.0129\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0125\n",
            "      2       37.1930  0.0149\n",
            "      3       37.1930  0.0155\n",
            "      4       37.1930  0.0143\n",
            "      5       37.1930  0.0110\n",
            "      6       37.1930  0.0116\n",
            "      7       37.1930  0.0150\n",
            "      8       37.1930  0.0148\n",
            "      9       37.1930  0.0129\n",
            "     10       37.1930  0.0122\n",
            "     11       37.1930  0.0143\n",
            "     12       37.1930  0.0148\n",
            "     13       37.1930  0.0137\n",
            "     14       37.1930  0.0123\n",
            "     15       37.1930  0.0150\n",
            "     16       37.1930  0.0147\n",
            "     17       37.1930  0.0147\n",
            "     18       37.1930  0.0155\n",
            "     19       37.1930  0.0134\n",
            "     20       37.1930  0.0161\n",
            "     21       37.1930  0.0160\n",
            "     22       37.1930  0.0124\n",
            "     23       37.1930  0.0132\n",
            "     24       37.1930  0.0159\n",
            "     25       37.1930  0.0149\n",
            "     26       37.1930  0.0135\n",
            "     27       37.1930  0.0105\n",
            "     28       37.1930  0.0139\n",
            "     29       37.1930  0.0145\n",
            "     30       37.1930  0.0141\n",
            "     31       37.1930  0.0129\n",
            "     32       37.1930  0.0112\n",
            "     33       37.1930  0.0160\n",
            "     34       37.1930  0.0146\n",
            "     35       37.1930  0.0123\n",
            "     36       37.1930  0.0121\n",
            "     37       37.1930  0.0160\n",
            "     38       37.1930  0.0182\n",
            "     39       37.1930  0.0171\n",
            "     40       37.1930  0.0154\n",
            "     41       37.1930  0.0149\n",
            "     42       37.1930  0.0145\n",
            "     43       37.1930  0.0202\n",
            "     44       37.1930  0.0159\n",
            "     45       37.1930  0.0197\n",
            "     46       37.1930  0.0187\n",
            "     47       37.1930  0.0159\n",
            "     48       37.1930  0.0180\n",
            "     49       37.1930  0.0172\n",
            "     50       37.1930  0.0172\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8441\u001b[0m  0.0146\n",
            "      2        \u001b[36m1.8179\u001b[0m  0.0172\n",
            "      3        \u001b[36m1.7919\u001b[0m  0.0195\n",
            "      4        \u001b[36m1.7655\u001b[0m  0.0170\n",
            "      5        \u001b[36m1.7389\u001b[0m  0.0151\n",
            "      6        \u001b[36m1.7120\u001b[0m  0.0184\n",
            "      7        \u001b[36m1.6848\u001b[0m  0.0202\n",
            "      8        \u001b[36m1.6571\u001b[0m  0.0175\n",
            "      9        \u001b[36m1.6290\u001b[0m  0.0150\n",
            "     10        \u001b[36m1.6001\u001b[0m  0.0187\n",
            "     11        \u001b[36m1.5704\u001b[0m  0.0188\n",
            "     12        \u001b[36m1.5395\u001b[0m  0.0179\n",
            "     13        \u001b[36m1.5070\u001b[0m  0.0150\n",
            "     14        \u001b[36m1.4722\u001b[0m  0.0217\n",
            "     15        \u001b[36m1.4344\u001b[0m  0.0187\n",
            "     16        \u001b[36m1.3927\u001b[0m  0.0210\n",
            "     17        \u001b[36m1.3460\u001b[0m  0.0152\n",
            "     18        \u001b[36m1.2931\u001b[0m  0.0226\n",
            "     19        \u001b[36m1.2334\u001b[0m  0.0193\n",
            "     20        \u001b[36m1.1665\u001b[0m  0.0202\n",
            "     21        \u001b[36m1.0934\u001b[0m  0.0211\n",
            "     22        \u001b[36m1.0164\u001b[0m  0.0181\n",
            "     23        \u001b[36m0.9393\u001b[0m  0.0177\n",
            "     24        \u001b[36m0.8669\u001b[0m  0.0169\n",
            "     25        \u001b[36m0.8039\u001b[0m  0.0177\n",
            "     26        \u001b[36m0.7535\u001b[0m  0.0181\n",
            "     27        \u001b[36m0.7170\u001b[0m  0.0172\n",
            "     28        \u001b[36m0.6930\u001b[0m  0.0173\n",
            "     29        \u001b[36m0.6788\u001b[0m  0.0170\n",
            "     30        \u001b[36m0.6710\u001b[0m  0.0175\n",
            "     31        \u001b[36m0.6669\u001b[0m  0.0189\n",
            "     32        \u001b[36m0.6648\u001b[0m  0.0172\n",
            "     33        \u001b[36m0.6637\u001b[0m  0.0173\n",
            "     34        \u001b[36m0.6630\u001b[0m  0.0170\n",
            "     35        \u001b[36m0.6627\u001b[0m  0.0167\n",
            "     36        \u001b[36m0.6625\u001b[0m  0.0197\n",
            "     37        \u001b[36m0.6624\u001b[0m  0.0157\n",
            "     38        \u001b[36m0.6623\u001b[0m  0.0174\n",
            "     39        \u001b[36m0.6622\u001b[0m  0.0182\n",
            "     40        \u001b[36m0.6622\u001b[0m  0.0202\n",
            "     41        \u001b[36m0.6622\u001b[0m  0.0208\n",
            "     42        \u001b[36m0.6622\u001b[0m  0.0230\n",
            "     43        \u001b[36m0.6621\u001b[0m  0.0190\n",
            "     44        \u001b[36m0.6621\u001b[0m  0.0203\n",
            "     45        \u001b[36m0.6621\u001b[0m  0.0218\n",
            "     46        \u001b[36m0.6621\u001b[0m  0.0216\n",
            "     47        \u001b[36m0.6621\u001b[0m  0.0200\n",
            "     48        \u001b[36m0.6621\u001b[0m  0.0185\n",
            "     49        \u001b[36m0.6621\u001b[0m  0.0179\n",
            "     50        \u001b[36m0.6621\u001b[0m  0.0181\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8906\u001b[0m  0.0143\n",
            "      2        \u001b[36m1.8636\u001b[0m  0.0167\n",
            "      3        \u001b[36m1.8385\u001b[0m  0.0173\n",
            "      4        \u001b[36m1.8134\u001b[0m  0.0174\n",
            "      5        \u001b[36m1.7881\u001b[0m  0.0147\n",
            "      6        \u001b[36m1.7627\u001b[0m  0.0186\n",
            "      7        \u001b[36m1.7370\u001b[0m  0.0181\n",
            "      8        \u001b[36m1.7111\u001b[0m  0.0175\n",
            "      9        \u001b[36m1.6848\u001b[0m  0.0142\n",
            "     10        \u001b[36m1.6582\u001b[0m  0.0178\n",
            "     11        \u001b[36m1.6310\u001b[0m  0.0185\n",
            "     12        \u001b[36m1.6031\u001b[0m  0.0175\n",
            "     13        \u001b[36m1.5743\u001b[0m  0.0149\n",
            "     14        \u001b[36m1.5441\u001b[0m  0.0195\n",
            "     15        \u001b[36m1.5121\u001b[0m  0.0171\n",
            "     16        \u001b[36m1.4776\u001b[0m  0.0168\n",
            "     17        \u001b[36m1.4398\u001b[0m  0.0151\n",
            "     18        \u001b[36m1.3975\u001b[0m  0.0205\n",
            "     19        \u001b[36m1.3493\u001b[0m  0.0175\n",
            "     20        \u001b[36m1.2936\u001b[0m  0.0173\n",
            "     21        \u001b[36m1.2291\u001b[0m  0.0143\n",
            "     22        \u001b[36m1.1548\u001b[0m  0.0178\n",
            "     23        \u001b[36m1.0713\u001b[0m  0.0186\n",
            "     24        \u001b[36m0.9817\u001b[0m  0.0164\n",
            "     25        \u001b[36m0.8925\u001b[0m  0.0159\n",
            "     26        \u001b[36m0.8127\u001b[0m  0.0202\n",
            "     27        \u001b[36m0.7504\u001b[0m  0.0163\n",
            "     28        \u001b[36m0.7090\u001b[0m  0.0185\n",
            "     29        \u001b[36m0.6853\u001b[0m  0.0145\n",
            "     30        \u001b[36m0.6732\u001b[0m  0.0190\n",
            "     31        \u001b[36m0.6672\u001b[0m  0.0171\n",
            "     32        \u001b[36m0.6643\u001b[0m  0.0180\n",
            "     33        \u001b[36m0.6630\u001b[0m  0.0148\n",
            "     34        \u001b[36m0.6624\u001b[0m  0.0179\n",
            "     35        \u001b[36m0.6623\u001b[0m  0.0184\n",
            "     36        \u001b[36m0.6622\u001b[0m  0.0194\n",
            "     37        0.6623  0.0154\n",
            "     38        0.6623  0.0190\n",
            "     39        0.6623  0.0161\n",
            "     40        0.6623  0.0192\n",
            "     41        0.6623  0.0150\n",
            "     42        0.6623  0.0199\n",
            "     43        0.6623  0.0211\n",
            "     44        0.6623  0.0263\n",
            "     45        0.6623  0.0193\n",
            "     46        0.6623  0.0212\n",
            "     47        \u001b[36m0.6622\u001b[0m  0.0189\n",
            "     48        \u001b[36m0.6622\u001b[0m  0.0215\n",
            "     49        \u001b[36m0.6622\u001b[0m  0.0250\n",
            "     50        \u001b[36m0.6622\u001b[0m  0.0180\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0595\u001b[0m  0.0101\n",
            "      2        \u001b[36m1.0510\u001b[0m  0.0138\n",
            "      3        \u001b[36m1.0426\u001b[0m  0.0133\n",
            "      4        \u001b[36m1.0343\u001b[0m  0.0133\n",
            "      5        \u001b[36m1.0261\u001b[0m  0.0104\n",
            "      6        \u001b[36m1.0180\u001b[0m  0.0104\n",
            "      7        \u001b[36m1.0100\u001b[0m  0.0151\n",
            "      8        \u001b[36m1.0021\u001b[0m  0.0146\n",
            "      9        \u001b[36m0.9943\u001b[0m  0.0139\n",
            "     10        \u001b[36m0.9867\u001b[0m  0.0115\n",
            "     11        \u001b[36m0.9791\u001b[0m  0.0122\n",
            "     12        \u001b[36m0.9716\u001b[0m  0.0151\n",
            "     13        \u001b[36m0.9642\u001b[0m  0.0148\n",
            "     14        \u001b[36m0.9569\u001b[0m  0.0121\n",
            "     15        \u001b[36m0.9498\u001b[0m  0.0128\n",
            "     16        \u001b[36m0.9427\u001b[0m  0.0148\n",
            "     17        \u001b[36m0.9358\u001b[0m  0.0141\n",
            "     18        \u001b[36m0.9289\u001b[0m  0.0137\n",
            "     19        \u001b[36m0.9222\u001b[0m  0.0136\n",
            "     20        \u001b[36m0.9156\u001b[0m  0.0144\n",
            "     21        \u001b[36m0.9090\u001b[0m  0.0143\n",
            "     22        \u001b[36m0.9026\u001b[0m  0.0131\n",
            "     23        \u001b[36m0.8963\u001b[0m  0.0136\n",
            "     24        \u001b[36m0.8902\u001b[0m  0.0162\n",
            "     25        \u001b[36m0.8841\u001b[0m  0.0149\n",
            "     26        \u001b[36m0.8781\u001b[0m  0.0117\n",
            "     27        \u001b[36m0.8723\u001b[0m  0.0117\n",
            "     28        \u001b[36m0.8665\u001b[0m  0.0154\n",
            "     29        \u001b[36m0.8609\u001b[0m  0.0143\n",
            "     30        \u001b[36m0.8554\u001b[0m  0.0122\n",
            "     31        \u001b[36m0.8500\u001b[0m  0.0121\n",
            "     32        \u001b[36m0.8447\u001b[0m  0.0152\n",
            "     33        \u001b[36m0.8395\u001b[0m  0.0147\n",
            "     34        \u001b[36m0.8344\u001b[0m  0.0126\n",
            "     35        \u001b[36m0.8294\u001b[0m  0.0123\n",
            "     36        \u001b[36m0.8245\u001b[0m  0.0169\n",
            "     37        \u001b[36m0.8197\u001b[0m  0.0150\n",
            "     38        \u001b[36m0.8151\u001b[0m  0.0131\n",
            "     39        \u001b[36m0.8105\u001b[0m  0.0129\n",
            "     40        \u001b[36m0.8061\u001b[0m  0.0148\n",
            "     41        \u001b[36m0.8017\u001b[0m  0.0142\n",
            "     42        \u001b[36m0.7974\u001b[0m  0.0118\n",
            "     43        \u001b[36m0.7933\u001b[0m  0.0126\n",
            "     44        \u001b[36m0.7892\u001b[0m  0.0151\n",
            "     45        \u001b[36m0.7853\u001b[0m  0.0150\n",
            "     46        \u001b[36m0.7814\u001b[0m  0.0123\n",
            "     47        \u001b[36m0.7777\u001b[0m  0.0136\n",
            "     48        \u001b[36m0.7740\u001b[0m  0.0155\n",
            "     49        \u001b[36m0.7704\u001b[0m  0.0146\n",
            "     50        \u001b[36m0.7669\u001b[0m  0.0138\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3807\u001b[0m  0.0173\n",
            "      2        \u001b[36m1.3706\u001b[0m  0.0168\n",
            "      3        \u001b[36m1.3604\u001b[0m  0.0183\n",
            "      4        \u001b[36m1.3503\u001b[0m  0.0182\n",
            "      5        \u001b[36m1.3403\u001b[0m  0.0188\n",
            "      6        \u001b[36m1.3303\u001b[0m  0.0177\n",
            "      7        \u001b[36m1.3204\u001b[0m  0.0167\n",
            "      8        \u001b[36m1.3105\u001b[0m  0.0154\n",
            "      9        \u001b[36m1.3006\u001b[0m  0.0148\n",
            "     10        \u001b[36m1.2908\u001b[0m  0.0158\n",
            "     11        \u001b[36m1.2811\u001b[0m  0.0153\n",
            "     12        \u001b[36m1.2714\u001b[0m  0.0147\n",
            "     13        \u001b[36m1.2618\u001b[0m  0.0155\n",
            "     14        \u001b[36m1.2523\u001b[0m  0.0154\n",
            "     15        \u001b[36m1.2428\u001b[0m  0.0146\n",
            "     16        \u001b[36m1.2333\u001b[0m  0.0145\n",
            "     17        \u001b[36m1.2239\u001b[0m  0.0143\n",
            "     18        \u001b[36m1.2146\u001b[0m  0.0145\n",
            "     19        \u001b[36m1.2054\u001b[0m  0.0168\n",
            "     20        \u001b[36m1.1962\u001b[0m  0.0148\n",
            "     21        \u001b[36m1.1871\u001b[0m  0.0141\n",
            "     22        \u001b[36m1.1780\u001b[0m  0.0141\n",
            "     23        \u001b[36m1.1690\u001b[0m  0.0150\n",
            "     24        \u001b[36m1.1601\u001b[0m  0.0143\n",
            "     25        \u001b[36m1.1513\u001b[0m  0.0159\n",
            "     26        \u001b[36m1.1425\u001b[0m  0.0143\n",
            "     27        \u001b[36m1.1338\u001b[0m  0.0141\n",
            "     28        \u001b[36m1.1252\u001b[0m  0.0148\n",
            "     29        \u001b[36m1.1166\u001b[0m  0.0156\n",
            "     30        \u001b[36m1.1081\u001b[0m  0.0171\n",
            "     31        \u001b[36m1.0997\u001b[0m  0.0160\n",
            "     32        \u001b[36m1.0914\u001b[0m  0.0169\n",
            "     33        \u001b[36m1.0832\u001b[0m  0.0146\n",
            "     34        \u001b[36m1.0750\u001b[0m  0.0154\n",
            "     35        \u001b[36m1.0670\u001b[0m  0.0148\n",
            "     36        \u001b[36m1.0590\u001b[0m  0.0148\n",
            "     37        \u001b[36m1.0511\u001b[0m  0.0154\n",
            "     38        \u001b[36m1.0433\u001b[0m  0.0145\n",
            "     39        \u001b[36m1.0355\u001b[0m  0.0146\n",
            "     40        \u001b[36m1.0279\u001b[0m  0.0141\n",
            "     41        \u001b[36m1.0203\u001b[0m  0.0137\n",
            "     42        \u001b[36m1.0129\u001b[0m  0.0152\n",
            "     43        \u001b[36m1.0055\u001b[0m  0.0151\n",
            "     44        \u001b[36m0.9982\u001b[0m  0.0143\n",
            "     45        \u001b[36m0.9910\u001b[0m  0.0143\n",
            "     46        \u001b[36m0.9839\u001b[0m  0.0145\n",
            "     47        \u001b[36m0.9769\u001b[0m  0.0136\n",
            "     48        \u001b[36m0.9700\u001b[0m  0.0127\n",
            "     49        \u001b[36m0.9632\u001b[0m  0.0139\n",
            "     50        \u001b[36m0.9564\u001b[0m  0.0142\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.8496\u001b[0m  0.0146\n",
            "      2        \u001b[36m2.8000\u001b[0m  0.0183\n",
            "      3        \u001b[36m2.7509\u001b[0m  0.0175\n",
            "      4        \u001b[36m2.7013\u001b[0m  0.0179\n",
            "      5        \u001b[36m2.6513\u001b[0m  0.0145\n",
            "      6        \u001b[36m2.6012\u001b[0m  0.0196\n",
            "      7        \u001b[36m2.5508\u001b[0m  0.0241\n",
            "      8        \u001b[36m2.5002\u001b[0m  0.0262\n",
            "      9        \u001b[36m2.4496\u001b[0m  0.0205\n",
            "     10        \u001b[36m2.3988\u001b[0m  0.0217\n",
            "     11        \u001b[36m2.3480\u001b[0m  0.0232\n",
            "     12        \u001b[36m2.2969\u001b[0m  0.0247\n",
            "     13        \u001b[36m2.2454\u001b[0m  0.0206\n",
            "     14        \u001b[36m2.1930\u001b[0m  0.0198\n",
            "     15        \u001b[36m2.1389\u001b[0m  0.0184\n",
            "     16        \u001b[36m2.0811\u001b[0m  0.0197\n",
            "     17        \u001b[36m2.0153\u001b[0m  0.0178\n",
            "     18        \u001b[36m1.9331\u001b[0m  0.0182\n",
            "     19        \u001b[36m1.8204\u001b[0m  0.0177\n",
            "     20        \u001b[36m1.6597\u001b[0m  0.0175\n",
            "     21        \u001b[36m1.4451\u001b[0m  0.0193\n",
            "     22        \u001b[36m1.1952\u001b[0m  0.0199\n",
            "     23        \u001b[36m0.9546\u001b[0m  0.0175\n",
            "     24        \u001b[36m0.7838\u001b[0m  0.0166\n",
            "     25        \u001b[36m0.7030\u001b[0m  0.0195\n",
            "     26        \u001b[36m0.6758\u001b[0m  0.0170\n",
            "     27        \u001b[36m0.6675\u001b[0m  0.0183\n",
            "     28        \u001b[36m0.6644\u001b[0m  0.0175\n",
            "     29        \u001b[36m0.6630\u001b[0m  0.0174\n",
            "     30        \u001b[36m0.6625\u001b[0m  0.0194\n",
            "     31        \u001b[36m0.6624\u001b[0m  0.0169\n",
            "     32        0.6625  0.0177\n",
            "     33        0.6626  0.0185\n",
            "     34        0.6627  0.0195\n",
            "     35        0.6627  0.0152\n",
            "     36        0.6627  0.0198\n",
            "     37        0.6627  0.0172\n",
            "     38        0.6627  0.0197\n",
            "     39        0.6627  0.0164\n",
            "     40        0.6627  0.0197\n",
            "     41        0.6627  0.0196\n",
            "     42        0.6627  0.0185\n",
            "     43        0.6627  0.0163\n",
            "     44        0.6627  0.0201\n",
            "     45        0.6627  0.0204\n",
            "     46        0.6627  0.0190\n",
            "     47        0.6627  0.0177\n",
            "     48        0.6627  0.0155\n",
            "     49        0.6626  0.0194\n",
            "     50        0.6626  0.0202\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6112\u001b[0m  0.0146\n",
            "      2        \u001b[36m2.5601\u001b[0m  0.0196\n",
            "      3        \u001b[36m2.5125\u001b[0m  0.0195\n",
            "      4        \u001b[36m2.4652\u001b[0m  0.0314\n",
            "      5        \u001b[36m2.4176\u001b[0m  0.0230\n",
            "      6        \u001b[36m2.3699\u001b[0m  0.0198\n",
            "      7        \u001b[36m2.3221\u001b[0m  0.0223\n",
            "      8        \u001b[36m2.2741\u001b[0m  0.0195\n",
            "      9        \u001b[36m2.2261\u001b[0m  0.0213\n",
            "     10        \u001b[36m2.1781\u001b[0m  0.0239\n",
            "     11        \u001b[36m2.1301\u001b[0m  0.0179\n",
            "     12        \u001b[36m2.0820\u001b[0m  0.0295\n",
            "     13        \u001b[36m2.0341\u001b[0m  0.0178\n",
            "     14        \u001b[36m1.9861\u001b[0m  0.0186\n",
            "     15        \u001b[36m1.9382\u001b[0m  0.0182\n",
            "     16        \u001b[36m1.8901\u001b[0m  0.0192\n",
            "     17        \u001b[36m1.8418\u001b[0m  0.0191\n",
            "     18        \u001b[36m1.7927\u001b[0m  0.0184\n",
            "     19        \u001b[36m1.7417\u001b[0m  0.0185\n",
            "     20        \u001b[36m1.6864\u001b[0m  0.0190\n",
            "     21        \u001b[36m1.6218\u001b[0m  0.0214\n",
            "     22        \u001b[36m1.5382\u001b[0m  0.0194\n",
            "     23        \u001b[36m1.4207\u001b[0m  0.0197\n",
            "     24        \u001b[36m1.2601\u001b[0m  0.0185\n",
            "     25        \u001b[36m1.0771\u001b[0m  0.0189\n",
            "     26        \u001b[36m0.9202\u001b[0m  0.0176\n",
            "     27        \u001b[36m0.8145\u001b[0m  0.0171\n",
            "     28        \u001b[36m0.7513\u001b[0m  0.0211\n",
            "     29        \u001b[36m0.7151\u001b[0m  0.0188\n",
            "     30        \u001b[36m0.6946\u001b[0m  0.0173\n",
            "     31        \u001b[36m0.6827\u001b[0m  0.0209\n",
            "     32        \u001b[36m0.6756\u001b[0m  0.0173\n",
            "     33        \u001b[36m0.6712\u001b[0m  0.0184\n",
            "     34        \u001b[36m0.6683\u001b[0m  0.0182\n",
            "     35        \u001b[36m0.6664\u001b[0m  0.0202\n",
            "     36        \u001b[36m0.6651\u001b[0m  0.0192\n",
            "     37        \u001b[36m0.6641\u001b[0m  0.0169\n",
            "     38        \u001b[36m0.6635\u001b[0m  0.0168\n",
            "     39        \u001b[36m0.6630\u001b[0m  0.0188\n",
            "     40        \u001b[36m0.6627\u001b[0m  0.0185\n",
            "     41        \u001b[36m0.6625\u001b[0m  0.0182\n",
            "     42        \u001b[36m0.6623\u001b[0m  0.0186\n",
            "     43        \u001b[36m0.6622\u001b[0m  0.0194\n",
            "     44        \u001b[36m0.6621\u001b[0m  0.0198\n",
            "     45        \u001b[36m0.6620\u001b[0m  0.0184\n",
            "     46        \u001b[36m0.6619\u001b[0m  0.0193\n",
            "     47        \u001b[36m0.6619\u001b[0m  0.0184\n",
            "     48        \u001b[36m0.6618\u001b[0m  0.0182\n",
            "     49        \u001b[36m0.6618\u001b[0m  0.0184\n",
            "     50        \u001b[36m0.6618\u001b[0m  0.0180\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1130\u001b[0m  0.0147\n",
            "      2        \u001b[36m3.0892\u001b[0m  0.0162\n",
            "      3        \u001b[36m3.0653\u001b[0m  0.0165\n",
            "      4        \u001b[36m3.0415\u001b[0m  0.0195\n",
            "      5        \u001b[36m3.0177\u001b[0m  0.0163\n",
            "      6        \u001b[36m2.9938\u001b[0m  0.0220\n",
            "      7        \u001b[36m2.9700\u001b[0m  0.0140\n",
            "      8        \u001b[36m2.9462\u001b[0m  0.0147\n",
            "      9        \u001b[36m2.9224\u001b[0m  0.0130\n",
            "     10        \u001b[36m2.8985\u001b[0m  0.0137\n",
            "     11        \u001b[36m2.8747\u001b[0m  0.0161\n",
            "     12        \u001b[36m2.8509\u001b[0m  0.0187\n",
            "     13        \u001b[36m2.8271\u001b[0m  0.0176\n",
            "     14        \u001b[36m2.8033\u001b[0m  0.0153\n",
            "     15        \u001b[36m2.7795\u001b[0m  0.0163\n",
            "     16        \u001b[36m2.7557\u001b[0m  0.0135\n",
            "     17        \u001b[36m2.7319\u001b[0m  0.0129\n",
            "     18        \u001b[36m2.7081\u001b[0m  0.0142\n",
            "     19        \u001b[36m2.6844\u001b[0m  0.0152\n",
            "     20        \u001b[36m2.6606\u001b[0m  0.0153\n",
            "     21        \u001b[36m2.6368\u001b[0m  0.0158\n",
            "     22        \u001b[36m2.6130\u001b[0m  0.0158\n",
            "     23        \u001b[36m2.5893\u001b[0m  0.0158\n",
            "     24        \u001b[36m2.5656\u001b[0m  0.0154\n",
            "     25        \u001b[36m2.5418\u001b[0m  0.0137\n",
            "     26        \u001b[36m2.5181\u001b[0m  0.0165\n",
            "     27        \u001b[36m2.4944\u001b[0m  0.0149\n",
            "     28        \u001b[36m2.4707\u001b[0m  0.0143\n",
            "     29        \u001b[36m2.4470\u001b[0m  0.0121\n",
            "     30        \u001b[36m2.4233\u001b[0m  0.0116\n",
            "     31        \u001b[36m2.3996\u001b[0m  0.0147\n",
            "     32        \u001b[36m2.3760\u001b[0m  0.0153\n",
            "     33        \u001b[36m2.3523\u001b[0m  0.0144\n",
            "     34        \u001b[36m2.3287\u001b[0m  0.0142\n",
            "     35        \u001b[36m2.3051\u001b[0m  0.0143\n",
            "     36        \u001b[36m2.2815\u001b[0m  0.0145\n",
            "     37        \u001b[36m2.2579\u001b[0m  0.0147\n",
            "     38        \u001b[36m2.2343\u001b[0m  0.0128\n",
            "     39        \u001b[36m2.2108\u001b[0m  0.0128\n",
            "     40        \u001b[36m2.1873\u001b[0m  0.0156\n",
            "     41        \u001b[36m2.1638\u001b[0m  0.0149\n",
            "     42        \u001b[36m2.1403\u001b[0m  0.0133\n",
            "     43        \u001b[36m2.1169\u001b[0m  0.0136\n",
            "     44        \u001b[36m2.0935\u001b[0m  0.0149\n",
            "     45        \u001b[36m2.0701\u001b[0m  0.0151\n",
            "     46        \u001b[36m2.0467\u001b[0m  0.0134\n",
            "     47        \u001b[36m2.0234\u001b[0m  0.0146\n",
            "     48        \u001b[36m2.0001\u001b[0m  0.0174\n",
            "     49        \u001b[36m1.9769\u001b[0m  0.0147\n",
            "     50        \u001b[36m1.9536\u001b[0m  0.0151\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.8912\u001b[0m  0.0109\n",
            "      2        \u001b[36m2.8689\u001b[0m  0.0164\n",
            "      3        \u001b[36m2.8467\u001b[0m  0.0143\n",
            "      4        \u001b[36m2.8244\u001b[0m  0.0136\n",
            "      5        \u001b[36m2.8021\u001b[0m  0.0156\n",
            "      6        \u001b[36m2.7798\u001b[0m  0.0110\n",
            "      7        \u001b[36m2.7576\u001b[0m  0.0123\n",
            "      8        \u001b[36m2.7353\u001b[0m  0.0196\n",
            "      9        \u001b[36m2.7130\u001b[0m  0.0250\n",
            "     10        \u001b[36m2.6908\u001b[0m  0.0160\n",
            "     11        \u001b[36m2.6685\u001b[0m  0.0183\n",
            "     12        \u001b[36m2.6463\u001b[0m  0.0151\n",
            "     13        \u001b[36m2.6240\u001b[0m  0.0220\n",
            "     14        \u001b[36m2.6018\u001b[0m  0.0169\n",
            "     15        \u001b[36m2.5796\u001b[0m  0.0155\n",
            "     16        \u001b[36m2.5574\u001b[0m  0.0168\n",
            "     17        \u001b[36m2.5351\u001b[0m  0.0147\n",
            "     18        \u001b[36m2.5130\u001b[0m  0.0151\n",
            "     19        \u001b[36m2.4908\u001b[0m  0.0152\n",
            "     20        \u001b[36m2.4686\u001b[0m  0.0113\n",
            "     21        \u001b[36m2.4464\u001b[0m  0.0197\n",
            "     22        \u001b[36m2.4242\u001b[0m  0.0168\n",
            "     23        \u001b[36m2.4021\u001b[0m  0.0156\n",
            "     24        \u001b[36m2.3799\u001b[0m  0.0152\n",
            "     25        \u001b[36m2.3578\u001b[0m  0.0141\n",
            "     26        \u001b[36m2.3357\u001b[0m  0.0130\n",
            "     27        \u001b[36m2.3136\u001b[0m  0.0151\n",
            "     28        \u001b[36m2.2915\u001b[0m  0.0152\n",
            "     29        \u001b[36m2.2694\u001b[0m  0.0130\n",
            "     30        \u001b[36m2.2474\u001b[0m  0.0137\n",
            "     31        \u001b[36m2.2253\u001b[0m  0.0154\n",
            "     32        \u001b[36m2.2033\u001b[0m  0.0151\n",
            "     33        \u001b[36m2.1813\u001b[0m  0.0136\n",
            "     34        \u001b[36m2.1593\u001b[0m  0.0126\n",
            "     35        \u001b[36m2.1374\u001b[0m  0.0146\n",
            "     36        \u001b[36m2.1154\u001b[0m  0.0149\n",
            "     37        \u001b[36m2.0935\u001b[0m  0.0107\n",
            "     38        \u001b[36m2.0717\u001b[0m  0.0120\n",
            "     39        \u001b[36m2.0498\u001b[0m  0.0157\n",
            "     40        \u001b[36m2.0280\u001b[0m  0.0145\n",
            "     41        \u001b[36m2.0062\u001b[0m  0.0113\n",
            "     42        \u001b[36m1.9844\u001b[0m  0.0131\n",
            "     43        \u001b[36m1.9627\u001b[0m  0.0147\n",
            "     44        \u001b[36m1.9410\u001b[0m  0.0144\n",
            "     45        \u001b[36m1.9194\u001b[0m  0.0132\n",
            "     46        \u001b[36m1.8977\u001b[0m  0.0142\n",
            "     47        \u001b[36m1.8762\u001b[0m  0.0171\n",
            "     48        \u001b[36m1.8547\u001b[0m  0.0153\n",
            "     49        \u001b[36m1.8332\u001b[0m  0.0127\n",
            "     50        \u001b[36m1.8118\u001b[0m  0.0131\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2403\u001b[0m  0.0184\n",
            "      2        \u001b[36m1.2087\u001b[0m  0.0180\n",
            "      3        \u001b[36m1.1630\u001b[0m  0.0205\n",
            "      4        \u001b[36m1.1226\u001b[0m  0.0176\n",
            "      5        \u001b[36m1.0851\u001b[0m  0.0155\n",
            "      6        \u001b[36m1.0470\u001b[0m  0.0178\n",
            "      7        \u001b[36m1.0141\u001b[0m  0.0198\n",
            "      8        \u001b[36m0.9771\u001b[0m  0.0201\n",
            "      9        \u001b[36m0.9464\u001b[0m  0.0174\n",
            "     10        \u001b[36m0.9186\u001b[0m  0.0161\n",
            "     11        \u001b[36m0.8904\u001b[0m  0.0196\n",
            "     12        \u001b[36m0.8655\u001b[0m  0.0199\n",
            "     13        \u001b[36m0.8428\u001b[0m  0.0223\n",
            "     14        \u001b[36m0.8230\u001b[0m  0.0186\n",
            "     15        \u001b[36m0.8059\u001b[0m  0.0250\n",
            "     16        \u001b[36m0.7901\u001b[0m  0.0222\n",
            "     17        \u001b[36m0.7768\u001b[0m  0.0226\n",
            "     18        \u001b[36m0.7652\u001b[0m  0.0174\n",
            "     19        \u001b[36m0.7551\u001b[0m  0.0181\n",
            "     20        \u001b[36m0.7463\u001b[0m  0.0189\n",
            "     21        \u001b[36m0.7385\u001b[0m  0.0180\n",
            "     22        \u001b[36m0.7315\u001b[0m  0.0224\n",
            "     23        \u001b[36m0.7253\u001b[0m  0.0234\n",
            "     24        \u001b[36m0.7197\u001b[0m  0.0217\n",
            "     25        \u001b[36m0.7146\u001b[0m  0.0272\n",
            "     26        \u001b[36m0.7099\u001b[0m  0.0284\n",
            "     27        \u001b[36m0.7055\u001b[0m  0.0223\n",
            "     28        \u001b[36m0.7015\u001b[0m  0.0208\n",
            "     29        \u001b[36m0.6978\u001b[0m  0.0223\n",
            "     30        \u001b[36m0.6943\u001b[0m  0.0259\n",
            "     31        \u001b[36m0.6910\u001b[0m  0.0221\n",
            "     32        \u001b[36m0.6879\u001b[0m  0.0224\n",
            "     33        \u001b[36m0.6849\u001b[0m  0.0217\n",
            "     34        \u001b[36m0.6824\u001b[0m  0.0196\n",
            "     35        \u001b[36m0.6794\u001b[0m  0.0197\n",
            "     36        \u001b[36m0.6768\u001b[0m  0.0222\n",
            "     37        \u001b[36m0.6744\u001b[0m  0.0233\n",
            "     38        \u001b[36m0.6723\u001b[0m  0.0197\n",
            "     39        \u001b[36m0.6700\u001b[0m  0.0194\n",
            "     40        \u001b[36m0.6678\u001b[0m  0.0203\n",
            "     41        \u001b[36m0.6657\u001b[0m  0.0259\n",
            "     42        \u001b[36m0.6637\u001b[0m  0.0269\n",
            "     43        \u001b[36m0.6617\u001b[0m  0.0250\n",
            "     44        \u001b[36m0.6600\u001b[0m  0.0229\n",
            "     45        \u001b[36m0.6580\u001b[0m  0.0260\n",
            "     46        \u001b[36m0.6578\u001b[0m  0.0200\n",
            "     47        \u001b[36m0.6564\u001b[0m  0.0195\n",
            "     48        \u001b[36m0.6543\u001b[0m  0.0199\n",
            "     49        \u001b[36m0.6530\u001b[0m  0.0246\n",
            "     50        \u001b[36m0.6514\u001b[0m  0.0226\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8101\u001b[0m  0.0200\n",
            "      2        \u001b[36m0.7572\u001b[0m  0.0188\n",
            "      3        \u001b[36m0.7233\u001b[0m  0.0256\n",
            "      4        \u001b[36m0.7005\u001b[0m  0.0229\n",
            "      5        \u001b[36m0.6838\u001b[0m  0.0286\n",
            "      6        \u001b[36m0.6724\u001b[0m  0.0275\n",
            "      7        \u001b[36m0.6648\u001b[0m  0.0263\n",
            "      8        \u001b[36m0.6597\u001b[0m  0.0248\n",
            "      9        \u001b[36m0.6568\u001b[0m  0.0206\n",
            "     10        \u001b[36m0.6539\u001b[0m  0.0256\n",
            "     11        \u001b[36m0.6522\u001b[0m  0.0218\n",
            "     12        \u001b[36m0.6460\u001b[0m  0.0223\n",
            "     13        \u001b[36m0.6450\u001b[0m  0.0210\n",
            "     14        \u001b[36m0.6442\u001b[0m  0.0207\n",
            "     15        \u001b[36m0.6435\u001b[0m  0.0188\n",
            "     16        \u001b[36m0.6428\u001b[0m  0.0236\n",
            "     17        \u001b[36m0.6423\u001b[0m  0.0248\n",
            "     18        \u001b[36m0.6409\u001b[0m  0.0214\n",
            "     19        \u001b[36m0.6395\u001b[0m  0.0256\n",
            "     20        \u001b[36m0.6390\u001b[0m  0.0193\n",
            "     21        \u001b[36m0.6384\u001b[0m  0.0195\n",
            "     22        \u001b[36m0.6379\u001b[0m  0.0203\n",
            "     23        \u001b[36m0.6374\u001b[0m  0.0195\n",
            "     24        \u001b[36m0.6369\u001b[0m  0.0199\n",
            "     25        \u001b[36m0.6364\u001b[0m  0.0195\n",
            "     26        \u001b[36m0.6358\u001b[0m  0.0195\n",
            "     27        \u001b[36m0.6353\u001b[0m  0.0192\n",
            "     28        \u001b[36m0.6347\u001b[0m  0.0191\n",
            "     29        \u001b[36m0.6342\u001b[0m  0.0285\n",
            "     30        \u001b[36m0.6336\u001b[0m  0.0262\n",
            "     31        \u001b[36m0.6330\u001b[0m  0.0191\n",
            "     32        \u001b[36m0.6324\u001b[0m  0.0197\n",
            "     33        \u001b[36m0.6318\u001b[0m  0.0204\n",
            "     34        \u001b[36m0.6311\u001b[0m  0.0198\n",
            "     35        \u001b[36m0.6304\u001b[0m  0.0197\n",
            "     36        \u001b[36m0.6298\u001b[0m  0.0191\n",
            "     37        \u001b[36m0.6291\u001b[0m  0.0191\n",
            "     38        \u001b[36m0.6284\u001b[0m  0.0206\n",
            "     39        \u001b[36m0.6278\u001b[0m  0.0236\n",
            "     40        \u001b[36m0.6272\u001b[0m  0.0208\n",
            "     41        \u001b[36m0.6266\u001b[0m  0.0198\n",
            "     42        \u001b[36m0.6260\u001b[0m  0.0269\n",
            "     43        \u001b[36m0.6248\u001b[0m  0.0227\n",
            "     44        0.6253  0.0221\n",
            "     45        \u001b[36m0.6239\u001b[0m  0.0224\n",
            "     46        \u001b[36m0.6235\u001b[0m  0.0223\n",
            "     47        \u001b[36m0.6231\u001b[0m  0.0192\n",
            "     48        \u001b[36m0.6227\u001b[0m  0.0237\n",
            "     49        \u001b[36m0.6223\u001b[0m  0.0212\n",
            "     50        \u001b[36m0.6220\u001b[0m  0.0186\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6552\u001b[0m  0.0144\n",
            "      2        \u001b[36m1.6362\u001b[0m  0.0146\n",
            "      3        \u001b[36m1.6175\u001b[0m  0.0148\n",
            "      4        \u001b[36m1.5991\u001b[0m  0.0146\n",
            "      5        \u001b[36m1.5808\u001b[0m  0.0147\n",
            "      6        \u001b[36m1.5627\u001b[0m  0.0150\n",
            "      7        \u001b[36m1.5448\u001b[0m  0.0148\n",
            "      8        \u001b[36m1.5271\u001b[0m  0.0143\n",
            "      9        \u001b[36m1.5095\u001b[0m  0.0148\n",
            "     10        \u001b[36m1.4922\u001b[0m  0.0191\n",
            "     11        \u001b[36m1.4751\u001b[0m  0.0188\n",
            "     12        \u001b[36m1.4582\u001b[0m  0.0152\n",
            "     13        \u001b[36m1.4415\u001b[0m  0.0143\n",
            "     14        \u001b[36m1.4249\u001b[0m  0.0197\n",
            "     15        \u001b[36m1.4086\u001b[0m  0.0174\n",
            "     16        \u001b[36m1.3925\u001b[0m  0.0154\n",
            "     17        \u001b[36m1.3766\u001b[0m  0.0154\n",
            "     18        \u001b[36m1.3609\u001b[0m  0.0151\n",
            "     19        \u001b[36m1.3454\u001b[0m  0.0164\n",
            "     20        \u001b[36m1.3301\u001b[0m  0.0147\n",
            "     21        \u001b[36m1.3150\u001b[0m  0.0148\n",
            "     22        \u001b[36m1.3001\u001b[0m  0.0152\n",
            "     23        \u001b[36m1.2854\u001b[0m  0.0148\n",
            "     24        \u001b[36m1.2710\u001b[0m  0.0144\n",
            "     25        \u001b[36m1.2567\u001b[0m  0.0159\n",
            "     26        \u001b[36m1.2427\u001b[0m  0.0242\n",
            "     27        \u001b[36m1.2289\u001b[0m  0.0232\n",
            "     28        \u001b[36m1.2153\u001b[0m  0.0213\n",
            "     29        \u001b[36m1.2019\u001b[0m  0.0241\n",
            "     30        \u001b[36m1.1887\u001b[0m  0.0184\n",
            "     31        \u001b[36m1.1757\u001b[0m  0.0181\n",
            "     32        \u001b[36m1.1630\u001b[0m  0.0160\n",
            "     33        \u001b[36m1.1504\u001b[0m  0.0182\n",
            "     34        \u001b[36m1.1381\u001b[0m  0.0173\n",
            "     35        \u001b[36m1.1260\u001b[0m  0.0148\n",
            "     36        \u001b[36m1.1141\u001b[0m  0.0186\n",
            "     37        \u001b[36m1.1024\u001b[0m  0.0186\n",
            "     38        \u001b[36m1.0909\u001b[0m  0.0209\n",
            "     39        \u001b[36m1.0796\u001b[0m  0.0178\n",
            "     40        \u001b[36m1.0686\u001b[0m  0.0195\n",
            "     41        \u001b[36m1.0577\u001b[0m  0.0239\n",
            "     42        \u001b[36m1.0471\u001b[0m  0.0219\n",
            "     43        \u001b[36m1.0366\u001b[0m  0.0190\n",
            "     44        \u001b[36m1.0264\u001b[0m  0.0203\n",
            "     45        \u001b[36m1.0163\u001b[0m  0.0196\n",
            "     46        \u001b[36m1.0065\u001b[0m  0.0198\n",
            "     47        \u001b[36m0.9969\u001b[0m  0.0182\n",
            "     48        \u001b[36m0.9874\u001b[0m  0.0184\n",
            "     49        \u001b[36m0.9782\u001b[0m  0.0174\n",
            "     50        \u001b[36m0.9691\u001b[0m  0.0168\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9448\u001b[0m  0.0169\n",
            "      2        \u001b[36m0.9404\u001b[0m  0.0180\n",
            "      3        \u001b[36m0.9360\u001b[0m  0.0172\n",
            "      4        \u001b[36m0.9316\u001b[0m  0.0166\n",
            "      5        \u001b[36m0.9273\u001b[0m  0.0206\n",
            "      6        \u001b[36m0.9230\u001b[0m  0.0197\n",
            "      7        \u001b[36m0.9187\u001b[0m  0.0160\n",
            "      8        \u001b[36m0.9144\u001b[0m  0.0236\n",
            "      9        \u001b[36m0.9101\u001b[0m  0.0174\n",
            "     10        \u001b[36m0.9059\u001b[0m  0.0190\n",
            "     11        \u001b[36m0.9017\u001b[0m  0.0191\n",
            "     12        \u001b[36m0.8975\u001b[0m  0.0199\n",
            "     13        \u001b[36m0.8934\u001b[0m  0.0168\n",
            "     14        \u001b[36m0.8892\u001b[0m  0.0232\n",
            "     15        \u001b[36m0.8851\u001b[0m  0.0178\n",
            "     16        \u001b[36m0.8811\u001b[0m  0.0177\n",
            "     17        \u001b[36m0.8770\u001b[0m  0.0204\n",
            "     18        \u001b[36m0.8730\u001b[0m  0.0184\n",
            "     19        \u001b[36m0.8690\u001b[0m  0.0193\n",
            "     20        \u001b[36m0.8650\u001b[0m  0.0153\n",
            "     21        \u001b[36m0.8611\u001b[0m  0.0177\n",
            "     22        \u001b[36m0.8572\u001b[0m  0.0186\n",
            "     23        \u001b[36m0.8533\u001b[0m  0.0227\n",
            "     24        \u001b[36m0.8494\u001b[0m  0.0164\n",
            "     25        \u001b[36m0.8456\u001b[0m  0.0149\n",
            "     26        \u001b[36m0.8418\u001b[0m  0.0149\n",
            "     27        \u001b[36m0.8381\u001b[0m  0.0188\n",
            "     28        \u001b[36m0.8344\u001b[0m  0.0170\n",
            "     29        \u001b[36m0.8307\u001b[0m  0.0221\n",
            "     30        \u001b[36m0.8270\u001b[0m  0.0236\n",
            "     31        \u001b[36m0.8234\u001b[0m  0.0188\n",
            "     32        \u001b[36m0.8198\u001b[0m  0.0242\n",
            "     33        \u001b[36m0.8163\u001b[0m  0.0200\n",
            "     34        \u001b[36m0.8128\u001b[0m  0.0221\n",
            "     35        \u001b[36m0.8093\u001b[0m  0.0206\n",
            "     36        \u001b[36m0.8059\u001b[0m  0.0237\n",
            "     37        \u001b[36m0.8025\u001b[0m  0.0200\n",
            "     38        \u001b[36m0.7992\u001b[0m  0.0184\n",
            "     39        \u001b[36m0.7959\u001b[0m  0.0251\n",
            "     40        \u001b[36m0.7927\u001b[0m  0.0205\n",
            "     41        \u001b[36m0.7895\u001b[0m  0.0173\n",
            "     42        \u001b[36m0.7864\u001b[0m  0.0191\n",
            "     43        \u001b[36m0.7833\u001b[0m  0.0216\n",
            "     44        \u001b[36m0.7803\u001b[0m  0.0202\n",
            "     45        \u001b[36m0.7773\u001b[0m  0.0187\n",
            "     46        \u001b[36m0.7744\u001b[0m  0.0204\n",
            "     47        \u001b[36m0.7716\u001b[0m  0.0193\n",
            "     48        \u001b[36m0.7688\u001b[0m  0.0162\n",
            "     49        \u001b[36m0.7661\u001b[0m  0.0156\n",
            "     50        \u001b[36m0.7634\u001b[0m  0.0164\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.4809\u001b[0m  0.0205\n",
            "      2        \u001b[36m2.1857\u001b[0m  0.0201\n",
            "      3        \u001b[36m1.9605\u001b[0m  0.0197\n",
            "      4        \u001b[36m1.7324\u001b[0m  0.0205\n",
            "      5        \u001b[36m1.5506\u001b[0m  0.0200\n",
            "      6        \u001b[36m1.3885\u001b[0m  0.0192\n",
            "      7        \u001b[36m1.2517\u001b[0m  0.0207\n",
            "      8        \u001b[36m1.1465\u001b[0m  0.0206\n",
            "      9        \u001b[36m1.0499\u001b[0m  0.0201\n",
            "     10        \u001b[36m0.9661\u001b[0m  0.0203\n",
            "     11        \u001b[36m0.9063\u001b[0m  0.0198\n",
            "     12        \u001b[36m0.8638\u001b[0m  0.0208\n",
            "     13        \u001b[36m0.8401\u001b[0m  0.0226\n",
            "     14        \u001b[36m0.8281\u001b[0m  0.0223\n",
            "     15        \u001b[36m0.8121\u001b[0m  0.0203\n",
            "     16        \u001b[36m0.8037\u001b[0m  0.0215\n",
            "     17        \u001b[36m0.7874\u001b[0m  0.0207\n",
            "     18        \u001b[36m0.7668\u001b[0m  0.0208\n",
            "     19        \u001b[36m0.7564\u001b[0m  0.0206\n",
            "     20        \u001b[36m0.7446\u001b[0m  0.0201\n",
            "     21        \u001b[36m0.7370\u001b[0m  0.0190\n",
            "     22        \u001b[36m0.7287\u001b[0m  0.0205\n",
            "     23        \u001b[36m0.7227\u001b[0m  0.0213\n",
            "     24        0.7272  0.0212\n",
            "     25        \u001b[36m0.7127\u001b[0m  0.0205\n",
            "     26        \u001b[36m0.7074\u001b[0m  0.0207\n",
            "     27        \u001b[36m0.7027\u001b[0m  0.0205\n",
            "     28        \u001b[36m0.6983\u001b[0m  0.0235\n",
            "     29        \u001b[36m0.6940\u001b[0m  0.0218\n",
            "     30        \u001b[36m0.6899\u001b[0m  0.0274\n",
            "     31        \u001b[36m0.6859\u001b[0m  0.0282\n",
            "     32        \u001b[36m0.6821\u001b[0m  0.0334\n",
            "     33        \u001b[36m0.6784\u001b[0m  0.0302\n",
            "     34        \u001b[36m0.6748\u001b[0m  0.0262\n",
            "     35        \u001b[36m0.6713\u001b[0m  0.0198\n",
            "     36        \u001b[36m0.6680\u001b[0m  0.0230\n",
            "     37        \u001b[36m0.6647\u001b[0m  0.0225\n",
            "     38        \u001b[36m0.6616\u001b[0m  0.0250\n",
            "     39        \u001b[36m0.6586\u001b[0m  0.0237\n",
            "     40        \u001b[36m0.6557\u001b[0m  0.0229\n",
            "     41        \u001b[36m0.6528\u001b[0m  0.0235\n",
            "     42        \u001b[36m0.6501\u001b[0m  0.0250\n",
            "     43        \u001b[36m0.6475\u001b[0m  0.0235\n",
            "     44        \u001b[36m0.6449\u001b[0m  0.0265\n",
            "     45        \u001b[36m0.6425\u001b[0m  0.0253\n",
            "     46        \u001b[36m0.6401\u001b[0m  0.0264\n",
            "     47        \u001b[36m0.6377\u001b[0m  0.0254\n",
            "     48        \u001b[36m0.6355\u001b[0m  0.0256\n",
            "     49        \u001b[36m0.6333\u001b[0m  0.0205\n",
            "     50        \u001b[36m0.6312\u001b[0m  0.0196\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1262\u001b[0m  0.0194\n",
            "      2        \u001b[36m1.0510\u001b[0m  0.0219\n",
            "      3        \u001b[36m1.0017\u001b[0m  0.0215\n",
            "      4        \u001b[36m0.9538\u001b[0m  0.0223\n",
            "      5        \u001b[36m0.9130\u001b[0m  0.0203\n",
            "      6        \u001b[36m0.8834\u001b[0m  0.0197\n",
            "      7        \u001b[36m0.8530\u001b[0m  0.0199\n",
            "      8        \u001b[36m0.8390\u001b[0m  0.0195\n",
            "      9        \u001b[36m0.8202\u001b[0m  0.0191\n",
            "     10        0.8284  0.0177\n",
            "     11        \u001b[36m0.8078\u001b[0m  0.0167\n",
            "     12        \u001b[36m0.7995\u001b[0m  0.0180\n",
            "     13        \u001b[36m0.7924\u001b[0m  0.0170\n",
            "     14        \u001b[36m0.7790\u001b[0m  0.0172\n",
            "     15        \u001b[36m0.7721\u001b[0m  0.0194\n",
            "     16        \u001b[36m0.7654\u001b[0m  0.0174\n",
            "     17        \u001b[36m0.7589\u001b[0m  0.0211\n",
            "     18        \u001b[36m0.7526\u001b[0m  0.0246\n",
            "     19        \u001b[36m0.7408\u001b[0m  0.0238\n",
            "     20        0.7514  0.0204\n",
            "     21        \u001b[36m0.7271\u001b[0m  0.0179\n",
            "     22        \u001b[36m0.7161\u001b[0m  0.0181\n",
            "     23        0.7176  0.0185\n",
            "     24        \u001b[36m0.7057\u001b[0m  0.0179\n",
            "     25        \u001b[36m0.7006\u001b[0m  0.0194\n",
            "     26        \u001b[36m0.6957\u001b[0m  0.0182\n",
            "     27        \u001b[36m0.6933\u001b[0m  0.0171\n",
            "     28        \u001b[36m0.6861\u001b[0m  0.0164\n",
            "     29        \u001b[36m0.6804\u001b[0m  0.0174\n",
            "     30        \u001b[36m0.6758\u001b[0m  0.0194\n",
            "     31        \u001b[36m0.6711\u001b[0m  0.0183\n",
            "     32        \u001b[36m0.6665\u001b[0m  0.0189\n",
            "     33        \u001b[36m0.6619\u001b[0m  0.0193\n",
            "     34        \u001b[36m0.6565\u001b[0m  0.0181\n",
            "     35        \u001b[36m0.6550\u001b[0m  0.0206\n",
            "     36        \u001b[36m0.6503\u001b[0m  0.0181\n",
            "     37        \u001b[36m0.6460\u001b[0m  0.0175\n",
            "     38        \u001b[36m0.6411\u001b[0m  0.0199\n",
            "     39        \u001b[36m0.6395\u001b[0m  0.0173\n",
            "     40        \u001b[36m0.6361\u001b[0m  0.0173\n",
            "     41        \u001b[36m0.6328\u001b[0m  0.0187\n",
            "     42        \u001b[36m0.6299\u001b[0m  0.0172\n",
            "     43        \u001b[36m0.6266\u001b[0m  0.0188\n",
            "     44        \u001b[36m0.6241\u001b[0m  0.0193\n",
            "     45        \u001b[36m0.6206\u001b[0m  0.0183\n",
            "     46        0.6271  0.0205\n",
            "     47        0.6273  0.0167\n",
            "     48        0.6267  0.0184\n",
            "     49        0.6350  0.0160\n",
            "     50        0.6637  0.0214\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.1309\u001b[0m  0.0124\n",
            "      2        \u001b[36m1.1001\u001b[0m  0.0160\n",
            "      3        \u001b[36m1.0746\u001b[0m  0.0147\n",
            "      4        \u001b[36m1.0462\u001b[0m  0.0201\n",
            "      5        \u001b[36m1.0286\u001b[0m  0.0153\n",
            "      6        \u001b[36m1.0074\u001b[0m  0.0149\n",
            "      7        \u001b[36m0.9947\u001b[0m  0.0147\n",
            "      8        \u001b[36m0.9832\u001b[0m  0.0157\n",
            "      9        \u001b[36m0.9722\u001b[0m  0.0110\n",
            "     10        \u001b[36m0.9631\u001b[0m  0.0143\n",
            "     11        \u001b[36m0.9550\u001b[0m  0.0177\n",
            "     12        \u001b[36m0.9477\u001b[0m  0.0162\n",
            "     13        \u001b[36m0.9412\u001b[0m  0.0127\n",
            "     14        \u001b[36m0.9353\u001b[0m  0.0138\n",
            "     15        \u001b[36m0.9300\u001b[0m  0.0151\n",
            "     16        \u001b[36m0.9251\u001b[0m  0.0148\n",
            "     17        \u001b[36m0.9207\u001b[0m  0.0114\n",
            "     18        \u001b[36m0.9167\u001b[0m  0.0121\n",
            "     19        \u001b[36m0.9130\u001b[0m  0.0181\n",
            "     20        \u001b[36m0.9096\u001b[0m  0.0233\n",
            "     21        \u001b[36m0.9064\u001b[0m  0.0177\n",
            "     22        \u001b[36m0.9034\u001b[0m  0.0181\n",
            "     23        \u001b[36m0.9006\u001b[0m  0.0172\n",
            "     24        \u001b[36m0.8980\u001b[0m  0.0162\n",
            "     25        \u001b[36m0.8956\u001b[0m  0.0163\n",
            "     26        \u001b[36m0.8932\u001b[0m  0.0153\n",
            "     27        \u001b[36m0.8910\u001b[0m  0.0149\n",
            "     28        \u001b[36m0.8888\u001b[0m  0.0135\n",
            "     29        \u001b[36m0.8868\u001b[0m  0.0168\n",
            "     30        \u001b[36m0.8848\u001b[0m  0.0134\n",
            "     31        \u001b[36m0.8829\u001b[0m  0.0146\n",
            "     32        \u001b[36m0.8810\u001b[0m  0.0148\n",
            "     33        \u001b[36m0.8792\u001b[0m  0.0147\n",
            "     34        \u001b[36m0.8774\u001b[0m  0.0173\n",
            "     35        \u001b[36m0.8756\u001b[0m  0.0146\n",
            "     36        \u001b[36m0.8739\u001b[0m  0.0158\n",
            "     37        \u001b[36m0.8722\u001b[0m  0.0151\n",
            "     38        \u001b[36m0.8706\u001b[0m  0.0146\n",
            "     39        \u001b[36m0.8689\u001b[0m  0.0151\n",
            "     40        \u001b[36m0.8673\u001b[0m  0.0148\n",
            "     41        \u001b[36m0.8657\u001b[0m  0.0147\n",
            "     42        \u001b[36m0.8641\u001b[0m  0.0170\n",
            "     43        \u001b[36m0.8625\u001b[0m  0.0156\n",
            "     44        \u001b[36m0.8609\u001b[0m  0.0149\n",
            "     45        \u001b[36m0.8594\u001b[0m  0.0143\n",
            "     46        \u001b[36m0.8578\u001b[0m  0.0152\n",
            "     47        \u001b[36m0.8563\u001b[0m  0.0134\n",
            "     48        \u001b[36m0.8547\u001b[0m  0.0149\n",
            "     49        \u001b[36m0.8532\u001b[0m  0.0144\n",
            "     50        \u001b[36m0.8516\u001b[0m  0.0137\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.8437\u001b[0m  0.0103\n",
            "      2        \u001b[36m1.8094\u001b[0m  0.0147\n",
            "      3        \u001b[36m1.7757\u001b[0m  0.0155\n",
            "      4        \u001b[36m1.7427\u001b[0m  0.0137\n",
            "      5        \u001b[36m1.7104\u001b[0m  0.0112\n",
            "      6        \u001b[36m1.6790\u001b[0m  0.0122\n",
            "      7        \u001b[36m1.6485\u001b[0m  0.0162\n",
            "      8        \u001b[36m1.6190\u001b[0m  0.0154\n",
            "      9        \u001b[36m1.5904\u001b[0m  0.0146\n",
            "     10        \u001b[36m1.5628\u001b[0m  0.0139\n",
            "     11        \u001b[36m1.5362\u001b[0m  0.0155\n",
            "     12        \u001b[36m1.5105\u001b[0m  0.0161\n",
            "     13        \u001b[36m1.4859\u001b[0m  0.0214\n",
            "     14        \u001b[36m1.4622\u001b[0m  0.0175\n",
            "     15        \u001b[36m1.4394\u001b[0m  0.0174\n",
            "     16        \u001b[36m1.4176\u001b[0m  0.0156\n",
            "     17        \u001b[36m1.3967\u001b[0m  0.0147\n",
            "     18        \u001b[36m1.3766\u001b[0m  0.0163\n",
            "     19        \u001b[36m1.3574\u001b[0m  0.0148\n",
            "     20        \u001b[36m1.3391\u001b[0m  0.0147\n",
            "     21        \u001b[36m1.3215\u001b[0m  0.0146\n",
            "     22        \u001b[36m1.3047\u001b[0m  0.0144\n",
            "     23        \u001b[36m1.2886\u001b[0m  0.0151\n",
            "     24        \u001b[36m1.2732\u001b[0m  0.0146\n",
            "     25        \u001b[36m1.2585\u001b[0m  0.0156\n",
            "     26        \u001b[36m1.2444\u001b[0m  0.0157\n",
            "     27        \u001b[36m1.2308\u001b[0m  0.0163\n",
            "     28        \u001b[36m1.2178\u001b[0m  0.0159\n",
            "     29        \u001b[36m1.2054\u001b[0m  0.0156\n",
            "     30        \u001b[36m1.1934\u001b[0m  0.0170\n",
            "     31        \u001b[36m1.1818\u001b[0m  0.0185\n",
            "     32        \u001b[36m1.1707\u001b[0m  0.0161\n",
            "     33        \u001b[36m1.1600\u001b[0m  0.0166\n",
            "     34        \u001b[36m1.1496\u001b[0m  0.0147\n",
            "     35        \u001b[36m1.1396\u001b[0m  0.0159\n",
            "     36        \u001b[36m1.1299\u001b[0m  0.0142\n",
            "     37        \u001b[36m1.1205\u001b[0m  0.0141\n",
            "     38        \u001b[36m1.1114\u001b[0m  0.0138\n",
            "     39        \u001b[36m1.1026\u001b[0m  0.0156\n",
            "     40        \u001b[36m1.0940\u001b[0m  0.0148\n",
            "     41        \u001b[36m1.0857\u001b[0m  0.0166\n",
            "     42        \u001b[36m1.0776\u001b[0m  0.0145\n",
            "     43        \u001b[36m1.0737\u001b[0m  0.0162\n",
            "     44        \u001b[36m1.0598\u001b[0m  0.0143\n",
            "     45        \u001b[36m1.0254\u001b[0m  0.0160\n",
            "     46        \u001b[36m1.0185\u001b[0m  0.0143\n",
            "     47        \u001b[36m1.0119\u001b[0m  0.0137\n",
            "     48        \u001b[36m1.0054\u001b[0m  0.0147\n",
            "     49        \u001b[36m0.9992\u001b[0m  0.0156\n",
            "     50        \u001b[36m0.9931\u001b[0m  0.0130\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0138\n",
            "      2       37.3239  0.0179\n",
            "      3       37.3239  0.0200\n",
            "      4       37.3239  0.0177\n",
            "      5       37.3239  0.0142\n",
            "      6       37.3239  0.0197\n",
            "      7       37.3239  0.0183\n",
            "      8       37.3239  0.0197\n",
            "      9       37.3239  0.0148\n",
            "     10       37.3239  0.0197\n",
            "     11       37.3239  0.0189\n",
            "     12       37.3239  0.0192\n",
            "     13       37.3239  0.0162\n",
            "     14       37.3239  0.0192\n",
            "     15       37.3239  0.0185\n",
            "     16       37.3239  0.0200\n",
            "     17       37.3239  0.0184\n",
            "     18       37.3239  0.0178\n",
            "     19       37.3239  0.0144\n",
            "     20       37.3239  0.0283\n",
            "     21       37.3239  0.0213\n",
            "     22       37.3239  0.0178\n",
            "     23       37.3239  0.0150\n",
            "     24       37.3239  0.0195\n",
            "     25       37.3239  0.0192\n",
            "     26       37.3239  0.0170\n",
            "     27       37.3239  0.0174\n",
            "     28       37.3239  0.0238\n",
            "     29       37.3239  0.0222\n",
            "     30       37.3239  0.0222\n",
            "     31       37.3239  0.0234\n",
            "     32       37.3239  0.0151\n",
            "     33       37.3239  0.0204\n",
            "     34       37.3239  0.0171\n",
            "     35       37.3239  0.0174\n",
            "     36       37.3239  0.0175\n",
            "     37       37.3239  0.0176\n",
            "     38       37.3239  0.0166\n",
            "     39       37.3239  0.0202\n",
            "     40       37.3239  0.0166\n",
            "     41       37.3239  0.0175\n",
            "     42       37.3239  0.0179\n",
            "     43       37.3239  0.0203\n",
            "     44       37.3239  0.0175\n",
            "     45       37.3239  0.0177\n",
            "     46       37.3239  0.0185\n",
            "     47       37.3239  0.0164\n",
            "     48       37.3239  0.0183\n",
            "     49       37.3239  0.0177\n",
            "     50       37.3239  0.0194\n",
            "     51       37.3239  0.0168\n",
            "     52       37.3239  0.0193\n",
            "     53       37.3239  0.0182\n",
            "     54       37.3239  0.0184\n",
            "     55       37.3239  0.0177\n",
            "     56       37.3239  0.0183\n",
            "     57       37.3239  0.0196\n",
            "     58       37.3239  0.0183\n",
            "     59       37.3239  0.0182\n",
            "     60       37.3239  0.0174\n",
            "     61       37.3239  0.0190\n",
            "     62       37.3239  0.0196\n",
            "     63       37.3239  0.0166\n",
            "     64       37.3239  0.0174\n",
            "     65       37.3239  0.0199\n",
            "     66       37.3239  0.0179\n",
            "     67       37.3239  0.0177\n",
            "     68       37.3239  0.0176\n",
            "     69       37.3239  0.0200\n",
            "     70       37.3239  0.0174\n",
            "     71       37.3239  0.0218\n",
            "     72       37.3239  0.0218\n",
            "     73       37.3239  0.0197\n",
            "     74       37.3239  0.0190\n",
            "     75       37.3239  0.0178\n",
            "     76       37.3239  0.0185\n",
            "     77       37.3239  0.0237\n",
            "     78       37.3239  0.0233\n",
            "     79       37.3239  0.0207\n",
            "     80       37.3239  0.0209\n",
            "     81       37.3239  0.0189\n",
            "     82       37.3239  0.0211\n",
            "     83       37.3239  0.0182\n",
            "     84       37.3239  0.0195\n",
            "     85       37.3239  0.0188\n",
            "     86       37.3239  0.0179\n",
            "     87       37.3239  0.0174\n",
            "     88       37.3239  0.0177\n",
            "     89       37.3239  0.0194\n",
            "     90       37.3239  0.0181\n",
            "     91       37.3239  0.0206\n",
            "     92       37.3239  0.0195\n",
            "     93       37.3239  0.0177\n",
            "     94       37.3239  0.0183\n",
            "     95       37.3239  0.0195\n",
            "     96       37.3239  0.0193\n",
            "     97       37.3239  0.0167\n",
            "     98       37.3239  0.0192\n",
            "     99       37.3239  0.0179\n",
            "    100       37.3239  0.0192\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0151\n",
            "      2       37.1930  0.0191\n",
            "      3       37.1930  0.0187\n",
            "      4       37.1930  0.0179\n",
            "      5       37.1930  0.0148\n",
            "      6       37.1930  0.0204\n",
            "      7       37.1930  0.0197\n",
            "      8       37.1930  0.0174\n",
            "      9       37.1930  0.0146\n",
            "     10       37.1930  0.0205\n",
            "     11       37.1930  0.0200\n",
            "     12       37.1930  0.0170\n",
            "     13       37.1930  0.0146\n",
            "     14       37.1930  0.0188\n",
            "     15       37.1930  0.0197\n",
            "     16       37.1930  0.0172\n",
            "     17       37.1930  0.0145\n",
            "     18       37.1930  0.0196\n",
            "     19       37.1930  0.0195\n",
            "     20       37.1930  0.0182\n",
            "     21       37.1930  0.0237\n",
            "     22       37.1930  0.0201\n",
            "     23       37.1930  0.0178\n",
            "     24       37.1930  0.0216\n",
            "     25       37.1930  0.0210\n",
            "     26       37.1930  0.0213\n",
            "     27       37.1930  0.0226\n",
            "     28       37.1930  0.0210\n",
            "     29       37.1930  0.0199\n",
            "     30       37.1930  0.0185\n",
            "     31       37.1930  0.0200\n",
            "     32       37.1930  0.0188\n",
            "     33       37.1930  0.0181\n",
            "     34       37.1930  0.0183\n",
            "     35       37.1930  0.0173\n",
            "     36       37.1930  0.0196\n",
            "     37       37.1930  0.0179\n",
            "     38       37.1930  0.0178\n",
            "     39       37.1930  0.0171\n",
            "     40       37.1930  0.0182\n",
            "     41       37.1930  0.0184\n",
            "     42       37.1930  0.0190\n",
            "     43       37.1930  0.0189\n",
            "     44       37.1930  0.0200\n",
            "     45       37.1930  0.0198\n",
            "     46       37.1930  0.0185\n",
            "     47       37.1930  0.0177\n",
            "     48       37.1930  0.0185\n",
            "     49       37.1930  0.0202\n",
            "     50       37.1930  0.0186\n",
            "     51       37.1930  0.0172\n",
            "     52       37.1930  0.0176\n",
            "     53       37.1930  0.0180\n",
            "     54       37.1930  0.0183\n",
            "     55       37.1930  0.0173\n",
            "     56       37.1930  0.0175\n",
            "     57       37.1930  0.0189\n",
            "     58       37.1930  0.0204\n",
            "     59       37.1930  0.0178\n",
            "     60       37.1930  0.0147\n",
            "     61       37.1930  0.0211\n",
            "     62       37.1930  0.0185\n",
            "     63       37.1930  0.0178\n",
            "     64       37.1930  0.0150\n",
            "     65       37.1930  0.0197\n",
            "     66       37.1930  0.0193\n",
            "     67       37.1930  0.0181\n",
            "     68       37.1930  0.0156\n",
            "     69       37.1930  0.0208\n",
            "     70       37.1930  0.0198\n",
            "     71       37.1930  0.0206\n",
            "     72       37.1930  0.0202\n",
            "     73       37.1930  0.0220\n",
            "     74       37.1930  0.0211\n",
            "     75       37.1930  0.0214\n",
            "     76       37.1930  0.0218\n",
            "     77       37.1930  0.0224\n",
            "     78       37.1930  0.0194\n",
            "     79       37.1930  0.0185\n",
            "     80       37.1930  0.0193\n",
            "     81       37.1930  0.0180\n",
            "     82       37.1930  0.0197\n",
            "     83       37.1930  0.0179\n",
            "     84       37.1930  0.0172\n",
            "     85       37.1930  0.0178\n",
            "     86       37.1930  0.0180\n",
            "     87       37.1930  0.0191\n",
            "     88       37.1930  0.0182\n",
            "     89       37.1930  0.0179\n",
            "     90       37.1930  0.0208\n",
            "     91       37.1930  0.0176\n",
            "     92       37.1930  0.0181\n",
            "     93       37.1930  0.0185\n",
            "     94       37.1930  0.0228\n",
            "     95       37.1930  0.0179\n",
            "     96       37.1930  0.0201\n",
            "     97       37.1930  0.0175\n",
            "     98       37.1930  0.0204\n",
            "     99       37.1930  0.0166\n",
            "    100       37.1930  0.0195\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0111\n",
            "      2       37.3239  0.0147\n",
            "      3       37.3239  0.0163\n",
            "      4       37.3239  0.0157\n",
            "      5       37.3239  0.0106\n",
            "      6       37.3239  0.0118\n",
            "      7       37.3239  0.0144\n",
            "      8       37.3239  0.0141\n",
            "      9       37.3239  0.0150\n",
            "     10       37.3239  0.0138\n",
            "     11       37.3239  0.0142\n",
            "     12       37.3239  0.0146\n",
            "     13       37.3239  0.0140\n",
            "     14       37.3239  0.0113\n",
            "     15       37.3239  0.0148\n",
            "     16       37.3239  0.0142\n",
            "     17       37.3239  0.0116\n",
            "     18       37.3239  0.0113\n",
            "     19       37.3239  0.0148\n",
            "     20       37.3239  0.0145\n",
            "     21       37.3239  0.0139\n",
            "     22       37.3239  0.0126\n",
            "     23       37.3239  0.0147\n",
            "     24       37.3239  0.0141\n",
            "     25       37.3239  0.0133\n",
            "     26       37.3239  0.0205\n",
            "     27       37.3239  0.0180\n",
            "     28       37.3239  0.0162\n",
            "     29       37.3239  0.0198\n",
            "     30       37.3239  0.0145\n",
            "     31       37.3239  0.0177\n",
            "     32       37.3239  0.0170\n",
            "     33       37.3239  0.0155\n",
            "     34       37.3239  0.0175\n",
            "     35       37.3239  0.0206\n",
            "     36       37.3239  0.0167\n",
            "     37       37.3239  0.0149\n",
            "     38       37.3239  0.0155\n",
            "     39       37.3239  0.0138\n",
            "     40       37.3239  0.0151\n",
            "     41       37.3239  0.0144\n",
            "     42       37.3239  0.0120\n",
            "     43       37.3239  0.0127\n",
            "     44       37.3239  0.0158\n",
            "     45       37.3239  0.0157\n",
            "     46       37.3239  0.0151\n",
            "     47       37.3239  0.0127\n",
            "     48       37.3239  0.0146\n",
            "     49       37.3239  0.0141\n",
            "     50       37.3239  0.0278\n",
            "     51       37.3239  0.0182\n",
            "     52       37.3239  0.0156\n",
            "     53       37.3239  0.0178\n",
            "     54       37.3239  0.0162\n",
            "     55       37.3239  0.0156\n",
            "     56       37.3239  0.0146\n",
            "     57       37.3239  0.0292\n",
            "     58       37.3239  0.0240\n",
            "     59       37.3239  0.0140\n",
            "     60       37.3239  0.0156\n",
            "     61       37.3239  0.0145\n",
            "     62       37.3239  0.0159\n",
            "     63       37.3239  0.0149\n",
            "     64       37.3239  0.0157\n",
            "     65       37.3239  0.0141\n",
            "     66       37.3239  0.0151\n",
            "     67       37.3239  0.0153\n",
            "     68       37.3239  0.0147\n",
            "     69       37.3239  0.0149\n",
            "     70       37.3239  0.0153\n",
            "     71       37.3239  0.0153\n",
            "     72       37.3239  0.0143\n",
            "     73       37.3239  0.0154\n",
            "     74       37.3239  0.0155\n",
            "     75       37.3239  0.0148\n",
            "     76       37.3239  0.0161\n",
            "     77       37.3239  0.0146\n",
            "     78       37.3239  0.0166\n",
            "     79       37.3239  0.0167\n",
            "     80       37.3239  0.0162\n",
            "     81       37.3239  0.0287\n",
            "     82       37.3239  0.0202\n",
            "     83       37.3239  0.0200\n",
            "     84       37.3239  0.0180\n",
            "     85       37.3239  0.0179\n",
            "     86       37.3239  0.0171\n",
            "     87       37.3239  0.0140\n",
            "     88       37.3239  0.0146\n",
            "     89       37.3239  0.0149\n",
            "     90       37.3239  0.0164\n",
            "     91       37.3239  0.0139\n",
            "     92       37.3239  0.0144\n",
            "     93       37.3239  0.0144\n",
            "     94       37.3239  0.0158\n",
            "     95       37.3239  0.0143\n",
            "     96       37.3239  0.0152\n",
            "     97       37.3239  0.0150\n",
            "     98       37.3239  0.0142\n",
            "     99       37.3239  0.0160\n",
            "    100       37.3239  0.0150\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0111\n",
            "      2       37.1930  0.0171\n",
            "      3       37.1930  0.0137\n",
            "      4       37.1930  0.0149\n",
            "      5       37.1930  0.0115\n",
            "      6       37.1930  0.0119\n",
            "      7       37.1930  0.0153\n",
            "      8       37.1930  0.0147\n",
            "      9       37.1930  0.0143\n",
            "     10       37.1930  0.0121\n",
            "     11       37.1930  0.0157\n",
            "     12       37.1930  0.0154\n",
            "     13       37.1930  0.0135\n",
            "     14       37.1930  0.0130\n",
            "     15       37.1930  0.0149\n",
            "     16       37.1930  0.0143\n",
            "     17       37.1930  0.0146\n",
            "     18       37.1930  0.0124\n",
            "     19       37.1930  0.0148\n",
            "     20       37.1930  0.0185\n",
            "     21       37.1930  0.0119\n",
            "     22       37.1930  0.0131\n",
            "     23       37.1930  0.0142\n",
            "     24       37.1930  0.0147\n",
            "     25       37.1930  0.0131\n",
            "     26       37.1930  0.0121\n",
            "     27       37.1930  0.0148\n",
            "     28       37.1930  0.0141\n",
            "     29       37.1930  0.0148\n",
            "     30       37.1930  0.0133\n",
            "     31       37.1930  0.0147\n",
            "     32       37.1930  0.0145\n",
            "     33       37.1930  0.0133\n",
            "     34       37.1930  0.0116\n",
            "     35       37.1930  0.0147\n",
            "     36       37.1930  0.0143\n",
            "     37       37.1930  0.0156\n",
            "     38       37.1930  0.0192\n",
            "     39       37.1930  0.0163\n",
            "     40       37.1930  0.0173\n",
            "     41       37.1930  0.0206\n",
            "     42       37.1930  0.0248\n",
            "     43       37.1930  0.0172\n",
            "     44       37.1930  0.0189\n",
            "     45       37.1930  0.0174\n",
            "     46       37.1930  0.0174\n",
            "     47       37.1930  0.0144\n",
            "     48       37.1930  0.0166\n",
            "     49       37.1930  0.0140\n",
            "     50       37.1930  0.0139\n",
            "     51       37.1930  0.0140\n",
            "     52       37.1930  0.0147\n",
            "     53       37.1930  0.0134\n",
            "     54       37.1930  0.0138\n",
            "     55       37.1930  0.0154\n",
            "     56       37.1930  0.0148\n",
            "     57       37.1930  0.0156\n",
            "     58       37.1930  0.0160\n",
            "     59       37.1930  0.0153\n",
            "     60       37.1930  0.0149\n",
            "     61       37.1930  0.0174\n",
            "     62       37.1930  0.0150\n",
            "     63       37.1930  0.0150\n",
            "     64       37.1930  0.0149\n",
            "     65       37.1930  0.0165\n",
            "     66       37.1930  0.0173\n",
            "     67       37.1930  0.0152\n",
            "     68       37.1930  0.0149\n",
            "     69       37.1930  0.0171\n",
            "     70       37.1930  0.0152\n",
            "     71       37.1930  0.0206\n",
            "     72       37.1930  0.0172\n",
            "     73       37.1930  0.0176\n",
            "     74       37.1930  0.0200\n",
            "     75       37.1930  0.0169\n",
            "     76       37.1930  0.0215\n",
            "     77       37.1930  0.0179\n",
            "     78       37.1930  0.0174\n",
            "     79       37.1930  0.0169\n",
            "     80       37.1930  0.0150\n",
            "     81       37.1930  0.0174\n",
            "     82       37.1930  0.0173\n",
            "     83       37.1930  0.0159\n",
            "     84       37.1930  0.0170\n",
            "     85       37.1930  0.0181\n",
            "     86       37.1930  0.0208\n",
            "     87       37.1930  0.0153\n",
            "     88       37.1930  0.0152\n",
            "     89       37.1930  0.0152\n",
            "     90       37.1930  0.0180\n",
            "     91       37.1930  0.0175\n",
            "     92       37.1930  0.0184\n",
            "     93       37.1930  0.0173\n",
            "     94       37.1930  0.0170\n",
            "     95       37.1930  0.0165\n",
            "     96       37.1930  0.0184\n",
            "     97       37.1930  0.0181\n",
            "     98       37.1930  0.0188\n",
            "     99       37.1930  0.0179\n",
            "    100       37.1930  0.0184\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0236\n",
            "      2       37.3239  0.0230\n",
            "      3       37.3239  0.0241\n",
            "      4       37.3239  0.0227\n",
            "      5       37.3239  0.0221\n",
            "      6       37.3239  0.0275\n",
            "      7       37.3239  0.0222\n",
            "      8       37.3239  0.0184\n",
            "      9       37.3239  0.0245\n",
            "     10       37.3239  0.0227\n",
            "     11       37.3239  0.0246\n",
            "     12       37.3239  0.0186\n",
            "     13       37.3239  0.0186\n",
            "     14       37.3239  0.0190\n",
            "     15       37.3239  0.0192\n",
            "     16       37.3239  0.0227\n",
            "     17       37.3239  0.0212\n",
            "     18       37.3239  0.0201\n",
            "     19       37.3239  0.0191\n",
            "     20       37.3239  0.0222\n",
            "     21       37.3239  0.0195\n",
            "     22       37.3239  0.0196\n",
            "     23       37.3239  0.0192\n",
            "     24       37.3239  0.0227\n",
            "     25       37.3239  0.0245\n",
            "     26       37.3239  0.0240\n",
            "     27       37.3239  0.0190\n",
            "     28       37.3239  0.0198\n",
            "     29       37.3239  0.0195\n",
            "     30       37.3239  0.0202\n",
            "     31       37.3239  0.0204\n",
            "     32       37.3239  0.0229\n",
            "     33       37.3239  0.0220\n",
            "     34       37.3239  0.0221\n",
            "     35       37.3239  0.0232\n",
            "     36       37.3239  0.0211\n",
            "     37       37.3239  0.0243\n",
            "     38       37.3239  0.0222\n",
            "     39       37.3239  0.0230\n",
            "     40       37.3239  0.0219\n",
            "     41       37.3239  0.0248\n",
            "     42       37.3239  0.0233\n",
            "     43       37.3239  0.0229\n",
            "     44       37.3239  0.0221\n",
            "     45       37.3239  0.0250\n",
            "     46       37.3239  0.0188\n",
            "     47       37.3239  0.0188\n",
            "     48       37.3239  0.0184\n",
            "     49       37.3239  0.0277\n",
            "     50       37.3239  0.0188\n",
            "     51       37.3239  0.0183\n",
            "     52       37.3239  0.0187\n",
            "     53       37.3239  0.0187\n",
            "     54       37.3239  0.0187\n",
            "     55       37.3239  0.0193\n",
            "     56       37.3239  0.0205\n",
            "     57       37.3239  0.0211\n",
            "     58       37.3239  0.0200\n",
            "     59       37.3239  0.0187\n",
            "     60       37.3239  0.0193\n",
            "     61       37.3239  0.0184\n",
            "     62       37.3239  0.0185\n",
            "     63       37.3239  0.0220\n",
            "     64       37.3239  0.0189\n",
            "     65       37.3239  0.0194\n",
            "     66       37.3239  0.0194\n",
            "     67       37.3239  0.0188\n",
            "     68       37.3239  0.0188\n",
            "     69       37.3239  0.0197\n",
            "     70       37.3239  0.0189\n",
            "     71       37.3239  0.0191\n",
            "     72       37.3239  0.0192\n",
            "     73       37.3239  0.0193\n",
            "     74       37.3239  0.0190\n",
            "     75       37.3239  0.0199\n",
            "     76       37.3239  0.0197\n",
            "     77       37.3239  0.0193\n",
            "     78       37.3239  0.0216\n",
            "     79       37.3239  0.0223\n",
            "     80       37.3239  0.0219\n",
            "     81       37.3239  0.0229\n",
            "     82       37.3239  0.0224\n",
            "     83       37.3239  0.0213\n",
            "     84       37.3239  0.0210\n",
            "     85       37.3239  0.0217\n",
            "     86       37.3239  0.0219\n",
            "     87       37.3239  0.0223\n",
            "     88       37.3239  0.0223\n",
            "     89       37.3239  0.0245\n",
            "     90       37.3239  0.0260\n",
            "     91       37.3239  0.0254\n",
            "     92       37.3239  0.0264\n",
            "     93       37.3239  0.0276\n",
            "     94       37.3239  0.0239\n",
            "     95       37.3239  0.0272\n",
            "     96       37.3239  0.0306\n",
            "     97       37.3239  0.0255\n",
            "     98       37.3239  0.0244\n",
            "     99       37.3239  0.0312\n",
            "    100       37.3239  0.0332\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0193\n",
            "      2       37.1930  0.0236\n",
            "      3       37.1930  0.0213\n",
            "      4       37.1930  0.0212\n",
            "      5       37.1930  0.0234\n",
            "      6       37.1930  0.0250\n",
            "      7       37.1930  0.0276\n",
            "      8       37.1930  0.0236\n",
            "      9       37.1930  0.0248\n",
            "     10       37.1930  0.0305\n",
            "     11       37.1930  0.0279\n",
            "     12       37.1930  0.0247\n",
            "     13       37.1930  0.0269\n",
            "     14       37.1930  0.0271\n",
            "     15       37.1930  0.0272\n",
            "     16       37.1930  0.0292\n",
            "     17       37.1930  0.0249\n",
            "     18       37.1930  0.0245\n",
            "     19       37.1930  0.0253\n",
            "     20       37.1930  0.0295\n",
            "     21       37.1930  0.0290\n",
            "     22       37.1930  0.0285\n",
            "     23       37.1930  0.0272\n",
            "     24       37.1930  0.0304\n",
            "     25       37.1930  0.0290\n",
            "     26       37.1930  0.0251\n",
            "     27       37.1930  0.0300\n",
            "     28       37.1930  0.0273\n",
            "     29       37.1930  0.0300\n",
            "     30       37.1930  0.0232\n",
            "     31       37.1930  0.0256\n",
            "     32       37.1930  0.0224\n",
            "     33       37.1930  0.0219\n",
            "     34       37.1930  0.0204\n",
            "     35       37.1930  0.0205\n",
            "     36       37.1930  0.0230\n",
            "     37       37.1930  0.0206\n",
            "     38       37.1930  0.0197\n",
            "     39       37.1930  0.0237\n",
            "     40       37.1930  0.0207\n",
            "     41       37.1930  0.0210\n",
            "     42       37.1930  0.0204\n",
            "     43       37.1930  0.0210\n",
            "     44       37.1930  0.0209\n",
            "     45       37.1930  0.0207\n",
            "     46       37.1930  0.0211\n",
            "     47       37.1930  0.0193\n",
            "     48       37.1930  0.0245\n",
            "     49       37.1930  0.0239\n",
            "     50       37.1930  0.0229\n",
            "     51       37.1930  0.0235\n",
            "     52       37.1930  0.0206\n",
            "     53       37.1930  0.0230\n",
            "     54       37.1930  0.0235\n",
            "     55       37.1930  0.0232\n",
            "     56       37.1930  0.0244\n",
            "     57       37.1930  0.0239\n",
            "     58       37.1930  0.0209\n",
            "     59       37.1930  0.0205\n",
            "     60       37.1930  0.0209\n",
            "     61       37.1930  0.0289\n",
            "     62       37.1930  0.0307\n",
            "     63       37.1930  0.0209\n",
            "     64       37.1930  0.0213\n",
            "     65       37.1930  0.0237\n",
            "     66       37.1930  0.0267\n",
            "     67       37.1930  0.0298\n",
            "     68       37.1930  0.0250\n",
            "     69       37.1930  0.0220\n",
            "     70       37.1930  0.0208\n",
            "     71       37.1930  0.0239\n",
            "     72       37.1930  0.0234\n",
            "     73       37.1930  0.0252\n",
            "     74       37.1930  0.0234\n",
            "     75       37.1930  0.0247\n",
            "     76       37.1930  0.0243\n",
            "     77       37.1930  0.0248\n",
            "     78       37.1930  0.0265\n",
            "     79       37.1930  0.0281\n",
            "     80       37.1930  0.0269\n",
            "     81       37.1930  0.0255\n",
            "     82       37.1930  0.0218\n",
            "     83       37.1930  0.0224\n",
            "     84       37.1930  0.0255\n",
            "     85       37.1930  0.0264\n",
            "     86       37.1930  0.0343\n",
            "     87       37.1930  0.0242\n",
            "     88       37.1930  0.0231\n",
            "     89       37.1930  0.0228\n",
            "     90       37.1930  0.0242\n",
            "     91       37.1930  0.0287\n",
            "     92       37.1930  0.0286\n",
            "     93       37.1930  0.0218\n",
            "     94       37.1930  0.0234\n",
            "     95       37.1930  0.0243\n",
            "     96       37.1930  0.0223\n",
            "     97       37.1930  0.0206\n",
            "     98       37.1930  0.0191\n",
            "     99       37.1930  0.0204\n",
            "    100       37.1930  0.0207\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.3239\u001b[0m  0.0164\n",
            "      2       37.3239  0.0160\n",
            "      3       37.3239  0.0149\n",
            "      4       37.3239  0.0153\n",
            "      5       37.3239  0.0158\n",
            "      6       37.3239  0.0204\n",
            "      7       37.3239  0.0300\n",
            "      8       37.3239  0.0264\n",
            "      9       37.3239  0.0151\n",
            "     10       37.3239  0.0161\n",
            "     11       37.3239  0.0172\n",
            "     12       37.3239  0.0166\n",
            "     13       37.3239  0.0148\n",
            "     14       37.3239  0.0174\n",
            "     15       37.3239  0.0201\n",
            "     16       37.3239  0.0144\n",
            "     17       37.3239  0.0161\n",
            "     18       37.3239  0.0165\n",
            "     19       37.3239  0.0161\n",
            "     20       37.3239  0.0146\n",
            "     21       37.3239  0.0160\n",
            "     22       37.3239  0.0160\n",
            "     23       37.3239  0.0167\n",
            "     24       37.3239  0.0161\n",
            "     25       37.3239  0.0158\n",
            "     26       37.3239  0.0165\n",
            "     27       37.3239  0.0166\n",
            "     28       37.3239  0.0177\n",
            "     29       37.3239  0.0181\n",
            "     30       37.3239  0.0174\n",
            "     31       37.3239  0.0165\n",
            "     32       37.3239  0.0160\n",
            "     33       37.3239  0.0180\n",
            "     34       37.3239  0.0188\n",
            "     35       37.3239  0.0227\n",
            "     36       37.3239  0.0223\n",
            "     37       37.3239  0.0214\n",
            "     38       37.3239  0.0175\n",
            "     39       37.3239  0.0195\n",
            "     40       37.3239  0.0189\n",
            "     41       37.3239  0.0171\n",
            "     42       37.3239  0.0177\n",
            "     43       37.3239  0.0212\n",
            "     44       37.3239  0.0168\n",
            "     45       37.3239  0.0157\n",
            "     46       37.3239  0.0189\n",
            "     47       37.3239  0.0159\n",
            "     48       37.3239  0.0191\n",
            "     49       37.3239  0.0217\n",
            "     50       37.3239  0.0180\n",
            "     51       37.3239  0.0165\n",
            "     52       37.3239  0.0197\n",
            "     53       37.3239  0.0180\n",
            "     54       37.3239  0.0167\n",
            "     55       37.3239  0.0145\n",
            "     56       37.3239  0.0149\n",
            "     57       37.3239  0.0184\n",
            "     58       37.3239  0.0283\n",
            "     59       37.3239  0.0153\n",
            "     60       37.3239  0.0153\n",
            "     61       37.3239  0.0151\n",
            "     62       37.3239  0.0155\n",
            "     63       37.3239  0.0152\n",
            "     64       37.3239  0.0167\n",
            "     65       37.3239  0.0156\n",
            "     66       37.3239  0.0151\n",
            "     67       37.3239  0.0154\n",
            "     68       37.3239  0.0156\n",
            "     69       37.3239  0.0149\n",
            "     70       37.3239  0.0149\n",
            "     71       37.3239  0.0161\n",
            "     72       37.3239  0.0144\n",
            "     73       37.3239  0.0153\n",
            "     74       37.3239  0.0146\n",
            "     75       37.3239  0.0171\n",
            "     76       37.3239  0.0160\n",
            "     77       37.3239  0.0158\n",
            "     78       37.3239  0.0225\n",
            "     79       37.3239  0.0169\n",
            "     80       37.3239  0.0193\n",
            "     81       37.3239  0.0165\n",
            "     82       37.3239  0.0177\n",
            "     83       37.3239  0.0170\n",
            "     84       37.3239  0.0292\n",
            "     85       37.3239  0.0230\n",
            "     86       37.3239  0.0181\n",
            "     87       37.3239  0.0211\n",
            "     88       37.3239  0.0185\n",
            "     89       37.3239  0.0171\n",
            "     90       37.3239  0.0168\n",
            "     91       37.3239  0.0171\n",
            "     92       37.3239  0.0171\n",
            "     93       37.3239  0.0164\n",
            "     94       37.3239  0.0169\n",
            "     95       37.3239  0.0165\n",
            "     96       37.3239  0.0151\n",
            "     97       37.3239  0.0152\n",
            "     98       37.3239  0.0155\n",
            "     99       37.3239  0.0154\n",
            "    100       37.3239  0.0159\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.1930\u001b[0m  0.0148\n",
            "      2       37.1930  0.0147\n",
            "      3       37.1930  0.0154\n",
            "      4       37.1930  0.0154\n",
            "      5       37.1930  0.0152\n",
            "      6       37.1930  0.0136\n",
            "      7       37.1930  0.0166\n",
            "      8       37.1930  0.0152\n",
            "      9       37.1930  0.0153\n",
            "     10       37.1930  0.0155\n",
            "     11       37.1930  0.0197\n",
            "     12       37.1930  0.0149\n",
            "     13       37.1930  0.0234\n",
            "     14       37.1930  0.0158\n",
            "     15       37.1930  0.0154\n",
            "     16       37.1930  0.0177\n",
            "     17       37.1930  0.0147\n",
            "     18       37.1930  0.0156\n",
            "     19       37.1930  0.0148\n",
            "     20       37.1930  0.0164\n",
            "     21       37.1930  0.0154\n",
            "     22       37.1930  0.0153\n",
            "     23       37.1930  0.0157\n",
            "     24       37.1930  0.0160\n",
            "     25       37.1930  0.0153\n",
            "     26       37.1930  0.0157\n",
            "     27       37.1930  0.0157\n",
            "     28       37.1930  0.0168\n",
            "     29       37.1930  0.0154\n",
            "     30       37.1930  0.0164\n",
            "     31       37.1930  0.0163\n",
            "     32       37.1930  0.0193\n",
            "     33       37.1930  0.0185\n",
            "     34       37.1930  0.0218\n",
            "     35       37.1930  0.0179\n",
            "     36       37.1930  0.0196\n",
            "     37       37.1930  0.0164\n",
            "     38       37.1930  0.0183\n",
            "     39       37.1930  0.0172\n",
            "     40       37.1930  0.0172\n",
            "     41       37.1930  0.0170\n",
            "     42       37.1930  0.0176\n",
            "     43       37.1930  0.0177\n",
            "     44       37.1930  0.0174\n",
            "     45       37.1930  0.0174\n",
            "     46       37.1930  0.0173\n",
            "     47       37.1930  0.0206\n",
            "     48       37.1930  0.0188\n",
            "     49       37.1930  0.0260\n",
            "     50       37.1930  0.0166\n",
            "     51       37.1930  0.0186\n",
            "     52       37.1930  0.0147\n",
            "     53       37.1930  0.0156\n",
            "     54       37.1930  0.0144\n",
            "     55       37.1930  0.0148\n",
            "     56       37.1930  0.0146\n",
            "     57       37.1930  0.0152\n",
            "     58       37.1930  0.0169\n",
            "     59       37.1930  0.0148\n",
            "     60       37.1930  0.0149\n",
            "     61       37.1930  0.0147\n",
            "     62       37.1930  0.0154\n",
            "     63       37.1930  0.0162\n",
            "     64       37.1930  0.0171\n",
            "     65       37.1930  0.0154\n",
            "     66       37.1930  0.0202\n",
            "     67       37.1930  0.0211\n",
            "     68       37.1930  0.0181\n",
            "     69       37.1930  0.0177\n",
            "     70       37.1930  0.0153\n",
            "     71       37.1930  0.0155\n",
            "     72       37.1930  0.0165\n",
            "     73       37.1930  0.0146\n",
            "     74       37.1930  0.0144\n",
            "     75       37.1930  0.0150\n",
            "     76       37.1930  0.0160\n",
            "     77       37.1930  0.0137\n",
            "     78       37.1930  0.0145\n",
            "     79       37.1930  0.0157\n",
            "     80       37.1930  0.0156\n",
            "     81       37.1930  0.0161\n",
            "     82       37.1930  0.0172\n",
            "     83       37.1930  0.0192\n",
            "     84       37.1930  0.0153\n",
            "     85       37.1930  0.0163\n",
            "     86       37.1930  0.0163\n",
            "     87       37.1930  0.0157\n",
            "     88       37.1930  0.0201\n",
            "     89       37.1930  0.0176\n",
            "     90       37.1930  0.0168\n",
            "     91       37.1930  0.0178\n",
            "     92       37.1930  0.0170\n",
            "     93       37.1930  0.0186\n",
            "     94       37.1930  0.0190\n",
            "     95       37.1930  0.0180\n",
            "     96       37.1930  0.0189\n",
            "     97       37.1930  0.0206\n",
            "     98       37.1930  0.0192\n",
            "     99       37.1930  0.0184\n",
            "    100       37.1930  0.0163\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m62.6761\u001b[0m  0.0176\n",
            "      2       62.6761  0.0210\n",
            "      3       62.6761  0.0194\n",
            "      4       62.6761  0.0193\n",
            "      5       62.6761  0.0176\n",
            "      6       62.6761  0.0233\n",
            "      7       62.6761  0.0208\n",
            "      8       62.6761  0.0207\n",
            "      9       62.6761  0.0222\n",
            "     10       62.6761  0.0197\n",
            "     11       62.6761  0.0201\n",
            "     12       62.6761  0.0219\n",
            "     13       62.6761  0.0203\n",
            "     14       62.6761  0.0221\n",
            "     15       62.6761  0.0206\n",
            "     16       62.6761  0.0198\n",
            "     17       62.6761  0.0199\n",
            "     18       62.6761  0.0263\n",
            "     19       62.6761  0.0220\n",
            "     20       62.6761  0.0201\n",
            "     21       62.6761  0.0212\n",
            "     22       62.6761  0.0233\n",
            "     23       62.6761  0.0196\n",
            "     24       62.6761  0.0205\n",
            "     25       62.6761  0.0219\n",
            "     26       62.6761  0.0204\n",
            "     27       62.6761  0.0211\n",
            "     28       62.6761  0.0213\n",
            "     29       \u001b[36m62.3239\u001b[0m  0.0273\n",
            "     30       \u001b[36m61.6865\u001b[0m  0.0209\n",
            "     31       \u001b[36m61.2676\u001b[0m  0.0257\n",
            "     32       61.2676  0.0218\n",
            "     33       61.2676  0.0230\n",
            "     34       61.2676  0.0238\n",
            "     35       61.2676  0.0240\n",
            "     36       61.2676  0.0240\n",
            "     37       61.2676  0.0243\n",
            "     38       61.2676  0.0273\n",
            "     39       61.2676  0.0239\n",
            "     40       61.2676  0.0228\n",
            "     41       61.2676  0.0235\n",
            "     42       61.2676  0.0236\n",
            "     43       61.2676  0.0184\n",
            "     44       61.2676  0.0198\n",
            "     45       61.2676  0.0217\n",
            "     46       61.2676  0.0190\n",
            "     47       61.2676  0.0191\n",
            "     48       \u001b[36m61.1818\u001b[0m  0.0197\n",
            "     49       \u001b[36m61.1552\u001b[0m  0.0205\n",
            "     50       61.1667  0.0178\n",
            "     51       61.1785  0.0222\n",
            "     52       61.1905  0.0219\n",
            "     53       61.2028  0.0160\n",
            "     54       61.2152  0.0220\n",
            "     55       61.2279  0.0193\n",
            "     56       61.2676  0.0194\n",
            "     57       61.2676  0.0149\n",
            "     58       61.2676  0.0223\n",
            "     59       61.2676  0.0217\n",
            "     60       61.2676  0.0204\n",
            "     61       61.2676  0.0141\n",
            "     62       61.2676  0.0198\n",
            "     63       61.2676  0.0280\n",
            "     64       61.2676  0.0207\n",
            "     65       61.2676  0.0146\n",
            "     66       61.2676  0.0199\n",
            "     67       61.2676  0.0202\n",
            "     68       61.2676  0.0187\n",
            "     69       61.2676  0.0149\n",
            "     70       61.2676  0.0231\n",
            "     71       61.2676  0.0204\n",
            "     72       61.2676  0.0205\n",
            "     73       61.2676  0.0186\n",
            "     74       61.2676  0.0215\n",
            "     75       61.2676  0.0222\n",
            "     76       61.2676  0.0219\n",
            "     77       61.2676  0.0234\n",
            "     78       61.2676  0.0256\n",
            "     79       61.2676  0.0207\n",
            "     80       61.2676  0.0254\n",
            "     81       61.2676  0.0227\n",
            "     82       61.2676  0.0228\n",
            "     83       61.2676  0.0201\n",
            "     84       61.2676  0.0223\n",
            "     85       61.2676  0.0166\n",
            "     86       61.2676  0.0191\n",
            "     87       61.2676  0.0189\n",
            "     88       61.2676  0.0192\n",
            "     89       61.2676  0.0194\n",
            "     90       61.2676  0.0198\n",
            "     91       61.2676  0.0195\n",
            "     92       61.2676  0.0190\n",
            "     93       61.2676  0.0184\n",
            "     94       61.2676  0.0194\n",
            "     95       61.2676  0.0207\n",
            "     96       61.2676  0.0182\n",
            "     97       61.2676  0.0183\n",
            "     98       61.2676  0.0192\n",
            "     99       61.2676  0.0208\n",
            "    100       61.2676  0.0187\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m54.1997\u001b[0m  0.0167\n",
            "      2       \u001b[36m54.0767\u001b[0m  0.0195\n",
            "      3       \u001b[36m54.0351\u001b[0m  0.0210\n",
            "      4       54.3860  0.0212\n",
            "      5       54.3860  0.0150\n",
            "      6       54.3860  0.0238\n",
            "      7       54.3860  0.0195\n",
            "      8       54.3860  0.0177\n",
            "      9       54.3860  0.0174\n",
            "     10       54.3860  0.0270\n",
            "     11       54.3860  0.0178\n",
            "     12       54.3860  0.0193\n",
            "     13       54.3860  0.0164\n",
            "     14       54.4192  0.0199\n",
            "     15       54.3860  0.0196\n",
            "     16       54.3860  0.0182\n",
            "     17       54.3860  0.0191\n",
            "     18       54.3860  0.0262\n",
            "     19       54.3860  0.0229\n",
            "     20       54.3860  0.0197\n",
            "     21       54.3860  0.0216\n",
            "     22       54.3860  0.0297\n",
            "     23       54.3860  0.0240\n",
            "     24       54.3860  0.0216\n",
            "     25       54.3860  0.0233\n",
            "     26       54.3860  0.0221\n",
            "     27       54.3860  0.0236\n",
            "     28       54.3860  0.0255\n",
            "     29       54.3860  0.0232\n",
            "     30       54.3860  0.0251\n",
            "     31       54.3860  0.0193\n",
            "     32       54.3860  0.0198\n",
            "     33       54.3860  0.0199\n",
            "     34       54.3860  0.0209\n",
            "     35       54.3860  0.0189\n",
            "     36       54.3860  0.0194\n",
            "     37       54.3860  0.0181\n",
            "     38       54.3860  0.0209\n",
            "     39       54.3860  0.0188\n",
            "     40       54.3860  0.0191\n",
            "     41       54.3860  0.0196\n",
            "     42       54.3860  0.0221\n",
            "     43       54.3860  0.0187\n",
            "     44       54.3860  0.0198\n",
            "     45       54.3860  0.0186\n",
            "     46       54.3860  0.0208\n",
            "     47       54.3860  0.0188\n",
            "     48       54.3860  0.0197\n",
            "     49       54.3860  0.0217\n",
            "     50       54.3860  0.0236\n",
            "     51       54.3860  0.0199\n",
            "     52       54.3860  0.0186\n",
            "     53       54.3860  0.0261\n",
            "     54       54.3882  0.0252\n",
            "     55       54.3860  0.0243\n",
            "     56       54.3860  0.0193\n",
            "     57       54.3860  0.0189\n",
            "     58       54.3860  0.0192\n",
            "     59       54.3860  0.0217\n",
            "     60       54.3860  0.0215\n",
            "     61       54.3860  0.0221\n",
            "     62       54.3860  0.0224\n",
            "     63       54.3860  0.0212\n",
            "     64       54.3860  0.0232\n",
            "     65       54.3860  0.0228\n",
            "     66       54.3860  0.0234\n",
            "     67       54.3860  0.0234\n",
            "     68       54.3860  0.0218\n",
            "     69       54.3860  0.0255\n",
            "     70       54.3860  0.0240\n",
            "     71       54.3860  0.0245\n",
            "     72       54.3860  0.0200\n",
            "     73       54.3860  0.0204\n",
            "     74       54.3860  0.0192\n",
            "     75       54.3860  0.0205\n",
            "     76       54.3860  0.0206\n",
            "     77       54.3860  0.0218\n",
            "     78       54.3860  0.0215\n",
            "     79       54.3860  0.0211\n",
            "     80       54.3860  0.0202\n",
            "     81       54.3860  0.0185\n",
            "     82       54.3860  0.0201\n",
            "     83       54.3860  0.0196\n",
            "     84       54.3860  0.0221\n",
            "     85       54.3860  0.0204\n",
            "     86       54.3860  0.0189\n",
            "     87       54.3860  0.0205\n",
            "     88       54.3860  0.0197\n",
            "     89       54.3860  0.0194\n",
            "     90       54.3860  0.0207\n",
            "     91       54.3860  0.0192\n",
            "     92       54.3860  0.0208\n",
            "     93       54.3860  0.0209\n",
            "     94       54.3860  0.0219\n",
            "     95       54.3860  0.0191\n",
            "     96       54.3860  0.0186\n",
            "     97       54.3860  0.0194\n",
            "     98       54.3860  0.0204\n",
            "     99       54.3860  0.0250\n",
            "    100       54.3860  0.0245\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m53.8732\u001b[0m  0.0158\n",
            "      2       53.8732  0.0169\n",
            "      3       53.8732  0.0193\n",
            "      4       53.8732  0.0184\n",
            "      5       53.8732  0.0145\n",
            "      6       53.8732  0.0173\n",
            "      7       53.8732  0.0195\n",
            "      8       53.8732  0.0168\n",
            "      9       53.8732  0.0157\n",
            "     10       53.8732  0.0183\n",
            "     11       53.8732  0.0206\n",
            "     12       53.8732  0.0185\n",
            "     13       53.8732  0.0190\n",
            "     14       53.8732  0.0183\n",
            "     15       53.8732  0.0189\n",
            "     16       53.8732  0.0185\n",
            "     17       53.8732  0.0155\n",
            "     18       53.8732  0.0161\n",
            "     19       53.8732  0.0171\n",
            "     20       53.8732  0.0167\n",
            "     21       53.8732  0.0181\n",
            "     22       53.8732  0.0163\n",
            "     23       53.8732  0.0159\n",
            "     24       53.8732  0.0208\n",
            "     25       53.8732  0.0146\n",
            "     26       53.8732  0.0151\n",
            "     27       53.8732  0.0165\n",
            "     28       53.8732  0.0166\n",
            "     29       53.8732  0.0154\n",
            "     30       53.8732  0.0170\n",
            "     31       53.8732  0.0150\n",
            "     32       53.8732  0.0162\n",
            "     33       53.8732  0.0159\n",
            "     34       53.8732  0.0181\n",
            "     35       53.8732  0.0149\n",
            "     36       53.8732  0.0161\n",
            "     37       53.8732  0.0161\n",
            "     38       53.8732  0.0184\n",
            "     39       53.8732  0.0167\n",
            "     40       53.8732  0.0163\n",
            "     41       53.8732  0.0168\n",
            "     42       53.8732  0.0173\n",
            "     43       53.8732  0.0179\n",
            "     44       53.8732  0.0175\n",
            "     45       53.8732  0.0160\n",
            "     46       53.8732  0.0167\n",
            "     47       53.8732  0.0158\n",
            "     48       53.8732  0.0169\n",
            "     49       53.8732  0.0172\n",
            "     50       53.8732  0.0162\n",
            "     51       53.8732  0.0192\n",
            "     52       53.8732  0.0185\n",
            "     53       53.8732  0.0177\n",
            "     54       53.8732  0.0165\n",
            "     55       53.8732  0.0203\n",
            "     56       53.8732  0.0194\n",
            "     57       53.8732  0.0179\n",
            "     58       53.8732  0.0187\n",
            "     59       53.8732  0.0156\n",
            "     60       53.8732  0.0240\n",
            "     61       53.8732  0.0192\n",
            "     62       53.8732  0.0187\n",
            "     63       53.8732  0.0180\n",
            "     64       53.8732  0.0186\n",
            "     65       53.8732  0.0178\n",
            "     66       53.8732  0.0202\n",
            "     67       53.8732  0.0227\n",
            "     68       53.8732  0.0192\n",
            "     69       53.8732  0.0193\n",
            "     70       53.8732  0.0207\n",
            "     71       53.8732  0.0235\n",
            "     72       53.8732  0.0208\n",
            "     73       53.8732  0.0233\n",
            "     74       53.8732  0.0207\n",
            "     75       53.8732  0.0169\n",
            "     76       53.8732  0.0266\n",
            "     77       53.8732  0.0191\n",
            "     78       53.8732  0.0199\n",
            "     79       53.8732  0.0187\n",
            "     80       53.8732  0.0156\n",
            "     81       53.8732  0.0167\n",
            "     82       53.8732  0.0170\n",
            "     83       53.8732  0.0175\n",
            "     84       53.8732  0.0170\n",
            "     85       53.8732  0.0182\n",
            "     86       53.8732  0.0191\n",
            "     87       53.8732  0.0183\n",
            "     88       53.8732  0.0179\n",
            "     89       53.8732  0.0204\n",
            "     90       53.8732  0.0198\n",
            "     91       53.8732  0.0198\n",
            "     92       53.8732  0.0164\n",
            "     93       53.8732  0.0170\n",
            "     94       53.8732  0.0189\n",
            "     95       53.8732  0.0166\n",
            "     96       53.8732  0.0155\n",
            "     97       53.8732  0.0154\n",
            "     98       53.8732  0.0195\n",
            "     99       53.8732  0.0236\n",
            "    100       53.8732  0.0191\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m39.2982\u001b[0m  0.0178\n",
            "      2       39.2982  0.0178\n",
            "      3       39.2982  0.0181\n",
            "      4       39.2982  0.0266\n",
            "      5       39.2982  0.0222\n",
            "      6       39.2982  0.0212\n",
            "      7       39.2982  0.0247\n",
            "      8       39.2982  0.0246\n",
            "      9       39.2982  0.0245\n",
            "     10       39.2982  0.0224\n",
            "     11       39.2982  0.0199\n",
            "     12       39.2982  0.0172\n",
            "     13       39.2982  0.0162\n",
            "     14       39.2982  0.0181\n",
            "     15       39.2982  0.0164\n",
            "     16       39.2982  0.0146\n",
            "     17       39.2982  0.0184\n",
            "     18       39.2982  0.0173\n",
            "     19       39.2982  0.0164\n",
            "     20       39.2982  0.0140\n",
            "     21       39.2982  0.0165\n",
            "     22       39.2982  0.0150\n",
            "     23       39.2982  0.0158\n",
            "     24       39.2982  0.0151\n",
            "     25       39.2982  0.0160\n",
            "     26       39.2982  0.0159\n",
            "     27       39.2982  0.0217\n",
            "     28       39.2982  0.0165\n",
            "     29       39.2982  0.0161\n",
            "     30       39.2982  0.0149\n",
            "     31       39.2982  0.0143\n",
            "     32       39.2982  0.0148\n",
            "     33       39.2982  0.0152\n",
            "     34       39.2982  0.0161\n",
            "     35       39.2982  0.0145\n",
            "     36       39.2982  0.0143\n",
            "     37       39.2982  0.0160\n",
            "     38       39.2982  0.0140\n",
            "     39       39.2982  0.0156\n",
            "     40       39.2982  0.0147\n",
            "     41       39.2982  0.0150\n",
            "     42       39.2982  0.0151\n",
            "     43       39.2982  0.0152\n",
            "     44       39.2982  0.0136\n",
            "     45       39.2982  0.0152\n",
            "     46       39.2982  0.0154\n",
            "     47       39.2982  0.0152\n",
            "     48       39.2982  0.0154\n",
            "     49       39.2982  0.0159\n",
            "     50       39.2982  0.0162\n",
            "     51       39.2982  0.0254\n",
            "     52       39.2982  0.0231\n",
            "     53       39.2982  0.0235\n",
            "     54       39.2982  0.0239\n",
            "     55       39.2982  0.0233\n",
            "     56       39.2982  0.0240\n",
            "     57       39.2982  0.0269\n",
            "     58       39.2982  0.0231\n",
            "     59       39.2982  0.0202\n",
            "     60       39.2982  0.0225\n",
            "     61       39.2982  0.0206\n",
            "     62       39.2982  0.0170\n",
            "     63       39.2982  0.0212\n",
            "     64       39.2982  0.0212\n",
            "     65       39.2982  0.0207\n",
            "     66       39.2982  0.0151\n",
            "     67       39.2982  0.0190\n",
            "     68       39.2982  0.0189\n",
            "     69       39.2982  0.0176\n",
            "     70       39.2982  0.0182\n",
            "     71       39.2982  0.0197\n",
            "     72       39.2982  0.0216\n",
            "     73       39.2982  0.0195\n",
            "     74       39.2982  0.0171\n",
            "     75       39.2982  0.0180\n",
            "     76       39.2982  0.0164\n",
            "     77       39.2982  0.0167\n",
            "     78       39.2982  0.0179\n",
            "     79       39.2982  0.0187\n",
            "     80       39.2982  0.0181\n",
            "     81       39.2982  0.0184\n",
            "     82       39.2982  0.0182\n",
            "     83       39.2982  0.0221\n",
            "     84       39.2982  0.0189\n",
            "     85       39.2982  0.0152\n",
            "     86       39.2982  0.0147\n",
            "     87       39.2982  0.0153\n",
            "     88       39.2982  0.0148\n",
            "     89       39.2982  0.0148\n",
            "     90       39.2982  0.0149\n",
            "     91       39.2982  0.0170\n",
            "     92       39.2982  0.0162\n",
            "     93       39.2982  0.0241\n",
            "     94       39.2982  0.0213\n",
            "     95       39.2982  0.0233\n",
            "     96       39.2982  0.0221\n",
            "     97       39.2982  0.0213\n",
            "     98       39.2982  0.0228\n",
            "     99       39.2982  0.0189\n",
            "    100       39.2982  0.0194\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m49.2958\u001b[0m  0.0316\n",
            "      2       \u001b[36m48.7085\u001b[0m  0.0279\n",
            "      3       \u001b[36m48.5240\u001b[0m  0.0274\n",
            "      4       \u001b[36m48.2394\u001b[0m  0.0308\n",
            "      5       48.2394  0.0279\n",
            "      6       48.2394  0.0260\n",
            "      7       48.2394  0.0241\n",
            "      8       48.2394  0.0252\n",
            "      9       48.2394  0.0263\n",
            "     10       48.2394  0.0277\n",
            "     11       48.2394  0.0283\n",
            "     12       48.2394  0.0241\n",
            "     13       48.2394  0.0257\n",
            "     14       48.2394  0.0246\n",
            "     15       48.2394  0.0265\n",
            "     16       48.2394  0.0234\n",
            "     17       48.2394  0.0252\n",
            "     18       48.2394  0.0209\n",
            "     19       48.2394  0.0278\n",
            "     20       48.2394  0.0263\n",
            "     21       48.2394  0.0231\n",
            "     22       48.2394  0.0221\n",
            "     23       48.2394  0.0295\n",
            "     24       48.2394  0.0221\n",
            "     25       48.2394  0.0205\n",
            "     26       48.2394  0.0249\n",
            "     27       48.2394  0.0266\n",
            "     28       48.2394  0.0315\n",
            "     29       48.2394  0.0294\n",
            "     30       48.2394  0.0361\n",
            "     31       48.2394  0.0317\n",
            "     32       48.2394  0.0318\n",
            "     33       48.2394  0.0367\n",
            "     34       48.2394  0.0302\n",
            "     35       48.2394  0.0315\n",
            "     36       48.2394  0.0250\n",
            "     37       48.2394  0.0268\n",
            "     38       48.2394  0.0215\n",
            "     39       48.2394  0.0203\n",
            "     40       48.2394  0.0209\n",
            "     41       48.2394  0.0207\n",
            "     42       48.2394  0.0216\n",
            "     43       48.2394  0.0227\n",
            "     44       48.2394  0.0204\n",
            "     45       48.2394  0.0217\n",
            "     46       48.2394  0.0201\n",
            "     47       48.2394  0.0211\n",
            "     48       48.2394  0.0206\n",
            "     49       48.2394  0.0205\n",
            "     50       48.2394  0.0207\n",
            "     51       48.2394  0.0210\n",
            "     52       48.2394  0.0214\n",
            "     53       48.2394  0.0210\n",
            "     54       48.2394  0.0207\n",
            "     55       48.2394  0.0238\n",
            "     56       48.2394  0.0204\n",
            "     57       48.2394  0.0200\n",
            "     58       48.2394  0.0208\n",
            "     59       48.2394  0.0199\n",
            "     60       48.2394  0.0200\n",
            "     61       48.2394  0.0202\n",
            "     62       48.2394  0.0269\n",
            "     63       48.2394  0.0254\n",
            "     64       48.2394  0.0302\n",
            "     65       48.2394  0.0252\n",
            "     66       48.2394  0.0339\n",
            "     67       48.2394  0.0291\n",
            "     68       48.2394  0.0268\n",
            "     69       48.2394  0.0286\n",
            "     70       48.2394  0.0267\n",
            "     71       48.2394  0.0272\n",
            "     72       48.2394  0.0281\n",
            "     73       48.2394  0.0290\n",
            "     74       48.2394  0.0288\n",
            "     75       48.2394  0.0276\n",
            "     76       48.2394  0.0251\n",
            "     77       48.2394  0.0249\n",
            "     78       48.2394  0.0219\n",
            "     79       48.2394  0.0225\n",
            "     80       48.2394  0.0216\n",
            "     81       48.2394  0.0210\n",
            "     82       48.2394  0.0197\n",
            "     83       48.2394  0.0200\n",
            "     84       48.2394  0.0197\n",
            "     85       48.2394  0.0207\n",
            "     86       48.2394  0.0200\n",
            "     87       48.2394  0.0191\n",
            "     88       48.2394  0.0211\n",
            "     89       48.2394  0.0218\n",
            "     90       48.2394  0.0213\n",
            "     91       48.2394  0.0214\n",
            "     92       48.2394  0.0222\n",
            "     93       48.2394  0.0248\n",
            "     94       48.2394  0.0204\n",
            "     95       48.2394  0.0207\n",
            "     96       \u001b[36m48.1324\u001b[0m  0.0192\n",
            "     97       \u001b[36m47.8873\u001b[0m  0.0195\n",
            "     98       47.8873  0.0223\n",
            "     99       \u001b[36m47.1831\u001b[0m  0.0199\n",
            "    100       47.1831  0.0214\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m40.3509\u001b[0m  0.0223\n",
            "      2       40.3509  0.0263\n",
            "      3       40.3509  0.0255\n",
            "      4       40.3509  0.0297\n",
            "      5       40.3509  0.0235\n",
            "      6       40.3509  0.0257\n",
            "      7       40.3509  0.0277\n",
            "      8       40.3509  0.0228\n",
            "      9       40.3509  0.0294\n",
            "     10       40.3509  0.0234\n",
            "     11       40.3509  0.0220\n",
            "     12       40.3509  0.0223\n",
            "     13       40.3509  0.0236\n",
            "     14       40.3509  0.0221\n",
            "     15       40.3509  0.0210\n",
            "     16       40.3509  0.0215\n",
            "     17       40.3509  0.0269\n",
            "     18       40.3509  0.0289\n",
            "     19       40.3509  0.0193\n",
            "     20       40.3509  0.0210\n",
            "     21       40.3509  0.0198\n",
            "     22       40.3509  0.0237\n",
            "     23       \u001b[36m40.0000\u001b[0m  0.0204\n",
            "     24       40.0000  0.0199\n",
            "     25       40.0000  0.0207\n",
            "     26       40.0000  0.0213\n",
            "     27       40.0000  0.0199\n",
            "     28       40.0000  0.0205\n",
            "     29       40.0000  0.0211\n",
            "     30       40.0000  0.0242\n",
            "     31       40.0000  0.0220\n",
            "     32       40.0000  0.0236\n",
            "     33       40.0000  0.0227\n",
            "     34       40.0000  0.0209\n",
            "     35       40.0000  0.0214\n",
            "     36       40.0000  0.0213\n",
            "     37       40.0000  0.0208\n",
            "     38       40.0675  0.0208\n",
            "     39       40.0000  0.0212\n",
            "     40       40.0000  0.0215\n",
            "     41       40.0000  0.0229\n",
            "     42       40.3509  0.0253\n",
            "     43       40.3509  0.0246\n",
            "     44       40.3509  0.0241\n",
            "     45       40.3509  0.0214\n",
            "     46       40.3509  0.0267\n",
            "     47       40.3509  0.0261\n",
            "     48       40.3509  0.0246\n",
            "     49       40.3509  0.0271\n",
            "     50       40.3509  0.0284\n",
            "     51       40.3509  0.0302\n",
            "     52       40.3509  0.0253\n",
            "     53       40.3509  0.0313\n",
            "     54       40.3509  0.0239\n",
            "     55       40.3509  0.0187\n",
            "     56       40.3509  0.0207\n",
            "     57       40.3509  0.0227\n",
            "     58       40.3509  0.0294\n",
            "     59       40.3509  0.0224\n",
            "     60       40.3509  0.0184\n",
            "     61       40.3509  0.0187\n",
            "     62       40.3509  0.0199\n",
            "     63       40.3509  0.0202\n",
            "     64       40.3509  0.0203\n",
            "     65       40.3509  0.0190\n",
            "     66       40.3509  0.0201\n",
            "     67       40.3509  0.0193\n",
            "     68       40.3509  0.0210\n",
            "     69       40.3509  0.0192\n",
            "     70       40.3509  0.0234\n",
            "     71       40.3509  0.0201\n",
            "     72       40.3509  0.0212\n",
            "     73       40.3509  0.0200\n",
            "     74       40.3509  0.0188\n",
            "     75       40.3509  0.0197\n",
            "     76       40.3509  0.0203\n",
            "     77       40.3509  0.0186\n",
            "     78       40.3509  0.0197\n",
            "     79       40.3509  0.0182\n",
            "     80       40.3509  0.0251\n",
            "     81       40.3509  0.0222\n",
            "     82       40.3509  0.0234\n",
            "     83       40.3509  0.0235\n",
            "     84       40.3509  0.0244\n",
            "     85       40.3509  0.0253\n",
            "     86       40.3509  0.0253\n",
            "     87       40.3509  0.0251\n",
            "     88       40.3509  0.0228\n",
            "     89       40.3509  0.0242\n",
            "     90       40.3509  0.0339\n",
            "     91       40.3509  0.0222\n",
            "     92       40.3509  0.0205\n",
            "     93       40.3509  0.0191\n",
            "     94       40.3509  0.0204\n",
            "     95       40.3509  0.0210\n",
            "     96       40.1976  0.0192\n",
            "     97       40.0608  0.0202\n",
            "     98       \u001b[36m38.8258\u001b[0m  0.0196\n",
            "     99       38.9474  0.0211\n",
            "    100       \u001b[36m38.5195\u001b[0m  0.0207\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m39.0845\u001b[0m  0.0114\n",
            "      2       39.0845  0.0210\n",
            "      3       39.0845  0.0157\n",
            "      4       39.0845  0.0168\n",
            "      5       39.0845  0.0142\n",
            "      6       39.0845  0.0148\n",
            "      7       39.0845  0.0153\n",
            "      8       39.0845  0.0159\n",
            "      9       39.0845  0.0132\n",
            "     10       39.0845  0.0146\n",
            "     11       39.0845  0.0173\n",
            "     12       39.0845  0.0152\n",
            "     13       39.0845  0.0162\n",
            "     14       39.0845  0.0153\n",
            "     15       39.0845  0.0156\n",
            "     16       39.0845  0.0158\n",
            "     17       39.0845  0.0154\n",
            "     18       39.0845  0.0148\n",
            "     19       39.0845  0.0169\n",
            "     20       39.0845  0.0153\n",
            "     21       39.0845  0.0118\n",
            "     22       39.0845  0.0131\n",
            "     23       39.0845  0.0149\n",
            "     24       39.0845  0.0169\n",
            "     25       39.0845  0.0154\n",
            "     26       39.0845  0.0142\n",
            "     27       39.0845  0.0194\n",
            "     28       39.0845  0.0186\n",
            "     29       39.0845  0.0167\n",
            "     30       39.0845  0.0175\n",
            "     31       39.0845  0.0205\n",
            "     32       39.0845  0.0163\n",
            "     33       39.0845  0.0177\n",
            "     34       39.0845  0.0199\n",
            "     35       39.0845  0.0166\n",
            "     36       39.0845  0.0207\n",
            "     37       39.0845  0.0207\n",
            "     38       39.0845  0.0188\n",
            "     39       39.0845  0.0175\n",
            "     40       39.0845  0.0188\n",
            "     41       39.0845  0.0221\n",
            "     42       39.0845  0.0179\n",
            "     43       39.0845  0.0189\n",
            "     44       39.0845  0.0183\n",
            "     45       39.0845  0.0181\n",
            "     46       39.0845  0.0155\n",
            "     47       39.0845  0.0157\n",
            "     48       39.0845  0.0168\n",
            "     49       39.0845  0.0155\n",
            "     50       39.0845  0.0156\n",
            "     51       39.0845  0.0157\n",
            "     52       39.0845  0.0157\n",
            "     53       39.0845  0.0154\n",
            "     54       39.0845  0.0158\n",
            "     55       39.0845  0.0165\n",
            "     56       39.0845  0.0152\n",
            "     57       39.0845  0.0217\n",
            "     58       39.0845  0.0170\n",
            "     59       39.0845  0.0185\n",
            "     60       39.0845  0.0158\n",
            "     61       39.0845  0.0163\n",
            "     62       39.0845  0.0158\n",
            "     63       39.0845  0.0157\n",
            "     64       39.0845  0.0162\n",
            "     65       39.0845  0.0168\n",
            "     66       39.0845  0.0155\n",
            "     67       39.0845  0.0167\n",
            "     68       39.0845  0.0179\n",
            "     69       39.0845  0.0151\n",
            "     70       39.0845  0.0161\n",
            "     71       39.0845  0.0169\n",
            "     72       39.0845  0.0153\n",
            "     73       39.0845  0.0155\n",
            "     74       39.0845  0.0150\n",
            "     75       39.0845  0.0158\n",
            "     76       39.0845  0.0175\n",
            "     77       39.0845  0.0161\n",
            "     78       39.0845  0.0162\n",
            "     79       39.0845  0.0173\n",
            "     80       39.0845  0.0173\n",
            "     81       39.0845  0.0175\n",
            "     82       39.0845  0.0178\n",
            "     83       39.0845  0.0203\n",
            "     84       39.0845  0.0195\n",
            "     85       39.0845  0.0187\n",
            "     86       39.0845  0.0176\n",
            "     87       39.0845  0.0197\n",
            "     88       39.0845  0.0179\n",
            "     89       39.0845  0.0177\n",
            "     90       39.0845  0.0157\n",
            "     91       39.0845  0.0178\n",
            "     92       39.0845  0.0186\n",
            "     93       39.0845  0.0238\n",
            "     94       39.0845  0.0176\n",
            "     95       39.0845  0.0172\n",
            "     96       39.0845  0.0170\n",
            "     97       39.0845  0.0163\n",
            "     98       39.0845  0.0152\n",
            "     99       39.0845  0.0161\n",
            "    100       39.0845  0.0156\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m59.8703\u001b[0m  0.0148\n",
            "      2       \u001b[36m59.8703\u001b[0m  0.0190\n",
            "      3       \u001b[36m59.8703\u001b[0m  0.0157\n",
            "      4       \u001b[36m59.8703\u001b[0m  0.0155\n",
            "      5       \u001b[36m59.8703\u001b[0m  0.0146\n",
            "      6       \u001b[36m59.8703\u001b[0m  0.0146\n",
            "      7       \u001b[36m59.8703\u001b[0m  0.0150\n",
            "      8       \u001b[36m59.8703\u001b[0m  0.0150\n",
            "      9       \u001b[36m59.8703\u001b[0m  0.0151\n",
            "     10       \u001b[36m59.8703\u001b[0m  0.0154\n",
            "     11       \u001b[36m59.8703\u001b[0m  0.0226\n",
            "     12       \u001b[36m59.8703\u001b[0m  0.0198\n",
            "     13       \u001b[36m59.8703\u001b[0m  0.0171\n",
            "     14       \u001b[36m59.8703\u001b[0m  0.0156\n",
            "     15       \u001b[36m59.8702\u001b[0m  0.0151\n",
            "     16       \u001b[36m59.8702\u001b[0m  0.0143\n",
            "     17       \u001b[36m59.8702\u001b[0m  0.0152\n",
            "     18       \u001b[36m59.8702\u001b[0m  0.0153\n",
            "     19       \u001b[36m59.8702\u001b[0m  0.0163\n",
            "     20       \u001b[36m59.8702\u001b[0m  0.0155\n",
            "     21       \u001b[36m59.8702\u001b[0m  0.0154\n",
            "     22       \u001b[36m59.8702\u001b[0m  0.0195\n",
            "     23       \u001b[36m59.8702\u001b[0m  0.0144\n",
            "     24       \u001b[36m59.8702\u001b[0m  0.0144\n",
            "     25       \u001b[36m59.8702\u001b[0m  0.0149\n",
            "     26       \u001b[36m59.8702\u001b[0m  0.0159\n",
            "     27       \u001b[36m59.8701\u001b[0m  0.0134\n",
            "     28       \u001b[36m59.8701\u001b[0m  0.0137\n",
            "     29       \u001b[36m59.8701\u001b[0m  0.0158\n",
            "     30       \u001b[36m59.8701\u001b[0m  0.0173\n",
            "     31       \u001b[36m59.8701\u001b[0m  0.0174\n",
            "     32       \u001b[36m59.8701\u001b[0m  0.0168\n",
            "     33       \u001b[36m59.8701\u001b[0m  0.0180\n",
            "     34       \u001b[36m59.8701\u001b[0m  0.0186\n",
            "     35       \u001b[36m59.8701\u001b[0m  0.0206\n",
            "     36       \u001b[36m59.8701\u001b[0m  0.0175\n",
            "     37       \u001b[36m59.8701\u001b[0m  0.0192\n",
            "     38       \u001b[36m59.8701\u001b[0m  0.0150\n",
            "     39       \u001b[36m59.8701\u001b[0m  0.0219\n",
            "     40       \u001b[36m59.8700\u001b[0m  0.0250\n",
            "     41       \u001b[36m59.8700\u001b[0m  0.0244\n",
            "     42       \u001b[36m59.8700\u001b[0m  0.0242\n",
            "     43       59.8700  0.0262\n",
            "     44       \u001b[36m59.8700\u001b[0m  0.0153\n",
            "     45       \u001b[36m59.8700\u001b[0m  0.0152\n",
            "     46       \u001b[36m59.8700\u001b[0m  0.0156\n",
            "     47       \u001b[36m59.8700\u001b[0m  0.0155\n",
            "     48       \u001b[36m59.8700\u001b[0m  0.0151\n",
            "     49       \u001b[36m59.8700\u001b[0m  0.0156\n",
            "     50       \u001b[36m59.8700\u001b[0m  0.0161\n",
            "     51       \u001b[36m59.8700\u001b[0m  0.0162\n",
            "     52       \u001b[36m59.8700\u001b[0m  0.0154\n",
            "     53       \u001b[36m59.8699\u001b[0m  0.0160\n",
            "     54       \u001b[36m59.8699\u001b[0m  0.0156\n",
            "     55       \u001b[36m59.8699\u001b[0m  0.0181\n",
            "     56       \u001b[36m59.8699\u001b[0m  0.0162\n",
            "     57       \u001b[36m59.8699\u001b[0m  0.0189\n",
            "     58       \u001b[36m59.8699\u001b[0m  0.0157\n",
            "     59       \u001b[36m59.8699\u001b[0m  0.0176\n",
            "     60       \u001b[36m59.8699\u001b[0m  0.0159\n",
            "     61       \u001b[36m59.8699\u001b[0m  0.0163\n",
            "     62       \u001b[36m59.8699\u001b[0m  0.0189\n",
            "     63       \u001b[36m59.8699\u001b[0m  0.0160\n",
            "     64       \u001b[36m59.8699\u001b[0m  0.0159\n",
            "     65       \u001b[36m59.8698\u001b[0m  0.0149\n",
            "     66       \u001b[36m59.8698\u001b[0m  0.0193\n",
            "     67       \u001b[36m59.8698\u001b[0m  0.0195\n",
            "     68       \u001b[36m59.8698\u001b[0m  0.0163\n",
            "     69       \u001b[36m59.8698\u001b[0m  0.0157\n",
            "     70       \u001b[36m59.8698\u001b[0m  0.0191\n",
            "     71       \u001b[36m59.8698\u001b[0m  0.0153\n",
            "     72       \u001b[36m59.8698\u001b[0m  0.0174\n",
            "     73       \u001b[36m59.8698\u001b[0m  0.0164\n",
            "     74       \u001b[36m59.8698\u001b[0m  0.0163\n",
            "     75       \u001b[36m59.8698\u001b[0m  0.0153\n",
            "     76       \u001b[36m59.8698\u001b[0m  0.0166\n",
            "     77       \u001b[36m59.8698\u001b[0m  0.0158\n",
            "     78       \u001b[36m59.8697\u001b[0m  0.0159\n",
            "     79       \u001b[36m59.8697\u001b[0m  0.0150\n",
            "     80       \u001b[36m59.8697\u001b[0m  0.0190\n",
            "     81       \u001b[36m59.8697\u001b[0m  0.0161\n",
            "     82       \u001b[36m59.8697\u001b[0m  0.0179\n",
            "     83       \u001b[36m59.8697\u001b[0m  0.0181\n",
            "     84       \u001b[36m59.8697\u001b[0m  0.0171\n",
            "     85       \u001b[36m59.8697\u001b[0m  0.0215\n",
            "     86       \u001b[36m59.8697\u001b[0m  0.0252\n",
            "     87       \u001b[36m59.8697\u001b[0m  0.0176\n",
            "     88       \u001b[36m59.8697\u001b[0m  0.0172\n",
            "     89       \u001b[36m59.8697\u001b[0m  0.0163\n",
            "     90       \u001b[36m59.8696\u001b[0m  0.0172\n",
            "     91       \u001b[36m59.8696\u001b[0m  0.0176\n",
            "     92       \u001b[36m59.8696\u001b[0m  0.0181\n",
            "     93       \u001b[36m59.8696\u001b[0m  0.0174\n",
            "     94       \u001b[36m59.8696\u001b[0m  0.0172\n",
            "     95       \u001b[36m59.8696\u001b[0m  0.0171\n",
            "     96       \u001b[36m59.8696\u001b[0m  0.0170\n",
            "     97       \u001b[36m59.8696\u001b[0m  0.0192\n",
            "     98       \u001b[36m59.8696\u001b[0m  0.0204\n",
            "     99       \u001b[36m59.8696\u001b[0m  0.0196\n",
            "    100       \u001b[36m59.8696\u001b[0m  0.0169\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0151\u001b[0m  0.0176\n",
            "      2        \u001b[36m0.9956\u001b[0m  0.0191\n",
            "      3        \u001b[36m0.9770\u001b[0m  0.0211\n",
            "      4        \u001b[36m0.9588\u001b[0m  0.0179\n",
            "      5        \u001b[36m0.9409\u001b[0m  0.0156\n",
            "      6        \u001b[36m0.9235\u001b[0m  0.0201\n",
            "      7        \u001b[36m0.9065\u001b[0m  0.0206\n",
            "      8        \u001b[36m0.8900\u001b[0m  0.0200\n",
            "      9        \u001b[36m0.8740\u001b[0m  0.0174\n",
            "     10        \u001b[36m0.8586\u001b[0m  0.0211\n",
            "     11        \u001b[36m0.8437\u001b[0m  0.0197\n",
            "     12        \u001b[36m0.8293\u001b[0m  0.0194\n",
            "     13        \u001b[36m0.8155\u001b[0m  0.0182\n",
            "     14        \u001b[36m0.8021\u001b[0m  0.0211\n",
            "     15        \u001b[36m0.7891\u001b[0m  0.0199\n",
            "     16        \u001b[36m0.7766\u001b[0m  0.0194\n",
            "     17        \u001b[36m0.7646\u001b[0m  0.0310\n",
            "     18        \u001b[36m0.7529\u001b[0m  0.0220\n",
            "     19        \u001b[36m0.7418\u001b[0m  0.0204\n",
            "     20        \u001b[36m0.7311\u001b[0m  0.0211\n",
            "     21        \u001b[36m0.7209\u001b[0m  0.0257\n",
            "     22        \u001b[36m0.7114\u001b[0m  0.0231\n",
            "     23        \u001b[36m0.7026\u001b[0m  0.0200\n",
            "     24        \u001b[36m0.6948\u001b[0m  0.0188\n",
            "     25        \u001b[36m0.6879\u001b[0m  0.0214\n",
            "     26        \u001b[36m0.6820\u001b[0m  0.0222\n",
            "     27        \u001b[36m0.6772\u001b[0m  0.0233\n",
            "     28        \u001b[36m0.6733\u001b[0m  0.0253\n",
            "     29        \u001b[36m0.6703\u001b[0m  0.0225\n",
            "     30        \u001b[36m0.6680\u001b[0m  0.0209\n",
            "     31        \u001b[36m0.6663\u001b[0m  0.0235\n",
            "     32        \u001b[36m0.6650\u001b[0m  0.0223\n",
            "     33        \u001b[36m0.6641\u001b[0m  0.0214\n",
            "     34        \u001b[36m0.6634\u001b[0m  0.0218\n",
            "     35        \u001b[36m0.6629\u001b[0m  0.0231\n",
            "     36        \u001b[36m0.6626\u001b[0m  0.0205\n",
            "     37        \u001b[36m0.6623\u001b[0m  0.0218\n",
            "     38        \u001b[36m0.6621\u001b[0m  0.0200\n",
            "     39        \u001b[36m0.6620\u001b[0m  0.0228\n",
            "     40        \u001b[36m0.6619\u001b[0m  0.0207\n",
            "     41        \u001b[36m0.6618\u001b[0m  0.0215\n",
            "     42        \u001b[36m0.6617\u001b[0m  0.0203\n",
            "     43        \u001b[36m0.6617\u001b[0m  0.0193\n",
            "     44        \u001b[36m0.6616\u001b[0m  0.0218\n",
            "     45        \u001b[36m0.6616\u001b[0m  0.0193\n",
            "     46        \u001b[36m0.6616\u001b[0m  0.0218\n",
            "     47        \u001b[36m0.6616\u001b[0m  0.0197\n",
            "     48        \u001b[36m0.6615\u001b[0m  0.0211\n",
            "     49        \u001b[36m0.6615\u001b[0m  0.0196\n",
            "     50        \u001b[36m0.6615\u001b[0m  0.0200\n",
            "     51        \u001b[36m0.6615\u001b[0m  0.0191\n",
            "     52        \u001b[36m0.6615\u001b[0m  0.0209\n",
            "     53        \u001b[36m0.6615\u001b[0m  0.0188\n",
            "     54        \u001b[36m0.6615\u001b[0m  0.0206\n",
            "     55        \u001b[36m0.6615\u001b[0m  0.0216\n",
            "     56        \u001b[36m0.6615\u001b[0m  0.0205\n",
            "     57        \u001b[36m0.6615\u001b[0m  0.0197\n",
            "     58        \u001b[36m0.6615\u001b[0m  0.0189\n",
            "     59        \u001b[36m0.6615\u001b[0m  0.0193\n",
            "     60        \u001b[36m0.6615\u001b[0m  0.0208\n",
            "     61        \u001b[36m0.6614\u001b[0m  0.0222\n",
            "     62        \u001b[36m0.6614\u001b[0m  0.0247\n",
            "     63        \u001b[36m0.6614\u001b[0m  0.0207\n",
            "     64        \u001b[36m0.6614\u001b[0m  0.0203\n",
            "     65        \u001b[36m0.6614\u001b[0m  0.0183\n",
            "     66        \u001b[36m0.6614\u001b[0m  0.0185\n",
            "     67        \u001b[36m0.6614\u001b[0m  0.0199\n",
            "     68        \u001b[36m0.6614\u001b[0m  0.0196\n",
            "     69        \u001b[36m0.6614\u001b[0m  0.0206\n",
            "     70        \u001b[36m0.6614\u001b[0m  0.0251\n",
            "     71        \u001b[36m0.6614\u001b[0m  0.0224\n",
            "     72        \u001b[36m0.6614\u001b[0m  0.0233\n",
            "     73        \u001b[36m0.6614\u001b[0m  0.0234\n",
            "     74        \u001b[36m0.6614\u001b[0m  0.0219\n",
            "     75        \u001b[36m0.6614\u001b[0m  0.0231\n",
            "     76        \u001b[36m0.6614\u001b[0m  0.0265\n",
            "     77        \u001b[36m0.6614\u001b[0m  0.0245\n",
            "     78        \u001b[36m0.6614\u001b[0m  0.0222\n",
            "     79        \u001b[36m0.6614\u001b[0m  0.0228\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0204\n",
            "     81        \u001b[36m0.6614\u001b[0m  0.0213\n",
            "     82        \u001b[36m0.6614\u001b[0m  0.0212\n",
            "     83        \u001b[36m0.6614\u001b[0m  0.0209\n",
            "     84        \u001b[36m0.6614\u001b[0m  0.0188\n",
            "     85        \u001b[36m0.6614\u001b[0m  0.0193\n",
            "     86        \u001b[36m0.6614\u001b[0m  0.0203\n",
            "     87        \u001b[36m0.6614\u001b[0m  0.0182\n",
            "     88        \u001b[36m0.6614\u001b[0m  0.0200\n",
            "     89        \u001b[36m0.6614\u001b[0m  0.0202\n",
            "     90        \u001b[36m0.6614\u001b[0m  0.0184\n",
            "     91        \u001b[36m0.6614\u001b[0m  0.0192\n",
            "     92        \u001b[36m0.6614\u001b[0m  0.0185\n",
            "     93        \u001b[36m0.6614\u001b[0m  0.0239\n",
            "     94        \u001b[36m0.6614\u001b[0m  0.0203\n",
            "     95        \u001b[36m0.6614\u001b[0m  0.0192\n",
            "     96        \u001b[36m0.6614\u001b[0m  0.0215\n",
            "     97        \u001b[36m0.6614\u001b[0m  0.0177\n",
            "     98        \u001b[36m0.6614\u001b[0m  0.0190\n",
            "     99        \u001b[36m0.6614\u001b[0m  0.0193\n",
            "    100        \u001b[36m0.6614\u001b[0m  0.0215\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.3374\u001b[0m  0.0145\n",
            "      2        \u001b[36m1.3129\u001b[0m  0.0200\n",
            "      3        \u001b[36m1.2906\u001b[0m  0.0195\n",
            "      4        \u001b[36m1.2685\u001b[0m  0.0223\n",
            "      5        \u001b[36m1.2467\u001b[0m  0.0164\n",
            "      6        \u001b[36m1.2250\u001b[0m  0.0253\n",
            "      7        \u001b[36m1.2034\u001b[0m  0.0243\n",
            "      8        \u001b[36m1.1821\u001b[0m  0.0227\n",
            "      9        \u001b[36m1.1610\u001b[0m  0.0183\n",
            "     10        \u001b[36m1.1401\u001b[0m  0.0190\n",
            "     11        \u001b[36m1.1195\u001b[0m  0.0219\n",
            "     12        \u001b[36m1.0991\u001b[0m  0.0193\n",
            "     13        \u001b[36m1.0790\u001b[0m  0.0214\n",
            "     14        \u001b[36m1.0591\u001b[0m  0.0226\n",
            "     15        \u001b[36m1.0395\u001b[0m  0.0249\n",
            "     16        \u001b[36m1.0200\u001b[0m  0.0231\n",
            "     17        \u001b[36m1.0007\u001b[0m  0.0225\n",
            "     18        \u001b[36m0.9813\u001b[0m  0.0223\n",
            "     19        \u001b[36m0.9619\u001b[0m  0.0189\n",
            "     20        \u001b[36m0.9423\u001b[0m  0.0225\n",
            "     21        \u001b[36m0.9222\u001b[0m  0.0228\n",
            "     22        \u001b[36m0.9014\u001b[0m  0.0224\n",
            "     23        \u001b[36m0.8798\u001b[0m  0.0287\n",
            "     24        \u001b[36m0.8571\u001b[0m  0.0306\n",
            "     25        \u001b[36m0.8332\u001b[0m  0.0194\n",
            "     26        \u001b[36m0.8083\u001b[0m  0.0202\n",
            "     27        \u001b[36m0.7828\u001b[0m  0.0186\n",
            "     28        \u001b[36m0.7578\u001b[0m  0.0187\n",
            "     29        \u001b[36m0.7345\u001b[0m  0.0203\n",
            "     30        \u001b[36m0.7143\u001b[0m  0.0181\n",
            "     31        \u001b[36m0.6980\u001b[0m  0.0272\n",
            "     32        \u001b[36m0.6859\u001b[0m  0.0253\n",
            "     33        \u001b[36m0.6775\u001b[0m  0.0281\n",
            "     34        \u001b[36m0.6719\u001b[0m  0.0203\n",
            "     35        \u001b[36m0.6683\u001b[0m  0.0204\n",
            "     36        \u001b[36m0.6660\u001b[0m  0.0190\n",
            "     37        \u001b[36m0.6646\u001b[0m  0.0210\n",
            "     38        \u001b[36m0.6637\u001b[0m  0.0256\n",
            "     39        \u001b[36m0.6631\u001b[0m  0.0282\n",
            "     40        \u001b[36m0.6627\u001b[0m  0.0290\n",
            "     41        \u001b[36m0.6624\u001b[0m  0.0302\n",
            "     42        \u001b[36m0.6622\u001b[0m  0.0266\n",
            "     43        \u001b[36m0.6621\u001b[0m  0.0188\n",
            "     44        \u001b[36m0.6620\u001b[0m  0.0186\n",
            "     45        \u001b[36m0.6620\u001b[0m  0.0197\n",
            "     46        \u001b[36m0.6619\u001b[0m  0.0215\n",
            "     47        \u001b[36m0.6619\u001b[0m  0.0311\n",
            "     48        \u001b[36m0.6618\u001b[0m  0.0264\n",
            "     49        \u001b[36m0.6618\u001b[0m  0.0261\n",
            "     50        \u001b[36m0.6618\u001b[0m  0.0250\n",
            "     51        \u001b[36m0.6618\u001b[0m  0.0239\n",
            "     52        \u001b[36m0.6618\u001b[0m  0.0247\n",
            "     53        \u001b[36m0.6618\u001b[0m  0.0243\n",
            "     54        \u001b[36m0.6617\u001b[0m  0.0268\n",
            "     55        \u001b[36m0.6617\u001b[0m  0.0274\n",
            "     56        \u001b[36m0.6617\u001b[0m  0.0223\n",
            "     57        \u001b[36m0.6617\u001b[0m  0.0234\n",
            "     58        \u001b[36m0.6617\u001b[0m  0.0199\n",
            "     59        \u001b[36m0.6617\u001b[0m  0.0235\n",
            "     60        \u001b[36m0.6617\u001b[0m  0.0229\n",
            "     61        \u001b[36m0.6617\u001b[0m  0.0237\n",
            "     62        \u001b[36m0.6617\u001b[0m  0.0234\n",
            "     63        \u001b[36m0.6617\u001b[0m  0.0198\n",
            "     64        \u001b[36m0.6617\u001b[0m  0.0197\n",
            "     65        \u001b[36m0.6617\u001b[0m  0.0245\n",
            "     66        \u001b[36m0.6617\u001b[0m  0.0270\n",
            "     67        \u001b[36m0.6617\u001b[0m  0.0204\n",
            "     68        \u001b[36m0.6617\u001b[0m  0.0210\n",
            "     69        \u001b[36m0.6617\u001b[0m  0.0206\n",
            "     70        \u001b[36m0.6616\u001b[0m  0.0247\n",
            "     71        \u001b[36m0.6616\u001b[0m  0.0201\n",
            "     72        \u001b[36m0.6616\u001b[0m  0.0200\n",
            "     73        \u001b[36m0.6616\u001b[0m  0.0229\n",
            "     74        \u001b[36m0.6616\u001b[0m  0.0209\n",
            "     75        \u001b[36m0.6616\u001b[0m  0.0196\n",
            "     76        \u001b[36m0.6616\u001b[0m  0.0198\n",
            "     77        \u001b[36m0.6616\u001b[0m  0.0201\n",
            "     78        \u001b[36m0.6616\u001b[0m  0.0247\n",
            "     79        \u001b[36m0.6616\u001b[0m  0.0192\n",
            "     80        \u001b[36m0.6616\u001b[0m  0.0192\n",
            "     81        \u001b[36m0.6616\u001b[0m  0.0185\n",
            "     82        \u001b[36m0.6616\u001b[0m  0.0190\n",
            "     83        \u001b[36m0.6616\u001b[0m  0.0203\n",
            "     84        \u001b[36m0.6616\u001b[0m  0.0244\n",
            "     85        \u001b[36m0.6616\u001b[0m  0.0188\n",
            "     86        \u001b[36m0.6616\u001b[0m  0.0194\n",
            "     87        \u001b[36m0.6616\u001b[0m  0.0190\n",
            "     88        \u001b[36m0.6616\u001b[0m  0.0193\n",
            "     89        \u001b[36m0.6616\u001b[0m  0.0189\n",
            "     90        \u001b[36m0.6616\u001b[0m  0.0194\n",
            "     91        \u001b[36m0.6616\u001b[0m  0.0304\n",
            "     92        \u001b[36m0.6616\u001b[0m  0.0267\n",
            "     93        \u001b[36m0.6616\u001b[0m  0.0287\n",
            "     94        \u001b[36m0.6616\u001b[0m  0.0245\n",
            "     95        \u001b[36m0.6616\u001b[0m  0.0329\n",
            "     96        \u001b[36m0.6616\u001b[0m  0.0297\n",
            "     97        \u001b[36m0.6616\u001b[0m  0.0309\n",
            "     98        \u001b[36m0.6616\u001b[0m  0.0350\n",
            "     99        \u001b[36m0.6616\u001b[0m  0.0272\n",
            "    100        \u001b[36m0.6616\u001b[0m  0.0274\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.6882\u001b[0m  0.0213\n",
            "      2        \u001b[36m1.6763\u001b[0m  0.0164\n",
            "      3        \u001b[36m1.6645\u001b[0m  0.0268\n",
            "      4        \u001b[36m1.6527\u001b[0m  0.0184\n",
            "      5        \u001b[36m1.6409\u001b[0m  0.0162\n",
            "      6        \u001b[36m1.6291\u001b[0m  0.0247\n",
            "      7        \u001b[36m1.6174\u001b[0m  0.0197\n",
            "      8        \u001b[36m1.6057\u001b[0m  0.0238\n",
            "      9        \u001b[36m1.5940\u001b[0m  0.0207\n",
            "     10        \u001b[36m1.5824\u001b[0m  0.0218\n",
            "     11        \u001b[36m1.5708\u001b[0m  0.0212\n",
            "     12        \u001b[36m1.5592\u001b[0m  0.0176\n",
            "     13        \u001b[36m1.5477\u001b[0m  0.0178\n",
            "     14        \u001b[36m1.5362\u001b[0m  0.0163\n",
            "     15        \u001b[36m1.5247\u001b[0m  0.0151\n",
            "     16        \u001b[36m1.5132\u001b[0m  0.0198\n",
            "     17        \u001b[36m1.5018\u001b[0m  0.0218\n",
            "     18        \u001b[36m1.4905\u001b[0m  0.0185\n",
            "     19        \u001b[36m1.4791\u001b[0m  0.0172\n",
            "     20        \u001b[36m1.4678\u001b[0m  0.0156\n",
            "     21        \u001b[36m1.4566\u001b[0m  0.0164\n",
            "     22        \u001b[36m1.4454\u001b[0m  0.0168\n",
            "     23        \u001b[36m1.4342\u001b[0m  0.0198\n",
            "     24        \u001b[36m1.4231\u001b[0m  0.0234\n",
            "     25        \u001b[36m1.4120\u001b[0m  0.0200\n",
            "     26        \u001b[36m1.4010\u001b[0m  0.0162\n",
            "     27        \u001b[36m1.3900\u001b[0m  0.0202\n",
            "     28        \u001b[36m1.3791\u001b[0m  0.0174\n",
            "     29        \u001b[36m1.3682\u001b[0m  0.0202\n",
            "     30        \u001b[36m1.3573\u001b[0m  0.0179\n",
            "     31        \u001b[36m1.3466\u001b[0m  0.0208\n",
            "     32        \u001b[36m1.3358\u001b[0m  0.0180\n",
            "     33        \u001b[36m1.3252\u001b[0m  0.0176\n",
            "     34        \u001b[36m1.3145\u001b[0m  0.0257\n",
            "     35        \u001b[36m1.3040\u001b[0m  0.0240\n",
            "     36        \u001b[36m1.2935\u001b[0m  0.0288\n",
            "     37        \u001b[36m1.2830\u001b[0m  0.0258\n",
            "     38        \u001b[36m1.2727\u001b[0m  0.0250\n",
            "     39        \u001b[36m1.2624\u001b[0m  0.0237\n",
            "     40        \u001b[36m1.2521\u001b[0m  0.0249\n",
            "     41        \u001b[36m1.2419\u001b[0m  0.0254\n",
            "     42        \u001b[36m1.2318\u001b[0m  0.0258\n",
            "     43        \u001b[36m1.2218\u001b[0m  0.0156\n",
            "     44        \u001b[36m1.2118\u001b[0m  0.0171\n",
            "     45        \u001b[36m1.2019\u001b[0m  0.0161\n",
            "     46        \u001b[36m1.1920\u001b[0m  0.0167\n",
            "     47        \u001b[36m1.1823\u001b[0m  0.0161\n",
            "     48        \u001b[36m1.1726\u001b[0m  0.0157\n",
            "     49        \u001b[36m1.1630\u001b[0m  0.0197\n",
            "     50        \u001b[36m1.1535\u001b[0m  0.0204\n",
            "     51        \u001b[36m1.1440\u001b[0m  0.0180\n",
            "     52        \u001b[36m1.1347\u001b[0m  0.0168\n",
            "     53        \u001b[36m1.1254\u001b[0m  0.0193\n",
            "     54        \u001b[36m1.1162\u001b[0m  0.0189\n",
            "     55        \u001b[36m1.1071\u001b[0m  0.0239\n",
            "     56        \u001b[36m1.0981\u001b[0m  0.0205\n",
            "     57        \u001b[36m1.0892\u001b[0m  0.0189\n",
            "     58        \u001b[36m1.0803\u001b[0m  0.0180\n",
            "     59        \u001b[36m1.0716\u001b[0m  0.0230\n",
            "     60        \u001b[36m1.0629\u001b[0m  0.0158\n",
            "     61        \u001b[36m1.0544\u001b[0m  0.0197\n",
            "     62        \u001b[36m1.0459\u001b[0m  0.0203\n",
            "     63        \u001b[36m1.0375\u001b[0m  0.0177\n",
            "     64        \u001b[36m1.0293\u001b[0m  0.0166\n",
            "     65        \u001b[36m1.0211\u001b[0m  0.0165\n",
            "     66        \u001b[36m1.0130\u001b[0m  0.0233\n",
            "     67        \u001b[36m1.0051\u001b[0m  0.0198\n",
            "     68        \u001b[36m0.9972\u001b[0m  0.0199\n",
            "     69        \u001b[36m0.9894\u001b[0m  0.0157\n",
            "     70        \u001b[36m0.9818\u001b[0m  0.0250\n",
            "     71        \u001b[36m0.9742\u001b[0m  0.0205\n",
            "     72        \u001b[36m0.9668\u001b[0m  0.0184\n",
            "     73        \u001b[36m0.9594\u001b[0m  0.0196\n",
            "     74        \u001b[36m0.9522\u001b[0m  0.0193\n",
            "     75        \u001b[36m0.9451\u001b[0m  0.0198\n",
            "     76        \u001b[36m0.9381\u001b[0m  0.0180\n",
            "     77        \u001b[36m0.9312\u001b[0m  0.0219\n",
            "     78        \u001b[36m0.9244\u001b[0m  0.0198\n",
            "     79        \u001b[36m0.9177\u001b[0m  0.0258\n",
            "     80        \u001b[36m0.9111\u001b[0m  0.0245\n",
            "     81        \u001b[36m0.9046\u001b[0m  0.0295\n",
            "     82        \u001b[36m0.8983\u001b[0m  0.0238\n",
            "     83        \u001b[36m0.8920\u001b[0m  0.0216\n",
            "     84        \u001b[36m0.8859\u001b[0m  0.0277\n",
            "     85        \u001b[36m0.8799\u001b[0m  0.0231\n",
            "     86        \u001b[36m0.8740\u001b[0m  0.0210\n",
            "     87        \u001b[36m0.8682\u001b[0m  0.0248\n",
            "     88        \u001b[36m0.8625\u001b[0m  0.0258\n",
            "     89        \u001b[36m0.8569\u001b[0m  0.0217\n",
            "     90        \u001b[36m0.8514\u001b[0m  0.0183\n",
            "     91        \u001b[36m0.8461\u001b[0m  0.0173\n",
            "     92        \u001b[36m0.8408\u001b[0m  0.0180\n",
            "     93        \u001b[36m0.8357\u001b[0m  0.0224\n",
            "     94        \u001b[36m0.8307\u001b[0m  0.0212\n",
            "     95        \u001b[36m0.8257\u001b[0m  0.0187\n",
            "     96        \u001b[36m0.8209\u001b[0m  0.0169\n",
            "     97        \u001b[36m0.8162\u001b[0m  0.0165\n",
            "     98        \u001b[36m0.8116\u001b[0m  0.0164\n",
            "     99        \u001b[36m0.8071\u001b[0m  0.0165\n",
            "    100        \u001b[36m0.8027\u001b[0m  0.0177\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0928\u001b[0m  0.0158\n",
            "      2        \u001b[36m1.0845\u001b[0m  0.0171\n",
            "      3        \u001b[36m1.0764\u001b[0m  0.0185\n",
            "      4        \u001b[36m1.0683\u001b[0m  0.0172\n",
            "      5        \u001b[36m1.0603\u001b[0m  0.0172\n",
            "      6        \u001b[36m1.0524\u001b[0m  0.0168\n",
            "      7        \u001b[36m1.0445\u001b[0m  0.0192\n",
            "      8        \u001b[36m1.0368\u001b[0m  0.0195\n",
            "      9        \u001b[36m1.0291\u001b[0m  0.0175\n",
            "     10        \u001b[36m1.0216\u001b[0m  0.0168\n",
            "     11        \u001b[36m1.0141\u001b[0m  0.0164\n",
            "     12        \u001b[36m1.0067\u001b[0m  0.0188\n",
            "     13        \u001b[36m0.9994\u001b[0m  0.0194\n",
            "     14        \u001b[36m0.9922\u001b[0m  0.0152\n",
            "     15        \u001b[36m0.9851\u001b[0m  0.0159\n",
            "     16        \u001b[36m0.9780\u001b[0m  0.0154\n",
            "     17        \u001b[36m0.9711\u001b[0m  0.0158\n",
            "     18        \u001b[36m0.9643\u001b[0m  0.0163\n",
            "     19        \u001b[36m0.9575\u001b[0m  0.0150\n",
            "     20        \u001b[36m0.9509\u001b[0m  0.0175\n",
            "     21        \u001b[36m0.9443\u001b[0m  0.0174\n",
            "     22        \u001b[36m0.9378\u001b[0m  0.0258\n",
            "     23        \u001b[36m0.9315\u001b[0m  0.0249\n",
            "     24        \u001b[36m0.9252\u001b[0m  0.0231\n",
            "     25        \u001b[36m0.9190\u001b[0m  0.0222\n",
            "     26        \u001b[36m0.9130\u001b[0m  0.0246\n",
            "     27        \u001b[36m0.9070\u001b[0m  0.0283\n",
            "     28        \u001b[36m0.9011\u001b[0m  0.0208\n",
            "     29        \u001b[36m0.8953\u001b[0m  0.0234\n",
            "     30        \u001b[36m0.8896\u001b[0m  0.0186\n",
            "     31        \u001b[36m0.8841\u001b[0m  0.0195\n",
            "     32        \u001b[36m0.8786\u001b[0m  0.0206\n",
            "     33        \u001b[36m0.8732\u001b[0m  0.0189\n",
            "     34        \u001b[36m0.8679\u001b[0m  0.0173\n",
            "     35        \u001b[36m0.8627\u001b[0m  0.0183\n",
            "     36        \u001b[36m0.8576\u001b[0m  0.0175\n",
            "     37        \u001b[36m0.8526\u001b[0m  0.0182\n",
            "     38        \u001b[36m0.8477\u001b[0m  0.0175\n",
            "     39        \u001b[36m0.8428\u001b[0m  0.0241\n",
            "     40        \u001b[36m0.8381\u001b[0m  0.0204\n",
            "     41        \u001b[36m0.8335\u001b[0m  0.0202\n",
            "     42        \u001b[36m0.8290\u001b[0m  0.0159\n",
            "     43        \u001b[36m0.8245\u001b[0m  0.0234\n",
            "     44        \u001b[36m0.8202\u001b[0m  0.0225\n",
            "     45        \u001b[36m0.8159\u001b[0m  0.0164\n",
            "     46        \u001b[36m0.8117\u001b[0m  0.0152\n",
            "     47        \u001b[36m0.8076\u001b[0m  0.0155\n",
            "     48        \u001b[36m0.8037\u001b[0m  0.0158\n",
            "     49        \u001b[36m0.7997\u001b[0m  0.0158\n",
            "     50        \u001b[36m0.7959\u001b[0m  0.0156\n",
            "     51        \u001b[36m0.7922\u001b[0m  0.0166\n",
            "     52        \u001b[36m0.7886\u001b[0m  0.0183\n",
            "     53        \u001b[36m0.7850\u001b[0m  0.0173\n",
            "     54        \u001b[36m0.7815\u001b[0m  0.0147\n",
            "     55        \u001b[36m0.7781\u001b[0m  0.0146\n",
            "     56        \u001b[36m0.7748\u001b[0m  0.0159\n",
            "     57        \u001b[36m0.7716\u001b[0m  0.0147\n",
            "     58        \u001b[36m0.7684\u001b[0m  0.0187\n",
            "     59        \u001b[36m0.7653\u001b[0m  0.0163\n",
            "     60        \u001b[36m0.7623\u001b[0m  0.0152\n",
            "     61        \u001b[36m0.7594\u001b[0m  0.0147\n",
            "     62        \u001b[36m0.7565\u001b[0m  0.0179\n",
            "     63        \u001b[36m0.7538\u001b[0m  0.0161\n",
            "     64        \u001b[36m0.7510\u001b[0m  0.0161\n",
            "     65        \u001b[36m0.7484\u001b[0m  0.0196\n",
            "     66        \u001b[36m0.7458\u001b[0m  0.0155\n",
            "     67        \u001b[36m0.7433\u001b[0m  0.0176\n",
            "     68        \u001b[36m0.7409\u001b[0m  0.0179\n",
            "     69        \u001b[36m0.7385\u001b[0m  0.0193\n",
            "     70        \u001b[36m0.7362\u001b[0m  0.0180\n",
            "     71        \u001b[36m0.7340\u001b[0m  0.0180\n",
            "     72        \u001b[36m0.7318\u001b[0m  0.0184\n",
            "     73        \u001b[36m0.7296\u001b[0m  0.0175\n",
            "     74        \u001b[36m0.7276\u001b[0m  0.0177\n",
            "     75        \u001b[36m0.7256\u001b[0m  0.0178\n",
            "     76        \u001b[36m0.7236\u001b[0m  0.0195\n",
            "     77        \u001b[36m0.7217\u001b[0m  0.0244\n",
            "     78        \u001b[36m0.7199\u001b[0m  0.0184\n",
            "     79        \u001b[36m0.7181\u001b[0m  0.0202\n",
            "     80        \u001b[36m0.7163\u001b[0m  0.0175\n",
            "     81        \u001b[36m0.7146\u001b[0m  0.0157\n",
            "     82        \u001b[36m0.7130\u001b[0m  0.0160\n",
            "     83        \u001b[36m0.7114\u001b[0m  0.0199\n",
            "     84        \u001b[36m0.7099\u001b[0m  0.0152\n",
            "     85        \u001b[36m0.7084\u001b[0m  0.0143\n",
            "     86        \u001b[36m0.7069\u001b[0m  0.0151\n",
            "     87        \u001b[36m0.7055\u001b[0m  0.0139\n",
            "     88        \u001b[36m0.7041\u001b[0m  0.0148\n",
            "     89        \u001b[36m0.7028\u001b[0m  0.0142\n",
            "     90        \u001b[36m0.7015\u001b[0m  0.0157\n",
            "     91        \u001b[36m0.7002\u001b[0m  0.0148\n",
            "     92        \u001b[36m0.6990\u001b[0m  0.0148\n",
            "     93        \u001b[36m0.6979\u001b[0m  0.0160\n",
            "     94        \u001b[36m0.6967\u001b[0m  0.0155\n",
            "     95        \u001b[36m0.6956\u001b[0m  0.0157\n",
            "     96        \u001b[36m0.6945\u001b[0m  0.0172\n",
            "     97        \u001b[36m0.6935\u001b[0m  0.0167\n",
            "     98        \u001b[36m0.6925\u001b[0m  0.0171\n",
            "     99        \u001b[36m0.6915\u001b[0m  0.0167\n",
            "    100        \u001b[36m0.6906\u001b[0m  0.0179\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6232\u001b[0m  0.0201\n",
            "      2        \u001b[36m2.5736\u001b[0m  0.0209\n",
            "      3        \u001b[36m2.5246\u001b[0m  0.0230\n",
            "      4        \u001b[36m2.4751\u001b[0m  0.0209\n",
            "      5        \u001b[36m2.4253\u001b[0m  0.0204\n",
            "      6        \u001b[36m2.3753\u001b[0m  0.0204\n",
            "      7        \u001b[36m2.3251\u001b[0m  0.0213\n",
            "      8        \u001b[36m2.2748\u001b[0m  0.0194\n",
            "      9        \u001b[36m2.2245\u001b[0m  0.0202\n",
            "     10        \u001b[36m2.1741\u001b[0m  0.0204\n",
            "     11        \u001b[36m2.1238\u001b[0m  0.0229\n",
            "     12        \u001b[36m2.0735\u001b[0m  0.0264\n",
            "     13        \u001b[36m2.0232\u001b[0m  0.0250\n",
            "     14        \u001b[36m1.9731\u001b[0m  0.0294\n",
            "     15        \u001b[36m1.9231\u001b[0m  0.0245\n",
            "     16        \u001b[36m1.8732\u001b[0m  0.0252\n",
            "     17        \u001b[36m1.8234\u001b[0m  0.0249\n",
            "     18        \u001b[36m1.7739\u001b[0m  0.0280\n",
            "     19        \u001b[36m1.7244\u001b[0m  0.0225\n",
            "     20        \u001b[36m1.6750\u001b[0m  0.0215\n",
            "     21        \u001b[36m1.6252\u001b[0m  0.0203\n",
            "     22        \u001b[36m1.5743\u001b[0m  0.0218\n",
            "     23        \u001b[36m1.5201\u001b[0m  0.0223\n",
            "     24        \u001b[36m1.4579\u001b[0m  0.0271\n",
            "     25        \u001b[36m1.3774\u001b[0m  0.0207\n",
            "     26        \u001b[36m1.2623\u001b[0m  0.0183\n",
            "     27        \u001b[36m1.1030\u001b[0m  0.0218\n",
            "     28        \u001b[36m0.9282\u001b[0m  0.0222\n",
            "     29        \u001b[36m0.7952\u001b[0m  0.0214\n",
            "     30        \u001b[36m0.7226\u001b[0m  0.0212\n",
            "     31        \u001b[36m0.6892\u001b[0m  0.0205\n",
            "     32        \u001b[36m0.6747\u001b[0m  0.0186\n",
            "     33        \u001b[36m0.6682\u001b[0m  0.0212\n",
            "     34        \u001b[36m0.6653\u001b[0m  0.0195\n",
            "     35        \u001b[36m0.6638\u001b[0m  0.0209\n",
            "     36        \u001b[36m0.6631\u001b[0m  0.0182\n",
            "     37        \u001b[36m0.6627\u001b[0m  0.0226\n",
            "     38        \u001b[36m0.6625\u001b[0m  0.0216\n",
            "     39        \u001b[36m0.6624\u001b[0m  0.0191\n",
            "     40        \u001b[36m0.6624\u001b[0m  0.0205\n",
            "     41        \u001b[36m0.6624\u001b[0m  0.0197\n",
            "     42        \u001b[36m0.6623\u001b[0m  0.0197\n",
            "     43        \u001b[36m0.6623\u001b[0m  0.0216\n",
            "     44        \u001b[36m0.6623\u001b[0m  0.0203\n",
            "     45        \u001b[36m0.6623\u001b[0m  0.0188\n",
            "     46        \u001b[36m0.6623\u001b[0m  0.0202\n",
            "     47        \u001b[36m0.6623\u001b[0m  0.0196\n",
            "     48        \u001b[36m0.6623\u001b[0m  0.0197\n",
            "     49        \u001b[36m0.6622\u001b[0m  0.0204\n",
            "     50        \u001b[36m0.6622\u001b[0m  0.0230\n",
            "     51        \u001b[36m0.6622\u001b[0m  0.0213\n",
            "     52        \u001b[36m0.6622\u001b[0m  0.0224\n",
            "     53        \u001b[36m0.6622\u001b[0m  0.0256\n",
            "     54        \u001b[36m0.6622\u001b[0m  0.0275\n",
            "     55        \u001b[36m0.6622\u001b[0m  0.0308\n",
            "     56        \u001b[36m0.6622\u001b[0m  0.0236\n",
            "     57        \u001b[36m0.6622\u001b[0m  0.0249\n",
            "     58        \u001b[36m0.6622\u001b[0m  0.0226\n",
            "     59        \u001b[36m0.6622\u001b[0m  0.0251\n",
            "     60        \u001b[36m0.6622\u001b[0m  0.0282\n",
            "     61        \u001b[36m0.6622\u001b[0m  0.0238\n",
            "     62        \u001b[36m0.6622\u001b[0m  0.0283\n",
            "     63        \u001b[36m0.6622\u001b[0m  0.0298\n",
            "     64        \u001b[36m0.6622\u001b[0m  0.0258\n",
            "     65        \u001b[36m0.6622\u001b[0m  0.0249\n",
            "     66        \u001b[36m0.6622\u001b[0m  0.0204\n",
            "     67        \u001b[36m0.6622\u001b[0m  0.0222\n",
            "     68        \u001b[36m0.6622\u001b[0m  0.0196\n",
            "     69        \u001b[36m0.6622\u001b[0m  0.0191\n",
            "     70        \u001b[36m0.6622\u001b[0m  0.0194\n",
            "     71        \u001b[36m0.6622\u001b[0m  0.0188\n",
            "     72        \u001b[36m0.6622\u001b[0m  0.0195\n",
            "     73        \u001b[36m0.6622\u001b[0m  0.0194\n",
            "     74        \u001b[36m0.6622\u001b[0m  0.0198\n",
            "     75        \u001b[36m0.6622\u001b[0m  0.0205\n",
            "     76        \u001b[36m0.6622\u001b[0m  0.0196\n",
            "     77        \u001b[36m0.6622\u001b[0m  0.0192\n",
            "     78        \u001b[36m0.6622\u001b[0m  0.0198\n",
            "     79        \u001b[36m0.6567\u001b[0m  0.0218\n",
            "     80        0.6672  0.0204\n",
            "     81        0.6640  0.0205\n",
            "     82        0.6618  0.0213\n",
            "     83        0.6616  0.0194\n",
            "     84        0.6614  0.0204\n",
            "     85        0.6613  0.0205\n",
            "     86        0.6612  0.0205\n",
            "     87        0.6612  0.0205\n",
            "     88        0.6613  0.0227\n",
            "     89        0.6609  0.0230\n",
            "     90        0.6609  0.0220\n",
            "     91        0.6608  0.0237\n",
            "     92        0.6608  0.0242\n",
            "     93        0.6608  0.0225\n",
            "     94        0.6608  0.0244\n",
            "     95        0.6608  0.0215\n",
            "     96        0.6608  0.0231\n",
            "     97        0.6608  0.0235\n",
            "     98        0.6608  0.0235\n",
            "     99        0.6608  0.0213\n",
            "    100        0.6606  0.0219\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1816\u001b[0m  0.0158\n",
            "      2        \u001b[36m3.1304\u001b[0m  0.0200\n",
            "      3        \u001b[36m3.0827\u001b[0m  0.0206\n",
            "      4        \u001b[36m3.0351\u001b[0m  0.0195\n",
            "      5        \u001b[36m2.9874\u001b[0m  0.0155\n",
            "      6        \u001b[36m2.9394\u001b[0m  0.0209\n",
            "      7        \u001b[36m2.8913\u001b[0m  0.0192\n",
            "      8        \u001b[36m2.8430\u001b[0m  0.0227\n",
            "      9        \u001b[36m2.7946\u001b[0m  0.0273\n",
            "     10        \u001b[36m2.7461\u001b[0m  0.0206\n",
            "     11        \u001b[36m2.6976\u001b[0m  0.0215\n",
            "     12        \u001b[36m2.6489\u001b[0m  0.0190\n",
            "     13        \u001b[36m2.6003\u001b[0m  0.0209\n",
            "     14        \u001b[36m2.5514\u001b[0m  0.0199\n",
            "     15        \u001b[36m2.5024\u001b[0m  0.0225\n",
            "     16        \u001b[36m2.4530\u001b[0m  0.0207\n",
            "     17        \u001b[36m2.4027\u001b[0m  0.0186\n",
            "     18        \u001b[36m2.3505\u001b[0m  0.0187\n",
            "     19        \u001b[36m2.2945\u001b[0m  0.0220\n",
            "     20        \u001b[36m2.2305\u001b[0m  0.0193\n",
            "     21        \u001b[36m2.1513\u001b[0m  0.0196\n",
            "     22        \u001b[36m2.0481\u001b[0m  0.0207\n",
            "     23        \u001b[36m1.9185\u001b[0m  0.0190\n",
            "     24        \u001b[36m1.7721\u001b[0m  0.0216\n",
            "     25        \u001b[36m1.6162\u001b[0m  0.0214\n",
            "     26        \u001b[36m1.4426\u001b[0m  0.0199\n",
            "     27        \u001b[36m1.2404\u001b[0m  0.0207\n",
            "     28        \u001b[36m1.0176\u001b[0m  0.0190\n",
            "     29        \u001b[36m0.8238\u001b[0m  0.0189\n",
            "     30        \u001b[36m0.7159\u001b[0m  0.0200\n",
            "     31        \u001b[36m0.6771\u001b[0m  0.0194\n",
            "     32        \u001b[36m0.6635\u001b[0m  0.0237\n",
            "     33        \u001b[36m0.6596\u001b[0m  0.0245\n",
            "     34        0.6604  0.0263\n",
            "     35        0.6622  0.0246\n",
            "     36        0.6635  0.0240\n",
            "     37        0.6640  0.0193\n",
            "     38        0.6640  0.0227\n",
            "     39        0.6638  0.0227\n",
            "     40        0.6636  0.0213\n",
            "     41        0.6635  0.0266\n",
            "     42        0.6634  0.0223\n",
            "     43        0.6633  0.0260\n",
            "     44        0.6633  0.0222\n",
            "     45        0.6632  0.0201\n",
            "     46        0.6632  0.0188\n",
            "     47        0.6632  0.0181\n",
            "     48        0.6632  0.0184\n",
            "     49        0.6632  0.0210\n",
            "     50        0.6631  0.0192\n",
            "     51        0.6631  0.0187\n",
            "     52        0.6631  0.0201\n",
            "     53        0.6631  0.0284\n",
            "     54        0.6631  0.0209\n",
            "     55        0.6631  0.0194\n",
            "     56        0.6630  0.0185\n",
            "     57        0.6630  0.0185\n",
            "     58        0.6630  0.0206\n",
            "     59        0.6630  0.0190\n",
            "     60        0.6630  0.0193\n",
            "     61        0.6630  0.0216\n",
            "     62        0.6630  0.0185\n",
            "     63        0.6630  0.0218\n",
            "     64        0.6630  0.0196\n",
            "     65        0.6630  0.0205\n",
            "     66        0.6630  0.0203\n",
            "     67        0.6630  0.0189\n",
            "     68        0.6629  0.0195\n",
            "     69        0.6629  0.0223\n",
            "     70        0.6629  0.0183\n",
            "     71        0.6629  0.0209\n",
            "     72        0.6629  0.0226\n",
            "     73        0.6629  0.0215\n",
            "     74        0.6629  0.0179\n",
            "     75        0.6629  0.0207\n",
            "     76        0.6629  0.0234\n",
            "     77        0.6629  0.0254\n",
            "     78        0.6629  0.0243\n",
            "     79        0.6629  0.0258\n",
            "     80        0.6629  0.0239\n",
            "     81        0.6629  0.0223\n",
            "     82        0.6629  0.0248\n",
            "     83        0.6629  0.0254\n",
            "     84        0.6629  0.0236\n",
            "     85        0.6629  0.0267\n",
            "     86        0.6629  0.0231\n",
            "     87        0.6629  0.0246\n",
            "     88        0.6629  0.0224\n",
            "     89        0.6629  0.0199\n",
            "     90        0.6629  0.0208\n",
            "     91        0.6629  0.0194\n",
            "     92        0.6629  0.0197\n",
            "     93        0.6629  0.0231\n",
            "     94        0.6629  0.0213\n",
            "     95        0.6628  0.0195\n",
            "     96        0.6628  0.0207\n",
            "     97        0.6628  0.0215\n",
            "     98        0.6628  0.0268\n",
            "     99        0.6628  0.0206\n",
            "    100        0.6628  0.0185\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.5278\u001b[0m  0.0121\n",
            "      2        \u001b[36m2.5041\u001b[0m  0.0169\n",
            "      3        \u001b[36m2.4803\u001b[0m  0.0180\n",
            "      4        \u001b[36m2.4566\u001b[0m  0.0159\n",
            "      5        \u001b[36m2.4330\u001b[0m  0.0120\n",
            "      6        \u001b[36m2.4093\u001b[0m  0.0132\n",
            "      7        \u001b[36m2.3856\u001b[0m  0.0152\n",
            "      8        \u001b[36m2.3620\u001b[0m  0.0156\n",
            "      9        \u001b[36m2.3383\u001b[0m  0.0163\n",
            "     10        \u001b[36m2.3147\u001b[0m  0.0117\n",
            "     11        \u001b[36m2.2911\u001b[0m  0.0170\n",
            "     12        \u001b[36m2.2675\u001b[0m  0.0149\n",
            "     13        \u001b[36m2.2439\u001b[0m  0.0167\n",
            "     14        \u001b[36m2.2204\u001b[0m  0.0154\n",
            "     15        \u001b[36m2.1969\u001b[0m  0.0149\n",
            "     16        \u001b[36m2.1734\u001b[0m  0.0156\n",
            "     17        \u001b[36m2.1499\u001b[0m  0.0160\n",
            "     18        \u001b[36m2.1264\u001b[0m  0.0154\n",
            "     19        \u001b[36m2.1030\u001b[0m  0.0149\n",
            "     20        \u001b[36m2.0796\u001b[0m  0.0158\n",
            "     21        \u001b[36m2.0562\u001b[0m  0.0153\n",
            "     22        \u001b[36m2.0329\u001b[0m  0.0140\n",
            "     23        \u001b[36m2.0096\u001b[0m  0.0164\n",
            "     24        \u001b[36m1.9863\u001b[0m  0.0174\n",
            "     25        \u001b[36m1.9631\u001b[0m  0.0168\n",
            "     26        \u001b[36m1.9399\u001b[0m  0.0176\n",
            "     27        \u001b[36m1.9168\u001b[0m  0.0174\n",
            "     28        \u001b[36m1.8937\u001b[0m  0.0162\n",
            "     29        \u001b[36m1.8706\u001b[0m  0.0191\n",
            "     30        \u001b[36m1.8477\u001b[0m  0.0171\n",
            "     31        \u001b[36m1.8247\u001b[0m  0.0221\n",
            "     32        \u001b[36m1.8019\u001b[0m  0.0240\n",
            "     33        \u001b[36m1.7790\u001b[0m  0.0170\n",
            "     34        \u001b[36m1.7563\u001b[0m  0.0165\n",
            "     35        \u001b[36m1.7336\u001b[0m  0.0157\n",
            "     36        \u001b[36m1.7110\u001b[0m  0.0166\n",
            "     37        \u001b[36m1.6885\u001b[0m  0.0169\n",
            "     38        \u001b[36m1.6661\u001b[0m  0.0168\n",
            "     39        \u001b[36m1.6437\u001b[0m  0.0179\n",
            "     40        \u001b[36m1.6215\u001b[0m  0.0182\n",
            "     41        \u001b[36m1.5993\u001b[0m  0.0147\n",
            "     42        \u001b[36m1.5773\u001b[0m  0.0172\n",
            "     43        \u001b[36m1.5553\u001b[0m  0.0171\n",
            "     44        \u001b[36m1.5335\u001b[0m  0.0159\n",
            "     45        \u001b[36m1.5118\u001b[0m  0.0168\n",
            "     46        \u001b[36m1.4903\u001b[0m  0.0170\n",
            "     47        \u001b[36m1.4688\u001b[0m  0.0183\n",
            "     48        \u001b[36m1.4476\u001b[0m  0.0168\n",
            "     49        \u001b[36m1.4264\u001b[0m  0.0190\n",
            "     50        \u001b[36m1.4055\u001b[0m  0.0163\n",
            "     51        \u001b[36m1.3847\u001b[0m  0.0255\n",
            "     52        \u001b[36m1.3640\u001b[0m  0.0180\n",
            "     53        \u001b[36m1.3436\u001b[0m  0.0150\n",
            "     54        \u001b[36m1.3234\u001b[0m  0.0158\n",
            "     55        \u001b[36m1.3033\u001b[0m  0.0159\n",
            "     56        \u001b[36m1.2835\u001b[0m  0.0152\n",
            "     57        \u001b[36m1.2639\u001b[0m  0.0147\n",
            "     58        \u001b[36m1.2445\u001b[0m  0.0152\n",
            "     59        \u001b[36m1.2254\u001b[0m  0.0167\n",
            "     60        \u001b[36m1.2065\u001b[0m  0.0167\n",
            "     61        \u001b[36m1.1879\u001b[0m  0.0161\n",
            "     62        \u001b[36m1.1696\u001b[0m  0.0166\n",
            "     63        \u001b[36m1.1515\u001b[0m  0.0173\n",
            "     64        \u001b[36m1.1337\u001b[0m  0.0158\n",
            "     65        \u001b[36m1.1163\u001b[0m  0.0168\n",
            "     66        \u001b[36m1.0991\u001b[0m  0.0181\n",
            "     67        \u001b[36m1.0823\u001b[0m  0.0190\n",
            "     68        \u001b[36m1.0657\u001b[0m  0.0158\n",
            "     69        \u001b[36m1.0496\u001b[0m  0.0155\n",
            "     70        \u001b[36m1.0337\u001b[0m  0.0160\n",
            "     71        \u001b[36m1.0183\u001b[0m  0.0145\n",
            "     72        \u001b[36m1.0031\u001b[0m  0.0164\n",
            "     73        \u001b[36m0.9884\u001b[0m  0.0198\n",
            "     74        \u001b[36m0.9740\u001b[0m  0.0197\n",
            "     75        \u001b[36m0.9600\u001b[0m  0.0184\n",
            "     76        \u001b[36m0.9464\u001b[0m  0.0209\n",
            "     77        \u001b[36m0.9332\u001b[0m  0.0163\n",
            "     78        \u001b[36m0.9204\u001b[0m  0.0212\n",
            "     79        \u001b[36m0.9080\u001b[0m  0.0208\n",
            "     80        \u001b[36m0.8959\u001b[0m  0.0198\n",
            "     81        \u001b[36m0.8843\u001b[0m  0.0210\n",
            "     82        \u001b[36m0.8731\u001b[0m  0.0177\n",
            "     83        \u001b[36m0.8622\u001b[0m  0.0178\n",
            "     84        \u001b[36m0.8518\u001b[0m  0.0183\n",
            "     85        \u001b[36m0.8417\u001b[0m  0.0199\n",
            "     86        \u001b[36m0.8321\u001b[0m  0.0168\n",
            "     87        \u001b[36m0.8228\u001b[0m  0.0207\n",
            "     88        \u001b[36m0.8139\u001b[0m  0.0167\n",
            "     89        \u001b[36m0.8054\u001b[0m  0.0198\n",
            "     90        \u001b[36m0.7973\u001b[0m  0.0164\n",
            "     91        \u001b[36m0.7895\u001b[0m  0.0161\n",
            "     92        \u001b[36m0.7821\u001b[0m  0.0191\n",
            "     93        \u001b[36m0.7750\u001b[0m  0.0179\n",
            "     94        \u001b[36m0.7683\u001b[0m  0.0195\n",
            "     95        \u001b[36m0.7618\u001b[0m  0.0181\n",
            "     96        \u001b[36m0.7558\u001b[0m  0.0167\n",
            "     97        \u001b[36m0.7500\u001b[0m  0.0161\n",
            "     98        \u001b[36m0.7445\u001b[0m  0.0165\n",
            "     99        \u001b[36m0.7393\u001b[0m  0.0164\n",
            "    100        \u001b[36m0.7344\u001b[0m  0.0153\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0783\u001b[0m  0.0110\n",
            "      2        \u001b[36m3.0560\u001b[0m  0.0171\n",
            "      3        \u001b[36m3.0337\u001b[0m  0.0175\n",
            "      4        \u001b[36m3.0114\u001b[0m  0.0173\n",
            "      5        \u001b[36m2.9891\u001b[0m  0.0150\n",
            "      6        \u001b[36m2.9668\u001b[0m  0.0162\n",
            "      7        \u001b[36m2.9445\u001b[0m  0.0167\n",
            "      8        \u001b[36m2.9222\u001b[0m  0.0147\n",
            "      9        \u001b[36m2.8999\u001b[0m  0.0150\n",
            "     10        \u001b[36m2.8777\u001b[0m  0.0142\n",
            "     11        \u001b[36m2.8554\u001b[0m  0.0155\n",
            "     12        \u001b[36m2.8331\u001b[0m  0.0152\n",
            "     13        \u001b[36m2.8108\u001b[0m  0.0153\n",
            "     14        \u001b[36m2.7885\u001b[0m  0.0152\n",
            "     15        \u001b[36m2.7663\u001b[0m  0.0164\n",
            "     16        \u001b[36m2.7440\u001b[0m  0.0149\n",
            "     17        \u001b[36m2.7218\u001b[0m  0.0145\n",
            "     18        \u001b[36m2.6995\u001b[0m  0.0154\n",
            "     19        \u001b[36m2.6773\u001b[0m  0.0153\n",
            "     20        \u001b[36m2.6550\u001b[0m  0.0158\n",
            "     21        \u001b[36m2.6328\u001b[0m  0.0155\n",
            "     22        \u001b[36m2.6105\u001b[0m  0.0154\n",
            "     23        \u001b[36m2.5883\u001b[0m  0.0153\n",
            "     24        \u001b[36m2.5661\u001b[0m  0.0181\n",
            "     25        \u001b[36m2.5439\u001b[0m  0.0185\n",
            "     26        \u001b[36m2.5217\u001b[0m  0.0183\n",
            "     27        \u001b[36m2.4995\u001b[0m  0.0172\n",
            "     28        \u001b[36m2.4773\u001b[0m  0.0210\n",
            "     29        \u001b[36m2.4551\u001b[0m  0.0254\n",
            "     30        \u001b[36m2.4329\u001b[0m  0.0194\n",
            "     31        \u001b[36m2.4108\u001b[0m  0.0178\n",
            "     32        \u001b[36m2.3886\u001b[0m  0.0151\n",
            "     33        \u001b[36m2.3665\u001b[0m  0.0255\n",
            "     34        \u001b[36m2.3444\u001b[0m  0.0179\n",
            "     35        \u001b[36m2.3223\u001b[0m  0.0177\n",
            "     36        \u001b[36m2.3002\u001b[0m  0.0173\n",
            "     37        \u001b[36m2.2781\u001b[0m  0.0157\n",
            "     38        \u001b[36m2.2561\u001b[0m  0.0194\n",
            "     39        \u001b[36m2.2340\u001b[0m  0.0166\n",
            "     40        \u001b[36m2.2120\u001b[0m  0.0157\n",
            "     41        \u001b[36m2.1900\u001b[0m  0.0173\n",
            "     42        \u001b[36m2.1680\u001b[0m  0.0172\n",
            "     43        \u001b[36m2.1460\u001b[0m  0.0179\n",
            "     44        \u001b[36m2.1241\u001b[0m  0.0154\n",
            "     45        \u001b[36m2.1022\u001b[0m  0.0153\n",
            "     46        \u001b[36m2.0803\u001b[0m  0.0145\n",
            "     47        \u001b[36m2.0584\u001b[0m  0.0149\n",
            "     48        \u001b[36m2.0366\u001b[0m  0.0150\n",
            "     49        \u001b[36m2.0148\u001b[0m  0.0149\n",
            "     50        \u001b[36m1.9930\u001b[0m  0.0158\n",
            "     51        \u001b[36m1.9713\u001b[0m  0.0168\n",
            "     52        \u001b[36m1.9496\u001b[0m  0.0146\n",
            "     53        \u001b[36m1.9279\u001b[0m  0.0152\n",
            "     54        \u001b[36m1.9063\u001b[0m  0.0145\n",
            "     55        \u001b[36m1.8847\u001b[0m  0.0155\n",
            "     56        \u001b[36m1.8632\u001b[0m  0.0191\n",
            "     57        \u001b[36m1.8417\u001b[0m  0.0218\n",
            "     58        \u001b[36m1.8203\u001b[0m  0.0181\n",
            "     59        \u001b[36m1.7989\u001b[0m  0.0170\n",
            "     60        \u001b[36m1.7776\u001b[0m  0.0156\n",
            "     61        \u001b[36m1.7563\u001b[0m  0.0163\n",
            "     62        \u001b[36m1.7351\u001b[0m  0.0148\n",
            "     63        \u001b[36m1.7140\u001b[0m  0.0159\n",
            "     64        \u001b[36m1.6929\u001b[0m  0.0161\n",
            "     65        \u001b[36m1.6719\u001b[0m  0.0165\n",
            "     66        \u001b[36m1.6510\u001b[0m  0.0181\n",
            "     67        \u001b[36m1.6302\u001b[0m  0.0159\n",
            "     68        \u001b[36m1.6094\u001b[0m  0.0152\n",
            "     69        \u001b[36m1.5888\u001b[0m  0.0172\n",
            "     70        \u001b[36m1.5682\u001b[0m  0.0180\n",
            "     71        \u001b[36m1.5478\u001b[0m  0.0154\n",
            "     72        \u001b[36m1.5274\u001b[0m  0.0154\n",
            "     73        \u001b[36m1.5072\u001b[0m  0.0173\n",
            "     74        \u001b[36m1.4871\u001b[0m  0.0188\n",
            "     75        \u001b[36m1.4671\u001b[0m  0.0161\n",
            "     76        \u001b[36m1.4473\u001b[0m  0.0189\n",
            "     77        \u001b[36m1.4275\u001b[0m  0.0208\n",
            "     78        \u001b[36m1.4080\u001b[0m  0.0193\n",
            "     79        \u001b[36m1.3885\u001b[0m  0.0181\n",
            "     80        \u001b[36m1.3693\u001b[0m  0.0154\n",
            "     81        \u001b[36m1.3502\u001b[0m  0.0172\n",
            "     82        \u001b[36m1.3312\u001b[0m  0.0177\n",
            "     83        \u001b[36m1.3125\u001b[0m  0.0195\n",
            "     84        \u001b[36m1.2939\u001b[0m  0.0181\n",
            "     85        \u001b[36m1.2755\u001b[0m  0.0174\n",
            "     86        \u001b[36m1.2573\u001b[0m  0.0179\n",
            "     87        \u001b[36m1.2394\u001b[0m  0.0181\n",
            "     88        \u001b[36m1.2216\u001b[0m  0.0186\n",
            "     89        \u001b[36m1.2041\u001b[0m  0.0180\n",
            "     90        \u001b[36m1.1868\u001b[0m  0.0189\n",
            "     91        \u001b[36m1.1698\u001b[0m  0.0172\n",
            "     92        \u001b[36m1.1530\u001b[0m  0.0164\n",
            "     93        \u001b[36m1.1364\u001b[0m  0.0190\n",
            "     94        \u001b[36m1.1202\u001b[0m  0.0178\n",
            "     95        \u001b[36m1.1042\u001b[0m  0.0152\n",
            "     96        \u001b[36m1.0884\u001b[0m  0.0154\n",
            "     97        \u001b[36m1.0730\u001b[0m  0.0149\n",
            "     98        \u001b[36m1.0579\u001b[0m  0.0155\n",
            "     99        \u001b[36m1.0431\u001b[0m  0.0157\n",
            "    100        \u001b[36m1.0285\u001b[0m  0.0152\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.7868\u001b[0m  0.0188\n",
            "      2        \u001b[36m2.7339\u001b[0m  0.0206\n",
            "      3        \u001b[36m2.6737\u001b[0m  0.0217\n",
            "      4        \u001b[36m2.6106\u001b[0m  0.0200\n",
            "      5        \u001b[36m2.5415\u001b[0m  0.0150\n",
            "      6        \u001b[36m2.4709\u001b[0m  0.0237\n",
            "      7        \u001b[36m2.3956\u001b[0m  0.0216\n",
            "      8        \u001b[36m2.3156\u001b[0m  0.0238\n",
            "      9        \u001b[36m2.2315\u001b[0m  0.0267\n",
            "     10        \u001b[36m2.1424\u001b[0m  0.0219\n",
            "     11        \u001b[36m2.0492\u001b[0m  0.0272\n",
            "     12        \u001b[36m1.9535\u001b[0m  0.0202\n",
            "     13        \u001b[36m1.8567\u001b[0m  0.0227\n",
            "     14        \u001b[36m1.7611\u001b[0m  0.0198\n",
            "     15        \u001b[36m1.6688\u001b[0m  0.0295\n",
            "     16        \u001b[36m1.5823\u001b[0m  0.0274\n",
            "     17        \u001b[36m1.4990\u001b[0m  0.0213\n",
            "     18        \u001b[36m1.4317\u001b[0m  0.0237\n",
            "     19        \u001b[36m1.3735\u001b[0m  0.0247\n",
            "     20        \u001b[36m1.3244\u001b[0m  0.0247\n",
            "     21        \u001b[36m1.2777\u001b[0m  0.0254\n",
            "     22        \u001b[36m1.2419\u001b[0m  0.0213\n",
            "     23        \u001b[36m1.2039\u001b[0m  0.0222\n",
            "     24        \u001b[36m1.1672\u001b[0m  0.0256\n",
            "     25        \u001b[36m1.1417\u001b[0m  0.0243\n",
            "     26        \u001b[36m1.1185\u001b[0m  0.0218\n",
            "     27        \u001b[36m1.0940\u001b[0m  0.0309\n",
            "     28        \u001b[36m1.0735\u001b[0m  0.0295\n",
            "     29        \u001b[36m1.0529\u001b[0m  0.0256\n",
            "     30        \u001b[36m1.0328\u001b[0m  0.0260\n",
            "     31        \u001b[36m1.0136\u001b[0m  0.0287\n",
            "     32        \u001b[36m0.9967\u001b[0m  0.0258\n",
            "     33        \u001b[36m0.9763\u001b[0m  0.0213\n",
            "     34        \u001b[36m0.9583\u001b[0m  0.0230\n",
            "     35        \u001b[36m0.9414\u001b[0m  0.0186\n",
            "     36        \u001b[36m0.9252\u001b[0m  0.0194\n",
            "     37        \u001b[36m0.9097\u001b[0m  0.0196\n",
            "     38        \u001b[36m0.8949\u001b[0m  0.0187\n",
            "     39        \u001b[36m0.8808\u001b[0m  0.0192\n",
            "     40        \u001b[36m0.8662\u001b[0m  0.0197\n",
            "     41        \u001b[36m0.8543\u001b[0m  0.0193\n",
            "     42        \u001b[36m0.8420\u001b[0m  0.0199\n",
            "     43        \u001b[36m0.8302\u001b[0m  0.0217\n",
            "     44        \u001b[36m0.8190\u001b[0m  0.0193\n",
            "     45        \u001b[36m0.8082\u001b[0m  0.0186\n",
            "     46        \u001b[36m0.7979\u001b[0m  0.0207\n",
            "     47        \u001b[36m0.7881\u001b[0m  0.0190\n",
            "     48        \u001b[36m0.7775\u001b[0m  0.0192\n",
            "     49        \u001b[36m0.7684\u001b[0m  0.0233\n",
            "     50        \u001b[36m0.7598\u001b[0m  0.0242\n",
            "     51        \u001b[36m0.7511\u001b[0m  0.0201\n",
            "     52        \u001b[36m0.7431\u001b[0m  0.0221\n",
            "     53        \u001b[36m0.7353\u001b[0m  0.0219\n",
            "     54        \u001b[36m0.7277\u001b[0m  0.0235\n",
            "     55        \u001b[36m0.7202\u001b[0m  0.0215\n",
            "     56        \u001b[36m0.7121\u001b[0m  0.0191\n",
            "     57        \u001b[36m0.7047\u001b[0m  0.0191\n",
            "     58        \u001b[36m0.6971\u001b[0m  0.0218\n",
            "     59        \u001b[36m0.6894\u001b[0m  0.0220\n",
            "     60        \u001b[36m0.6815\u001b[0m  0.0218\n",
            "     61        \u001b[36m0.6735\u001b[0m  0.0222\n",
            "     62        \u001b[36m0.6656\u001b[0m  0.0252\n",
            "     63        \u001b[36m0.6580\u001b[0m  0.0210\n",
            "     64        \u001b[36m0.6513\u001b[0m  0.0225\n",
            "     65        \u001b[36m0.6458\u001b[0m  0.0223\n",
            "     66        \u001b[36m0.6416\u001b[0m  0.0207\n",
            "     67        \u001b[36m0.6387\u001b[0m  0.0207\n",
            "     68        \u001b[36m0.6367\u001b[0m  0.0202\n",
            "     69        \u001b[36m0.6354\u001b[0m  0.0215\n",
            "     70        \u001b[36m0.6332\u001b[0m  0.0255\n",
            "     71        \u001b[36m0.6325\u001b[0m  0.0201\n",
            "     72        \u001b[36m0.6319\u001b[0m  0.0200\n",
            "     73        \u001b[36m0.6277\u001b[0m  0.0189\n",
            "     74        \u001b[36m0.6229\u001b[0m  0.0216\n",
            "     75        0.6262  0.0213\n",
            "     76        0.6243  0.0220\n",
            "     77        \u001b[36m0.6179\u001b[0m  0.0182\n",
            "     78        \u001b[36m0.6154\u001b[0m  0.0184\n",
            "     79        \u001b[36m0.6129\u001b[0m  0.0185\n",
            "     80        \u001b[36m0.6120\u001b[0m  0.0190\n",
            "     81        \u001b[36m0.6112\u001b[0m  0.0182\n",
            "     82        \u001b[36m0.6105\u001b[0m  0.0184\n",
            "     83        \u001b[36m0.6100\u001b[0m  0.0191\n",
            "     84        \u001b[36m0.6095\u001b[0m  0.0181\n",
            "     85        \u001b[36m0.6091\u001b[0m  0.0257\n",
            "     86        \u001b[36m0.6087\u001b[0m  0.0195\n",
            "     87        \u001b[36m0.6084\u001b[0m  0.0208\n",
            "     88        \u001b[36m0.6059\u001b[0m  0.0200\n",
            "     89        \u001b[36m0.6055\u001b[0m  0.0194\n",
            "     90        \u001b[36m0.6051\u001b[0m  0.0198\n",
            "     91        \u001b[36m0.6048\u001b[0m  0.0185\n",
            "     92        \u001b[36m0.6045\u001b[0m  0.0185\n",
            "     93        \u001b[36m0.6042\u001b[0m  0.0196\n",
            "     94        \u001b[36m0.6040\u001b[0m  0.0197\n",
            "     95        \u001b[36m0.6037\u001b[0m  0.0211\n",
            "     96        \u001b[36m0.6034\u001b[0m  0.0196\n",
            "     97        \u001b[36m0.6032\u001b[0m  0.0182\n",
            "     98        \u001b[36m0.6030\u001b[0m  0.0184\n",
            "     99        \u001b[36m0.6027\u001b[0m  0.0251\n",
            "    100        \u001b[36m0.6020\u001b[0m  0.0207\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5617\u001b[0m  0.0354\n",
            "      2        \u001b[36m1.4932\u001b[0m  0.0299\n",
            "      3        \u001b[36m1.4262\u001b[0m  0.0231\n",
            "      4        \u001b[36m1.3584\u001b[0m  0.0343\n",
            "      5        \u001b[36m1.2904\u001b[0m  0.0320\n",
            "      6        \u001b[36m1.2272\u001b[0m  0.0302\n",
            "      7        \u001b[36m1.1628\u001b[0m  0.0287\n",
            "      8        \u001b[36m1.0989\u001b[0m  0.0325\n",
            "      9        \u001b[36m1.0328\u001b[0m  0.0288\n",
            "     10        \u001b[36m0.9797\u001b[0m  0.0256\n",
            "     11        \u001b[36m0.9345\u001b[0m  0.0240\n",
            "     12        \u001b[36m0.8915\u001b[0m  0.0249\n",
            "     13        \u001b[36m0.8549\u001b[0m  0.0238\n",
            "     14        \u001b[36m0.8237\u001b[0m  0.0255\n",
            "     15        \u001b[36m0.7987\u001b[0m  0.0274\n",
            "     16        \u001b[36m0.7801\u001b[0m  0.0229\n",
            "     17        \u001b[36m0.7655\u001b[0m  0.0282\n",
            "     18        \u001b[36m0.7540\u001b[0m  0.0249\n",
            "     19        \u001b[36m0.7448\u001b[0m  0.0245\n",
            "     20        \u001b[36m0.7373\u001b[0m  0.0219\n",
            "     21        \u001b[36m0.7321\u001b[0m  0.0239\n",
            "     22        \u001b[36m0.7277\u001b[0m  0.0236\n",
            "     23        \u001b[36m0.7249\u001b[0m  0.0218\n",
            "     24        \u001b[36m0.7203\u001b[0m  0.0198\n",
            "     25        \u001b[36m0.7161\u001b[0m  0.0249\n",
            "     26        \u001b[36m0.7115\u001b[0m  0.0253\n",
            "     27        \u001b[36m0.7085\u001b[0m  0.0221\n",
            "     28        \u001b[36m0.7050\u001b[0m  0.0253\n",
            "     29        \u001b[36m0.7027\u001b[0m  0.0212\n",
            "     30        \u001b[36m0.6987\u001b[0m  0.0239\n",
            "     31        \u001b[36m0.6926\u001b[0m  0.0273\n",
            "     32        \u001b[36m0.6906\u001b[0m  0.0271\n",
            "     33        \u001b[36m0.6905\u001b[0m  0.0310\n",
            "     34        \u001b[36m0.6883\u001b[0m  0.0279\n",
            "     35        \u001b[36m0.6855\u001b[0m  0.0275\n",
            "     36        \u001b[36m0.6829\u001b[0m  0.0234\n",
            "     37        \u001b[36m0.6804\u001b[0m  0.0232\n",
            "     38        \u001b[36m0.6780\u001b[0m  0.0226\n",
            "     39        \u001b[36m0.6757\u001b[0m  0.0234\n",
            "     40        \u001b[36m0.6735\u001b[0m  0.0215\n",
            "     41        \u001b[36m0.6714\u001b[0m  0.0285\n",
            "     42        \u001b[36m0.6694\u001b[0m  0.0292\n",
            "     43        \u001b[36m0.6675\u001b[0m  0.0275\n",
            "     44        \u001b[36m0.6656\u001b[0m  0.0235\n",
            "     45        \u001b[36m0.6639\u001b[0m  0.0242\n",
            "     46        \u001b[36m0.6622\u001b[0m  0.0250\n",
            "     47        \u001b[36m0.6606\u001b[0m  0.0217\n",
            "     48        \u001b[36m0.6590\u001b[0m  0.0219\n",
            "     49        \u001b[36m0.6575\u001b[0m  0.0215\n",
            "     50        \u001b[36m0.6561\u001b[0m  0.0209\n",
            "     51        \u001b[36m0.6547\u001b[0m  0.0234\n",
            "     52        \u001b[36m0.6533\u001b[0m  0.0219\n",
            "     53        \u001b[36m0.6520\u001b[0m  0.0212\n",
            "     54        \u001b[36m0.6508\u001b[0m  0.0210\n",
            "     55        \u001b[36m0.6496\u001b[0m  0.0227\n",
            "     56        \u001b[36m0.6484\u001b[0m  0.0237\n",
            "     57        \u001b[36m0.6473\u001b[0m  0.0270\n",
            "     58        \u001b[36m0.6462\u001b[0m  0.0212\n",
            "     59        \u001b[36m0.6451\u001b[0m  0.0209\n",
            "     60        \u001b[36m0.6441\u001b[0m  0.0218\n",
            "     61        \u001b[36m0.6431\u001b[0m  0.0233\n",
            "     62        \u001b[36m0.6422\u001b[0m  0.0211\n",
            "     63        \u001b[36m0.6412\u001b[0m  0.0218\n",
            "     64        \u001b[36m0.6403\u001b[0m  0.0217\n",
            "     65        \u001b[36m0.6394\u001b[0m  0.0230\n",
            "     66        \u001b[36m0.6385\u001b[0m  0.0206\n",
            "     67        \u001b[36m0.6377\u001b[0m  0.0222\n",
            "     68        \u001b[36m0.6319\u001b[0m  0.0205\n",
            "     69        \u001b[36m0.6310\u001b[0m  0.0193\n",
            "     70        0.6311  0.0200\n",
            "     71        \u001b[36m0.6295\u001b[0m  0.0199\n",
            "     72        \u001b[36m0.6284\u001b[0m  0.0198\n",
            "     73        0.6295  0.0210\n",
            "     74        0.6288  0.0235\n",
            "     75        \u001b[36m0.6279\u001b[0m  0.0253\n",
            "     76        \u001b[36m0.6272\u001b[0m  0.0281\n",
            "     77        \u001b[36m0.6253\u001b[0m  0.0253\n",
            "     78        \u001b[36m0.6247\u001b[0m  0.0227\n",
            "     79        \u001b[36m0.6241\u001b[0m  0.0245\n",
            "     80        \u001b[36m0.6235\u001b[0m  0.0217\n",
            "     81        \u001b[36m0.6229\u001b[0m  0.0287\n",
            "     82        \u001b[36m0.6223\u001b[0m  0.0236\n",
            "     83        \u001b[36m0.6222\u001b[0m  0.0207\n",
            "     84        \u001b[36m0.6220\u001b[0m  0.0206\n",
            "     85        \u001b[36m0.6215\u001b[0m  0.0264\n",
            "     86        \u001b[36m0.6210\u001b[0m  0.0238\n",
            "     87        \u001b[36m0.6205\u001b[0m  0.0278\n",
            "     88        \u001b[36m0.6200\u001b[0m  0.0208\n",
            "     89        \u001b[36m0.6195\u001b[0m  0.0210\n",
            "     90        0.6201  0.0203\n",
            "     91        \u001b[36m0.6194\u001b[0m  0.0204\n",
            "     92        \u001b[36m0.6191\u001b[0m  0.0206\n",
            "     93        \u001b[36m0.6185\u001b[0m  0.0194\n",
            "     94        0.6189  0.0212\n",
            "     95        \u001b[36m0.6184\u001b[0m  0.0239\n",
            "     96        \u001b[36m0.6165\u001b[0m  0.0248\n",
            "     97        \u001b[36m0.6148\u001b[0m  0.0295\n",
            "     98        \u001b[36m0.6133\u001b[0m  0.0260\n",
            "     99        \u001b[36m0.6096\u001b[0m  0.0265\n",
            "    100        \u001b[36m0.6077\u001b[0m  0.0229\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8402\u001b[0m  0.0186\n",
            "      2        \u001b[36m0.8388\u001b[0m  0.0181\n",
            "      3        \u001b[36m0.8375\u001b[0m  0.0194\n",
            "      4        \u001b[36m0.8362\u001b[0m  0.0168\n",
            "      5        \u001b[36m0.8349\u001b[0m  0.0183\n",
            "      6        \u001b[36m0.8336\u001b[0m  0.0153\n",
            "      7        \u001b[36m0.8323\u001b[0m  0.0145\n",
            "      8        \u001b[36m0.8310\u001b[0m  0.0139\n",
            "      9        \u001b[36m0.8298\u001b[0m  0.0143\n",
            "     10        \u001b[36m0.8285\u001b[0m  0.0150\n",
            "     11        \u001b[36m0.8272\u001b[0m  0.0141\n",
            "     12        \u001b[36m0.8260\u001b[0m  0.0175\n",
            "     13        \u001b[36m0.8247\u001b[0m  0.0167\n",
            "     14        \u001b[36m0.8235\u001b[0m  0.0210\n",
            "     15        \u001b[36m0.8223\u001b[0m  0.0173\n",
            "     16        \u001b[36m0.8211\u001b[0m  0.0164\n",
            "     17        \u001b[36m0.8199\u001b[0m  0.0173\n",
            "     18        \u001b[36m0.8187\u001b[0m  0.0164\n",
            "     19        \u001b[36m0.8175\u001b[0m  0.0169\n",
            "     20        \u001b[36m0.8163\u001b[0m  0.0170\n",
            "     21        \u001b[36m0.8151\u001b[0m  0.0200\n",
            "     22        \u001b[36m0.8140\u001b[0m  0.0171\n",
            "     23        \u001b[36m0.8128\u001b[0m  0.0241\n",
            "     24        \u001b[36m0.8117\u001b[0m  0.0216\n",
            "     25        \u001b[36m0.8105\u001b[0m  0.0164\n",
            "     26        \u001b[36m0.8094\u001b[0m  0.0174\n",
            "     27        \u001b[36m0.8083\u001b[0m  0.0229\n",
            "     28        \u001b[36m0.8072\u001b[0m  0.0190\n",
            "     29        \u001b[36m0.8060\u001b[0m  0.0196\n",
            "     30        \u001b[36m0.8049\u001b[0m  0.0150\n",
            "     31        \u001b[36m0.8038\u001b[0m  0.0144\n",
            "     32        \u001b[36m0.8028\u001b[0m  0.0153\n",
            "     33        \u001b[36m0.8017\u001b[0m  0.0160\n",
            "     34        \u001b[36m0.8006\u001b[0m  0.0144\n",
            "     35        \u001b[36m0.7996\u001b[0m  0.0143\n",
            "     36        \u001b[36m0.7985\u001b[0m  0.0152\n",
            "     37        \u001b[36m0.7975\u001b[0m  0.0146\n",
            "     38        \u001b[36m0.7964\u001b[0m  0.0188\n",
            "     39        \u001b[36m0.7954\u001b[0m  0.0144\n",
            "     40        \u001b[36m0.7944\u001b[0m  0.0143\n",
            "     41        \u001b[36m0.7934\u001b[0m  0.0146\n",
            "     42        \u001b[36m0.7924\u001b[0m  0.0180\n",
            "     43        \u001b[36m0.7914\u001b[0m  0.0167\n",
            "     44        \u001b[36m0.7904\u001b[0m  0.0148\n",
            "     45        \u001b[36m0.7894\u001b[0m  0.0145\n",
            "     46        \u001b[36m0.7884\u001b[0m  0.0145\n",
            "     47        \u001b[36m0.7874\u001b[0m  0.0147\n",
            "     48        \u001b[36m0.7865\u001b[0m  0.0149\n",
            "     49        \u001b[36m0.7855\u001b[0m  0.0148\n",
            "     50        \u001b[36m0.7846\u001b[0m  0.0152\n",
            "     51        \u001b[36m0.7836\u001b[0m  0.0145\n",
            "     52        \u001b[36m0.7827\u001b[0m  0.0145\n",
            "     53        \u001b[36m0.7818\u001b[0m  0.0163\n",
            "     54        \u001b[36m0.7809\u001b[0m  0.0142\n",
            "     55        \u001b[36m0.7800\u001b[0m  0.0148\n",
            "     56        \u001b[36m0.7791\u001b[0m  0.0165\n",
            "     57        \u001b[36m0.7782\u001b[0m  0.0166\n",
            "     58        \u001b[36m0.7773\u001b[0m  0.0175\n",
            "     59        \u001b[36m0.7764\u001b[0m  0.0165\n",
            "     60        \u001b[36m0.7755\u001b[0m  0.0170\n",
            "     61        \u001b[36m0.7746\u001b[0m  0.0165\n",
            "     62        \u001b[36m0.7738\u001b[0m  0.0162\n",
            "     63        \u001b[36m0.7729\u001b[0m  0.0142\n",
            "     64        \u001b[36m0.7721\u001b[0m  0.0156\n",
            "     65        \u001b[36m0.7713\u001b[0m  0.0159\n",
            "     66        \u001b[36m0.7704\u001b[0m  0.0156\n",
            "     67        \u001b[36m0.7696\u001b[0m  0.0188\n",
            "     68        \u001b[36m0.7688\u001b[0m  0.0175\n",
            "     69        \u001b[36m0.7680\u001b[0m  0.0173\n",
            "     70        \u001b[36m0.7672\u001b[0m  0.0158\n",
            "     71        \u001b[36m0.7664\u001b[0m  0.0180\n",
            "     72        \u001b[36m0.7656\u001b[0m  0.0164\n",
            "     73        \u001b[36m0.7648\u001b[0m  0.0168\n",
            "     74        \u001b[36m0.7640\u001b[0m  0.0167\n",
            "     75        \u001b[36m0.7632\u001b[0m  0.0168\n",
            "     76        \u001b[36m0.7625\u001b[0m  0.0165\n",
            "     77        \u001b[36m0.7617\u001b[0m  0.0188\n",
            "     78        \u001b[36m0.7610\u001b[0m  0.0261\n",
            "     79        \u001b[36m0.7602\u001b[0m  0.0234\n",
            "     80        \u001b[36m0.7595\u001b[0m  0.0178\n",
            "     81        \u001b[36m0.7587\u001b[0m  0.0171\n",
            "     82        \u001b[36m0.7580\u001b[0m  0.0175\n",
            "     83        \u001b[36m0.7573\u001b[0m  0.0182\n",
            "     84        \u001b[36m0.7566\u001b[0m  0.0176\n",
            "     85        \u001b[36m0.7559\u001b[0m  0.0197\n",
            "     86        \u001b[36m0.7552\u001b[0m  0.0176\n",
            "     87        \u001b[36m0.7545\u001b[0m  0.0178\n",
            "     88        \u001b[36m0.7538\u001b[0m  0.0180\n",
            "     89        \u001b[36m0.7531\u001b[0m  0.0167\n",
            "     90        \u001b[36m0.7524\u001b[0m  0.0191\n",
            "     91        \u001b[36m0.7518\u001b[0m  0.0154\n",
            "     92        \u001b[36m0.7511\u001b[0m  0.0151\n",
            "     93        \u001b[36m0.7504\u001b[0m  0.0151\n",
            "     94        \u001b[36m0.7498\u001b[0m  0.0153\n",
            "     95        \u001b[36m0.7491\u001b[0m  0.0161\n",
            "     96        \u001b[36m0.7485\u001b[0m  0.0148\n",
            "     97        \u001b[36m0.7478\u001b[0m  0.0165\n",
            "     98        \u001b[36m0.7472\u001b[0m  0.0139\n",
            "     99        \u001b[36m0.7466\u001b[0m  0.0149\n",
            "    100        \u001b[36m0.7459\u001b[0m  0.0204\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.2026\u001b[0m  0.0149\n",
            "      2        \u001b[36m1.1436\u001b[0m  0.0159\n",
            "      3        \u001b[36m1.1345\u001b[0m  0.0159\n",
            "      4        \u001b[36m1.1256\u001b[0m  0.0180\n",
            "      5        \u001b[36m1.1167\u001b[0m  0.0165\n",
            "      6        \u001b[36m1.1078\u001b[0m  0.0161\n",
            "      7        \u001b[36m1.0991\u001b[0m  0.0171\n",
            "      8        \u001b[36m1.0904\u001b[0m  0.0165\n",
            "      9        \u001b[36m1.0818\u001b[0m  0.0156\n",
            "     10        \u001b[36m1.0732\u001b[0m  0.0164\n",
            "     11        \u001b[36m1.0648\u001b[0m  0.0155\n",
            "     12        \u001b[36m1.0564\u001b[0m  0.0167\n",
            "     13        \u001b[36m1.0480\u001b[0m  0.0186\n",
            "     14        \u001b[36m1.0397\u001b[0m  0.0179\n",
            "     15        \u001b[36m1.0315\u001b[0m  0.0181\n",
            "     16        \u001b[36m1.0234\u001b[0m  0.0186\n",
            "     17        \u001b[36m1.0153\u001b[0m  0.0185\n",
            "     18        \u001b[36m1.0073\u001b[0m  0.0182\n",
            "     19        \u001b[36m0.9994\u001b[0m  0.0202\n",
            "     20        \u001b[36m0.9915\u001b[0m  0.0170\n",
            "     21        \u001b[36m0.9837\u001b[0m  0.0191\n",
            "     22        \u001b[36m0.9760\u001b[0m  0.0149\n",
            "     23        \u001b[36m0.9683\u001b[0m  0.0179\n",
            "     24        \u001b[36m0.9607\u001b[0m  0.0181\n",
            "     25        \u001b[36m0.9532\u001b[0m  0.0226\n",
            "     26        \u001b[36m0.9457\u001b[0m  0.0164\n",
            "     27        \u001b[36m0.9383\u001b[0m  0.0168\n",
            "     28        \u001b[36m0.9310\u001b[0m  0.0164\n",
            "     29        \u001b[36m0.9237\u001b[0m  0.0211\n",
            "     30        \u001b[36m0.9166\u001b[0m  0.0194\n",
            "     31        \u001b[36m0.9095\u001b[0m  0.0149\n",
            "     32        \u001b[36m0.9024\u001b[0m  0.0166\n",
            "     33        \u001b[36m0.8955\u001b[0m  0.0169\n",
            "     34        \u001b[36m0.8886\u001b[0m  0.0153\n",
            "     35        \u001b[36m0.8817\u001b[0m  0.0138\n",
            "     36        \u001b[36m0.8750\u001b[0m  0.0159\n",
            "     37        \u001b[36m0.8683\u001b[0m  0.0183\n",
            "     38        \u001b[36m0.8618\u001b[0m  0.0161\n",
            "     39        \u001b[36m0.8553\u001b[0m  0.0162\n",
            "     40        \u001b[36m0.8488\u001b[0m  0.0162\n",
            "     41        \u001b[36m0.8425\u001b[0m  0.0158\n",
            "     42        \u001b[36m0.8362\u001b[0m  0.0154\n",
            "     43        \u001b[36m0.8300\u001b[0m  0.0160\n",
            "     44        \u001b[36m0.8239\u001b[0m  0.0161\n",
            "     45        \u001b[36m0.8179\u001b[0m  0.0155\n",
            "     46        \u001b[36m0.8120\u001b[0m  0.0156\n",
            "     47        \u001b[36m0.8062\u001b[0m  0.0146\n",
            "     48        \u001b[36m0.8004\u001b[0m  0.0150\n",
            "     49        \u001b[36m0.7948\u001b[0m  0.0148\n",
            "     50        \u001b[36m0.7892\u001b[0m  0.0163\n",
            "     51        \u001b[36m0.7838\u001b[0m  0.0198\n",
            "     52        \u001b[36m0.7784\u001b[0m  0.0148\n",
            "     53        \u001b[36m0.7731\u001b[0m  0.0150\n",
            "     54        \u001b[36m0.7680\u001b[0m  0.0141\n",
            "     55        \u001b[36m0.7629\u001b[0m  0.0172\n",
            "     56        \u001b[36m0.7579\u001b[0m  0.0149\n",
            "     57        \u001b[36m0.7530\u001b[0m  0.0148\n",
            "     58        \u001b[36m0.7483\u001b[0m  0.0189\n",
            "     59        \u001b[36m0.7436\u001b[0m  0.0148\n",
            "     60        \u001b[36m0.7390\u001b[0m  0.0147\n",
            "     61        \u001b[36m0.7346\u001b[0m  0.0154\n",
            "     62        \u001b[36m0.7302\u001b[0m  0.0150\n",
            "     63        \u001b[36m0.7260\u001b[0m  0.0144\n",
            "     64        \u001b[36m0.7218\u001b[0m  0.0167\n",
            "     65        \u001b[36m0.7178\u001b[0m  0.0169\n",
            "     66        \u001b[36m0.7139\u001b[0m  0.0169\n",
            "     67        \u001b[36m0.7100\u001b[0m  0.0162\n",
            "     68        \u001b[36m0.7063\u001b[0m  0.0198\n",
            "     69        \u001b[36m0.7027\u001b[0m  0.0233\n",
            "     70        \u001b[36m0.6992\u001b[0m  0.0225\n",
            "     71        \u001b[36m0.6958\u001b[0m  0.0199\n",
            "     72        \u001b[36m0.6925\u001b[0m  0.0198\n",
            "     73        \u001b[36m0.6893\u001b[0m  0.0240\n",
            "     74        \u001b[36m0.6862\u001b[0m  0.0212\n",
            "     75        \u001b[36m0.6832\u001b[0m  0.0223\n",
            "     76        \u001b[36m0.6803\u001b[0m  0.0215\n",
            "     77        \u001b[36m0.6775\u001b[0m  0.0241\n",
            "     78        \u001b[36m0.6747\u001b[0m  0.0241\n",
            "     79        \u001b[36m0.6721\u001b[0m  0.0168\n",
            "     80        \u001b[36m0.6696\u001b[0m  0.0237\n",
            "     81        \u001b[36m0.6672\u001b[0m  0.0228\n",
            "     82        \u001b[36m0.6648\u001b[0m  0.0221\n",
            "     83        \u001b[36m0.6626\u001b[0m  0.0192\n",
            "     84        \u001b[36m0.6604\u001b[0m  0.0216\n",
            "     85        \u001b[36m0.6583\u001b[0m  0.0226\n",
            "     86        \u001b[36m0.6563\u001b[0m  0.0205\n",
            "     87        \u001b[36m0.6543\u001b[0m  0.0174\n",
            "     88        \u001b[36m0.6525\u001b[0m  0.0156\n",
            "     89        \u001b[36m0.6507\u001b[0m  0.0194\n",
            "     90        \u001b[36m0.6489\u001b[0m  0.0210\n",
            "     91        \u001b[36m0.6473\u001b[0m  0.0155\n",
            "     92        \u001b[36m0.6457\u001b[0m  0.0140\n",
            "     93        \u001b[36m0.6442\u001b[0m  0.0145\n",
            "     94        \u001b[36m0.6427\u001b[0m  0.0148\n",
            "     95        \u001b[36m0.6413\u001b[0m  0.0145\n",
            "     96        \u001b[36m0.6400\u001b[0m  0.0147\n",
            "     97        \u001b[36m0.6387\u001b[0m  0.0168\n",
            "     98        \u001b[36m0.6375\u001b[0m  0.0149\n",
            "     99        \u001b[36m0.6363\u001b[0m  0.0154\n",
            "    100        \u001b[36m0.6351\u001b[0m  0.0153\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7918\u001b[0m  0.0227\n",
            "      2        \u001b[36m0.7720\u001b[0m  0.0209\n",
            "      3        \u001b[36m0.7579\u001b[0m  0.0214\n",
            "      4        \u001b[36m0.7413\u001b[0m  0.0191\n",
            "      5        \u001b[36m0.7261\u001b[0m  0.0192\n",
            "      6        \u001b[36m0.7167\u001b[0m  0.0194\n",
            "      7        \u001b[36m0.7076\u001b[0m  0.0197\n",
            "      8        \u001b[36m0.6955\u001b[0m  0.0206\n",
            "      9        \u001b[36m0.6879\u001b[0m  0.0206\n",
            "     10        \u001b[36m0.6766\u001b[0m  0.0251\n",
            "     11        \u001b[36m0.6695\u001b[0m  0.0217\n",
            "     12        \u001b[36m0.6630\u001b[0m  0.0205\n",
            "     13        \u001b[36m0.6561\u001b[0m  0.0228\n",
            "     14        \u001b[36m0.6480\u001b[0m  0.0232\n",
            "     15        \u001b[36m0.6436\u001b[0m  0.0244\n",
            "     16        \u001b[36m0.6393\u001b[0m  0.0233\n",
            "     17        \u001b[36m0.6385\u001b[0m  0.0239\n",
            "     18        \u001b[36m0.6349\u001b[0m  0.0225\n",
            "     19        \u001b[36m0.6300\u001b[0m  0.0206\n",
            "     20        \u001b[36m0.6234\u001b[0m  0.0206\n",
            "     21        \u001b[36m0.6182\u001b[0m  0.0209\n",
            "     22        \u001b[36m0.6153\u001b[0m  0.0234\n",
            "     23        \u001b[36m0.6122\u001b[0m  0.0204\n",
            "     24        \u001b[36m0.6094\u001b[0m  0.0242\n",
            "     25        \u001b[36m0.6065\u001b[0m  0.0297\n",
            "     26        \u001b[36m0.6037\u001b[0m  0.0194\n",
            "     27        \u001b[36m0.6009\u001b[0m  0.0185\n",
            "     28        \u001b[36m0.5981\u001b[0m  0.0207\n",
            "     29        \u001b[36m0.5955\u001b[0m  0.0205\n",
            "     30        \u001b[36m0.5929\u001b[0m  0.0191\n",
            "     31        \u001b[36m0.5905\u001b[0m  0.0190\n",
            "     32        \u001b[36m0.5882\u001b[0m  0.0196\n",
            "     33        \u001b[36m0.5860\u001b[0m  0.0186\n",
            "     34        \u001b[36m0.5801\u001b[0m  0.0190\n",
            "     35        0.5822  0.0196\n",
            "     36        0.5805  0.0191\n",
            "     37        \u001b[36m0.5782\u001b[0m  0.0193\n",
            "     38        0.5858  0.0190\n",
            "     39        0.5904  0.0197\n",
            "     40        0.5884  0.0195\n",
            "     41        0.5863  0.0190\n",
            "     42        \u001b[36m0.5767\u001b[0m  0.0191\n",
            "     43        \u001b[36m0.5738\u001b[0m  0.0198\n",
            "     44        \u001b[36m0.5694\u001b[0m  0.0196\n",
            "     45        \u001b[36m0.5686\u001b[0m  0.0230\n",
            "     46        \u001b[36m0.5654\u001b[0m  0.0189\n",
            "     47        0.5714  0.0198\n",
            "     48        0.5692  0.0193\n",
            "     49        0.5657  0.0196\n",
            "     50        \u001b[36m0.5648\u001b[0m  0.0211\n",
            "     51        0.5657  0.0211\n",
            "     52        \u001b[36m0.5609\u001b[0m  0.0232\n",
            "     53        \u001b[36m0.5579\u001b[0m  0.0203\n",
            "     54        0.5657  0.0261\n",
            "     55        0.5669  0.0243\n",
            "     56        0.5658  0.0258\n",
            "     57        0.5646  0.0225\n",
            "     58        0.5636  0.0276\n",
            "     59        0.5629  0.0277\n",
            "     60        0.5629  0.0290\n",
            "     61        0.5621  0.0286\n",
            "     62        0.5604  0.0282\n",
            "     63        0.5664  0.0288\n",
            "     64        0.5669  0.0263\n",
            "     65        0.5602  0.0217\n",
            "     66        0.5609  0.0251\n",
            "     67        0.5599  0.0270\n",
            "     68        0.5586  0.0225\n",
            "     69        \u001b[36m0.5576\u001b[0m  0.0192\n",
            "     70        \u001b[36m0.5566\u001b[0m  0.0199\n",
            "     71        \u001b[36m0.5555\u001b[0m  0.0208\n",
            "     72        \u001b[36m0.5544\u001b[0m  0.0202\n",
            "     73        \u001b[36m0.5533\u001b[0m  0.0205\n",
            "     74        \u001b[36m0.5520\u001b[0m  0.0194\n",
            "     75        \u001b[36m0.5507\u001b[0m  0.0227\n",
            "     76        \u001b[36m0.5492\u001b[0m  0.0192\n",
            "     77        \u001b[36m0.5475\u001b[0m  0.0196\n",
            "     78        \u001b[36m0.5457\u001b[0m  0.0200\n",
            "     79        \u001b[36m0.5439\u001b[0m  0.0196\n",
            "     80        \u001b[36m0.5420\u001b[0m  0.0191\n",
            "     81        \u001b[36m0.5403\u001b[0m  0.0198\n",
            "     82        \u001b[36m0.5386\u001b[0m  0.0208\n",
            "     83        \u001b[36m0.5373\u001b[0m  0.0202\n",
            "     84        \u001b[36m0.5354\u001b[0m  0.0196\n",
            "     85        0.5362  0.0237\n",
            "     86        \u001b[36m0.5354\u001b[0m  0.0186\n",
            "     87        \u001b[36m0.5341\u001b[0m  0.0189\n",
            "     88        \u001b[36m0.5326\u001b[0m  0.0205\n",
            "     89        0.5329  0.0201\n",
            "     90        0.5339  0.0220\n",
            "     91        0.5343  0.0235\n",
            "     92        0.5336  0.0216\n",
            "     93        \u001b[36m0.5316\u001b[0m  0.0238\n",
            "     94        \u001b[36m0.5306\u001b[0m  0.0239\n",
            "     95        \u001b[36m0.5305\u001b[0m  0.0256\n",
            "     96        \u001b[36m0.5290\u001b[0m  0.0233\n",
            "     97        \u001b[36m0.5284\u001b[0m  0.0231\n",
            "     98        \u001b[36m0.5283\u001b[0m  0.0213\n",
            "     99        \u001b[36m0.5264\u001b[0m  0.0254\n",
            "    100        \u001b[36m0.5263\u001b[0m  0.0227\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.0425\u001b[0m  0.0200\n",
            "      2        \u001b[36m1.9133\u001b[0m  0.0216\n",
            "      3        \u001b[36m1.7931\u001b[0m  0.0197\n",
            "      4        \u001b[36m1.6691\u001b[0m  0.0217\n",
            "      5        \u001b[36m1.5636\u001b[0m  0.0216\n",
            "      6        \u001b[36m1.4879\u001b[0m  0.0235\n",
            "      7        \u001b[36m1.4281\u001b[0m  0.0218\n",
            "      8        \u001b[36m1.3772\u001b[0m  0.0210\n",
            "      9        \u001b[36m1.3331\u001b[0m  0.0247\n",
            "     10        \u001b[36m1.2933\u001b[0m  0.0225\n",
            "     11        \u001b[36m1.2450\u001b[0m  0.0212\n",
            "     12        \u001b[36m1.2012\u001b[0m  0.0209\n",
            "     13        \u001b[36m1.1597\u001b[0m  0.0200\n",
            "     14        \u001b[36m1.1201\u001b[0m  0.0212\n",
            "     15        \u001b[36m1.0833\u001b[0m  0.0193\n",
            "     16        \u001b[36m1.0493\u001b[0m  0.0202\n",
            "     17        \u001b[36m1.0182\u001b[0m  0.0207\n",
            "     18        \u001b[36m0.9897\u001b[0m  0.0220\n",
            "     19        \u001b[36m0.9637\u001b[0m  0.0210\n",
            "     20        \u001b[36m0.9398\u001b[0m  0.0212\n",
            "     21        \u001b[36m0.9178\u001b[0m  0.0200\n",
            "     22        \u001b[36m0.8986\u001b[0m  0.0211\n",
            "     23        \u001b[36m0.8762\u001b[0m  0.0225\n",
            "     24        \u001b[36m0.8586\u001b[0m  0.0194\n",
            "     25        \u001b[36m0.8429\u001b[0m  0.0232\n",
            "     26        \u001b[36m0.8268\u001b[0m  0.0210\n",
            "     27        \u001b[36m0.8126\u001b[0m  0.0191\n",
            "     28        \u001b[36m0.7995\u001b[0m  0.0185\n",
            "     29        \u001b[36m0.7872\u001b[0m  0.0204\n",
            "     30        \u001b[36m0.7726\u001b[0m  0.0214\n",
            "     31        \u001b[36m0.7589\u001b[0m  0.0217\n",
            "     32        \u001b[36m0.7512\u001b[0m  0.0231\n",
            "     33        \u001b[36m0.7427\u001b[0m  0.0226\n",
            "     34        \u001b[36m0.7350\u001b[0m  0.0224\n",
            "     35        \u001b[36m0.7248\u001b[0m  0.0216\n",
            "     36        \u001b[36m0.7180\u001b[0m  0.0241\n",
            "     37        \u001b[36m0.7116\u001b[0m  0.0287\n",
            "     38        \u001b[36m0.7062\u001b[0m  0.0297\n",
            "     39        \u001b[36m0.7018\u001b[0m  0.0224\n",
            "     40        0.7038  0.0266\n",
            "     41        \u001b[36m0.7000\u001b[0m  0.0294\n",
            "     42        0.7023  0.0301\n",
            "     43        \u001b[36m0.6987\u001b[0m  0.0239\n",
            "     44        0.7045  0.0251\n",
            "     45        \u001b[36m0.6866\u001b[0m  0.0210\n",
            "     46        \u001b[36m0.6795\u001b[0m  0.0223\n",
            "     47        \u001b[36m0.6774\u001b[0m  0.0197\n",
            "     48        \u001b[36m0.6768\u001b[0m  0.0193\n",
            "     49        \u001b[36m0.6704\u001b[0m  0.0208\n",
            "     50        0.6711  0.0218\n",
            "     51        \u001b[36m0.6689\u001b[0m  0.0265\n",
            "     52        \u001b[36m0.6663\u001b[0m  0.0184\n",
            "     53        \u001b[36m0.6625\u001b[0m  0.0185\n",
            "     54        \u001b[36m0.6603\u001b[0m  0.0207\n",
            "     55        \u001b[36m0.6581\u001b[0m  0.0198\n",
            "     56        \u001b[36m0.6560\u001b[0m  0.0195\n",
            "     57        \u001b[36m0.6540\u001b[0m  0.0198\n",
            "     58        \u001b[36m0.6519\u001b[0m  0.0197\n",
            "     59        \u001b[36m0.6500\u001b[0m  0.0184\n",
            "     60        \u001b[36m0.6480\u001b[0m  0.0188\n",
            "     61        \u001b[36m0.6461\u001b[0m  0.0202\n",
            "     62        \u001b[36m0.6442\u001b[0m  0.0197\n",
            "     63        \u001b[36m0.6424\u001b[0m  0.0201\n",
            "     64        \u001b[36m0.6396\u001b[0m  0.0194\n",
            "     65        \u001b[36m0.6378\u001b[0m  0.0197\n",
            "     66        \u001b[36m0.6360\u001b[0m  0.0219\n",
            "     67        \u001b[36m0.6343\u001b[0m  0.0217\n",
            "     68        \u001b[36m0.6326\u001b[0m  0.0213\n",
            "     69        \u001b[36m0.6309\u001b[0m  0.0181\n",
            "     70        \u001b[36m0.6292\u001b[0m  0.0183\n",
            "     71        \u001b[36m0.6275\u001b[0m  0.0225\n",
            "     72        \u001b[36m0.6259\u001b[0m  0.0239\n",
            "     73        \u001b[36m0.6246\u001b[0m  0.0235\n",
            "     74        \u001b[36m0.6229\u001b[0m  0.0255\n",
            "     75        \u001b[36m0.6213\u001b[0m  0.0227\n",
            "     76        \u001b[36m0.6197\u001b[0m  0.0235\n",
            "     77        \u001b[36m0.6181\u001b[0m  0.0219\n",
            "     78        \u001b[36m0.6165\u001b[0m  0.0234\n",
            "     79        \u001b[36m0.6149\u001b[0m  0.0263\n",
            "     80        \u001b[36m0.6133\u001b[0m  0.0231\n",
            "     81        \u001b[36m0.6118\u001b[0m  0.0279\n",
            "     82        \u001b[36m0.6103\u001b[0m  0.0220\n",
            "     83        \u001b[36m0.6088\u001b[0m  0.0214\n",
            "     84        \u001b[36m0.6074\u001b[0m  0.0192\n",
            "     85        \u001b[36m0.6059\u001b[0m  0.0191\n",
            "     86        \u001b[36m0.6045\u001b[0m  0.0218\n",
            "     87        \u001b[36m0.6032\u001b[0m  0.0194\n",
            "     88        \u001b[36m0.6018\u001b[0m  0.0236\n",
            "     89        \u001b[36m0.6005\u001b[0m  0.0197\n",
            "     90        \u001b[36m0.5992\u001b[0m  0.0216\n",
            "     91        \u001b[36m0.5979\u001b[0m  0.0195\n",
            "     92        \u001b[36m0.5966\u001b[0m  0.0199\n",
            "     93        \u001b[36m0.5953\u001b[0m  0.0217\n",
            "     94        \u001b[36m0.5941\u001b[0m  0.0199\n",
            "     95        \u001b[36m0.5929\u001b[0m  0.0210\n",
            "     96        \u001b[36m0.5917\u001b[0m  0.0280\n",
            "     97        \u001b[36m0.5905\u001b[0m  0.0181\n",
            "     98        \u001b[36m0.5890\u001b[0m  0.0189\n",
            "     99        0.5906  0.0192\n",
            "    100        0.5902  0.0189\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0172\u001b[0m  0.0128\n",
            "      2        \u001b[36m1.0131\u001b[0m  0.0127\n",
            "      3        \u001b[36m1.0092\u001b[0m  0.0150\n",
            "      4        \u001b[36m1.0055\u001b[0m  0.0146\n",
            "      5        \u001b[36m1.0000\u001b[0m  0.0185\n",
            "      6        1.0113  0.0144\n",
            "      7        1.0075  0.0147\n",
            "      8        1.0037  0.0150\n",
            "      9        \u001b[36m1.0000\u001b[0m  0.0149\n",
            "     10        \u001b[36m0.9962\u001b[0m  0.0169\n",
            "     11        \u001b[36m0.9925\u001b[0m  0.0146\n",
            "     12        \u001b[36m0.9888\u001b[0m  0.0167\n",
            "     13        \u001b[36m0.9852\u001b[0m  0.0151\n",
            "     14        \u001b[36m0.9815\u001b[0m  0.0159\n",
            "     15        \u001b[36m0.9779\u001b[0m  0.0148\n",
            "     16        \u001b[36m0.9744\u001b[0m  0.0192\n",
            "     17        \u001b[36m0.9708\u001b[0m  0.0180\n",
            "     18        \u001b[36m0.9673\u001b[0m  0.0171\n",
            "     19        \u001b[36m0.9638\u001b[0m  0.0188\n",
            "     20        \u001b[36m0.9603\u001b[0m  0.0182\n",
            "     21        \u001b[36m0.9568\u001b[0m  0.0166\n",
            "     22        \u001b[36m0.9534\u001b[0m  0.0154\n",
            "     23        \u001b[36m0.9500\u001b[0m  0.0182\n",
            "     24        \u001b[36m0.9466\u001b[0m  0.0189\n",
            "     25        \u001b[36m0.9433\u001b[0m  0.0182\n",
            "     26        \u001b[36m0.9399\u001b[0m  0.0203\n",
            "     27        \u001b[36m0.9366\u001b[0m  0.0188\n",
            "     28        \u001b[36m0.9333\u001b[0m  0.0169\n",
            "     29        \u001b[36m0.9301\u001b[0m  0.0206\n",
            "     30        \u001b[36m0.9268\u001b[0m  0.0195\n",
            "     31        \u001b[36m0.9236\u001b[0m  0.0181\n",
            "     32        \u001b[36m0.9204\u001b[0m  0.0179\n",
            "     33        \u001b[36m0.9173\u001b[0m  0.0179\n",
            "     34        \u001b[36m0.9141\u001b[0m  0.0163\n",
            "     35        \u001b[36m0.9110\u001b[0m  0.0150\n",
            "     36        \u001b[36m0.9079\u001b[0m  0.0152\n",
            "     37        \u001b[36m0.9049\u001b[0m  0.0166\n",
            "     38        \u001b[36m0.9018\u001b[0m  0.0154\n",
            "     39        \u001b[36m0.8988\u001b[0m  0.0157\n",
            "     40        \u001b[36m0.8958\u001b[0m  0.0146\n",
            "     41        \u001b[36m0.8928\u001b[0m  0.0148\n",
            "     42        \u001b[36m0.8899\u001b[0m  0.0149\n",
            "     43        \u001b[36m0.8869\u001b[0m  0.0155\n",
            "     44        \u001b[36m0.8840\u001b[0m  0.0145\n",
            "     45        \u001b[36m0.8812\u001b[0m  0.0149\n",
            "     46        \u001b[36m0.8783\u001b[0m  0.0152\n",
            "     47        \u001b[36m0.8755\u001b[0m  0.0147\n",
            "     48        \u001b[36m0.8726\u001b[0m  0.0138\n",
            "     49        \u001b[36m0.8699\u001b[0m  0.0214\n",
            "     50        \u001b[36m0.8671\u001b[0m  0.0189\n",
            "     51        \u001b[36m0.8643\u001b[0m  0.0177\n",
            "     52        \u001b[36m0.8616\u001b[0m  0.0144\n",
            "     53        \u001b[36m0.8589\u001b[0m  0.0207\n",
            "     54        \u001b[36m0.8562\u001b[0m  0.0158\n",
            "     55        \u001b[36m0.8536\u001b[0m  0.0157\n",
            "     56        \u001b[36m0.8509\u001b[0m  0.0149\n",
            "     57        \u001b[36m0.8456\u001b[0m  0.0151\n",
            "     58        \u001b[36m0.8431\u001b[0m  0.0155\n",
            "     59        \u001b[36m0.8405\u001b[0m  0.0150\n",
            "     60        \u001b[36m0.8380\u001b[0m  0.0215\n",
            "     61        \u001b[36m0.8356\u001b[0m  0.0172\n",
            "     62        \u001b[36m0.8331\u001b[0m  0.0210\n",
            "     63        \u001b[36m0.8307\u001b[0m  0.0175\n",
            "     64        \u001b[36m0.8283\u001b[0m  0.0196\n",
            "     65        \u001b[36m0.8259\u001b[0m  0.0183\n",
            "     66        \u001b[36m0.8235\u001b[0m  0.0174\n",
            "     67        \u001b[36m0.8212\u001b[0m  0.0201\n",
            "     68        \u001b[36m0.8189\u001b[0m  0.0181\n",
            "     69        \u001b[36m0.8166\u001b[0m  0.0219\n",
            "     70        \u001b[36m0.8143\u001b[0m  0.0226\n",
            "     71        \u001b[36m0.8120\u001b[0m  0.0219\n",
            "     72        \u001b[36m0.8098\u001b[0m  0.0202\n",
            "     73        \u001b[36m0.8076\u001b[0m  0.0219\n",
            "     74        \u001b[36m0.8054\u001b[0m  0.0189\n",
            "     75        \u001b[36m0.8032\u001b[0m  0.0277\n",
            "     76        \u001b[36m0.8010\u001b[0m  0.0229\n",
            "     77        \u001b[36m0.7989\u001b[0m  0.0246\n",
            "     78        \u001b[36m0.7968\u001b[0m  0.0233\n",
            "     79        \u001b[36m0.7947\u001b[0m  0.0244\n",
            "     80        \u001b[36m0.7926\u001b[0m  0.0202\n",
            "     81        \u001b[36m0.7906\u001b[0m  0.0212\n",
            "     82        \u001b[36m0.7886\u001b[0m  0.0180\n",
            "     83        \u001b[36m0.7866\u001b[0m  0.0219\n",
            "     84        \u001b[36m0.7846\u001b[0m  0.0246\n",
            "     85        \u001b[36m0.7826\u001b[0m  0.0257\n",
            "     86        \u001b[36m0.7807\u001b[0m  0.0219\n",
            "     87        \u001b[36m0.7787\u001b[0m  0.0181\n",
            "     88        \u001b[36m0.7768\u001b[0m  0.0196\n",
            "     89        \u001b[36m0.7749\u001b[0m  0.0220\n",
            "     90        \u001b[36m0.7731\u001b[0m  0.0185\n",
            "     91        \u001b[36m0.7712\u001b[0m  0.0163\n",
            "     92        \u001b[36m0.7694\u001b[0m  0.0160\n",
            "     93        \u001b[36m0.7676\u001b[0m  0.0165\n",
            "     94        \u001b[36m0.7658\u001b[0m  0.0195\n",
            "     95        \u001b[36m0.7640\u001b[0m  0.0184\n",
            "     96        \u001b[36m0.7623\u001b[0m  0.0221\n",
            "     97        \u001b[36m0.7606\u001b[0m  0.0150\n",
            "     98        \u001b[36m0.7589\u001b[0m  0.0161\n",
            "     99        \u001b[36m0.7572\u001b[0m  0.0156\n",
            "    100        \u001b[36m0.7555\u001b[0m  0.0152\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.1826\u001b[0m  0.0148\n",
            "      2        \u001b[36m3.0447\u001b[0m  0.0158\n",
            "      3        \u001b[36m2.9172\u001b[0m  0.0153\n",
            "      4        \u001b[36m2.7874\u001b[0m  0.0148\n",
            "      5        \u001b[36m2.6557\u001b[0m  0.0162\n",
            "      6        \u001b[36m2.5230\u001b[0m  0.0148\n",
            "      7        \u001b[36m2.3906\u001b[0m  0.0156\n",
            "      8        \u001b[36m2.2603\u001b[0m  0.0151\n",
            "      9        \u001b[36m2.1340\u001b[0m  0.0148\n",
            "     10        \u001b[36m2.0025\u001b[0m  0.0142\n",
            "     11        \u001b[36m1.9563\u001b[0m  0.0157\n",
            "     12        \u001b[36m1.8488\u001b[0m  0.0172\n",
            "     13        \u001b[36m1.7548\u001b[0m  0.0153\n",
            "     14        \u001b[36m1.6634\u001b[0m  0.0157\n",
            "     15        \u001b[36m1.5802\u001b[0m  0.0165\n",
            "     16        \u001b[36m1.5137\u001b[0m  0.0161\n",
            "     17        \u001b[36m1.4564\u001b[0m  0.0212\n",
            "     18        \u001b[36m1.4071\u001b[0m  0.0209\n",
            "     19        \u001b[36m1.3649\u001b[0m  0.0235\n",
            "     20        \u001b[36m1.3286\u001b[0m  0.0176\n",
            "     21        \u001b[36m1.2972\u001b[0m  0.0210\n",
            "     22        \u001b[36m1.2703\u001b[0m  0.0189\n",
            "     23        \u001b[36m1.2481\u001b[0m  0.0218\n",
            "     24        \u001b[36m1.2277\u001b[0m  0.0202\n",
            "     25        \u001b[36m1.2098\u001b[0m  0.0160\n",
            "     26        \u001b[36m1.1939\u001b[0m  0.0157\n",
            "     27        \u001b[36m1.1799\u001b[0m  0.0156\n",
            "     28        \u001b[36m1.1673\u001b[0m  0.0154\n",
            "     29        \u001b[36m1.1559\u001b[0m  0.0157\n",
            "     30        \u001b[36m1.1456\u001b[0m  0.0151\n",
            "     31        \u001b[36m1.1362\u001b[0m  0.0151\n",
            "     32        \u001b[36m1.1275\u001b[0m  0.0162\n",
            "     33        \u001b[36m1.1195\u001b[0m  0.0159\n",
            "     34        \u001b[36m1.1120\u001b[0m  0.0197\n",
            "     35        \u001b[36m1.1050\u001b[0m  0.0162\n",
            "     36        \u001b[36m1.0983\u001b[0m  0.0171\n",
            "     37        \u001b[36m1.0920\u001b[0m  0.0152\n",
            "     38        \u001b[36m1.0860\u001b[0m  0.0156\n",
            "     39        \u001b[36m1.0803\u001b[0m  0.0239\n",
            "     40        \u001b[36m1.0748\u001b[0m  0.0186\n",
            "     41        \u001b[36m1.0695\u001b[0m  0.0150\n",
            "     42        \u001b[36m1.0643\u001b[0m  0.0160\n",
            "     43        \u001b[36m1.0594\u001b[0m  0.0167\n",
            "     44        \u001b[36m1.0545\u001b[0m  0.0174\n",
            "     45        \u001b[36m1.0498\u001b[0m  0.0173\n",
            "     46        \u001b[36m1.0453\u001b[0m  0.0176\n",
            "     47        \u001b[36m1.0408\u001b[0m  0.0207\n",
            "     48        \u001b[36m1.0365\u001b[0m  0.0209\n",
            "     49        \u001b[36m1.0322\u001b[0m  0.0179\n",
            "     50        \u001b[36m1.0280\u001b[0m  0.0185\n",
            "     51        \u001b[36m1.0240\u001b[0m  0.0199\n",
            "     52        \u001b[36m1.0200\u001b[0m  0.0175\n",
            "     53        \u001b[36m1.0160\u001b[0m  0.0185\n",
            "     54        \u001b[36m1.0122\u001b[0m  0.0156\n",
            "     55        \u001b[36m1.0084\u001b[0m  0.0182\n",
            "     56        \u001b[36m1.0047\u001b[0m  0.0162\n",
            "     57        \u001b[36m1.0011\u001b[0m  0.0154\n",
            "     58        \u001b[36m0.9975\u001b[0m  0.0158\n",
            "     59        \u001b[36m0.9940\u001b[0m  0.0151\n",
            "     60        \u001b[36m0.9905\u001b[0m  0.0162\n",
            "     61        \u001b[36m0.9871\u001b[0m  0.0173\n",
            "     62        \u001b[36m0.9838\u001b[0m  0.0177\n",
            "     63        \u001b[36m0.9805\u001b[0m  0.0200\n",
            "     64        \u001b[36m0.9773\u001b[0m  0.0231\n",
            "     65        \u001b[36m0.9741\u001b[0m  0.0253\n",
            "     66        \u001b[36m0.9709\u001b[0m  0.0241\n",
            "     67        \u001b[36m0.9679\u001b[0m  0.0182\n",
            "     68        \u001b[36m0.9648\u001b[0m  0.0189\n",
            "     69        \u001b[36m0.9618\u001b[0m  0.0202\n",
            "     70        \u001b[36m0.9589\u001b[0m  0.0169\n",
            "     71        \u001b[36m0.9560\u001b[0m  0.0170\n",
            "     72        \u001b[36m0.9531\u001b[0m  0.0192\n",
            "     73        \u001b[36m0.9503\u001b[0m  0.0237\n",
            "     74        \u001b[36m0.9476\u001b[0m  0.0252\n",
            "     75        \u001b[36m0.9448\u001b[0m  0.0176\n",
            "     76        \u001b[36m0.9422\u001b[0m  0.0155\n",
            "     77        \u001b[36m0.9395\u001b[0m  0.0158\n",
            "     78        \u001b[36m0.9369\u001b[0m  0.0158\n",
            "     79        \u001b[36m0.9343\u001b[0m  0.0172\n",
            "     80        \u001b[36m0.9318\u001b[0m  0.0162\n",
            "     81        \u001b[36m0.9293\u001b[0m  0.0161\n",
            "     82        \u001b[36m0.9269\u001b[0m  0.0160\n",
            "     83        \u001b[36m0.9244\u001b[0m  0.0149\n",
            "     84        \u001b[36m0.9220\u001b[0m  0.0146\n",
            "     85        \u001b[36m0.9197\u001b[0m  0.0161\n",
            "     86        \u001b[36m0.9174\u001b[0m  0.0148\n",
            "     87        \u001b[36m0.9151\u001b[0m  0.0236\n",
            "     88        \u001b[36m0.9128\u001b[0m  0.0182\n",
            "     89        \u001b[36m0.9106\u001b[0m  0.0183\n",
            "     90        \u001b[36m0.9084\u001b[0m  0.0196\n",
            "     91        \u001b[36m0.9062\u001b[0m  0.0169\n",
            "     92        \u001b[36m0.9041\u001b[0m  0.0181\n",
            "     93        \u001b[36m0.9020\u001b[0m  0.0173\n",
            "     94        \u001b[36m0.8999\u001b[0m  0.0193\n",
            "     95        \u001b[36m0.8979\u001b[0m  0.0216\n",
            "     96        \u001b[36m0.8958\u001b[0m  0.0172\n",
            "     97        \u001b[36m0.8938\u001b[0m  0.0148\n",
            "     98        \u001b[36m0.8919\u001b[0m  0.0157\n",
            "     99        \u001b[36m0.8899\u001b[0m  0.0227\n",
            "    100        \u001b[36m0.8880\u001b[0m  0.0199\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0209\n",
            "      2        1.0000  0.0256\n",
            "      3        1.0000  0.0225\n",
            "      4        1.0000  0.0218\n",
            "      5        1.0000  0.0243\n",
            "      6        1.0000  0.0251\n",
            "      7        1.0000  0.0255\n",
            "      8        1.0000  0.0219\n",
            "      9        1.0000  0.0257\n",
            "     10        1.0000  0.0304\n",
            "     11        1.0000  0.0328\n",
            "     12        1.0000  0.0298\n",
            "     13        1.0000  0.0261\n",
            "     14        1.0000  0.0275\n",
            "     15        1.0000  0.0249\n",
            "     16        1.0000  0.0242\n",
            "     17        1.0000  0.0263\n",
            "     18        1.0000  0.0278\n",
            "     19        1.0000  0.0282\n",
            "     20        1.0000  0.0257\n",
            "     21        1.0000  0.0209\n",
            "     22        1.0000  0.0244\n",
            "     23        1.0000  0.0205\n",
            "     24        1.0000  0.0264\n",
            "     25        1.0000  0.0262\n",
            "     26        1.0000  0.0295\n",
            "     27        1.0000  0.0291\n",
            "     28        1.0000  0.0214\n",
            "     29        1.0000  0.0205\n",
            "     30        1.0000  0.0201\n",
            "     31        1.0000  0.0270\n",
            "     32        1.0000  0.0228\n",
            "     33        1.0000  0.0226\n",
            "     34        1.0000  0.0226\n",
            "     35        1.0000  0.0267\n",
            "     36        1.0000  0.0254\n",
            "     37        1.0000  0.0309\n",
            "     38        1.0000  0.0263\n",
            "     39        1.0000  0.0264\n",
            "     40        1.0000  0.0299\n",
            "     41        1.0000  0.0339\n",
            "     42        1.0000  0.0330\n",
            "     43        1.0000  0.0316\n",
            "     44        1.0000  0.0303\n",
            "     45        1.0000  0.0314\n",
            "     46        1.0000  0.0307\n",
            "     47        1.0000  0.0324\n",
            "     48        1.0000  0.0375\n",
            "     49        1.0000  0.0275\n",
            "     50        1.0000  0.0219\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0324\n",
            "      2        1.0000  0.0267\n",
            "      3        1.0000  0.0259\n",
            "      4        1.0000  0.0261\n",
            "      5        1.0000  0.0276\n",
            "      6        1.0000  0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        1.0000  0.0261\n",
            "      8        1.0000  0.0302\n",
            "      9        1.0000  0.0281\n",
            "     10        1.0000  0.0210\n",
            "     11        1.0000  0.0207\n",
            "     12        1.0000  0.0225\n",
            "     13        1.0000  0.0213\n",
            "     14        1.0000  0.0206\n",
            "     15        1.0000  0.0218\n",
            "     16        1.0000  0.0205\n",
            "     17        1.0000  0.0205\n",
            "     18        1.0000  0.0210\n",
            "     19        1.0000  0.0214\n",
            "     20        1.0000  0.0246\n",
            "     21        1.0000  0.0205\n",
            "     22        1.0000  0.0253\n",
            "     23        1.0000  0.0268\n",
            "     24        1.0000  0.0230\n",
            "     25        1.0000  0.0232\n",
            "     26        1.0000  0.0241\n",
            "     27        1.0000  0.0291\n",
            "     28        1.0000  0.0271\n",
            "     29        1.0000  0.0287\n",
            "     30        1.0000  0.0274\n",
            "     31        1.0000  0.0270\n",
            "     32        1.0000  0.0272\n",
            "     33        1.0000  0.0320\n",
            "     34        1.0000  0.0282\n",
            "     35        1.0000  0.0267\n",
            "     36        1.0000  0.0241\n",
            "     37        1.0000  0.0229\n",
            "     38        1.0000  0.0223\n",
            "     39        1.0000  0.0215\n",
            "     40        1.0000  0.0221\n",
            "     41        1.0000  0.0216\n",
            "     42        1.0000  0.0225\n",
            "     43        1.0000  0.0204\n",
            "     44        1.0000  0.0215\n",
            "     45        1.0000  0.0204\n",
            "     46        1.0000  0.0204\n",
            "     47        1.0000  0.0206\n",
            "     48        1.0000  0.0222\n",
            "     49        1.0000  0.0205\n",
            "     50        1.0000  0.0213\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0154\n",
            "      2        1.0000  0.0159\n",
            "      3        1.0000  0.0173\n",
            "      4        1.0000  0.0173\n",
            "      5        1.0000  0.0166\n",
            "      6        1.0000  0.0175\n",
            "      7        1.0000  0.0168\n",
            "      8        1.0000  0.0151\n",
            "      9        1.0000  0.0167\n",
            "     10        1.0000  0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        1.0000  0.0186\n",
            "     12        1.0000  0.0168\n",
            "     13        1.0000  0.0177\n",
            "     14        1.0000  0.0178\n",
            "     15        1.0000  0.0221\n",
            "     16        1.0000  0.0206\n",
            "     17        1.0000  0.0248\n",
            "     18        1.0000  0.0209\n",
            "     19        1.0000  0.0184\n",
            "     20        1.0000  0.0204\n",
            "     21        1.0000  0.0206\n",
            "     22        1.0000  0.0235\n",
            "     23        1.0000  0.0201\n",
            "     24        1.0000  0.0176\n",
            "     25        1.0000  0.0183\n",
            "     26        1.0000  0.0173\n",
            "     27        1.0000  0.0189\n",
            "     28        1.0000  0.0196\n",
            "     29        1.0000  0.0190\n",
            "     30        1.0000  0.0178\n",
            "     31        1.0000  0.0172\n",
            "     32        1.0000  0.0164\n",
            "     33        1.0000  0.0167\n",
            "     34        1.0000  0.0178\n",
            "     35        1.0000  0.0160\n",
            "     36        1.0000  0.0174\n",
            "     37        1.0000  0.0175\n",
            "     38        1.0000  0.0173\n",
            "     39        1.0000  0.0175\n",
            "     40        1.0000  0.0170\n",
            "     41        1.0000  0.0177\n",
            "     42        1.0000  0.0169\n",
            "     43        1.0000  0.0176\n",
            "     44        1.0000  0.0165\n",
            "     45        1.0000  0.0171\n",
            "     46        1.0000  0.0174\n",
            "     47        1.0000  0.0168\n",
            "     48        1.0000  0.0178\n",
            "     49        1.0000  0.0187\n",
            "     50        1.0000  0.0168\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0171\n",
            "      2        1.0000  0.0170\n",
            "      3        1.0000  0.0178\n",
            "      4        1.0000  0.0175\n",
            "      5        1.0000  0.0164\n",
            "      6        1.0000  0.0181\n",
            "      7        1.0000  0.0178\n",
            "      8        1.0000  0.0170\n",
            "      9        1.0000  0.0167\n",
            "     10        1.0000  0.0169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        1.0000  0.0203\n",
            "     12        1.0000  0.0176\n",
            "     13        1.0000  0.0194\n",
            "     14        1.0000  0.0188\n",
            "     15        1.0000  0.0203\n",
            "     16        1.0000  0.0210\n",
            "     17        1.0000  0.0283\n",
            "     18        1.0000  0.0216\n",
            "     19        1.0000  0.0170\n",
            "     20        1.0000  0.0195\n",
            "     21        1.0000  0.0185\n",
            "     22        1.0000  0.0198\n",
            "     23        1.0000  0.0188\n",
            "     24        1.0000  0.0192\n",
            "     25        1.0000  0.0198\n",
            "     26        1.0000  0.0192\n",
            "     27        1.0000  0.0199\n",
            "     28        1.0000  0.0215\n",
            "     29        1.0000  0.0163\n",
            "     30        1.0000  0.0184\n",
            "     31        1.0000  0.0194\n",
            "     32        1.0000  0.0163\n",
            "     33        1.0000  0.0163\n",
            "     34        1.0000  0.0154\n",
            "     35        1.0000  0.0206\n",
            "     36        1.0000  0.0181\n",
            "     37        1.0000  0.0169\n",
            "     38        1.0000  0.0166\n",
            "     39        1.0000  0.0165\n",
            "     40        1.0000  0.0241\n",
            "     41        1.0000  0.0170\n",
            "     42        1.0000  0.0183\n",
            "     43        1.0000  0.0184\n",
            "     44        1.0000  0.0190\n",
            "     45        1.0000  0.0180\n",
            "     46        1.0000  0.0176\n",
            "     47        1.0000  0.0178\n",
            "     48        1.0000  0.0180\n",
            "     49        1.0000  0.0177\n",
            "     50        1.0000  0.0184\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0231\n",
            "      2        1.0000  0.0234\n",
            "      3        1.0000  0.0223\n",
            "      4        1.0000  0.0215\n",
            "      5        1.0000  0.0235\n",
            "      6        1.0000  0.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        1.0000  0.0241\n",
            "      8        1.0000  0.0264\n",
            "      9        1.0000  0.0318\n",
            "     10        1.0000  0.0340\n",
            "     11        1.0000  0.0284\n",
            "     12        1.0000  0.0273\n",
            "     13        1.0000  0.0250\n",
            "     14        1.0000  0.0349\n",
            "     15        1.0000  0.0350\n",
            "     16        1.0000  0.0308\n",
            "     17        1.0000  0.0263\n",
            "     18        1.0000  0.0228\n",
            "     19        1.0000  0.0211\n",
            "     20        1.0000  0.0209\n",
            "     21        1.0000  0.0209\n",
            "     22        1.0000  0.0205\n",
            "     23        1.0000  0.0212\n",
            "     24        1.0000  0.0206\n",
            "     25        1.0000  0.0214\n",
            "     26        1.0000  0.0207\n",
            "     27        1.0000  0.0219\n",
            "     28        1.0000  0.0212\n",
            "     29        1.0000  0.0213\n",
            "     30        1.0000  0.0213\n",
            "     31        1.0000  0.0206\n",
            "     32        1.0000  0.0213\n",
            "     33        1.0000  0.0211\n",
            "     34        1.0000  0.0204\n",
            "     35        1.0000  0.0216\n",
            "     36        1.0000  0.0210\n",
            "     37        1.0000  0.0205\n",
            "     38        1.0000  0.0214\n",
            "     39        1.0000  0.0258\n",
            "     40        1.0000  0.0219\n",
            "     41        1.0000  0.0220\n",
            "     42        1.0000  0.0384\n",
            "     43        1.0000  0.0244\n",
            "     44        1.0000  0.0251\n",
            "     45        1.0000  0.0250\n",
            "     46        1.0000  0.0256\n",
            "     47        1.0000  0.0267\n",
            "     48        1.0000  0.0259\n",
            "     49        1.0000  0.0345\n",
            "     50        1.0000  0.0352\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0226\n",
            "      2        1.0000  0.0207\n",
            "      3        1.0000  0.0224\n",
            "      4        1.0000  0.0217\n",
            "      5        1.0000  0.0218\n",
            "      6        1.0000  0.0227\n",
            "      7        1.0000  0.0202\n",
            "      8        1.0000  0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        1.0000  0.0228\n",
            "     10        1.0000  0.0214\n",
            "     11        1.0000  0.0203\n",
            "     12        1.0000  0.0210\n",
            "     13        1.0000  0.0206\n",
            "     14        1.0000  0.0215\n",
            "     15        1.0000  0.0206\n",
            "     16        1.0000  0.0207\n",
            "     17        1.0000  0.0212\n",
            "     18        1.0000  0.0204\n",
            "     19        1.0000  0.0230\n",
            "     20        1.0000  0.0206\n",
            "     21        1.0000  0.0223\n",
            "     22        1.0000  0.0209\n",
            "     23        1.0000  0.0222\n",
            "     24        1.0000  0.0204\n",
            "     25        1.0000  0.0207\n",
            "     26        1.0000  0.0225\n",
            "     27        1.0000  0.0214\n",
            "     28        1.0000  0.0205\n",
            "     29        1.0000  0.0230\n",
            "     30        1.0000  0.0246\n",
            "     31        1.0000  0.0241\n",
            "     32        1.0000  0.0237\n",
            "     33        1.0000  0.0283\n",
            "     34        1.0000  0.0243\n",
            "     35        1.0000  0.0277\n",
            "     36        1.0000  0.0260\n",
            "     37        1.0000  0.0255\n",
            "     38        1.0000  0.0256\n",
            "     39        1.0000  0.0279\n",
            "     40        1.0000  0.0243\n",
            "     41        1.0000  0.0256\n",
            "     42        1.0000  0.0278\n",
            "     43        1.0000  0.0235\n",
            "     44        1.0000  0.0244\n",
            "     45        1.0000  0.0213\n",
            "     46        1.0000  0.0211\n",
            "     47        1.0000  0.0229\n",
            "     48        1.0000  0.0202\n",
            "     49        1.0000  0.0202\n",
            "     50        1.0000  0.0214\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0125\n",
            "      2        1.0000  0.0186\n",
            "      3        1.0000  0.0158\n",
            "      4        1.0000  0.0162\n",
            "      5        1.0000  0.0132\n",
            "      6        1.0000  0.0145\n",
            "      7        1.0000  0.0163\n",
            "      8        1.0000  0.0174\n",
            "      9        1.0000  0.0164\n",
            "     10        1.0000  0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        1.0000  0.0205\n",
            "     12        1.0000  0.0172\n",
            "     13        1.0000  0.0164\n",
            "     14        1.0000  0.0173\n",
            "     15        1.0000  0.0164\n",
            "     16        1.0000  0.0187\n",
            "     17        1.0000  0.0164\n",
            "     18        1.0000  0.0135\n",
            "     19        1.0000  0.0171\n",
            "     20        1.0000  0.0208\n",
            "     21        1.0000  0.0170\n",
            "     22        1.0000  0.0148\n",
            "     23        1.0000  0.0180\n",
            "     24        1.0000  0.0190\n",
            "     25        1.0000  0.0213\n",
            "     26        1.0000  0.0154\n",
            "     27        1.0000  0.0214\n",
            "     28        1.0000  0.0195\n",
            "     29        1.0000  0.0191\n",
            "     30        1.0000  0.0177\n",
            "     31        1.0000  0.0236\n",
            "     32        1.0000  0.0176\n",
            "     33        1.0000  0.0198\n",
            "     34        1.0000  0.0185\n",
            "     35        1.0000  0.0196\n",
            "     36        1.0000  0.0219\n",
            "     37        1.0000  0.0213\n",
            "     38        1.0000  0.0196\n",
            "     39        1.0000  0.0295\n",
            "     40        1.0000  0.0287\n",
            "     41        1.0000  0.0205\n",
            "     42        1.0000  0.0168\n",
            "     43        1.0000  0.0167\n",
            "     44        1.0000  0.0171\n",
            "     45        1.0000  0.0171\n",
            "     46        1.0000  0.0162\n",
            "     47        1.0000  0.0170\n",
            "     48        1.0000  0.0160\n",
            "     49        1.0000  0.0167\n",
            "     50        1.0000  0.0186\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0137\n",
            "      2        1.0000  0.0178\n",
            "      3        1.0000  0.0165\n",
            "      4        1.0000  0.0164\n",
            "      5        1.0000  0.0145\n",
            "      6        1.0000  0.0157\n",
            "      7        1.0000  0.0161\n",
            "      8        1.0000  0.0226\n",
            "      9        1.0000  0.0149\n",
            "     10        1.0000  0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        1.0000  0.0182\n",
            "     12        1.0000  0.0164\n",
            "     13        1.0000  0.0181\n",
            "     14        1.0000  0.0172\n",
            "     15        1.0000  0.0169\n",
            "     16        1.0000  0.0166\n",
            "     17        1.0000  0.0204\n",
            "     18        1.0000  0.0130\n",
            "     19        1.0000  0.0158\n",
            "     20        1.0000  0.0158\n",
            "     21        1.0000  0.0159\n",
            "     22        1.0000  0.0176\n",
            "     23        1.0000  0.0183\n",
            "     24        1.0000  0.0200\n",
            "     25        1.0000  0.0178\n",
            "     26        1.0000  0.0189\n",
            "     27        1.0000  0.0197\n",
            "     28        1.0000  0.0203\n",
            "     29        1.0000  0.0200\n",
            "     30        1.0000  0.0221\n",
            "     31        1.0000  0.0179\n",
            "     32        1.0000  0.0198\n",
            "     33        1.0000  0.0195\n",
            "     34        1.0000  0.0244\n",
            "     35        1.0000  0.0207\n",
            "     36        1.0000  0.0210\n",
            "     37        1.0000  0.0185\n",
            "     38        1.0000  0.0163\n",
            "     39        1.0000  0.0162\n",
            "     40        1.0000  0.0222\n",
            "     41        1.0000  0.0242\n",
            "     42        1.0000  0.0167\n",
            "     43        1.0000  0.0170\n",
            "     44        1.0000  0.0160\n",
            "     45        1.0000  0.0171\n",
            "     46        1.0000  0.0168\n",
            "     47        1.0000  0.0164\n",
            "     48        1.0000  0.0171\n",
            "     49        1.0000  0.0162\n",
            "     50        1.0000  0.0154\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0154\n",
            "      2        0.3732  0.0192\n",
            "      3        0.3732  0.0206\n",
            "      4        0.3732  0.0228\n",
            "      5        0.3732  0.0204\n",
            "      6        0.3732  0.0204\n",
            "      7        0.3732  0.0198\n",
            "      8        0.3732  0.0210\n",
            "      9        0.3732  0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.3732  0.0246\n",
            "     11        0.3732  0.0223\n",
            "     12        0.3732  0.0199\n",
            "     13        0.3732  0.0170\n",
            "     14        0.3732  0.0227\n",
            "     15        0.3732  0.0225\n",
            "     16        0.3732  0.0222\n",
            "     17        0.3732  0.0209\n",
            "     18        0.3732  0.0225\n",
            "     19        0.3732  0.0220\n",
            "     20        0.3732  0.0225\n",
            "     21        0.3732  0.0272\n",
            "     22        0.3732  0.0235\n",
            "     23        0.3732  0.0223\n",
            "     24        0.3732  0.0240\n",
            "     25        0.3732  0.0232\n",
            "     26        0.3732  0.0221\n",
            "     27        0.3732  0.0354\n",
            "     28        0.3732  0.0231\n",
            "     29        0.3732  0.0215\n",
            "     30        0.3732  0.0211\n",
            "     31        0.3732  0.0215\n",
            "     32        0.3732  0.0215\n",
            "     33        0.3732  0.0239\n",
            "     34        0.3732  0.0200\n",
            "     35        0.3732  0.0247\n",
            "     36        0.3732  0.0244\n",
            "     37        0.3732  0.0205\n",
            "     38        0.3732  0.0203\n",
            "     39        0.3732  0.0211\n",
            "     40        0.3732  0.0202\n",
            "     41        0.3732  0.0203\n",
            "     42        0.3732  0.0241\n",
            "     43        0.3732  0.0206\n",
            "     44        0.3732  0.0200\n",
            "     45        0.3732  0.0213\n",
            "     46        0.3732  0.0200\n",
            "     47        0.3732  0.0194\n",
            "     48        0.3732  0.0197\n",
            "     49        0.3732  0.0197\n",
            "     50        0.3732  0.0201\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0165\n",
            "      2        1.0000  0.0203\n",
            "      3        1.0000  0.0199\n",
            "      4        1.0000  0.0201\n",
            "      5        1.0000  0.0181\n",
            "      6        1.0000  0.0257\n",
            "      7        1.0000  0.0218\n",
            "      8        1.0000  0.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        1.0000  0.0270\n",
            "     10        1.0000  0.0309\n",
            "     11        1.0000  0.0253\n",
            "     12        1.0000  0.0215\n",
            "     13        1.0000  0.0224\n",
            "     14        1.0000  0.0283\n",
            "     15        1.0000  0.0233\n",
            "     16        1.0000  0.0217\n",
            "     17        1.0000  0.0222\n",
            "     18        1.0000  0.0224\n",
            "     19        1.0000  0.0241\n",
            "     20        1.0000  0.0255\n",
            "     21        1.0000  0.0267\n",
            "     22        1.0000  0.0192\n",
            "     23        1.0000  0.0209\n",
            "     24        1.0000  0.0219\n",
            "     25        1.0000  0.0247\n",
            "     26        1.0000  0.0205\n",
            "     27        1.0000  0.0243\n",
            "     28        1.0000  0.0235\n",
            "     29        1.0000  0.0218\n",
            "     30        1.0000  0.0203\n",
            "     31        1.0000  0.0198\n",
            "     32        1.0000  0.0205\n",
            "     33        1.0000  0.0214\n",
            "     34        1.0000  0.0259\n",
            "     35        1.0000  0.0242\n",
            "     36        1.0000  0.0225\n",
            "     37        1.0000  0.0243\n",
            "     38        1.0000  0.0274\n",
            "     39        1.0000  0.0240\n",
            "     40        \u001b[36m1.0000\u001b[0m  0.0215\n",
            "     41        \u001b[36m1.0000\u001b[0m  0.0275\n",
            "     42        \u001b[36m0.9895\u001b[0m  0.0261\n",
            "     43        \u001b[36m0.9895\u001b[0m  0.0316\n",
            "     44        0.9895  0.0293\n",
            "     45        0.9895  0.0255\n",
            "     46        0.9895  0.0239\n",
            "     47        0.9895  0.0309\n",
            "     48        0.9895  0.0247\n",
            "     49        0.9895  0.0256\n",
            "     50        0.9895  0.0253\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0199\n",
            "      2        0.3732  0.0194\n",
            "      3        0.3732  0.0232\n",
            "      4        0.3732  0.0241\n",
            "      5        0.3732  0.0216\n",
            "      6        0.3732  0.0210\n",
            "      7        0.3732  0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        0.3732  0.0258\n",
            "      9        0.3732  0.0196\n",
            "     10        0.3732  0.0190\n",
            "     11        0.3732  0.0200\n",
            "     12        0.3732  0.0234\n",
            "     13        0.3732  0.0260\n",
            "     14        0.3732  0.0265\n",
            "     15        0.3732  0.0164\n",
            "     16        0.3732  0.0170\n",
            "     17        0.3732  0.0238\n",
            "     18        0.3732  0.0204\n",
            "     19        0.3732  0.0199\n",
            "     20        0.3732  0.0176\n",
            "     21        0.3732  0.0178\n",
            "     22        0.3732  0.0166\n",
            "     23        0.3732  0.0169\n",
            "     24        0.3732  0.0162\n",
            "     25        0.3732  0.0164\n",
            "     26        0.3732  0.0170\n",
            "     27        0.3732  0.0163\n",
            "     28        0.3732  0.0159\n",
            "     29        0.3732  0.0172\n",
            "     30        0.3732  0.0164\n",
            "     31        0.3732  0.0165\n",
            "     32        0.3732  0.0178\n",
            "     33        0.3732  0.0175\n",
            "     34        0.3732  0.0167\n",
            "     35        0.3732  0.0172\n",
            "     36        0.3732  0.0167\n",
            "     37        0.3732  0.0167\n",
            "     38        0.3732  0.0172\n",
            "     39        0.3732  0.0173\n",
            "     40        0.3732  0.0165\n",
            "     41        0.3732  0.0160\n",
            "     42        0.3732  0.0203\n",
            "     43        0.3732  0.0218\n",
            "     44        0.3732  0.0208\n",
            "     45        0.3732  0.0272\n",
            "     46        0.3732  0.0260\n",
            "     47        0.3732  0.0267\n",
            "     48        0.3732  0.0252\n",
            "     49        0.3732  0.0205\n",
            "     50        0.3732  0.0288\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9333\u001b[0m  0.0269\n",
            "      2        0.9333  0.0176\n",
            "      3        0.9333  0.0171\n",
            "      4        0.9333  0.0166\n",
            "      5        0.9333  0.0166\n",
            "      6        0.9333  0.0190\n",
            "      7        0.9333  0.0213\n",
            "      8        0.9333  0.0171\n",
            "      9        0.9333  0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.9333  0.0190\n",
            "     11        0.9333  0.0172\n",
            "     12        0.9333  0.0154\n",
            "     13        0.9333  0.0160\n",
            "     14        0.9333  0.0161\n",
            "     15        0.9333  0.0164\n",
            "     16        0.9333  0.0161\n",
            "     17        0.9333  0.0176\n",
            "     18        0.9333  0.0188\n",
            "     19        0.9333  0.0213\n",
            "     20        0.9333  0.0176\n",
            "     21        0.9333  0.0188\n",
            "     22        0.9333  0.0185\n",
            "     23        0.9333  0.0221\n",
            "     24        0.9333  0.0208\n",
            "     25        0.9333  0.0199\n",
            "     26        0.9333  0.0221\n",
            "     27        0.9333  0.0217\n",
            "     28        0.9333  0.0205\n",
            "     29        0.9333  0.0190\n",
            "     30        0.9333  0.0190\n",
            "     31        0.9333  0.0198\n",
            "     32        0.9333  0.0155\n",
            "     33        0.9333  0.0182\n",
            "     34        0.9333  0.0171\n",
            "     35        0.9333  0.0180\n",
            "     36        0.9333  0.0192\n",
            "     37        0.9333  0.0186\n",
            "     38        0.9333  0.0183\n",
            "     39        0.9333  0.0186\n",
            "     40        0.9333  0.0187\n",
            "     41        0.9333  0.0186\n",
            "     42        0.9333  0.0190\n",
            "     43        0.9333  0.0188\n",
            "     44        0.9333  0.0188\n",
            "     45        0.9333  0.0189\n",
            "     46        0.9333  0.0185\n",
            "     47        0.9333  0.0167\n",
            "     48        0.9333  0.0165\n",
            "     49        0.9333  0.0162\n",
            "     50        0.9333  0.0169\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0295\n",
            "      2        0.3732  0.0289\n",
            "      3        0.3732  0.0220\n",
            "      4        0.3732  0.0303\n",
            "      5        0.3732  0.0264\n",
            "      6        0.3732  0.0245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        0.3732  0.0235\n",
            "      8        0.3732  0.0223\n",
            "      9        0.3732  0.0265\n",
            "     10        0.3732  0.0264\n",
            "     11        0.3732  0.0250\n",
            "     12        0.3732  0.0248\n",
            "     13        0.3732  0.0287\n",
            "     14        0.3732  0.0226\n",
            "     15        0.3732  0.0243\n",
            "     16        0.3732  0.0273\n",
            "     17        0.3732  0.0240\n",
            "     18        0.3732  0.0284\n",
            "     19        0.3732  0.0287\n",
            "     20        0.3732  0.0297\n",
            "     21        0.3732  0.0265\n",
            "     22        0.3732  0.0236\n",
            "     23        0.3732  0.0284\n",
            "     24        0.3732  0.0323\n",
            "     25        0.3732  0.0319\n",
            "     26        0.3732  0.0290\n",
            "     27        0.3732  0.0312\n",
            "     28        0.3732  0.0331\n",
            "     29        0.3732  0.0296\n",
            "     30        0.3732  0.0266\n",
            "     31        0.3732  0.0224\n",
            "     32        0.3732  0.0290\n",
            "     33        0.3732  0.0304\n",
            "     34        0.3732  0.0230\n",
            "     35        0.3732  0.0283\n",
            "     36        0.3732  0.0255\n",
            "     37        0.3732  0.0227\n",
            "     38        0.3732  0.0237\n",
            "     39        0.3732  0.0253\n",
            "     40        0.3732  0.0223\n",
            "     41        0.3732  0.0230\n",
            "     42        0.3732  0.0220\n",
            "     43        0.3732  0.0225\n",
            "     44        0.3732  0.0253\n",
            "     45        0.3732  0.0262\n",
            "     46        0.3732  0.0241\n",
            "     47        0.3732  0.0281\n",
            "     48        0.3732  0.0256\n",
            "     49        0.3732  0.0290\n",
            "     50        0.3732  0.0248\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4667\u001b[0m  0.0214\n",
            "      2        0.4667  0.0217\n",
            "      3        0.4667  0.0215\n",
            "      4        0.4702  0.0240\n",
            "      5        0.4702  0.0224\n",
            "      6        0.4667  0.0263\n",
            "      7        \u001b[36m0.4596\u001b[0m  0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        0.4596  0.0307\n",
            "      9        0.4596  0.0363\n",
            "     10        0.4596  0.0356\n",
            "     11        0.4596  0.0363\n",
            "     12        0.4596  0.0318\n",
            "     13        0.4596  0.0232\n",
            "     14        0.4596  0.0221\n",
            "     15        0.4596  0.0226\n",
            "     16        0.4596  0.0231\n",
            "     17        0.4596  0.0257\n",
            "     18        0.4596  0.0254\n",
            "     19        0.4596  0.0227\n",
            "     20        0.4596  0.0247\n",
            "     21        0.4596  0.0287\n",
            "     22        0.4596  0.0233\n",
            "     23        0.4596  0.0265\n",
            "     24        0.4596  0.0267\n",
            "     25        0.4596  0.0241\n",
            "     26        0.4596  0.0262\n",
            "     27        0.4596  0.0275\n",
            "     28        0.4596  0.0291\n",
            "     29        0.4596  0.0271\n",
            "     30        0.4596  0.0342\n",
            "     31        0.4596  0.0264\n",
            "     32        0.4596  0.0246\n",
            "     33        0.4596  0.0228\n",
            "     34        0.4596  0.0252\n",
            "     35        0.4596  0.0324\n",
            "     36        0.4596  0.0227\n",
            "     37        0.4596  0.0207\n",
            "     38        0.4596  0.0242\n",
            "     39        0.4596  0.0219\n",
            "     40        0.4596  0.0232\n",
            "     41        0.4596  0.0230\n",
            "     42        0.4596  0.0237\n",
            "     43        0.4596  0.0277\n",
            "     44        0.4596  0.0244\n",
            "     45        0.4596  0.0259\n",
            "     46        0.4596  0.0250\n",
            "     47        0.4596  0.0263\n",
            "     48        0.4596  0.0247\n",
            "     49        0.4596  0.0240\n",
            "     50        0.4596  0.0242\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9577\u001b[0m  0.0186\n",
            "      2        0.9577  0.0163\n",
            "      3        0.9577  0.0167\n",
            "      4        0.9577  0.0171\n",
            "      5        0.9577  0.0161\n",
            "      6        0.9577  0.0174\n",
            "      7        0.9577  0.0164\n",
            "      8        0.9577  0.0160\n",
            "      9        0.9577  0.0164\n",
            "     10        0.9577  0.0207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        0.9577  0.0190\n",
            "     12        0.9577  0.0184\n",
            "     13        0.9577  0.0164\n",
            "     14        0.9577  0.0155\n",
            "     15        0.9577  0.0161\n",
            "     16        0.9577  0.0172\n",
            "     17        0.9577  0.0180\n",
            "     18        0.9577  0.0173\n",
            "     19        0.9577  0.0177\n",
            "     20        0.9577  0.0173\n",
            "     21        0.9577  0.0185\n",
            "     22        0.9577  0.0181\n",
            "     23        0.9577  0.0169\n",
            "     24        0.9577  0.0157\n",
            "     25        0.9577  0.0189\n",
            "     26        0.9577  0.0173\n",
            "     27        0.9577  0.0160\n",
            "     28        0.9577  0.0159\n",
            "     29        0.9577  0.0166\n",
            "     30        0.9577  0.0208\n",
            "     31        0.9577  0.0229\n",
            "     32        0.9577  0.0243\n",
            "     33        0.9577  0.0162\n",
            "     34        0.9577  0.0182\n",
            "     35        0.9577  0.0191\n",
            "     36        0.9577  0.0203\n",
            "     37        0.9577  0.0170\n",
            "     38        0.9577  0.0180\n",
            "     39        0.9577  0.0190\n",
            "     40        0.9577  0.0197\n",
            "     41        0.9577  0.0179\n",
            "     42        0.9577  0.0200\n",
            "     43        0.9577  0.0167\n",
            "     44        0.9577  0.0236\n",
            "     45        0.9577  0.0235\n",
            "     46        0.9577  0.0238\n",
            "     47        0.9577  0.0265\n",
            "     48        0.9577  0.0210\n",
            "     49        0.9577  0.0185\n",
            "     50        0.9577  0.0195\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8772\u001b[0m  0.0181\n",
            "      2        0.8772  0.0198\n",
            "      3        0.8772  0.0200\n",
            "      4        0.8772  0.0170\n",
            "      5        0.8772  0.0164\n",
            "      6        0.8772  0.0173\n",
            "      7        0.8772  0.0177\n",
            "      8        0.8772  0.0168\n",
            "      9        0.8772  0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.8772  0.0185\n",
            "     11        0.8772  0.0165\n",
            "     12        0.8772  0.0174\n",
            "     13        0.8772  0.0200\n",
            "     14        0.8772  0.0175\n",
            "     15        0.8772  0.0158\n",
            "     16        0.8772  0.0170\n",
            "     17        0.8772  0.0168\n",
            "     18        0.8772  0.0166\n",
            "     19        0.8772  0.0168\n",
            "     20        0.8772  0.0170\n",
            "     21        0.8772  0.0170\n",
            "     22        0.8772  0.0172\n",
            "     23        0.8772  0.0178\n",
            "     24        0.8772  0.0156\n",
            "     25        0.8772  0.0168\n",
            "     26        0.8772  0.0167\n",
            "     27        0.8772  0.0176\n",
            "     28        0.8772  0.0175\n",
            "     29        0.8772  0.0221\n",
            "     30        0.8772  0.0235\n",
            "     31        0.8772  0.0201\n",
            "     32        0.8772  0.0185\n",
            "     33        0.8772  0.0240\n",
            "     34        0.8772  0.0198\n",
            "     35        0.8772  0.0204\n",
            "     36        0.8772  0.0246\n",
            "     37        0.8772  0.0243\n",
            "     38        0.8772  0.0220\n",
            "     39        0.8772  0.0167\n",
            "     40        0.8772  0.0242\n",
            "     41        0.8772  0.0211\n",
            "     42        0.8772  0.0248\n",
            "     43        0.8772  0.0255\n",
            "     44        0.8772  0.0238\n",
            "     45        0.8772  0.0239\n",
            "     46        0.8772  0.0174\n",
            "     47        0.8772  0.0184\n",
            "     48        0.8772  0.0209\n",
            "     49        0.8772  0.0187\n",
            "     50        0.8772  0.0200\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9959\u001b[0m  0.0256\n",
            "      2        \u001b[36m0.9955\u001b[0m  0.0206\n",
            "      3        \u001b[36m0.9951\u001b[0m  0.0209\n",
            "      4        \u001b[36m0.9945\u001b[0m  0.0238\n",
            "      5        \u001b[36m0.9939\u001b[0m  0.0227\n",
            "      6        \u001b[36m0.9931\u001b[0m  0.0232\n",
            "      7        \u001b[36m0.9921\u001b[0m  0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.9909\u001b[0m  0.0236\n",
            "      9        \u001b[36m0.9892\u001b[0m  0.0228\n",
            "     10        \u001b[36m0.9869\u001b[0m  0.0201\n",
            "     11        \u001b[36m0.9838\u001b[0m  0.0222\n",
            "     12        \u001b[36m0.9793\u001b[0m  0.0216\n",
            "     13        \u001b[36m0.9729\u001b[0m  0.0215\n",
            "     14        \u001b[36m0.9637\u001b[0m  0.0218\n",
            "     15        \u001b[36m0.9506\u001b[0m  0.0212\n",
            "     16        \u001b[36m0.9318\u001b[0m  0.0218\n",
            "     17        \u001b[36m0.9052\u001b[0m  0.0254\n",
            "     18        \u001b[36m0.8681\u001b[0m  0.0223\n",
            "     19        \u001b[36m0.8185\u001b[0m  0.0276\n",
            "     20        \u001b[36m0.7567\u001b[0m  0.0323\n",
            "     21        \u001b[36m0.6878\u001b[0m  0.0245\n",
            "     22        \u001b[36m0.6208\u001b[0m  0.0244\n",
            "     23        \u001b[36m0.5641\u001b[0m  0.0267\n",
            "     24        \u001b[36m0.5212\u001b[0m  0.0260\n",
            "     25        \u001b[36m0.4909\u001b[0m  0.0278\n",
            "     26        \u001b[36m0.4697\u001b[0m  0.0233\n",
            "     27        \u001b[36m0.4546\u001b[0m  0.0217\n",
            "     28        \u001b[36m0.4434\u001b[0m  0.0217\n",
            "     29        \u001b[36m0.4348\u001b[0m  0.0207\n",
            "     30        \u001b[36m0.4279\u001b[0m  0.0216\n",
            "     31        \u001b[36m0.4222\u001b[0m  0.0226\n",
            "     32        \u001b[36m0.4174\u001b[0m  0.0229\n",
            "     33        \u001b[36m0.4134\u001b[0m  0.0230\n",
            "     34        \u001b[36m0.4102\u001b[0m  0.0218\n",
            "     35        \u001b[36m0.4075\u001b[0m  0.0229\n",
            "     36        \u001b[36m0.4053\u001b[0m  0.0220\n",
            "     37        \u001b[36m0.4034\u001b[0m  0.0208\n",
            "     38        \u001b[36m0.4017\u001b[0m  0.0224\n",
            "     39        \u001b[36m0.4003\u001b[0m  0.0215\n",
            "     40        \u001b[36m0.3990\u001b[0m  0.0233\n",
            "     41        \u001b[36m0.3978\u001b[0m  0.0211\n",
            "     42        \u001b[36m0.3967\u001b[0m  0.0222\n",
            "     43        \u001b[36m0.3957\u001b[0m  0.0218\n",
            "     44        \u001b[36m0.3948\u001b[0m  0.0200\n",
            "     45        \u001b[36m0.3940\u001b[0m  0.0212\n",
            "     46        \u001b[36m0.3932\u001b[0m  0.0241\n",
            "     47        \u001b[36m0.3925\u001b[0m  0.0216\n",
            "     48        \u001b[36m0.3918\u001b[0m  0.0205\n",
            "     49        \u001b[36m0.3912\u001b[0m  0.0206\n",
            "     50        \u001b[36m0.3906\u001b[0m  0.0204\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9824\u001b[0m  0.0156\n",
            "      2        \u001b[36m0.9807\u001b[0m  0.0224\n",
            "      3        \u001b[36m0.9789\u001b[0m  0.0215\n",
            "      4        \u001b[36m0.9769\u001b[0m  0.0211\n",
            "      5        \u001b[36m0.9746\u001b[0m  0.0168\n",
            "      6        \u001b[36m0.9719\u001b[0m  0.0240\n",
            "      7        \u001b[36m0.9688\u001b[0m  0.0223\n",
            "      8        \u001b[36m0.9651\u001b[0m  0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9607\u001b[0m  0.0279\n",
            "     10        \u001b[36m0.9554\u001b[0m  0.0221\n",
            "     11        \u001b[36m0.9488\u001b[0m  0.0340\n",
            "     12        \u001b[36m0.9407\u001b[0m  0.0303\n",
            "     13        \u001b[36m0.9307\u001b[0m  0.0251\n",
            "     14        \u001b[36m0.9184\u001b[0m  0.0218\n",
            "     15        \u001b[36m0.9033\u001b[0m  0.0247\n",
            "     16        \u001b[36m0.8851\u001b[0m  0.0247\n",
            "     17        \u001b[36m0.8631\u001b[0m  0.0231\n",
            "     18        \u001b[36m0.8362\u001b[0m  0.0243\n",
            "     19        \u001b[36m0.8030\u001b[0m  0.0223\n",
            "     20        \u001b[36m0.7619\u001b[0m  0.0247\n",
            "     21        \u001b[36m0.7118\u001b[0m  0.0258\n",
            "     22        \u001b[36m0.6545\u001b[0m  0.0245\n",
            "     23        \u001b[36m0.5959\u001b[0m  0.0240\n",
            "     24        \u001b[36m0.5441\u001b[0m  0.0247\n",
            "     25        \u001b[36m0.5041\u001b[0m  0.0238\n",
            "     26        \u001b[36m0.4760\u001b[0m  0.0225\n",
            "     27        \u001b[36m0.4569\u001b[0m  0.0205\n",
            "     28        \u001b[36m0.4436\u001b[0m  0.0209\n",
            "     29        \u001b[36m0.4342\u001b[0m  0.0234\n",
            "     30        \u001b[36m0.4272\u001b[0m  0.0215\n",
            "     31        \u001b[36m0.4218\u001b[0m  0.0235\n",
            "     32        \u001b[36m0.4175\u001b[0m  0.0222\n",
            "     33        \u001b[36m0.4141\u001b[0m  0.0207\n",
            "     34        \u001b[36m0.4111\u001b[0m  0.0205\n",
            "     35        \u001b[36m0.4087\u001b[0m  0.0218\n",
            "     36        \u001b[36m0.4065\u001b[0m  0.0218\n",
            "     37        \u001b[36m0.4046\u001b[0m  0.0182\n",
            "     38        \u001b[36m0.4030\u001b[0m  0.0239\n",
            "     39        \u001b[36m0.4015\u001b[0m  0.0215\n",
            "     40        \u001b[36m0.4001\u001b[0m  0.0204\n",
            "     41        \u001b[36m0.3989\u001b[0m  0.0208\n",
            "     42        \u001b[36m0.3978\u001b[0m  0.0216\n",
            "     43        \u001b[36m0.3967\u001b[0m  0.0225\n",
            "     44        \u001b[36m0.3958\u001b[0m  0.0250\n",
            "     45        \u001b[36m0.3949\u001b[0m  0.0214\n",
            "     46        \u001b[36m0.3940\u001b[0m  0.0214\n",
            "     47        \u001b[36m0.3933\u001b[0m  0.0214\n",
            "     48        \u001b[36m0.3925\u001b[0m  0.0264\n",
            "     49        \u001b[36m0.3918\u001b[0m  0.0239\n",
            "     50        \u001b[36m0.3912\u001b[0m  0.0243\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9861\u001b[0m  0.0163\n",
            "      2        \u001b[36m0.9861\u001b[0m  0.0198\n",
            "      3        \u001b[36m0.9861\u001b[0m  0.0274\n",
            "      4        \u001b[36m0.9861\u001b[0m  0.0208\n",
            "      5        \u001b[36m0.9861\u001b[0m  0.0165\n",
            "      6        \u001b[36m0.9860\u001b[0m  0.0180\n",
            "      7        \u001b[36m0.9860\u001b[0m  0.0179\n",
            "      8        \u001b[36m0.9860\u001b[0m  0.0176\n",
            "      9        \u001b[36m0.9860\u001b[0m  0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.9860\u001b[0m  0.0186\n",
            "     11        \u001b[36m0.9860\u001b[0m  0.0217\n",
            "     12        \u001b[36m0.9859\u001b[0m  0.0173\n",
            "     13        \u001b[36m0.9859\u001b[0m  0.0174\n",
            "     14        \u001b[36m0.9859\u001b[0m  0.0177\n",
            "     15        \u001b[36m0.9859\u001b[0m  0.0181\n",
            "     16        \u001b[36m0.9859\u001b[0m  0.0168\n",
            "     17        \u001b[36m0.9859\u001b[0m  0.0166\n",
            "     18        \u001b[36m0.9858\u001b[0m  0.0177\n",
            "     19        \u001b[36m0.9858\u001b[0m  0.0173\n",
            "     20        \u001b[36m0.9858\u001b[0m  0.0190\n",
            "     21        \u001b[36m0.9858\u001b[0m  0.0157\n",
            "     22        \u001b[36m0.9858\u001b[0m  0.0175\n",
            "     23        \u001b[36m0.9858\u001b[0m  0.0179\n",
            "     24        \u001b[36m0.9857\u001b[0m  0.0170\n",
            "     25        \u001b[36m0.9857\u001b[0m  0.0127\n",
            "     26        \u001b[36m0.9857\u001b[0m  0.0144\n",
            "     27        \u001b[36m0.9857\u001b[0m  0.0162\n",
            "     28        \u001b[36m0.9857\u001b[0m  0.0163\n",
            "     29        \u001b[36m0.9857\u001b[0m  0.0165\n",
            "     30        \u001b[36m0.9856\u001b[0m  0.0169\n",
            "     31        \u001b[36m0.9856\u001b[0m  0.0165\n",
            "     32        \u001b[36m0.9856\u001b[0m  0.0185\n",
            "     33        \u001b[36m0.9856\u001b[0m  0.0163\n",
            "     34        \u001b[36m0.9856\u001b[0m  0.0173\n",
            "     35        \u001b[36m0.9856\u001b[0m  0.0169\n",
            "     36        \u001b[36m0.9855\u001b[0m  0.0176\n",
            "     37        \u001b[36m0.9855\u001b[0m  0.0163\n",
            "     38        \u001b[36m0.9855\u001b[0m  0.0161\n",
            "     39        \u001b[36m0.9855\u001b[0m  0.0160\n",
            "     40        \u001b[36m0.9855\u001b[0m  0.0153\n",
            "     41        \u001b[36m0.9854\u001b[0m  0.0167\n",
            "     42        \u001b[36m0.9854\u001b[0m  0.0169\n",
            "     43        \u001b[36m0.9854\u001b[0m  0.0168\n",
            "     44        \u001b[36m0.9854\u001b[0m  0.0167\n",
            "     45        \u001b[36m0.9854\u001b[0m  0.0133\n",
            "     46        \u001b[36m0.9854\u001b[0m  0.0159\n",
            "     47        \u001b[36m0.9853\u001b[0m  0.0178\n",
            "     48        \u001b[36m0.9853\u001b[0m  0.0174\n",
            "     49        \u001b[36m0.9853\u001b[0m  0.0165\n",
            "     50        \u001b[36m0.9853\u001b[0m  0.0201\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9906\u001b[0m  0.0171\n",
            "      2        \u001b[36m0.9906\u001b[0m  0.0169\n",
            "      3        \u001b[36m0.9906\u001b[0m  0.0174\n",
            "      4        \u001b[36m0.9906\u001b[0m  0.0223\n",
            "      5        \u001b[36m0.9906\u001b[0m  0.0202\n",
            "      6        \u001b[36m0.9906\u001b[0m  0.0204\n",
            "      7        \u001b[36m0.9906\u001b[0m  0.0196\n",
            "      8        \u001b[36m0.9906\u001b[0m  0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9906\u001b[0m  0.0215\n",
            "     10        \u001b[36m0.9906\u001b[0m  0.0218\n",
            "     11        \u001b[36m0.9906\u001b[0m  0.0220\n",
            "     12        \u001b[36m0.9906\u001b[0m  0.0214\n",
            "     13        \u001b[36m0.9906\u001b[0m  0.0214\n",
            "     14        \u001b[36m0.9905\u001b[0m  0.0173\n",
            "     15        \u001b[36m0.9905\u001b[0m  0.0190\n",
            "     16        \u001b[36m0.9905\u001b[0m  0.0195\n",
            "     17        \u001b[36m0.9905\u001b[0m  0.0204\n",
            "     18        \u001b[36m0.9905\u001b[0m  0.0188\n",
            "     19        \u001b[36m0.9905\u001b[0m  0.0167\n",
            "     20        \u001b[36m0.9905\u001b[0m  0.0180\n",
            "     21        \u001b[36m0.9905\u001b[0m  0.0184\n",
            "     22        \u001b[36m0.9905\u001b[0m  0.0174\n",
            "     23        \u001b[36m0.9905\u001b[0m  0.0168\n",
            "     24        \u001b[36m0.9905\u001b[0m  0.0163\n",
            "     25        \u001b[36m0.9905\u001b[0m  0.0181\n",
            "     26        \u001b[36m0.9904\u001b[0m  0.0163\n",
            "     27        \u001b[36m0.9904\u001b[0m  0.0160\n",
            "     28        \u001b[36m0.9904\u001b[0m  0.0183\n",
            "     29        \u001b[36m0.9904\u001b[0m  0.0178\n",
            "     30        \u001b[36m0.9904\u001b[0m  0.0174\n",
            "     31        \u001b[36m0.9904\u001b[0m  0.0172\n",
            "     32        \u001b[36m0.9904\u001b[0m  0.0157\n",
            "     33        \u001b[36m0.9904\u001b[0m  0.0179\n",
            "     34        \u001b[36m0.9904\u001b[0m  0.0169\n",
            "     35        \u001b[36m0.9904\u001b[0m  0.0167\n",
            "     36        \u001b[36m0.9904\u001b[0m  0.0178\n",
            "     37        \u001b[36m0.9904\u001b[0m  0.0173\n",
            "     38        \u001b[36m0.9903\u001b[0m  0.0167\n",
            "     39        \u001b[36m0.9903\u001b[0m  0.0175\n",
            "     40        \u001b[36m0.9903\u001b[0m  0.0171\n",
            "     41        \u001b[36m0.9903\u001b[0m  0.0168\n",
            "     42        \u001b[36m0.9903\u001b[0m  0.0177\n",
            "     43        \u001b[36m0.9903\u001b[0m  0.0210\n",
            "     44        \u001b[36m0.9903\u001b[0m  0.0203\n",
            "     45        \u001b[36m0.9903\u001b[0m  0.0191\n",
            "     46        \u001b[36m0.9903\u001b[0m  0.0177\n",
            "     47        \u001b[36m0.9903\u001b[0m  0.0282\n",
            "     48        \u001b[36m0.9903\u001b[0m  0.0191\n",
            "     49        \u001b[36m0.9903\u001b[0m  0.0209\n",
            "     50        \u001b[36m0.9902\u001b[0m  0.0177\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9997\u001b[0m  0.0237\n",
            "      2        \u001b[36m0.9997\u001b[0m  0.0290\n",
            "      3        \u001b[36m0.9996\u001b[0m  0.0253\n",
            "      4        \u001b[36m0.9995\u001b[0m  0.0248\n",
            "      5        \u001b[36m0.9994\u001b[0m  0.0248\n",
            "      6        \u001b[36m0.9993\u001b[0m  0.0182\n",
            "      7        \u001b[36m0.9991\u001b[0m  0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.9989\u001b[0m  0.0291\n",
            "      9        \u001b[36m0.9986\u001b[0m  0.0224\n",
            "     10        \u001b[36m0.9982\u001b[0m  0.0199\n",
            "     11        \u001b[36m0.9977\u001b[0m  0.0161\n",
            "     12        \u001b[36m0.9969\u001b[0m  0.0228\n",
            "     13        \u001b[36m0.9958\u001b[0m  0.0200\n",
            "     14        \u001b[36m0.9942\u001b[0m  0.0218\n",
            "     15        \u001b[36m0.9919\u001b[0m  0.0210\n",
            "     16        \u001b[36m0.9885\u001b[0m  0.0211\n",
            "     17        \u001b[36m0.9835\u001b[0m  0.0207\n",
            "     18        \u001b[36m0.9759\u001b[0m  0.0201\n",
            "     19        \u001b[36m0.9643\u001b[0m  0.0243\n",
            "     20        \u001b[36m0.9465\u001b[0m  0.0203\n",
            "     21        \u001b[36m0.9179\u001b[0m  0.0201\n",
            "     22        \u001b[36m0.8700\u001b[0m  0.0204\n",
            "     23        \u001b[36m0.7905\u001b[0m  0.0192\n",
            "     24        \u001b[36m0.6857\u001b[0m  0.0249\n",
            "     25        \u001b[36m0.5937\u001b[0m  0.0199\n",
            "     26        \u001b[36m0.5328\u001b[0m  0.0209\n",
            "     27        \u001b[36m0.4946\u001b[0m  0.0219\n",
            "     28        \u001b[36m0.4698\u001b[0m  0.0205\n",
            "     29        \u001b[36m0.4528\u001b[0m  0.0219\n",
            "     30        \u001b[36m0.4406\u001b[0m  0.0243\n",
            "     31        \u001b[36m0.4315\u001b[0m  0.0211\n",
            "     32        \u001b[36m0.4244\u001b[0m  0.0227\n",
            "     33        \u001b[36m0.4187\u001b[0m  0.0225\n",
            "     34        \u001b[36m0.4137\u001b[0m  0.0234\n",
            "     35        \u001b[36m0.4086\u001b[0m  0.0234\n",
            "     36        \u001b[36m0.4027\u001b[0m  0.0250\n",
            "     37        \u001b[36m0.3965\u001b[0m  0.0264\n",
            "     38        \u001b[36m0.3923\u001b[0m  0.0246\n",
            "     39        \u001b[36m0.3901\u001b[0m  0.0261\n",
            "     40        \u001b[36m0.3889\u001b[0m  0.0236\n",
            "     41        \u001b[36m0.3881\u001b[0m  0.0267\n",
            "     42        \u001b[36m0.3873\u001b[0m  0.0215\n",
            "     43        \u001b[36m0.3866\u001b[0m  0.0280\n",
            "     44        \u001b[36m0.3857\u001b[0m  0.0313\n",
            "     45        \u001b[36m0.3847\u001b[0m  0.0254\n",
            "     46        \u001b[36m0.3839\u001b[0m  0.0222\n",
            "     47        \u001b[36m0.3834\u001b[0m  0.0228\n",
            "     48        \u001b[36m0.3831\u001b[0m  0.0206\n",
            "     49        \u001b[36m0.3828\u001b[0m  0.0211\n",
            "     50        \u001b[36m0.3825\u001b[0m  0.0222\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0160\n",
            "      2        \u001b[36m0.9998\u001b[0m  0.0191\n",
            "      3        \u001b[36m0.9998\u001b[0m  0.0205\n",
            "      4        \u001b[36m0.9998\u001b[0m  0.0211\n",
            "      5        \u001b[36m0.9997\u001b[0m  0.0159\n",
            "      6        \u001b[36m0.9997\u001b[0m  0.0274\n",
            "      7        \u001b[36m0.9996\u001b[0m  0.0216\n",
            "      8        \u001b[36m0.9995\u001b[0m  0.0195\n",
            "      9        \u001b[36m0.9994\u001b[0m  0.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.9992\u001b[0m  0.0234\n",
            "     11        \u001b[36m0.9990\u001b[0m  0.0206\n",
            "     12        \u001b[36m0.9987\u001b[0m  0.0226\n",
            "     13        \u001b[36m0.9982\u001b[0m  0.0199\n",
            "     14        \u001b[36m0.9975\u001b[0m  0.0239\n",
            "     15        \u001b[36m0.9965\u001b[0m  0.0203\n",
            "     16        \u001b[36m0.9951\u001b[0m  0.0207\n",
            "     17        \u001b[36m0.9928\u001b[0m  0.0209\n",
            "     18        \u001b[36m0.9895\u001b[0m  0.0210\n",
            "     19        \u001b[36m0.9842\u001b[0m  0.0244\n",
            "     20        \u001b[36m0.9758\u001b[0m  0.0227\n",
            "     21        \u001b[36m0.9617\u001b[0m  0.0203\n",
            "     22        \u001b[36m0.9370\u001b[0m  0.0214\n",
            "     23        \u001b[36m0.8942\u001b[0m  0.0290\n",
            "     24        \u001b[36m0.8292\u001b[0m  0.0282\n",
            "     25        \u001b[36m0.7433\u001b[0m  0.0273\n",
            "     26        \u001b[36m0.6479\u001b[0m  0.0274\n",
            "     27        \u001b[36m0.5672\u001b[0m  0.0277\n",
            "     28        \u001b[36m0.5140\u001b[0m  0.0269\n",
            "     29        \u001b[36m0.4809\u001b[0m  0.0300\n",
            "     30        \u001b[36m0.4591\u001b[0m  0.0305\n",
            "     31        \u001b[36m0.4436\u001b[0m  0.0234\n",
            "     32        \u001b[36m0.4311\u001b[0m  0.0249\n",
            "     33        \u001b[36m0.4193\u001b[0m  0.0232\n",
            "     34        \u001b[36m0.4083\u001b[0m  0.0214\n",
            "     35        \u001b[36m0.3995\u001b[0m  0.0279\n",
            "     36        \u001b[36m0.3927\u001b[0m  0.0265\n",
            "     37        \u001b[36m0.3876\u001b[0m  0.0206\n",
            "     38        \u001b[36m0.3848\u001b[0m  0.0250\n",
            "     39        \u001b[36m0.3836\u001b[0m  0.0274\n",
            "     40        \u001b[36m0.3828\u001b[0m  0.0231\n",
            "     41        \u001b[36m0.3823\u001b[0m  0.0227\n",
            "     42        \u001b[36m0.3819\u001b[0m  0.0244\n",
            "     43        \u001b[36m0.3816\u001b[0m  0.0244\n",
            "     44        \u001b[36m0.3812\u001b[0m  0.0268\n",
            "     45        \u001b[36m0.3806\u001b[0m  0.0221\n",
            "     46        \u001b[36m0.3797\u001b[0m  0.0243\n",
            "     47        \u001b[36m0.3786\u001b[0m  0.0234\n",
            "     48        \u001b[36m0.3780\u001b[0m  0.0220\n",
            "     49        \u001b[36m0.3777\u001b[0m  0.0258\n",
            "     50        \u001b[36m0.3775\u001b[0m  0.0216\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9995\u001b[0m  0.0136\n",
            "      2        \u001b[36m0.9995\u001b[0m  0.0229\n",
            "      3        \u001b[36m0.9995\u001b[0m  0.0211\n",
            "      4        \u001b[36m0.9995\u001b[0m  0.0194\n",
            "      5        \u001b[36m0.9995\u001b[0m  0.0180\n",
            "      6        \u001b[36m0.9995\u001b[0m  0.0236\n",
            "      7        \u001b[36m0.9995\u001b[0m  0.0201\n",
            "      8        \u001b[36m0.9995\u001b[0m  0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9995\u001b[0m  0.0182\n",
            "     10        \u001b[36m0.9995\u001b[0m  0.0220\n",
            "     11        \u001b[36m0.9995\u001b[0m  0.0199\n",
            "     12        \u001b[36m0.9995\u001b[0m  0.0238\n",
            "     13        0.9995  0.0226\n",
            "     14        \u001b[36m0.9995\u001b[0m  0.0207\n",
            "     15        \u001b[36m0.9995\u001b[0m  0.0191\n",
            "     16        \u001b[36m0.9995\u001b[0m  0.0201\n",
            "     17        \u001b[36m0.9995\u001b[0m  0.0222\n",
            "     18        \u001b[36m0.9995\u001b[0m  0.0287\n",
            "     19        \u001b[36m0.9995\u001b[0m  0.0203\n",
            "     20        0.9995  0.0179\n",
            "     21        0.9995  0.0169\n",
            "     22        \u001b[36m0.9995\u001b[0m  0.0203\n",
            "     23        \u001b[36m0.9995\u001b[0m  0.0231\n",
            "     24        \u001b[36m0.9995\u001b[0m  0.0184\n",
            "     25        0.9995  0.0211\n",
            "     26        \u001b[36m0.9995\u001b[0m  0.0176\n",
            "     27        \u001b[36m0.9995\u001b[0m  0.0226\n",
            "     28        \u001b[36m0.9995\u001b[0m  0.0220\n",
            "     29        \u001b[36m0.9995\u001b[0m  0.0220\n",
            "     30        \u001b[36m0.9995\u001b[0m  0.0197\n",
            "     31        \u001b[36m0.9995\u001b[0m  0.0217\n",
            "     32        \u001b[36m0.9995\u001b[0m  0.0239\n",
            "     33        \u001b[36m0.9995\u001b[0m  0.0246\n",
            "     34        \u001b[36m0.9995\u001b[0m  0.0198\n",
            "     35        \u001b[36m0.9995\u001b[0m  0.0185\n",
            "     36        \u001b[36m0.9995\u001b[0m  0.0222\n",
            "     37        \u001b[36m0.9995\u001b[0m  0.0214\n",
            "     38        \u001b[36m0.9995\u001b[0m  0.0182\n",
            "     39        \u001b[36m0.9995\u001b[0m  0.0208\n",
            "     40        0.9995  0.0179\n",
            "     41        \u001b[36m0.9995\u001b[0m  0.0170\n",
            "     42        \u001b[36m0.9995\u001b[0m  0.0201\n",
            "     43        \u001b[36m0.9995\u001b[0m  0.0214\n",
            "     44        0.9995  0.0172\n",
            "     45        \u001b[36m0.9995\u001b[0m  0.0163\n",
            "     46        \u001b[36m0.9995\u001b[0m  0.0190\n",
            "     47        \u001b[36m0.9995\u001b[0m  0.0185\n",
            "     48        0.9995  0.0173\n",
            "     49        \u001b[36m0.9995\u001b[0m  0.0182\n",
            "     50        0.9995  0.0174\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9993\u001b[0m  0.0157\n",
            "      2        \u001b[36m0.9993\u001b[0m  0.0271\n",
            "      3        \u001b[36m0.9993\u001b[0m  0.0266\n",
            "      4        \u001b[36m0.9993\u001b[0m  0.0282\n",
            "      5        \u001b[36m0.9993\u001b[0m  0.0265\n",
            "      6        \u001b[36m0.9993\u001b[0m  0.0206\n",
            "      7        \u001b[36m0.9993\u001b[0m  0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.9993\u001b[0m  0.0231\n",
            "      9        \u001b[36m0.9993\u001b[0m  0.0272\n",
            "     10        \u001b[36m0.9993\u001b[0m  0.0225\n",
            "     11        \u001b[36m0.9993\u001b[0m  0.0251\n",
            "     12        \u001b[36m0.9993\u001b[0m  0.0274\n",
            "     13        \u001b[36m0.9993\u001b[0m  0.0225\n",
            "     14        \u001b[36m0.9993\u001b[0m  0.0183\n",
            "     15        \u001b[36m0.9993\u001b[0m  0.0174\n",
            "     16        \u001b[36m0.9993\u001b[0m  0.0183\n",
            "     17        \u001b[36m0.9993\u001b[0m  0.0166\n",
            "     18        \u001b[36m0.9993\u001b[0m  0.0174\n",
            "     19        \u001b[36m0.9993\u001b[0m  0.0172\n",
            "     20        \u001b[36m0.9993\u001b[0m  0.0174\n",
            "     21        \u001b[36m0.9993\u001b[0m  0.0177\n",
            "     22        \u001b[36m0.9993\u001b[0m  0.0179\n",
            "     23        \u001b[36m0.9993\u001b[0m  0.0241\n",
            "     24        \u001b[36m0.9993\u001b[0m  0.0234\n",
            "     25        \u001b[36m0.9993\u001b[0m  0.0179\n",
            "     26        \u001b[36m0.9993\u001b[0m  0.0235\n",
            "     27        \u001b[36m0.9993\u001b[0m  0.0234\n",
            "     28        \u001b[36m0.9993\u001b[0m  0.0212\n",
            "     29        \u001b[36m0.9993\u001b[0m  0.0235\n",
            "     30        \u001b[36m0.9993\u001b[0m  0.0237\n",
            "     31        \u001b[36m0.9993\u001b[0m  0.0202\n",
            "     32        \u001b[36m0.9993\u001b[0m  0.0187\n",
            "     33        \u001b[36m0.9993\u001b[0m  0.0175\n",
            "     34        \u001b[36m0.9993\u001b[0m  0.0174\n",
            "     35        \u001b[36m0.9993\u001b[0m  0.0163\n",
            "     36        \u001b[36m0.9993\u001b[0m  0.0169\n",
            "     37        \u001b[36m0.9993\u001b[0m  0.0169\n",
            "     38        \u001b[36m0.9993\u001b[0m  0.0188\n",
            "     39        \u001b[36m0.9993\u001b[0m  0.0184\n",
            "     40        \u001b[36m0.9993\u001b[0m  0.0172\n",
            "     41        \u001b[36m0.9993\u001b[0m  0.0169\n",
            "     42        \u001b[36m0.9993\u001b[0m  0.0166\n",
            "     43        \u001b[36m0.9993\u001b[0m  0.0155\n",
            "     44        \u001b[36m0.9993\u001b[0m  0.0219\n",
            "     45        \u001b[36m0.9993\u001b[0m  0.0182\n",
            "     46        \u001b[36m0.9993\u001b[0m  0.0209\n",
            "     47        \u001b[36m0.9993\u001b[0m  0.0171\n",
            "     48        \u001b[36m0.9993\u001b[0m  0.0179\n",
            "     49        \u001b[36m0.9993\u001b[0m  0.0205\n",
            "     50        \u001b[36m0.9993\u001b[0m  0.0235\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5880\u001b[0m  0.0316\n",
            "      2        \u001b[36m0.5637\u001b[0m  0.0316\n",
            "      3        \u001b[36m0.5466\u001b[0m  0.0327\n",
            "      4        \u001b[36m0.5318\u001b[0m  0.0319\n",
            "      5        \u001b[36m0.5198\u001b[0m  0.0270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.5105\u001b[0m  0.0281\n",
            "      7        \u001b[36m0.5027\u001b[0m  0.0241\n",
            "      8        \u001b[36m0.4960\u001b[0m  0.0214\n",
            "      9        \u001b[36m0.4899\u001b[0m  0.0279\n",
            "     10        \u001b[36m0.4845\u001b[0m  0.0255\n",
            "     11        \u001b[36m0.4800\u001b[0m  0.0234\n",
            "     12        \u001b[36m0.4748\u001b[0m  0.0238\n",
            "     13        \u001b[36m0.4702\u001b[0m  0.0313\n",
            "     14        \u001b[36m0.4655\u001b[0m  0.0269\n",
            "     15        \u001b[36m0.4608\u001b[0m  0.0258\n",
            "     16        \u001b[36m0.4561\u001b[0m  0.0274\n",
            "     17        \u001b[36m0.4516\u001b[0m  0.0283\n",
            "     18        \u001b[36m0.4472\u001b[0m  0.0293\n",
            "     19        \u001b[36m0.4429\u001b[0m  0.0278\n",
            "     20        \u001b[36m0.4390\u001b[0m  0.0200\n",
            "     21        \u001b[36m0.4353\u001b[0m  0.0209\n",
            "     22        \u001b[36m0.4319\u001b[0m  0.0207\n",
            "     23        \u001b[36m0.4288\u001b[0m  0.0236\n",
            "     24        \u001b[36m0.4249\u001b[0m  0.0239\n",
            "     25        \u001b[36m0.4221\u001b[0m  0.0221\n",
            "     26        \u001b[36m0.4199\u001b[0m  0.0232\n",
            "     27        \u001b[36m0.4179\u001b[0m  0.0204\n",
            "     28        \u001b[36m0.4160\u001b[0m  0.0199\n",
            "     29        \u001b[36m0.4143\u001b[0m  0.0213\n",
            "     30        \u001b[36m0.4127\u001b[0m  0.0317\n",
            "     31        \u001b[36m0.4112\u001b[0m  0.0308\n",
            "     32        \u001b[36m0.4098\u001b[0m  0.0327\n",
            "     33        \u001b[36m0.4085\u001b[0m  0.0248\n",
            "     34        \u001b[36m0.4059\u001b[0m  0.0295\n",
            "     35        \u001b[36m0.4041\u001b[0m  0.0284\n",
            "     36        \u001b[36m0.4031\u001b[0m  0.0322\n",
            "     37        \u001b[36m0.4021\u001b[0m  0.0251\n",
            "     38        \u001b[36m0.4012\u001b[0m  0.0264\n",
            "     39        \u001b[36m0.4004\u001b[0m  0.0285\n",
            "     40        \u001b[36m0.3996\u001b[0m  0.0277\n",
            "     41        \u001b[36m0.3988\u001b[0m  0.0280\n",
            "     42        \u001b[36m0.3983\u001b[0m  0.0287\n",
            "     43        \u001b[36m0.3976\u001b[0m  0.0225\n",
            "     44        \u001b[36m0.3970\u001b[0m  0.0304\n",
            "     45        \u001b[36m0.3964\u001b[0m  0.0321\n",
            "     46        \u001b[36m0.3959\u001b[0m  0.0283\n",
            "     47        \u001b[36m0.3952\u001b[0m  0.0248\n",
            "     48        \u001b[36m0.3948\u001b[0m  0.0338\n",
            "     49        \u001b[36m0.3942\u001b[0m  0.0313\n",
            "     50        \u001b[36m0.3937\u001b[0m  0.0287\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7314\u001b[0m  0.0213\n",
            "      2        \u001b[36m0.7110\u001b[0m  0.0238\n",
            "      3        \u001b[36m0.6849\u001b[0m  0.0216\n",
            "      4        \u001b[36m0.6580\u001b[0m  0.0217\n",
            "      5        \u001b[36m0.6352\u001b[0m  0.0225\n",
            "      6        \u001b[36m0.6162\u001b[0m  0.0222\n",
            "      7        \u001b[36m0.5968\u001b[0m  0.0226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5803\u001b[0m  0.0220\n",
            "      9        \u001b[36m0.5608\u001b[0m  0.0239\n",
            "     10        \u001b[36m0.5477\u001b[0m  0.0234\n",
            "     11        \u001b[36m0.5353\u001b[0m  0.0246\n",
            "     12        \u001b[36m0.5211\u001b[0m  0.0247\n",
            "     13        \u001b[36m0.5107\u001b[0m  0.0357\n",
            "     14        \u001b[36m0.5004\u001b[0m  0.0374\n",
            "     15        \u001b[36m0.4901\u001b[0m  0.0408\n",
            "     16        \u001b[36m0.4815\u001b[0m  0.0333\n",
            "     17        \u001b[36m0.4736\u001b[0m  0.0369\n",
            "     18        \u001b[36m0.4660\u001b[0m  0.0343\n",
            "     19        \u001b[36m0.4588\u001b[0m  0.0295\n",
            "     20        \u001b[36m0.4516\u001b[0m  0.0257\n",
            "     21        \u001b[36m0.4446\u001b[0m  0.0250\n",
            "     22        \u001b[36m0.4388\u001b[0m  0.0244\n",
            "     23        \u001b[36m0.4337\u001b[0m  0.0261\n",
            "     24        \u001b[36m0.4291\u001b[0m  0.0295\n",
            "     25        \u001b[36m0.4249\u001b[0m  0.0281\n",
            "     26        \u001b[36m0.4212\u001b[0m  0.0261\n",
            "     27        \u001b[36m0.4178\u001b[0m  0.0239\n",
            "     28        \u001b[36m0.4148\u001b[0m  0.0218\n",
            "     29        \u001b[36m0.4122\u001b[0m  0.0208\n",
            "     30        \u001b[36m0.4093\u001b[0m  0.0222\n",
            "     31        \u001b[36m0.4072\u001b[0m  0.0212\n",
            "     32        \u001b[36m0.4052\u001b[0m  0.0218\n",
            "     33        \u001b[36m0.4019\u001b[0m  0.0213\n",
            "     34        \u001b[36m0.4002\u001b[0m  0.0212\n",
            "     35        \u001b[36m0.3987\u001b[0m  0.0212\n",
            "     36        \u001b[36m0.3973\u001b[0m  0.0267\n",
            "     37        \u001b[36m0.3960\u001b[0m  0.0215\n",
            "     38        \u001b[36m0.3947\u001b[0m  0.0234\n",
            "     39        \u001b[36m0.3934\u001b[0m  0.0217\n",
            "     40        \u001b[36m0.3923\u001b[0m  0.0213\n",
            "     41        \u001b[36m0.3914\u001b[0m  0.0208\n",
            "     42        \u001b[36m0.3905\u001b[0m  0.0230\n",
            "     43        \u001b[36m0.3897\u001b[0m  0.0232\n",
            "     44        \u001b[36m0.3889\u001b[0m  0.0208\n",
            "     45        \u001b[36m0.3883\u001b[0m  0.0213\n",
            "     46        \u001b[36m0.3876\u001b[0m  0.0226\n",
            "     47        \u001b[36m0.3870\u001b[0m  0.0258\n",
            "     48        \u001b[36m0.3865\u001b[0m  0.0277\n",
            "     49        \u001b[36m0.3859\u001b[0m  0.0270\n",
            "     50        \u001b[36m0.3855\u001b[0m  0.0309\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5872\u001b[0m  0.0230\n",
            "      2        \u001b[36m0.5853\u001b[0m  0.0224\n",
            "      3        \u001b[36m0.5817\u001b[0m  0.0224\n",
            "      4        \u001b[36m0.5799\u001b[0m  0.0245\n",
            "      5        \u001b[36m0.5780\u001b[0m  0.0184\n",
            "      6        \u001b[36m0.5762\u001b[0m  0.0236\n",
            "      7        \u001b[36m0.5743\u001b[0m  0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5724\u001b[0m  0.0212\n",
            "      9        \u001b[36m0.5706\u001b[0m  0.0229\n",
            "     10        \u001b[36m0.5687\u001b[0m  0.0269\n",
            "     11        \u001b[36m0.5669\u001b[0m  0.0198\n",
            "     12        \u001b[36m0.5650\u001b[0m  0.0228\n",
            "     13        \u001b[36m0.5632\u001b[0m  0.0182\n",
            "     14        \u001b[36m0.5613\u001b[0m  0.0211\n",
            "     15        \u001b[36m0.5595\u001b[0m  0.0168\n",
            "     16        \u001b[36m0.5576\u001b[0m  0.0192\n",
            "     17        \u001b[36m0.5558\u001b[0m  0.0194\n",
            "     18        \u001b[36m0.5539\u001b[0m  0.0183\n",
            "     19        \u001b[36m0.5521\u001b[0m  0.0169\n",
            "     20        \u001b[36m0.5503\u001b[0m  0.0173\n",
            "     21        \u001b[36m0.5485\u001b[0m  0.0172\n",
            "     22        \u001b[36m0.5467\u001b[0m  0.0170\n",
            "     23        \u001b[36m0.5450\u001b[0m  0.0164\n",
            "     24        \u001b[36m0.5432\u001b[0m  0.0164\n",
            "     25        \u001b[36m0.5415\u001b[0m  0.0168\n",
            "     26        \u001b[36m0.5397\u001b[0m  0.0167\n",
            "     27        \u001b[36m0.5380\u001b[0m  0.0168\n",
            "     28        \u001b[36m0.5363\u001b[0m  0.0168\n",
            "     29        \u001b[36m0.5347\u001b[0m  0.0241\n",
            "     30        \u001b[36m0.5330\u001b[0m  0.0172\n",
            "     31        \u001b[36m0.5313\u001b[0m  0.0170\n",
            "     32        \u001b[36m0.5297\u001b[0m  0.0164\n",
            "     33        \u001b[36m0.5281\u001b[0m  0.0169\n",
            "     34        \u001b[36m0.5265\u001b[0m  0.0166\n",
            "     35        \u001b[36m0.5250\u001b[0m  0.0169\n",
            "     36        \u001b[36m0.5234\u001b[0m  0.0164\n",
            "     37        \u001b[36m0.5219\u001b[0m  0.0169\n",
            "     38        \u001b[36m0.5204\u001b[0m  0.0180\n",
            "     39        \u001b[36m0.5189\u001b[0m  0.0174\n",
            "     40        \u001b[36m0.5174\u001b[0m  0.0206\n",
            "     41        \u001b[36m0.5160\u001b[0m  0.0221\n",
            "     42        \u001b[36m0.5146\u001b[0m  0.0184\n",
            "     43        \u001b[36m0.5132\u001b[0m  0.0177\n",
            "     44        \u001b[36m0.5118\u001b[0m  0.0170\n",
            "     45        \u001b[36m0.5104\u001b[0m  0.0195\n",
            "     46        \u001b[36m0.5091\u001b[0m  0.0259\n",
            "     47        \u001b[36m0.5078\u001b[0m  0.0256\n",
            "     48        \u001b[36m0.5065\u001b[0m  0.0256\n",
            "     49        \u001b[36m0.5052\u001b[0m  0.0234\n",
            "     50        \u001b[36m0.5040\u001b[0m  0.0185\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5404\u001b[0m  0.0172\n",
            "      2        \u001b[36m0.5399\u001b[0m  0.0168\n",
            "      3        \u001b[36m0.5393\u001b[0m  0.0158\n",
            "      4        \u001b[36m0.5387\u001b[0m  0.0177\n",
            "      5        \u001b[36m0.5381\u001b[0m  0.0164\n",
            "      6        \u001b[36m0.5375\u001b[0m  0.0190\n",
            "      7        \u001b[36m0.5370\u001b[0m  0.0214\n",
            "      8        \u001b[36m0.5364\u001b[0m  0.0184\n",
            "      9        \u001b[36m0.5358\u001b[0m  0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.5353\u001b[0m  0.0186\n",
            "     11        \u001b[36m0.5347\u001b[0m  0.0165\n",
            "     12        \u001b[36m0.5341\u001b[0m  0.0174\n",
            "     13        \u001b[36m0.5336\u001b[0m  0.0163\n",
            "     14        \u001b[36m0.5330\u001b[0m  0.0165\n",
            "     15        \u001b[36m0.5325\u001b[0m  0.0161\n",
            "     16        \u001b[36m0.5319\u001b[0m  0.0173\n",
            "     17        \u001b[36m0.5314\u001b[0m  0.0166\n",
            "     18        \u001b[36m0.5309\u001b[0m  0.0163\n",
            "     19        \u001b[36m0.5303\u001b[0m  0.0167\n",
            "     20        \u001b[36m0.5298\u001b[0m  0.0167\n",
            "     21        \u001b[36m0.5293\u001b[0m  0.0168\n",
            "     22        \u001b[36m0.5288\u001b[0m  0.0175\n",
            "     23        \u001b[36m0.5283\u001b[0m  0.0161\n",
            "     24        \u001b[36m0.5277\u001b[0m  0.0173\n",
            "     25        \u001b[36m0.5272\u001b[0m  0.0161\n",
            "     26        \u001b[36m0.5267\u001b[0m  0.0168\n",
            "     27        \u001b[36m0.5262\u001b[0m  0.0193\n",
            "     28        \u001b[36m0.5257\u001b[0m  0.0237\n",
            "     29        \u001b[36m0.5252\u001b[0m  0.0239\n",
            "     30        \u001b[36m0.5247\u001b[0m  0.0170\n",
            "     31        \u001b[36m0.5243\u001b[0m  0.0172\n",
            "     32        \u001b[36m0.5238\u001b[0m  0.0176\n",
            "     33        \u001b[36m0.5233\u001b[0m  0.0175\n",
            "     34        \u001b[36m0.5228\u001b[0m  0.0181\n",
            "     35        \u001b[36m0.5223\u001b[0m  0.0203\n",
            "     36        \u001b[36m0.5219\u001b[0m  0.0188\n",
            "     37        \u001b[36m0.5214\u001b[0m  0.0215\n",
            "     38        \u001b[36m0.5209\u001b[0m  0.0174\n",
            "     39        \u001b[36m0.5205\u001b[0m  0.0176\n",
            "     40        \u001b[36m0.5200\u001b[0m  0.0171\n",
            "     41        \u001b[36m0.5196\u001b[0m  0.0194\n",
            "     42        \u001b[36m0.5191\u001b[0m  0.0179\n",
            "     43        \u001b[36m0.5187\u001b[0m  0.0238\n",
            "     44        \u001b[36m0.5182\u001b[0m  0.0184\n",
            "     45        \u001b[36m0.5178\u001b[0m  0.0181\n",
            "     46        \u001b[36m0.5174\u001b[0m  0.0201\n",
            "     47        \u001b[36m0.5169\u001b[0m  0.0168\n",
            "     48        \u001b[36m0.5165\u001b[0m  0.0173\n",
            "     49        \u001b[36m0.5161\u001b[0m  0.0192\n",
            "     50        \u001b[36m0.5157\u001b[0m  0.0190\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7254\u001b[0m  0.0253\n",
            "      2        \u001b[36m0.6634\u001b[0m  0.0214\n",
            "      3        \u001b[36m0.6121\u001b[0m  0.0232\n",
            "      4        \u001b[36m0.5756\u001b[0m  0.0210\n",
            "      5        \u001b[36m0.5522\u001b[0m  0.0214\n",
            "      6        \u001b[36m0.5356\u001b[0m  0.0239\n",
            "      7        \u001b[36m0.5192\u001b[0m  0.0205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5061\u001b[0m  0.0210\n",
            "      9        \u001b[36m0.4928\u001b[0m  0.0214\n",
            "     10        \u001b[36m0.4842\u001b[0m  0.0208\n",
            "     11        \u001b[36m0.4783\u001b[0m  0.0205\n",
            "     12        \u001b[36m0.4738\u001b[0m  0.0214\n",
            "     13        \u001b[36m0.4705\u001b[0m  0.0217\n",
            "     14        \u001b[36m0.4677\u001b[0m  0.0210\n",
            "     15        \u001b[36m0.4618\u001b[0m  0.0210\n",
            "     16        0.4635  0.0235\n",
            "     17        \u001b[36m0.4606\u001b[0m  0.0214\n",
            "     18        \u001b[36m0.4573\u001b[0m  0.0220\n",
            "     19        \u001b[36m0.4533\u001b[0m  0.0207\n",
            "     20        \u001b[36m0.4483\u001b[0m  0.0215\n",
            "     21        \u001b[36m0.4420\u001b[0m  0.0211\n",
            "     22        \u001b[36m0.4353\u001b[0m  0.0239\n",
            "     23        \u001b[36m0.4289\u001b[0m  0.0219\n",
            "     24        \u001b[36m0.4235\u001b[0m  0.0251\n",
            "     25        \u001b[36m0.4190\u001b[0m  0.0209\n",
            "     26        \u001b[36m0.4154\u001b[0m  0.0274\n",
            "     27        \u001b[36m0.4123\u001b[0m  0.0228\n",
            "     28        \u001b[36m0.4096\u001b[0m  0.0211\n",
            "     29        \u001b[36m0.4073\u001b[0m  0.0250\n",
            "     30        \u001b[36m0.4053\u001b[0m  0.0219\n",
            "     31        \u001b[36m0.4034\u001b[0m  0.0278\n",
            "     32        \u001b[36m0.4016\u001b[0m  0.0298\n",
            "     33        \u001b[36m0.3999\u001b[0m  0.0302\n",
            "     34        \u001b[36m0.3982\u001b[0m  0.0310\n",
            "     35        \u001b[36m0.3965\u001b[0m  0.0244\n",
            "     36        \u001b[36m0.3949\u001b[0m  0.0224\n",
            "     37        \u001b[36m0.3933\u001b[0m  0.0229\n",
            "     38        \u001b[36m0.3918\u001b[0m  0.0222\n",
            "     39        \u001b[36m0.3904\u001b[0m  0.0233\n",
            "     40        \u001b[36m0.3891\u001b[0m  0.0239\n",
            "     41        \u001b[36m0.3879\u001b[0m  0.0240\n",
            "     42        \u001b[36m0.3868\u001b[0m  0.0220\n",
            "     43        \u001b[36m0.3858\u001b[0m  0.0219\n",
            "     44        \u001b[36m0.3849\u001b[0m  0.0214\n",
            "     45        \u001b[36m0.3840\u001b[0m  0.0224\n",
            "     46        \u001b[36m0.3832\u001b[0m  0.0210\n",
            "     47        \u001b[36m0.3825\u001b[0m  0.0211\n",
            "     48        \u001b[36m0.3819\u001b[0m  0.0209\n",
            "     49        \u001b[36m0.3812\u001b[0m  0.0262\n",
            "     50        \u001b[36m0.3807\u001b[0m  0.0208\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4733\u001b[0m  0.0208\n",
            "      2        \u001b[36m0.4462\u001b[0m  0.0206\n",
            "      3        \u001b[36m0.4313\u001b[0m  0.0208\n",
            "      4        \u001b[36m0.4207\u001b[0m  0.0207\n",
            "      5        \u001b[36m0.4122\u001b[0m  0.0206\n",
            "      6        \u001b[36m0.4068\u001b[0m  0.0212\n",
            "      7        \u001b[36m0.4029\u001b[0m  0.0204\n",
            "      8        \u001b[36m0.4000\u001b[0m  0.0213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.3985\u001b[0m  0.0278\n",
            "     10        \u001b[36m0.3954\u001b[0m  0.0202\n",
            "     11        \u001b[36m0.3935\u001b[0m  0.0208\n",
            "     12        \u001b[36m0.3922\u001b[0m  0.0254\n",
            "     13        \u001b[36m0.3911\u001b[0m  0.0239\n",
            "     14        \u001b[36m0.3902\u001b[0m  0.0307\n",
            "     15        \u001b[36m0.3891\u001b[0m  0.0276\n",
            "     16        \u001b[36m0.3878\u001b[0m  0.0222\n",
            "     17        \u001b[36m0.3869\u001b[0m  0.0285\n",
            "     18        \u001b[36m0.3858\u001b[0m  0.0314\n",
            "     19        \u001b[36m0.3851\u001b[0m  0.0243\n",
            "     20        \u001b[36m0.3832\u001b[0m  0.0272\n",
            "     21        \u001b[36m0.3824\u001b[0m  0.0276\n",
            "     22        \u001b[36m0.3813\u001b[0m  0.0326\n",
            "     23        \u001b[36m0.3807\u001b[0m  0.0295\n",
            "     24        \u001b[36m0.3803\u001b[0m  0.0259\n",
            "     25        \u001b[36m0.3800\u001b[0m  0.0280\n",
            "     26        \u001b[36m0.3796\u001b[0m  0.0278\n",
            "     27        \u001b[36m0.3794\u001b[0m  0.0236\n",
            "     28        \u001b[36m0.3791\u001b[0m  0.0241\n",
            "     29        \u001b[36m0.3789\u001b[0m  0.0216\n",
            "     30        \u001b[36m0.3787\u001b[0m  0.0235\n",
            "     31        \u001b[36m0.3785\u001b[0m  0.0207\n",
            "     32        \u001b[36m0.3783\u001b[0m  0.0205\n",
            "     33        \u001b[36m0.3781\u001b[0m  0.0213\n",
            "     34        \u001b[36m0.3779\u001b[0m  0.0203\n",
            "     35        \u001b[36m0.3777\u001b[0m  0.0208\n",
            "     36        \u001b[36m0.3776\u001b[0m  0.0210\n",
            "     37        \u001b[36m0.3775\u001b[0m  0.0205\n",
            "     38        \u001b[36m0.3773\u001b[0m  0.0209\n",
            "     39        \u001b[36m0.3772\u001b[0m  0.0217\n",
            "     40        \u001b[36m0.3771\u001b[0m  0.0207\n",
            "     41        \u001b[36m0.3770\u001b[0m  0.0213\n",
            "     42        \u001b[36m0.3769\u001b[0m  0.0213\n",
            "     43        \u001b[36m0.3768\u001b[0m  0.0214\n",
            "     44        \u001b[36m0.3767\u001b[0m  0.0211\n",
            "     45        \u001b[36m0.3766\u001b[0m  0.0260\n",
            "     46        \u001b[36m0.3766\u001b[0m  0.0213\n",
            "     47        \u001b[36m0.3765\u001b[0m  0.0215\n",
            "     48        \u001b[36m0.3764\u001b[0m  0.0208\n",
            "     49        \u001b[36m0.3764\u001b[0m  0.0210\n",
            "     50        \u001b[36m0.3763\u001b[0m  0.0209\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6136\u001b[0m  0.0221\n",
            "      2        \u001b[36m0.5965\u001b[0m  0.0248\n",
            "      3        \u001b[36m0.5956\u001b[0m  0.0296\n",
            "      4        \u001b[36m0.5948\u001b[0m  0.0210\n",
            "      5        \u001b[36m0.5936\u001b[0m  0.0209\n",
            "      6        \u001b[36m0.5866\u001b[0m  0.0186\n",
            "      7        \u001b[36m0.5859\u001b[0m  0.0211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5851\u001b[0m  0.0216\n",
            "      9        \u001b[36m0.5843\u001b[0m  0.0195\n",
            "     10        \u001b[36m0.5835\u001b[0m  0.0188\n",
            "     11        \u001b[36m0.5828\u001b[0m  0.0195\n",
            "     12        \u001b[36m0.5820\u001b[0m  0.0192\n",
            "     13        \u001b[36m0.5812\u001b[0m  0.0182\n",
            "     14        \u001b[36m0.5805\u001b[0m  0.0164\n",
            "     15        \u001b[36m0.5797\u001b[0m  0.0170\n",
            "     16        \u001b[36m0.5789\u001b[0m  0.0179\n",
            "     17        \u001b[36m0.5782\u001b[0m  0.0168\n",
            "     18        \u001b[36m0.5774\u001b[0m  0.0179\n",
            "     19        \u001b[36m0.5766\u001b[0m  0.0195\n",
            "     20        \u001b[36m0.5759\u001b[0m  0.0207\n",
            "     21        \u001b[36m0.5751\u001b[0m  0.0179\n",
            "     22        \u001b[36m0.5744\u001b[0m  0.0164\n",
            "     23        \u001b[36m0.5736\u001b[0m  0.0177\n",
            "     24        \u001b[36m0.5729\u001b[0m  0.0184\n",
            "     25        \u001b[36m0.5721\u001b[0m  0.0167\n",
            "     26        \u001b[36m0.5714\u001b[0m  0.0165\n",
            "     27        \u001b[36m0.5706\u001b[0m  0.0169\n",
            "     28        \u001b[36m0.5699\u001b[0m  0.0173\n",
            "     29        \u001b[36m0.5691\u001b[0m  0.0167\n",
            "     30        \u001b[36m0.5684\u001b[0m  0.0170\n",
            "     31        \u001b[36m0.5677\u001b[0m  0.0165\n",
            "     32        \u001b[36m0.5669\u001b[0m  0.0176\n",
            "     33        \u001b[36m0.5662\u001b[0m  0.0168\n",
            "     34        \u001b[36m0.5654\u001b[0m  0.0163\n",
            "     35        \u001b[36m0.5647\u001b[0m  0.0183\n",
            "     36        \u001b[36m0.5640\u001b[0m  0.0241\n",
            "     37        \u001b[36m0.5632\u001b[0m  0.0214\n",
            "     38        \u001b[36m0.5625\u001b[0m  0.0168\n",
            "     39        \u001b[36m0.5618\u001b[0m  0.0164\n",
            "     40        \u001b[36m0.5610\u001b[0m  0.0166\n",
            "     41        \u001b[36m0.5603\u001b[0m  0.0168\n",
            "     42        \u001b[36m0.5596\u001b[0m  0.0174\n",
            "     43        \u001b[36m0.5589\u001b[0m  0.0169\n",
            "     44        \u001b[36m0.5581\u001b[0m  0.0164\n",
            "     45        \u001b[36m0.5574\u001b[0m  0.0168\n",
            "     46        \u001b[36m0.5567\u001b[0m  0.0168\n",
            "     47        \u001b[36m0.5560\u001b[0m  0.0200\n",
            "     48        \u001b[36m0.5552\u001b[0m  0.0302\n",
            "     49        \u001b[36m0.5545\u001b[0m  0.0239\n",
            "     50        \u001b[36m0.5538\u001b[0m  0.0253\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8178\u001b[0m  0.0229\n",
            "      2        \u001b[36m0.8047\u001b[0m  0.0217\n",
            "      3        \u001b[36m0.8001\u001b[0m  0.0205\n",
            "      4        \u001b[36m0.7953\u001b[0m  0.0227\n",
            "      5        \u001b[36m0.7900\u001b[0m  0.0164\n",
            "      6        \u001b[36m0.7814\u001b[0m  0.0224\n",
            "      7        \u001b[36m0.7756\u001b[0m  0.0166\n",
            "      8        \u001b[36m0.7695\u001b[0m  0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.7600\u001b[0m  0.0277\n",
            "     10        \u001b[36m0.7537\u001b[0m  0.0182\n",
            "     11        \u001b[36m0.7472\u001b[0m  0.0187\n",
            "     12        \u001b[36m0.7406\u001b[0m  0.0201\n",
            "     13        \u001b[36m0.7341\u001b[0m  0.0187\n",
            "     14        \u001b[36m0.7276\u001b[0m  0.0229\n",
            "     15        \u001b[36m0.7213\u001b[0m  0.0187\n",
            "     16        \u001b[36m0.7149\u001b[0m  0.0210\n",
            "     17        \u001b[36m0.7082\u001b[0m  0.0197\n",
            "     18        \u001b[36m0.7026\u001b[0m  0.0189\n",
            "     19        \u001b[36m0.6974\u001b[0m  0.0177\n",
            "     20        \u001b[36m0.6924\u001b[0m  0.0178\n",
            "     21        \u001b[36m0.6877\u001b[0m  0.0165\n",
            "     22        \u001b[36m0.6834\u001b[0m  0.0161\n",
            "     23        \u001b[36m0.6793\u001b[0m  0.0182\n",
            "     24        \u001b[36m0.6754\u001b[0m  0.0165\n",
            "     25        \u001b[36m0.6718\u001b[0m  0.0182\n",
            "     26        \u001b[36m0.6685\u001b[0m  0.0167\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0175\n",
            "     28        \u001b[36m0.6623\u001b[0m  0.0171\n",
            "     29        \u001b[36m0.6595\u001b[0m  0.0168\n",
            "     30        \u001b[36m0.6569\u001b[0m  0.0178\n",
            "     31        \u001b[36m0.6544\u001b[0m  0.0163\n",
            "     32        \u001b[36m0.6520\u001b[0m  0.0176\n",
            "     33        \u001b[36m0.6498\u001b[0m  0.0170\n",
            "     34        \u001b[36m0.6477\u001b[0m  0.0163\n",
            "     35        \u001b[36m0.6456\u001b[0m  0.0170\n",
            "     36        \u001b[36m0.6437\u001b[0m  0.0175\n",
            "     37        \u001b[36m0.6418\u001b[0m  0.0169\n",
            "     38        \u001b[36m0.6400\u001b[0m  0.0198\n",
            "     39        \u001b[36m0.6383\u001b[0m  0.0171\n",
            "     40        \u001b[36m0.6367\u001b[0m  0.0175\n",
            "     41        \u001b[36m0.6351\u001b[0m  0.0172\n",
            "     42        \u001b[36m0.6336\u001b[0m  0.0202\n",
            "     43        \u001b[36m0.6321\u001b[0m  0.0224\n",
            "     44        \u001b[36m0.6307\u001b[0m  0.0199\n",
            "     45        \u001b[36m0.6293\u001b[0m  0.0203\n",
            "     46        \u001b[36m0.6280\u001b[0m  0.0212\n",
            "     47        \u001b[36m0.6267\u001b[0m  0.0216\n",
            "     48        \u001b[36m0.6255\u001b[0m  0.0210\n",
            "     49        \u001b[36m0.6242\u001b[0m  0.0268\n",
            "     50        \u001b[36m0.6231\u001b[0m  0.0254\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0198\n",
            "      2        1.0000  0.0241\n",
            "      3        1.0000  0.0250\n",
            "      4        1.0000  0.0247\n",
            "      5        1.0000  0.0252\n",
            "      6        1.0000  0.0227\n",
            "      7        1.0000  0.0201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        1.0000  0.0206\n",
            "      9        1.0000  0.0229\n",
            "     10        1.0000  0.0206\n",
            "     11        1.0000  0.0195\n",
            "     12        1.0000  0.0252\n",
            "     13        1.0000  0.0214\n",
            "     14        1.0000  0.0215\n",
            "     15        1.0000  0.0166\n",
            "     16        1.0000  0.0238\n",
            "     17        1.0000  0.0194\n",
            "     18        1.0000  0.0204\n",
            "     19        1.0000  0.0158\n",
            "     20        1.0000  0.0234\n",
            "     21        1.0000  0.0203\n",
            "     22        1.0000  0.0210\n",
            "     23        1.0000  0.0164\n",
            "     24        1.0000  0.0210\n",
            "     25        1.0000  0.0219\n",
            "     26        1.0000  0.0208\n",
            "     27        1.0000  0.0203\n",
            "     28        1.0000  0.0218\n",
            "     29        1.0000  0.0199\n",
            "     30        1.0000  0.0199\n",
            "     31        1.0000  0.0228\n",
            "     32        1.0000  0.0203\n",
            "     33        1.0000  0.0206\n",
            "     34        1.0000  0.0252\n",
            "     35        1.0000  0.0273\n",
            "     36        1.0000  0.0241\n",
            "     37        1.0000  0.0241\n",
            "     38        1.0000  0.0242\n",
            "     39        1.0000  0.0245\n",
            "     40        1.0000  0.0253\n",
            "     41        1.0000  0.0257\n",
            "     42        1.0000  0.0267\n",
            "     43        1.0000  0.0295\n",
            "     44        1.0000  0.0213\n",
            "     45        1.0000  0.0210\n",
            "     46        1.0000  0.0209\n",
            "     47        1.0000  0.0219\n",
            "     48        1.0000  0.0210\n",
            "     49        1.0000  0.0206\n",
            "     50        1.0000  0.0215\n",
            "     51        1.0000  0.0216\n",
            "     52        1.0000  0.0203\n",
            "     53        1.0000  0.0210\n",
            "     54        1.0000  0.0217\n",
            "     55        1.0000  0.0269\n",
            "     56        1.0000  0.0224\n",
            "     57        1.0000  0.0227\n",
            "     58        1.0000  0.0245\n",
            "     59        1.0000  0.0210\n",
            "     60        1.0000  0.0222\n",
            "     61        1.0000  0.0211\n",
            "     62        1.0000  0.0216\n",
            "     63        1.0000  0.0213\n",
            "     64        1.0000  0.0218\n",
            "     65        1.0000  0.0217\n",
            "     66        1.0000  0.0226\n",
            "     67        1.0000  0.0239\n",
            "     68        1.0000  0.0220\n",
            "     69        1.0000  0.0213\n",
            "     70        1.0000  0.0214\n",
            "     71        1.0000  0.0216\n",
            "     72        1.0000  0.0213\n",
            "     73        1.0000  0.0201\n",
            "     74        1.0000  0.0224\n",
            "     75        1.0000  0.0261\n",
            "     76        1.0000  0.0268\n",
            "     77        1.0000  0.0244\n",
            "     78        1.0000  0.0261\n",
            "     79        1.0000  0.0347\n",
            "     80        1.0000  0.0304\n",
            "     81        1.0000  0.0282\n",
            "     82        1.0000  0.0323\n",
            "     83        1.0000  0.0325\n",
            "     84        1.0000  0.0309\n",
            "     85        1.0000  0.0240\n",
            "     86        1.0000  0.0207\n",
            "     87        1.0000  0.0227\n",
            "     88        1.0000  0.0235\n",
            "     89        1.0000  0.0223\n",
            "     90        1.0000  0.0250\n",
            "     91        1.0000  0.0235\n",
            "     92        1.0000  0.0256\n",
            "     93        1.0000  0.0248\n",
            "     94        1.0000  0.0258\n",
            "     95        1.0000  0.0222\n",
            "     96        1.0000  0.0261\n",
            "     97        1.0000  0.0288\n",
            "     98        1.0000  0.0252\n",
            "     99        1.0000  0.0236\n",
            "    100        1.0000  0.0248\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0227\n",
            "      2        1.0000  0.0226\n",
            "      3        1.0000  0.0269\n",
            "      4        1.0000  0.0270\n",
            "      5        1.0000  0.0253\n",
            "      6        1.0000  0.0214\n",
            "      7        1.0000  0.0261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        1.0000  0.0326\n",
            "      9        1.0000  0.0286\n",
            "     10        1.0000  0.0347\n",
            "     11        1.0000  0.0308\n",
            "     12        1.0000  0.0328\n",
            "     13        1.0000  0.0316\n",
            "     14        1.0000  0.0372\n",
            "     15        1.0000  0.0326\n",
            "     16        1.0000  0.0265\n",
            "     17        1.0000  0.0215\n",
            "     18        1.0000  0.0239\n",
            "     19        1.0000  0.0285\n",
            "     20        1.0000  0.0303\n",
            "     21        1.0000  0.0238\n",
            "     22        1.0000  0.0280\n",
            "     23        1.0000  0.0277\n",
            "     24        1.0000  0.0212\n",
            "     25        1.0000  0.0210\n",
            "     26        1.0000  0.0211\n",
            "     27        1.0000  0.0203\n",
            "     28        1.0000  0.0205\n",
            "     29        1.0000  0.0221\n",
            "     30        1.0000  0.0202\n",
            "     31        1.0000  0.0214\n",
            "     32        1.0000  0.0215\n",
            "     33        1.0000  0.0219\n",
            "     34        1.0000  0.0216\n",
            "     35        1.0000  0.0210\n",
            "     36        1.0000  0.0217\n",
            "     37        1.0000  0.0217\n",
            "     38        1.0000  0.0205\n",
            "     39        1.0000  0.0212\n",
            "     40        1.0000  0.0209\n",
            "     41        1.0000  0.0213\n",
            "     42        1.0000  0.0213\n",
            "     43        1.0000  0.0208\n",
            "     44        1.0000  0.0213\n",
            "     45        1.0000  0.0235\n",
            "     46        1.0000  0.0271\n",
            "     47        1.0000  0.0218\n",
            "     48        1.0000  0.0301\n",
            "     49        1.0000  0.0293\n",
            "     50        1.0000  0.0296\n",
            "     51        1.0000  0.0263\n",
            "     52        1.0000  0.0331\n",
            "     53        1.0000  0.0309\n",
            "     54        1.0000  0.0204\n",
            "     55        1.0000  0.0203\n",
            "     56        1.0000  0.0217\n",
            "     57        1.0000  0.0206\n",
            "     58        1.0000  0.0217\n",
            "     59        1.0000  0.0246\n",
            "     60        1.0000  0.0245\n",
            "     61        1.0000  0.0277\n",
            "     62        1.0000  0.0212\n",
            "     63        1.0000  0.0199\n",
            "     64        1.0000  0.0213\n",
            "     65        1.0000  0.0213\n",
            "     66        1.0000  0.0204\n",
            "     67        1.0000  0.0197\n",
            "     68        1.0000  0.0206\n",
            "     69        1.0000  0.0196\n",
            "     70        1.0000  0.0211\n",
            "     71        1.0000  0.0200\n",
            "     72        1.0000  0.0199\n",
            "     73        1.0000  0.0203\n",
            "     74        1.0000  0.0201\n",
            "     75        1.0000  0.0197\n",
            "     76        1.0000  0.0209\n",
            "     77        1.0000  0.0198\n",
            "     78        1.0000  0.0198\n",
            "     79        1.0000  0.0201\n",
            "     80        1.0000  0.0202\n",
            "     81        1.0000  0.0196\n",
            "     82        1.0000  0.0210\n",
            "     83        1.0000  0.0222\n",
            "     84        1.0000  0.0220\n",
            "     85        1.0000  0.0230\n",
            "     86        1.0000  0.0240\n",
            "     87        1.0000  0.0397\n",
            "     88        1.0000  0.0336\n",
            "     89        1.0000  0.0322\n",
            "     90        1.0000  0.0343\n",
            "     91        1.0000  0.0288\n",
            "     92        1.0000  0.0331\n",
            "     93        1.0000  0.0246\n",
            "     94        1.0000  0.0261\n",
            "     95        1.0000  0.0221\n",
            "     96        1.0000  0.0259\n",
            "     97        1.0000  0.0264\n",
            "     98        1.0000  0.0262\n",
            "     99        1.0000  0.0225\n",
            "    100        1.0000  0.0250\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0208\n",
            "      2        1.0000  0.0226\n",
            "      3        1.0000  0.0170\n",
            "      4        1.0000  0.0218\n",
            "      5        1.0000  0.0195\n",
            "      6        1.0000  0.0198\n",
            "      7        1.0000  0.0222\n",
            "      8        1.0000  0.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        1.0000  0.0213\n",
            "     10        1.0000  0.0248\n",
            "     11        1.0000  0.0232\n",
            "     12        1.0000  0.0202\n",
            "     13        1.0000  0.0281\n",
            "     14        1.0000  0.0187\n",
            "     15        1.0000  0.0221\n",
            "     16        1.0000  0.0209\n",
            "     17        1.0000  0.0233\n",
            "     18        1.0000  0.0235\n",
            "     19        1.0000  0.0281\n",
            "     20        1.0000  0.0236\n",
            "     21        1.0000  0.0207\n",
            "     22        1.0000  0.0325\n",
            "     23        1.0000  0.0275\n",
            "     24        1.0000  0.0309\n",
            "     25        1.0000  0.0246\n",
            "     26        1.0000  0.0241\n",
            "     27        1.0000  0.0247\n",
            "     28        1.0000  0.0239\n",
            "     29        1.0000  0.0205\n",
            "     30        1.0000  0.0300\n",
            "     31        1.0000  0.0323\n",
            "     32        1.0000  0.0261\n",
            "     33        1.0000  0.0297\n",
            "     34        1.0000  0.0265\n",
            "     35        1.0000  0.0192\n",
            "     36        1.0000  0.0231\n",
            "     37        1.0000  0.0195\n",
            "     38        1.0000  0.0181\n",
            "     39        1.0000  0.0179\n",
            "     40        1.0000  0.0233\n",
            "     41        1.0000  0.0281\n",
            "     42        1.0000  0.0202\n",
            "     43        1.0000  0.0253\n",
            "     44        1.0000  0.0272\n",
            "     45        1.0000  0.0229\n",
            "     46        1.0000  0.0283\n",
            "     47        1.0000  0.0260\n",
            "     48        1.0000  0.0188\n",
            "     49        1.0000  0.0252\n",
            "     50        1.0000  0.0267\n",
            "     51        1.0000  0.0191\n",
            "     52        1.0000  0.0217\n",
            "     53        1.0000  0.0230\n",
            "     54        1.0000  0.0257\n",
            "     55        1.0000  0.0198\n",
            "     56        1.0000  0.0189\n",
            "     57        1.0000  0.0234\n",
            "     58        1.0000  0.0250\n",
            "     59        1.0000  0.0263\n",
            "     60        1.0000  0.0191\n",
            "     61        1.0000  0.0305\n",
            "     62        1.0000  0.0209\n",
            "     63        1.0000  0.0264\n",
            "     64        1.0000  0.0286\n",
            "     65        1.0000  0.0189\n",
            "     66        1.0000  0.0241\n",
            "     67        1.0000  0.0198\n",
            "     68        1.0000  0.0214\n",
            "     69        1.0000  0.0229\n",
            "     70        1.0000  0.0239\n",
            "     71        1.0000  0.0215\n",
            "     72        1.0000  0.0235\n",
            "     73        1.0000  0.0203\n",
            "     74        1.0000  0.0221\n",
            "     75        1.0000  0.0209\n",
            "     76        1.0000  0.0222\n",
            "     77        1.0000  0.0222\n",
            "     78        1.0000  0.0188\n",
            "     79        1.0000  0.0190\n",
            "     80        1.0000  0.0222\n",
            "     81        1.0000  0.0188\n",
            "     82        1.0000  0.0178\n",
            "     83        1.0000  0.0166\n",
            "     84        1.0000  0.0164\n",
            "     85        1.0000  0.0165\n",
            "     86        1.0000  0.0169\n",
            "     87        1.0000  0.0166\n",
            "     88        1.0000  0.0166\n",
            "     89        1.0000  0.0162\n",
            "     90        1.0000  0.0161\n",
            "     91        1.0000  0.0172\n",
            "     92        1.0000  0.0172\n",
            "     93        1.0000  0.0171\n",
            "     94        1.0000  0.0177\n",
            "     95        1.0000  0.0174\n",
            "     96        1.0000  0.0167\n",
            "     97        1.0000  0.0173\n",
            "     98        1.0000  0.0226\n",
            "     99        1.0000  0.0219\n",
            "    100        1.0000  0.0196\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0169\n",
            "      2        1.0000  0.0232\n",
            "      3        1.0000  0.0193\n",
            "      4        1.0000  0.0200\n",
            "      5        1.0000  0.0190\n",
            "      6        1.0000  0.0194\n",
            "      7        1.0000  0.0204\n",
            "      8        1.0000  0.0197\n",
            "      9        1.0000  0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        1.0000  0.0230\n",
            "     11        1.0000  0.0185\n",
            "     12        1.0000  0.0193\n",
            "     13        1.0000  0.0222\n",
            "     14        1.0000  0.0263\n",
            "     15        1.0000  0.0197\n",
            "     16        1.0000  0.0163\n",
            "     17        1.0000  0.0175\n",
            "     18        1.0000  0.0166\n",
            "     19        1.0000  0.0163\n",
            "     20        1.0000  0.0168\n",
            "     21        1.0000  0.0178\n",
            "     22        1.0000  0.0173\n",
            "     23        1.0000  0.0167\n",
            "     24        1.0000  0.0164\n",
            "     25        1.0000  0.0179\n",
            "     26        1.0000  0.0170\n",
            "     27        1.0000  0.0172\n",
            "     28        1.0000  0.0193\n",
            "     29        1.0000  0.0182\n",
            "     30        1.0000  0.0257\n",
            "     31        1.0000  0.0175\n",
            "     32        1.0000  0.0166\n",
            "     33        1.0000  0.0167\n",
            "     34        1.0000  0.0180\n",
            "     35        1.0000  0.0166\n",
            "     36        1.0000  0.0173\n",
            "     37        1.0000  0.0167\n",
            "     38        1.0000  0.0170\n",
            "     39        1.0000  0.0170\n",
            "     40        1.0000  0.0161\n",
            "     41        1.0000  0.0172\n",
            "     42        1.0000  0.0167\n",
            "     43        1.0000  0.0177\n",
            "     44        1.0000  0.0178\n",
            "     45        1.0000  0.0238\n",
            "     46        1.0000  0.0194\n",
            "     47        1.0000  0.0191\n",
            "     48        1.0000  0.0219\n",
            "     49        1.0000  0.0194\n",
            "     50        1.0000  0.0182\n",
            "     51        1.0000  0.0229\n",
            "     52        1.0000  0.0189\n",
            "     53        1.0000  0.0182\n",
            "     54        1.0000  0.0215\n",
            "     55        1.0000  0.0202\n",
            "     56        1.0000  0.0212\n",
            "     57        1.0000  0.0191\n",
            "     58        1.0000  0.0196\n",
            "     59        1.0000  0.0217\n",
            "     60        1.0000  0.0174\n",
            "     61        1.0000  0.0177\n",
            "     62        1.0000  0.0184\n",
            "     63        1.0000  0.0169\n",
            "     64        1.0000  0.0174\n",
            "     65        1.0000  0.0170\n",
            "     66        1.0000  0.0175\n",
            "     67        1.0000  0.0172\n",
            "     68        1.0000  0.0189\n",
            "     69        1.0000  0.0171\n",
            "     70        1.0000  0.0168\n",
            "     71        1.0000  0.0178\n",
            "     72        1.0000  0.0162\n",
            "     73        1.0000  0.0172\n",
            "     74        1.0000  0.0180\n",
            "     75        1.0000  0.0167\n",
            "     76        1.0000  0.0165\n",
            "     77        1.0000  0.0174\n",
            "     78        1.0000  0.0169\n",
            "     79        1.0000  0.0203\n",
            "     80        1.0000  0.0178\n",
            "     81        1.0000  0.0194\n",
            "     82        1.0000  0.0187\n",
            "     83        1.0000  0.0169\n",
            "     84        1.0000  0.0176\n",
            "     85        1.0000  0.0177\n",
            "     86        1.0000  0.0169\n",
            "     87        1.0000  0.0166\n",
            "     88        1.0000  0.0159\n",
            "     89        1.0000  0.0163\n",
            "     90        1.0000  0.0171\n",
            "     91        1.0000  0.0173\n",
            "     92        1.0000  0.0165\n",
            "     93        1.0000  0.0180\n",
            "     94        1.0000  0.0175\n",
            "     95        1.0000  0.0174\n",
            "     96        1.0000  0.0178\n",
            "     97        1.0000  0.0206\n",
            "     98        1.0000  0.0174\n",
            "     99        1.0000  0.0248\n",
            "    100        1.0000  0.0235\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0258\n",
            "      2        1.0000  0.0291\n",
            "      3        1.0000  0.0209\n",
            "      4        1.0000  0.0208\n",
            "      5        1.0000  0.0223\n",
            "      6        1.0000  0.0233\n",
            "      7        1.0000  0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        1.0000  0.0264\n",
            "      9        1.0000  0.0233\n",
            "     10        1.0000  0.0253\n",
            "     11        1.0000  0.0231\n",
            "     12        1.0000  0.0218\n",
            "     13        1.0000  0.0207\n",
            "     14        1.0000  0.0256\n",
            "     15        1.0000  0.0214\n",
            "     16        1.0000  0.0210\n",
            "     17        1.0000  0.0218\n",
            "     18        1.0000  0.0213\n",
            "     19        1.0000  0.0222\n",
            "     20        1.0000  0.0203\n",
            "     21        1.0000  0.0221\n",
            "     22        1.0000  0.0218\n",
            "     23        1.0000  0.0216\n",
            "     24        1.0000  0.0238\n",
            "     25        1.0000  0.0281\n",
            "     26        1.0000  0.0246\n",
            "     27        1.0000  0.0226\n",
            "     28        1.0000  0.0211\n",
            "     29        1.0000  0.0215\n",
            "     30        1.0000  0.0215\n",
            "     31        1.0000  0.0215\n",
            "     32        1.0000  0.0230\n",
            "     33        1.0000  0.0248\n",
            "     34        1.0000  0.0265\n",
            "     35        1.0000  0.0278\n",
            "     36        1.0000  0.0230\n",
            "     37        1.0000  0.0221\n",
            "     38        1.0000  0.0259\n",
            "     39        1.0000  0.0236\n",
            "     40        1.0000  0.0254\n",
            "     41        1.0000  0.0226\n",
            "     42        1.0000  0.0216\n",
            "     43        1.0000  0.0221\n",
            "     44        1.0000  0.0208\n",
            "     45        1.0000  0.0221\n",
            "     46        1.0000  0.0233\n",
            "     47        1.0000  0.0232\n",
            "     48        1.0000  0.0241\n",
            "     49        1.0000  0.0247\n",
            "     50        1.0000  0.0219\n",
            "     51        1.0000  0.0213\n",
            "     52        1.0000  0.0223\n",
            "     53        1.0000  0.0222\n",
            "     54        1.0000  0.0210\n",
            "     55        1.0000  0.0218\n",
            "     56        1.0000  0.0219\n",
            "     57        1.0000  0.0221\n",
            "     58        1.0000  0.0232\n",
            "     59        1.0000  0.0223\n",
            "     60        1.0000  0.0220\n",
            "     61        1.0000  0.0222\n",
            "     62        1.0000  0.0216\n",
            "     63        1.0000  0.0209\n",
            "     64        1.0000  0.0212\n",
            "     65        1.0000  0.0260\n",
            "     66        1.0000  0.0255\n",
            "     67        1.0000  0.0193\n",
            "     68        1.0000  0.0211\n",
            "     69        1.0000  0.0210\n",
            "     70        1.0000  0.0223\n",
            "     71        1.0000  0.0240\n",
            "     72        1.0000  0.0237\n",
            "     73        1.0000  0.0233\n",
            "     74        1.0000  0.0249\n",
            "     75        1.0000  0.0222\n",
            "     76        1.0000  0.0226\n",
            "     77        1.0000  0.0299\n",
            "     78        1.0000  0.0272\n",
            "     79        1.0000  0.0239\n",
            "     80        1.0000  0.0316\n",
            "     81        1.0000  0.0365\n",
            "     82        1.0000  0.0235\n",
            "     83        1.0000  0.0299\n",
            "     84        1.0000  0.0244\n",
            "     85        1.0000  0.0229\n",
            "     86        1.0000  0.0235\n",
            "     87        1.0000  0.0239\n",
            "     88        1.0000  0.0228\n",
            "     89        1.0000  0.0207\n",
            "     90        1.0000  0.0226\n",
            "     91        1.0000  0.0224\n",
            "     92        1.0000  0.0224\n",
            "     93        1.0000  0.0229\n",
            "     94        1.0000  0.0221\n",
            "     95        1.0000  0.0202\n",
            "     96        1.0000  0.0225\n",
            "     97        1.0000  0.0208\n",
            "     98        1.0000  0.0169\n",
            "     99        1.0000  0.0240\n",
            "    100        1.0000  0.0208\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0200\n",
            "      2        1.0000  0.0210\n",
            "      3        1.0000  0.0211\n",
            "      4        1.0000  0.0257\n",
            "      5        1.0000  0.0233\n",
            "      6        1.0000  0.0220\n",
            "      7        1.0000  0.0219\n",
            "      8        1.0000  0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        1.0000  0.0260\n",
            "     10        1.0000  0.0223\n",
            "     11        1.0000  0.0232\n",
            "     12        1.0000  0.0278\n",
            "     13        1.0000  0.0244\n",
            "     14        1.0000  0.0246\n",
            "     15        1.0000  0.0231\n",
            "     16        1.0000  0.0244\n",
            "     17        1.0000  0.0233\n",
            "     18        1.0000  0.0242\n",
            "     19        1.0000  0.0205\n",
            "     20        1.0000  0.0218\n",
            "     21        1.0000  0.0219\n",
            "     22        1.0000  0.0215\n",
            "     23        1.0000  0.0212\n",
            "     24        1.0000  0.0244\n",
            "     25        1.0000  0.0232\n",
            "     26        1.0000  0.0251\n",
            "     27        1.0000  0.0200\n",
            "     28        1.0000  0.0218\n",
            "     29        1.0000  0.0199\n",
            "     30        1.0000  0.0208\n",
            "     31        1.0000  0.0222\n",
            "     32        1.0000  0.0215\n",
            "     33        1.0000  0.0229\n",
            "     34        1.0000  0.0214\n",
            "     35        1.0000  0.0206\n",
            "     36        1.0000  0.0219\n",
            "     37        1.0000  0.0233\n",
            "     38        1.0000  0.0206\n",
            "     39        1.0000  0.0219\n",
            "     40        1.0000  0.0221\n",
            "     41        1.0000  0.0237\n",
            "     42        1.0000  0.0215\n",
            "     43        1.0000  0.0206\n",
            "     44        1.0000  0.0210\n",
            "     45        1.0000  0.0226\n",
            "     46        1.0000  0.0261\n",
            "     47        1.0000  0.0222\n",
            "     48        1.0000  0.0241\n",
            "     49        1.0000  0.0237\n",
            "     50        1.0000  0.0239\n",
            "     51        1.0000  0.0227\n",
            "     52        1.0000  0.0263\n",
            "     53        1.0000  0.0243\n",
            "     54        1.0000  0.0235\n",
            "     55        1.0000  0.0245\n",
            "     56        1.0000  0.0257\n",
            "     57        1.0000  0.0268\n",
            "     58        1.0000  0.0253\n",
            "     59        1.0000  0.0251\n",
            "     60        1.0000  0.0224\n",
            "     61        1.0000  0.0207\n",
            "     62        1.0000  0.0214\n",
            "     63        1.0000  0.0216\n",
            "     64        1.0000  0.0212\n",
            "     65        1.0000  0.0221\n",
            "     66        1.0000  0.0233\n",
            "     67        1.0000  0.0229\n",
            "     68        1.0000  0.0207\n",
            "     69        1.0000  0.0217\n",
            "     70        1.0000  0.0205\n",
            "     71        1.0000  0.0226\n",
            "     72        1.0000  0.0212\n",
            "     73        1.0000  0.0209\n",
            "     74        1.0000  0.0207\n",
            "     75        1.0000  0.0211\n",
            "     76        1.0000  0.0213\n",
            "     77        1.0000  0.0212\n",
            "     78        1.0000  0.0242\n",
            "     79        1.0000  0.0211\n",
            "     80        1.0000  0.0221\n",
            "     81        1.0000  0.0219\n",
            "     82        1.0000  0.0220\n",
            "     83        1.0000  0.0236\n",
            "     84        1.0000  0.0228\n",
            "     85        1.0000  0.0218\n",
            "     86        1.0000  0.0226\n",
            "     87        1.0000  0.0209\n",
            "     88        1.0000  0.0248\n",
            "     89        1.0000  0.0238\n",
            "     90        1.0000  0.0326\n",
            "     91        1.0000  0.0256\n",
            "     92        1.0000  0.0259\n",
            "     93        1.0000  0.0239\n",
            "     94        1.0000  0.0223\n",
            "     95        1.0000  0.0290\n",
            "     96        1.0000  0.0256\n",
            "     97        1.0000  0.0261\n",
            "     98        1.0000  0.0242\n",
            "     99        1.0000  0.0229\n",
            "    100        1.0000  0.0219\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0126\n",
            "      2        1.0000  0.0193\n",
            "      3        1.0000  0.0172\n",
            "      4        1.0000  0.0220\n",
            "      5        1.0000  0.0160\n",
            "      6        1.0000  0.0160\n",
            "      7        1.0000  0.0180\n",
            "      8        1.0000  0.0168\n",
            "      9        1.0000  0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        1.0000  0.0176\n",
            "     11        1.0000  0.0176\n",
            "     12        1.0000  0.0182\n",
            "     13        1.0000  0.0175\n",
            "     14        1.0000  0.0167\n",
            "     15        1.0000  0.0164\n",
            "     16        1.0000  0.0179\n",
            "     17        1.0000  0.0161\n",
            "     18        1.0000  0.0167\n",
            "     19        1.0000  0.0161\n",
            "     20        1.0000  0.0181\n",
            "     21        1.0000  0.0182\n",
            "     22        1.0000  0.0202\n",
            "     23        1.0000  0.0163\n",
            "     24        1.0000  0.0187\n",
            "     25        1.0000  0.0171\n",
            "     26        1.0000  0.0172\n",
            "     27        1.0000  0.0179\n",
            "     28        1.0000  0.0177\n",
            "     29        1.0000  0.0167\n",
            "     30        1.0000  0.0174\n",
            "     31        1.0000  0.0164\n",
            "     32        1.0000  0.0175\n",
            "     33        1.0000  0.0169\n",
            "     34        1.0000  0.0235\n",
            "     35        1.0000  0.0179\n",
            "     36        1.0000  0.0235\n",
            "     37        1.0000  0.0210\n",
            "     38        1.0000  0.0222\n",
            "     39        1.0000  0.0229\n",
            "     40        1.0000  0.0186\n",
            "     41        1.0000  0.0267\n",
            "     42        1.0000  0.0250\n",
            "     43        1.0000  0.0211\n",
            "     44        1.0000  0.0212\n",
            "     45        1.0000  0.0213\n",
            "     46        1.0000  0.0224\n",
            "     47        1.0000  0.0238\n",
            "     48        1.0000  0.0198\n",
            "     49        1.0000  0.0230\n",
            "     50        1.0000  0.0196\n",
            "     51        1.0000  0.0201\n",
            "     52        1.0000  0.0190\n",
            "     53        1.0000  0.0179\n",
            "     54        1.0000  0.0166\n",
            "     55        1.0000  0.0160\n",
            "     56        1.0000  0.0186\n",
            "     57        1.0000  0.0163\n",
            "     58        1.0000  0.0168\n",
            "     59        1.0000  0.0174\n",
            "     60        1.0000  0.0173\n",
            "     61        1.0000  0.0170\n",
            "     62        1.0000  0.0172\n",
            "     63        1.0000  0.0171\n",
            "     64        1.0000  0.0171\n",
            "     65        1.0000  0.0187\n",
            "     66        1.0000  0.0183\n",
            "     67        1.0000  0.0177\n",
            "     68        1.0000  0.0181\n",
            "     69        1.0000  0.0184\n",
            "     70        1.0000  0.0183\n",
            "     71        1.0000  0.0192\n",
            "     72        1.0000  0.0185\n",
            "     73        1.0000  0.0180\n",
            "     74        1.0000  0.0187\n",
            "     75        1.0000  0.0171\n",
            "     76        1.0000  0.0166\n",
            "     77        1.0000  0.0166\n",
            "     78        1.0000  0.0161\n",
            "     79        1.0000  0.0164\n",
            "     80        1.0000  0.0283\n",
            "     81        1.0000  0.0269\n",
            "     82        1.0000  0.0279\n",
            "     83        1.0000  0.0224\n",
            "     84        1.0000  0.0217\n",
            "     85        1.0000  0.0238\n",
            "     86        1.0000  0.0219\n",
            "     87        1.0000  0.0183\n",
            "     88        1.0000  0.0188\n",
            "     89        1.0000  0.0193\n",
            "     90        1.0000  0.0192\n",
            "     91        1.0000  0.0165\n",
            "     92        1.0000  0.0179\n",
            "     93        1.0000  0.0183\n",
            "     94        1.0000  0.0165\n",
            "     95        1.0000  0.0164\n",
            "     96        1.0000  0.0162\n",
            "     97        1.0000  0.0170\n",
            "     98        1.0000  0.0185\n",
            "     99        1.0000  0.0178\n",
            "    100        1.0000  0.0170\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.0000\u001b[0m  0.0172\n",
            "      2        1.0000  0.0189\n",
            "      3        1.0000  0.0181\n",
            "      4        1.0000  0.0172\n",
            "      5        1.0000  0.0166\n",
            "      6        1.0000  0.0226\n",
            "      7        1.0000  0.0218\n",
            "      8        1.0000  0.0180\n",
            "      9        1.0000  0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        1.0000  0.0235\n",
            "     11        1.0000  0.0183\n",
            "     12        1.0000  0.0224\n",
            "     13        1.0000  0.0185\n",
            "     14        1.0000  0.0170\n",
            "     15        1.0000  0.0167\n",
            "     16        1.0000  0.0174\n",
            "     17        1.0000  0.0179\n",
            "     18        1.0000  0.0225\n",
            "     19        1.0000  0.0184\n",
            "     20        1.0000  0.0234\n",
            "     21        1.0000  0.0159\n",
            "     22        1.0000  0.0176\n",
            "     23        1.0000  0.0163\n",
            "     24        1.0000  0.0206\n",
            "     25        1.0000  0.0194\n",
            "     26        1.0000  0.0220\n",
            "     27        1.0000  0.0234\n",
            "     28        1.0000  0.0245\n",
            "     29        1.0000  0.0228\n",
            "     30        1.0000  0.0269\n",
            "     31        1.0000  0.0292\n",
            "     32        1.0000  0.0271\n",
            "     33        1.0000  0.0261\n",
            "     34        1.0000  0.0190\n",
            "     35        1.0000  0.0253\n",
            "     36        1.0000  0.0210\n",
            "     37        1.0000  0.0248\n",
            "     38        1.0000  0.0171\n",
            "     39        1.0000  0.0246\n",
            "     40        1.0000  0.0239\n",
            "     41        1.0000  0.0225\n",
            "     42        1.0000  0.0216\n",
            "     43        1.0000  0.0235\n",
            "     44        1.0000  0.0217\n",
            "     45        1.0000  0.0257\n",
            "     46        1.0000  0.0169\n",
            "     47        1.0000  0.0207\n",
            "     48        1.0000  0.0218\n",
            "     49        1.0000  0.0202\n",
            "     50        1.0000  0.0261\n",
            "     51        1.0000  0.0159\n",
            "     52        1.0000  0.0167\n",
            "     53        1.0000  0.0246\n",
            "     54        1.0000  0.0171\n",
            "     55        1.0000  0.0217\n",
            "     56        1.0000  0.0170\n",
            "     57        1.0000  0.0170\n",
            "     58        1.0000  0.0184\n",
            "     59        1.0000  0.0187\n",
            "     60        1.0000  0.0157\n",
            "     61        1.0000  0.0171\n",
            "     62        1.0000  0.0164\n",
            "     63        1.0000  0.0176\n",
            "     64        1.0000  0.0179\n",
            "     65        1.0000  0.0173\n",
            "     66        1.0000  0.0192\n",
            "     67        1.0000  0.0213\n",
            "     68        1.0000  0.0261\n",
            "     69        1.0000  0.0267\n",
            "     70        1.0000  0.0265\n",
            "     71        1.0000  0.0213\n",
            "     72        1.0000  0.0233\n",
            "     73        1.0000  0.0188\n",
            "     74        1.0000  0.0241\n",
            "     75        1.0000  0.0234\n",
            "     76        1.0000  0.0211\n",
            "     77        1.0000  0.0223\n",
            "     78        1.0000  0.0176\n",
            "     79        1.0000  0.0156\n",
            "     80        1.0000  0.0172\n",
            "     81        1.0000  0.0176\n",
            "     82        1.0000  0.0168\n",
            "     83        1.0000  0.0170\n",
            "     84        1.0000  0.0174\n",
            "     85        1.0000  0.0165\n",
            "     86        1.0000  0.0169\n",
            "     87        1.0000  0.0173\n",
            "     88        1.0000  0.0180\n",
            "     89        1.0000  0.0186\n",
            "     90        1.0000  0.0162\n",
            "     91        1.0000  0.0167\n",
            "     92        1.0000  0.0211\n",
            "     93        1.0000  0.0181\n",
            "     94        1.0000  0.0164\n",
            "     95        1.0000  0.0190\n",
            "     96        1.0000  0.0173\n",
            "     97        1.0000  0.0172\n",
            "     98        1.0000  0.0201\n",
            "     99        1.0000  0.0195\n",
            "    100        1.0000  0.0187\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9754\u001b[0m  0.0208\n",
            "      2        0.9754  0.0224\n",
            "      3        0.9754  0.0218\n",
            "      4        0.9754  0.0208\n",
            "      5        \u001b[36m0.9754\u001b[0m  0.0208\n",
            "      6        \u001b[36m0.9613\u001b[0m  0.0217\n",
            "      7        \u001b[36m0.9542\u001b[0m  0.0213\n",
            "      8        \u001b[36m0.9437\u001b[0m  0.0211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9331\u001b[0m  0.0250\n",
            "     10        \u001b[36m0.9261\u001b[0m  0.0298\n",
            "     11        0.9261  0.0344\n",
            "     12        \u001b[36m0.9226\u001b[0m  0.0356\n",
            "     13        \u001b[36m0.8776\u001b[0m  0.0373\n",
            "     14        \u001b[36m0.8521\u001b[0m  0.0354\n",
            "     15        \u001b[36m0.8407\u001b[0m  0.0304\n",
            "     16        \u001b[36m0.8310\u001b[0m  0.0298\n",
            "     17        \u001b[36m0.8161\u001b[0m  0.0328\n",
            "     18        \u001b[36m0.7904\u001b[0m  0.0296\n",
            "     19        \u001b[36m0.7851\u001b[0m  0.0283\n",
            "     20        \u001b[36m0.7851\u001b[0m  0.0312\n",
            "     21        \u001b[36m0.7851\u001b[0m  0.0249\n",
            "     22        \u001b[36m0.7850\u001b[0m  0.0260\n",
            "     23        \u001b[36m0.7850\u001b[0m  0.0314\n",
            "     24        \u001b[36m0.7850\u001b[0m  0.0293\n",
            "     25        \u001b[36m0.7850\u001b[0m  0.0274\n",
            "     26        \u001b[36m0.7850\u001b[0m  0.0276\n",
            "     27        \u001b[36m0.7850\u001b[0m  0.0250\n",
            "     28        \u001b[36m0.7850\u001b[0m  0.0284\n",
            "     29        \u001b[36m0.7849\u001b[0m  0.0289\n",
            "     30        \u001b[36m0.7849\u001b[0m  0.0285\n",
            "     31        \u001b[36m0.7849\u001b[0m  0.0280\n",
            "     32        \u001b[36m0.7849\u001b[0m  0.0275\n",
            "     33        \u001b[36m0.7849\u001b[0m  0.0267\n",
            "     34        \u001b[36m0.7849\u001b[0m  0.0219\n",
            "     35        \u001b[36m0.7849\u001b[0m  0.0211\n",
            "     36        \u001b[36m0.7849\u001b[0m  0.0222\n",
            "     37        \u001b[36m0.7849\u001b[0m  0.0339\n",
            "     38        \u001b[36m0.7849\u001b[0m  0.0317\n",
            "     39        \u001b[36m0.7848\u001b[0m  0.0259\n",
            "     40        \u001b[36m0.7848\u001b[0m  0.0238\n",
            "     41        \u001b[36m0.7848\u001b[0m  0.0311\n",
            "     42        \u001b[36m0.7848\u001b[0m  0.0318\n",
            "     43        \u001b[36m0.7848\u001b[0m  0.0359\n",
            "     44        \u001b[36m0.7848\u001b[0m  0.0379\n",
            "     45        \u001b[36m0.7848\u001b[0m  0.0348\n",
            "     46        \u001b[36m0.7848\u001b[0m  0.0313\n",
            "     47        \u001b[36m0.7848\u001b[0m  0.0225\n",
            "     48        \u001b[36m0.7848\u001b[0m  0.0236\n",
            "     49        \u001b[36m0.7847\u001b[0m  0.0222\n",
            "     50        \u001b[36m0.7786\u001b[0m  0.0224\n",
            "     51        \u001b[36m0.7656\u001b[0m  0.0269\n",
            "     52        \u001b[36m0.7495\u001b[0m  0.0270\n",
            "     53        \u001b[36m0.7475\u001b[0m  0.0228\n",
            "     54        \u001b[36m0.7460\u001b[0m  0.0223\n",
            "     55        \u001b[36m0.7460\u001b[0m  0.0233\n",
            "     56        \u001b[36m0.7459\u001b[0m  0.0225\n",
            "     57        \u001b[36m0.7459\u001b[0m  0.0231\n",
            "     58        \u001b[36m0.7459\u001b[0m  0.0222\n",
            "     59        \u001b[36m0.7459\u001b[0m  0.0232\n",
            "     60        \u001b[36m0.7459\u001b[0m  0.0219\n",
            "     61        \u001b[36m0.7459\u001b[0m  0.0226\n",
            "     62        \u001b[36m0.7459\u001b[0m  0.0242\n",
            "     63        \u001b[36m0.7459\u001b[0m  0.0245\n",
            "     64        \u001b[36m0.7459\u001b[0m  0.0225\n",
            "     65        \u001b[36m0.7459\u001b[0m  0.0231\n",
            "     66        \u001b[36m0.7459\u001b[0m  0.0232\n",
            "     67        \u001b[36m0.7459\u001b[0m  0.0226\n",
            "     68        \u001b[36m0.7459\u001b[0m  0.0235\n",
            "     69        \u001b[36m0.7458\u001b[0m  0.0222\n",
            "     70        \u001b[36m0.7423\u001b[0m  0.0222\n",
            "     71        \u001b[36m0.7423\u001b[0m  0.0224\n",
            "     72        \u001b[36m0.7423\u001b[0m  0.0216\n",
            "     73        \u001b[36m0.7422\u001b[0m  0.0225\n",
            "     74        \u001b[36m0.7295\u001b[0m  0.0294\n",
            "     75        \u001b[36m0.7071\u001b[0m  0.0383\n",
            "     76        \u001b[36m0.7000\u001b[0m  0.0369\n",
            "     77        \u001b[36m0.7000\u001b[0m  0.0303\n",
            "     78        \u001b[36m0.7000\u001b[0m  0.0238\n",
            "     79        \u001b[36m0.7000\u001b[0m  0.0322\n",
            "     80        \u001b[36m0.7000\u001b[0m  0.0250\n",
            "     81        \u001b[36m0.7000\u001b[0m  0.0245\n",
            "     82        \u001b[36m0.7000\u001b[0m  0.0251\n",
            "     83        \u001b[36m0.6999\u001b[0m  0.0280\n",
            "     84        \u001b[36m0.6990\u001b[0m  0.0244\n",
            "     85        \u001b[36m0.6874\u001b[0m  0.0262\n",
            "     86        \u001b[36m0.6590\u001b[0m  0.0255\n",
            "     87        \u001b[36m0.6555\u001b[0m  0.0245\n",
            "     88        \u001b[36m0.6490\u001b[0m  0.0295\n",
            "     89        \u001b[36m0.6441\u001b[0m  0.0259\n",
            "     90        \u001b[36m0.6404\u001b[0m  0.0246\n",
            "     91        \u001b[36m0.6318\u001b[0m  0.0272\n",
            "     92        \u001b[36m0.6246\u001b[0m  0.0298\n",
            "     93        \u001b[36m0.6245\u001b[0m  0.0304\n",
            "     94        \u001b[36m0.6236\u001b[0m  0.0261\n",
            "     95        \u001b[36m0.6091\u001b[0m  0.0208\n",
            "     96        \u001b[36m0.6082\u001b[0m  0.0209\n",
            "     97        \u001b[36m0.6044\u001b[0m  0.0213\n",
            "     98        \u001b[36m0.5962\u001b[0m  0.0209\n",
            "     99        \u001b[36m0.5878\u001b[0m  0.0210\n",
            "    100        \u001b[36m0.5850\u001b[0m  0.0203\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8266\u001b[0m  0.0207\n",
            "      2        \u001b[36m0.8140\u001b[0m  0.0202\n",
            "      3        0.8140  0.0206\n",
            "      4        0.8140  0.0203\n",
            "      5        0.8140  0.0209\n",
            "      6        0.8140  0.0208\n",
            "      7        0.8140  0.0209\n",
            "      8        0.8140  0.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.8105\u001b[0m  0.0234\n",
            "     10        0.8105  0.0323\n",
            "     11        \u001b[36m0.8070\u001b[0m  0.0248\n",
            "     12        0.8070  0.0252\n",
            "     13        0.8070  0.0242\n",
            "     14        0.8070  0.0226\n",
            "     15        0.8070  0.0239\n",
            "     16        0.8070  0.0254\n",
            "     17        0.8070  0.0262\n",
            "     18        0.8070  0.0298\n",
            "     19        0.8070  0.0285\n",
            "     20        0.8070  0.0218\n",
            "     21        \u001b[36m0.8000\u001b[0m  0.0233\n",
            "     22        0.8000  0.0225\n",
            "     23        0.8000  0.0223\n",
            "     24        0.8000  0.0207\n",
            "     25        \u001b[36m0.7930\u001b[0m  0.0219\n",
            "     26        0.7930  0.0206\n",
            "     27        0.7930  0.0235\n",
            "     28        0.7930  0.0246\n",
            "     29        0.7930  0.0232\n",
            "     30        \u001b[36m0.7930\u001b[0m  0.0234\n",
            "     31        \u001b[36m0.7899\u001b[0m  0.0217\n",
            "     32        \u001b[36m0.7789\u001b[0m  0.0214\n",
            "     33        \u001b[36m0.7719\u001b[0m  0.0229\n",
            "     34        \u001b[36m0.7684\u001b[0m  0.0220\n",
            "     35        \u001b[36m0.7649\u001b[0m  0.0208\n",
            "     36        0.7649  0.0224\n",
            "     37        \u001b[36m0.7614\u001b[0m  0.0217\n",
            "     38        \u001b[36m0.7614\u001b[0m  0.0213\n",
            "     39        0.7614  0.0215\n",
            "     40        0.7614  0.0205\n",
            "     41        0.7614  0.0210\n",
            "     42        0.7614  0.0207\n",
            "     43        \u001b[36m0.7579\u001b[0m  0.0205\n",
            "     44        0.7579  0.0217\n",
            "     45        0.7579  0.0257\n",
            "     46        0.7579  0.0242\n",
            "     47        \u001b[36m0.7544\u001b[0m  0.0270\n",
            "     48        0.7544  0.0266\n",
            "     49        0.7544  0.0265\n",
            "     50        0.7544  0.0275\n",
            "     51        0.7544  0.0271\n",
            "     52        0.7544  0.0336\n",
            "     53        0.7544  0.0314\n",
            "     54        \u001b[36m0.7515\u001b[0m  0.0375\n",
            "     55        \u001b[36m0.7368\u001b[0m  0.0329\n",
            "     56        \u001b[36m0.7333\u001b[0m  0.0265\n",
            "     57        0.7333  0.0216\n",
            "     58        0.7333  0.0214\n",
            "     59        \u001b[36m0.7333\u001b[0m  0.0230\n",
            "     60        \u001b[36m0.7333\u001b[0m  0.0207\n",
            "     61        \u001b[36m0.7299\u001b[0m  0.0222\n",
            "     62        \u001b[36m0.7298\u001b[0m  0.0216\n",
            "     63        \u001b[36m0.7263\u001b[0m  0.0221\n",
            "     64        \u001b[36m0.7263\u001b[0m  0.0210\n",
            "     65        0.7263  0.0235\n",
            "     66        0.7263  0.0213\n",
            "     67        0.7263  0.0299\n",
            "     68        0.7263  0.0230\n",
            "     69        0.7263  0.0223\n",
            "     70        0.7263  0.0220\n",
            "     71        0.7263  0.0226\n",
            "     72        0.7263  0.0213\n",
            "     73        0.7263  0.0215\n",
            "     74        0.7263  0.0275\n",
            "     75        0.7263  0.0220\n",
            "     76        0.7263  0.0224\n",
            "     77        0.7263  0.0216\n",
            "     78        0.7263  0.0213\n",
            "     79        0.7263  0.0216\n",
            "     80        \u001b[36m0.7263\u001b[0m  0.0255\n",
            "     81        \u001b[36m0.7263\u001b[0m  0.0273\n",
            "     82        \u001b[36m0.7229\u001b[0m  0.0266\n",
            "     83        \u001b[36m0.7193\u001b[0m  0.0265\n",
            "     84        0.7193  0.0233\n",
            "     85        0.7193  0.0292\n",
            "     86        0.7193  0.0282\n",
            "     87        0.7193  0.0234\n",
            "     88        0.7193  0.0246\n",
            "     89        0.7193  0.0256\n",
            "     90        0.7193  0.0226\n",
            "     91        0.7193  0.0231\n",
            "     92        0.7193  0.0252\n",
            "     93        0.7193  0.0216\n",
            "     94        0.7193  0.0214\n",
            "     95        0.7193  0.0212\n",
            "     96        0.7193  0.0226\n",
            "     97        0.7193  0.0225\n",
            "     98        0.7193  0.0210\n",
            "     99        0.7193  0.0214\n",
            "    100        0.7193  0.0221\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6232\u001b[0m  0.0165\n",
            "      2        0.6232  0.0192\n",
            "      3        0.6232  0.0164\n",
            "      4        0.6232  0.0170\n",
            "      5        0.6232  0.0164\n",
            "      6        0.6232  0.0172\n",
            "      7        0.6232  0.0168\n",
            "      8        0.6232  0.0200\n",
            "      9        0.6232  0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.6232  0.0241\n",
            "     11        0.6232  0.0182\n",
            "     12        0.6232  0.0165\n",
            "     13        0.6232  0.0159\n",
            "     14        0.6232  0.0168\n",
            "     15        0.6232  0.0195\n",
            "     16        0.6232  0.0165\n",
            "     17        0.6232  0.0164\n",
            "     18        0.6232  0.0159\n",
            "     19        0.6232  0.0185\n",
            "     20        0.6232  0.0171\n",
            "     21        0.6232  0.0165\n",
            "     22        0.6232  0.0165\n",
            "     23        0.6232  0.0165\n",
            "     24        0.6232  0.0260\n",
            "     25        0.6232  0.0280\n",
            "     26        0.6232  0.0275\n",
            "     27        0.6232  0.0287\n",
            "     28        0.6232  0.0255\n",
            "     29        0.6232  0.0226\n",
            "     30        0.6232  0.0193\n",
            "     31        0.6232  0.0169\n",
            "     32        0.6232  0.0197\n",
            "     33        0.6232  0.0189\n",
            "     34        0.6232  0.0194\n",
            "     35        0.6232  0.0197\n",
            "     36        0.6232  0.0239\n",
            "     37        0.6232  0.0194\n",
            "     38        0.6232  0.0199\n",
            "     39        0.6232  0.0162\n",
            "     40        0.6232  0.0168\n",
            "     41        0.6232  0.0181\n",
            "     42        0.6232  0.0160\n",
            "     43        0.6232  0.0159\n",
            "     44        0.6232  0.0167\n",
            "     45        0.6232  0.0161\n",
            "     46        0.6232  0.0162\n",
            "     47        0.6232  0.0156\n",
            "     48        0.6232  0.0164\n",
            "     49        0.6232  0.0162\n",
            "     50        0.6232  0.0167\n",
            "     51        0.6232  0.0168\n",
            "     52        0.6232  0.0157\n",
            "     53        0.6232  0.0167\n",
            "     54        0.6232  0.0165\n",
            "     55        0.6232  0.0165\n",
            "     56        0.6232  0.0168\n",
            "     57        0.6232  0.0179\n",
            "     58        0.6232  0.0168\n",
            "     59        0.6232  0.0193\n",
            "     60        0.6232  0.0227\n",
            "     61        0.6232  0.0167\n",
            "     62        0.6232  0.0173\n",
            "     63        0.6232  0.0173\n",
            "     64        0.6232  0.0163\n",
            "     65        0.6232  0.0172\n",
            "     66        0.6232  0.0162\n",
            "     67        0.6232  0.0162\n",
            "     68        0.6232  0.0162\n",
            "     69        0.6232  0.0163\n",
            "     70        0.6232  0.0175\n",
            "     71        0.6232  0.0209\n",
            "     72        0.6232  0.0196\n",
            "     73        0.6232  0.0201\n",
            "     74        0.6232  0.0201\n",
            "     75        0.6232  0.0189\n",
            "     76        0.6232  0.0166\n",
            "     77        0.6232  0.0193\n",
            "     78        0.6232  0.0206\n",
            "     79        0.6232  0.0191\n",
            "     80        0.6232  0.0205\n",
            "     81        0.6232  0.0194\n",
            "     82        0.6232  0.0190\n",
            "     83        0.6232  0.0207\n",
            "     84        0.6232  0.0180\n",
            "     85        0.6232  0.0170\n",
            "     86        0.6232  0.0166\n",
            "     87        0.6232  0.0180\n",
            "     88        0.6232  0.0171\n",
            "     89        0.6232  0.0166\n",
            "     90        0.6232  0.0167\n",
            "     91        0.6232  0.0180\n",
            "     92        0.6232  0.0169\n",
            "     93        0.6232  0.0161\n",
            "     94        0.6232  0.0158\n",
            "     95        0.6232  0.0167\n",
            "     96        0.6232  0.0164\n",
            "     97        0.6232  0.0165\n",
            "     98        0.6232  0.0159\n",
            "     99        0.6232  0.0158\n",
            "    100        0.6232  0.0173\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4456\u001b[0m  0.0157\n",
            "      2        0.4456  0.0169\n",
            "      3        0.4456  0.0160\n",
            "      4        0.4456  0.0161\n",
            "      5        0.4456  0.0167\n",
            "      6        0.4456  0.0163\n",
            "      7        0.4456  0.0162\n",
            "      8        0.4456  0.0167\n",
            "      9        0.4456  0.0167\n",
            "     10        0.4456  0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        0.4456  0.0213\n",
            "     12        0.4456  0.0216\n",
            "     13        0.4456  0.0175\n",
            "     14        0.4456  0.0165\n",
            "     15        0.4456  0.0165\n",
            "     16        0.4456  0.0161\n",
            "     17        0.4456  0.0166\n",
            "     18        0.4456  0.0210\n",
            "     19        0.4456  0.0189\n",
            "     20        0.4456  0.0191\n",
            "     21        0.4456  0.0198\n",
            "     22        0.4456  0.0203\n",
            "     23        0.4456  0.0176\n",
            "     24        0.4456  0.0180\n",
            "     25        0.4456  0.0205\n",
            "     26        0.4456  0.0203\n",
            "     27        0.4456  0.0213\n",
            "     28        0.4456  0.0203\n",
            "     29        0.4456  0.0204\n",
            "     30        0.4456  0.0198\n",
            "     31        0.4456  0.0185\n",
            "     32        0.4456  0.0197\n",
            "     33        0.4456  0.0201\n",
            "     34        0.4456  0.0167\n",
            "     35        0.4456  0.0160\n",
            "     36        0.4456  0.0176\n",
            "     37        0.4456  0.0163\n",
            "     38        0.4456  0.0169\n",
            "     39        0.4456  0.0165\n",
            "     40        0.4456  0.0159\n",
            "     41        0.4456  0.0162\n",
            "     42        0.4456  0.0167\n",
            "     43        0.4456  0.0175\n",
            "     44        0.4456  0.0163\n",
            "     45        0.4456  0.0168\n",
            "     46        0.4456  0.0158\n",
            "     47        0.4456  0.0161\n",
            "     48        0.4456  0.0169\n",
            "     49        0.4456  0.0162\n",
            "     50        0.4456  0.0163\n",
            "     51        0.4456  0.0166\n",
            "     52        0.4456  0.0162\n",
            "     53        0.4456  0.0163\n",
            "     54        0.4456  0.0157\n",
            "     55        0.4456  0.0180\n",
            "     56        0.4456  0.0166\n",
            "     57        0.4456  0.0163\n",
            "     58        0.4456  0.0162\n",
            "     59        0.4456  0.0163\n",
            "     60        0.4456  0.0161\n",
            "     61        0.4456  0.0161\n",
            "     62        0.4456  0.0167\n",
            "     63        0.4456  0.0223\n",
            "     64        0.4456  0.0199\n",
            "     65        0.4456  0.0212\n",
            "     66        0.4456  0.0163\n",
            "     67        0.4456  0.0167\n",
            "     68        0.4456  0.0170\n",
            "     69        0.4456  0.0192\n",
            "     70        0.4456  0.0177\n",
            "     71        0.4456  0.0174\n",
            "     72        0.4456  0.0201\n",
            "     73        0.4456  0.0198\n",
            "     74        0.4456  0.0198\n",
            "     75        0.4456  0.0192\n",
            "     76        0.4456  0.0211\n",
            "     77        0.4456  0.0196\n",
            "     78        0.4456  0.0195\n",
            "     79        0.4456  0.0194\n",
            "     80        0.4456  0.0185\n",
            "     81        0.4456  0.0181\n",
            "     82        0.4456  0.0173\n",
            "     83        0.4456  0.0166\n",
            "     84        0.4456  0.0179\n",
            "     85        0.4456  0.0158\n",
            "     86        0.4456  0.0162\n",
            "     87        0.4456  0.0167\n",
            "     88        0.4456  0.0164\n",
            "     89        0.4456  0.0168\n",
            "     90        0.4456  0.0177\n",
            "     91        0.4456  0.0164\n",
            "     92        0.4456  0.0162\n",
            "     93        0.4456  0.0166\n",
            "     94        0.4456  0.0165\n",
            "     95        0.4456  0.0159\n",
            "     96        0.4456  0.0160\n",
            "     97        0.4456  0.0173\n",
            "     98        0.4456  0.0166\n",
            "     99        0.4456  0.0167\n",
            "    100        0.4456  0.0166\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0202\n",
            "      2        0.3732  0.0204\n",
            "      3        0.3732  0.0207\n",
            "      4        0.3732  0.0210\n",
            "      5        0.3732  0.0204\n",
            "      6        0.3732  0.0208\n",
            "      7        0.3732  0.0221\n",
            "      8        0.3732  0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        0.3732  0.0217\n",
            "     10        0.3732  0.0207\n",
            "     11        0.3732  0.0216\n",
            "     12        0.3732  0.0250\n",
            "     13        0.3732  0.0251\n",
            "     14        0.3732  0.0298\n",
            "     15        0.3732  0.0286\n",
            "     16        0.3732  0.0234\n",
            "     17        0.3732  0.0243\n",
            "     18        0.3732  0.0251\n",
            "     19        0.3732  0.0242\n",
            "     20        0.3732  0.0258\n",
            "     21        0.3732  0.0247\n",
            "     22        0.3732  0.0252\n",
            "     23        0.3732  0.0207\n",
            "     24        0.3732  0.0232\n",
            "     25        0.3768  0.0221\n",
            "     26        0.3768  0.0208\n",
            "     27        0.3768  0.0214\n",
            "     28        0.3768  0.0214\n",
            "     29        0.3768  0.0207\n",
            "     30        0.3768  0.0215\n",
            "     31        0.3768  0.0212\n",
            "     32        0.3768  0.0216\n",
            "     33        0.3768  0.0203\n",
            "     34        0.3768  0.0205\n",
            "     35        0.3768  0.0210\n",
            "     36        0.3768  0.0204\n",
            "     37        0.3768  0.0213\n",
            "     38        0.3768  0.0208\n",
            "     39        0.3768  0.0208\n",
            "     40        0.3768  0.0218\n",
            "     41        0.3768  0.0209\n",
            "     42        0.3768  0.0203\n",
            "     43        0.3768  0.0214\n",
            "     44        0.3768  0.0199\n",
            "     45        0.3768  0.0212\n",
            "     46        0.3768  0.0207\n",
            "     47        0.3768  0.0213\n",
            "     48        0.3768  0.0205\n",
            "     49        0.3768  0.0210\n",
            "     50        0.3768  0.0208\n",
            "     51        0.3768  0.0212\n",
            "     52        0.3768  0.0223\n",
            "     53        0.3768  0.0221\n",
            "     54        0.3768  0.0206\n",
            "     55        0.3768  0.0233\n",
            "     56        0.3768  0.0319\n",
            "     57        0.3768  0.0312\n",
            "     58        0.3768  0.0250\n",
            "     59        0.3768  0.0242\n",
            "     60        0.3768  0.0249\n",
            "     61        0.3768  0.0276\n",
            "     62        0.3768  0.0292\n",
            "     63        0.3768  0.0215\n",
            "     64        0.3768  0.0243\n",
            "     65        0.3768  0.0206\n",
            "     66        0.3768  0.0243\n",
            "     67        0.3768  0.0212\n",
            "     68        0.3768  0.0216\n",
            "     69        0.3768  0.0216\n",
            "     70        0.3768  0.0212\n",
            "     71        0.3768  0.0240\n",
            "     72        0.3768  0.0209\n",
            "     73        0.3768  0.0211\n",
            "     74        0.3768  0.0238\n",
            "     75        0.3768  0.0221\n",
            "     76        0.3768  0.0208\n",
            "     77        0.3768  0.0213\n",
            "     78        0.3768  0.0211\n",
            "     79        0.3768  0.0214\n",
            "     80        0.3768  0.0225\n",
            "     81        0.3768  0.0211\n",
            "     82        0.3768  0.0213\n",
            "     83        0.3768  0.0218\n",
            "     84        0.3768  0.0214\n",
            "     85        0.3768  0.0208\n",
            "     86        0.3768  0.0216\n",
            "     87        0.3768  0.0210\n",
            "     88        0.3768  0.0213\n",
            "     89        0.3768  0.0211\n",
            "     90        0.3768  0.0210\n",
            "     91        0.3768  0.0220\n",
            "     92        0.3768  0.0228\n",
            "     93        0.3768  0.0234\n",
            "     94        0.3768  0.0241\n",
            "     95        0.3768  0.0247\n",
            "     96        0.3768  0.0251\n",
            "     97        0.3768  0.0281\n",
            "     98        0.3768  0.0301\n",
            "     99        0.3768  0.0251\n",
            "    100        0.3768  0.0383\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7509\u001b[0m  0.0276\n",
            "      2        \u001b[36m0.6989\u001b[0m  0.0228\n",
            "      3        \u001b[36m0.6421\u001b[0m  0.0247\n",
            "      4        \u001b[36m0.5860\u001b[0m  0.0233\n",
            "      5        \u001b[36m0.5579\u001b[0m  0.0202\n",
            "      6        \u001b[36m0.5509\u001b[0m  0.0228\n",
            "      7        \u001b[36m0.5439\u001b[0m  0.0226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5400\u001b[0m  0.0249\n",
            "      9        \u001b[36m0.4877\u001b[0m  0.0265\n",
            "     10        0.4877  0.0226\n",
            "     11        0.4877  0.0225\n",
            "     12        \u001b[36m0.4877\u001b[0m  0.0230\n",
            "     13        \u001b[36m0.4807\u001b[0m  0.0220\n",
            "     14        0.4807  0.0222\n",
            "     15        0.4807  0.0223\n",
            "     16        0.4807  0.0224\n",
            "     17        0.4842  0.0222\n",
            "     18        0.4842  0.0260\n",
            "     19        0.4877  0.0296\n",
            "     20        0.4877  0.0254\n",
            "     21        0.4877  0.0238\n",
            "     22        0.4854  0.0250\n",
            "     23        \u001b[36m0.4456\u001b[0m  0.0239\n",
            "     24        \u001b[36m0.4316\u001b[0m  0.0231\n",
            "     25        \u001b[36m0.4315\u001b[0m  0.0268\n",
            "     26        \u001b[36m0.4105\u001b[0m  0.0233\n",
            "     27        \u001b[36m0.4105\u001b[0m  0.0240\n",
            "     28        \u001b[36m0.4105\u001b[0m  0.0277\n",
            "     29        \u001b[36m0.4091\u001b[0m  0.0331\n",
            "     30        \u001b[36m0.3789\u001b[0m  0.0294\n",
            "     31        \u001b[36m0.3754\u001b[0m  0.0319\n",
            "     32        0.3754  0.0303\n",
            "     33        0.3754  0.0299\n",
            "     34        0.3754  0.0283\n",
            "     35        0.3754  0.0275\n",
            "     36        0.3754  0.0279\n",
            "     37        0.3754  0.0224\n",
            "     38        0.3754  0.0237\n",
            "     39        0.3754  0.0276\n",
            "     40        0.3754  0.0254\n",
            "     41        0.3754  0.0248\n",
            "     42        0.3754  0.0243\n",
            "     43        0.3754  0.0301\n",
            "     44        0.3754  0.0328\n",
            "     45        0.3754  0.0260\n",
            "     46        0.3754  0.0253\n",
            "     47        0.3754  0.0322\n",
            "     48        0.3754  0.0227\n",
            "     49        0.3754  0.0257\n",
            "     50        0.3754  0.0287\n",
            "     51        0.3754  0.0247\n",
            "     52        0.3754  0.0309\n",
            "     53        0.3754  0.0255\n",
            "     54        0.3754  0.0273\n",
            "     55        0.3754  0.0265\n",
            "     56        0.3754  0.0262\n",
            "     57        0.3754  0.0290\n",
            "     58        0.3754  0.0247\n",
            "     59        0.3754  0.0228\n",
            "     60        0.3754  0.0255\n",
            "     61        0.3754  0.0312\n",
            "     62        0.3754  0.0280\n",
            "     63        0.3754  0.0312\n",
            "     64        0.3754  0.0350\n",
            "     65        0.3754  0.0289\n",
            "     66        0.3754  0.0277\n",
            "     67        0.3754  0.0274\n",
            "     68        0.3754  0.0316\n",
            "     69        0.3754  0.0291\n",
            "     70        0.3754  0.0250\n",
            "     71        0.3754  0.0210\n",
            "     72        0.3754  0.0215\n",
            "     73        0.3754  0.0211\n",
            "     74        0.3754  0.0214\n",
            "     75        0.3754  0.0324\n",
            "     76        0.3754  0.0211\n",
            "     77        0.3754  0.0208\n",
            "     78        0.3754  0.0261\n",
            "     79        0.3754  0.0258\n",
            "     80        0.3754  0.0212\n",
            "     81        0.3754  0.0208\n",
            "     82        0.3754  0.0210\n",
            "     83        0.3754  0.0221\n",
            "     84        0.3754  0.0214\n",
            "     85        0.3754  0.0215\n",
            "     86        0.3754  0.0218\n",
            "     87        0.3754  0.0217\n",
            "     88        0.3754  0.0224\n",
            "     89        0.3754  0.0213\n",
            "     90        0.3754  0.0213\n",
            "     91        0.3754  0.0209\n",
            "     92        0.3754  0.0211\n",
            "     93        0.3754  0.0204\n",
            "     94        0.3754  0.0202\n",
            "     95        0.3754  0.0214\n",
            "     96        0.3754  0.0208\n",
            "     97        0.3754  0.0217\n",
            "     98        0.3754  0.0229\n",
            "     99        0.3754  0.0233\n",
            "    100        0.3754  0.0299\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.3732\u001b[0m  0.0226\n",
            "      2        0.3732  0.0217\n",
            "      3        0.3732  0.0247\n",
            "      4        0.3732  0.0259\n",
            "      5        0.3732  0.0236\n",
            "      6        0.3732  0.0263\n",
            "      7        0.3732  0.0202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        0.3732  0.0215\n",
            "      9        0.3732  0.0231\n",
            "     10        0.3732  0.0216\n",
            "     11        0.3732  0.0239\n",
            "     12        0.3732  0.0255\n",
            "     13        0.3732  0.0243\n",
            "     14        0.3732  0.0196\n",
            "     15        0.3732  0.0169\n",
            "     16        0.3732  0.0159\n",
            "     17        0.3732  0.0198\n",
            "     18        0.3732  0.0166\n",
            "     19        0.3732  0.0190\n",
            "     20        0.3732  0.0216\n",
            "     21        0.3732  0.0196\n",
            "     22        0.3732  0.0160\n",
            "     23        0.3732  0.0167\n",
            "     24        0.3732  0.0167\n",
            "     25        0.3732  0.0158\n",
            "     26        0.3732  0.0169\n",
            "     27        0.3732  0.0167\n",
            "     28        0.3732  0.0199\n",
            "     29        0.3732  0.0180\n",
            "     30        0.3732  0.0175\n",
            "     31        0.3732  0.0211\n",
            "     32        0.3732  0.0214\n",
            "     33        0.3732  0.0272\n",
            "     34        0.3732  0.0219\n",
            "     35        0.3732  0.0210\n",
            "     36        0.3732  0.0200\n",
            "     37        0.3732  0.0206\n",
            "     38        0.3732  0.0213\n",
            "     39        0.3732  0.0184\n",
            "     40        0.3732  0.0265\n",
            "     41        0.3732  0.0265\n",
            "     42        0.3732  0.0257\n",
            "     43        0.3732  0.0247\n",
            "     44        0.3732  0.0286\n",
            "     45        0.3732  0.0280\n",
            "     46        0.3732  0.0242\n",
            "     47        0.3732  0.0229\n",
            "     48        0.3732  0.0268\n",
            "     49        0.3732  0.0272\n",
            "     50        0.3732  0.0201\n",
            "     51        0.3732  0.0234\n",
            "     52        0.3732  0.0278\n",
            "     53        0.3732  0.0216\n",
            "     54        0.3732  0.0215\n",
            "     55        0.3732  0.0279\n",
            "     56        0.3732  0.0178\n",
            "     57        0.3732  0.0239\n",
            "     58        0.3732  0.0196\n",
            "     59        0.3732  0.0170\n",
            "     60        0.3732  0.0163\n",
            "     61        0.3732  0.0175\n",
            "     62        0.3732  0.0222\n",
            "     63        0.3732  0.0243\n",
            "     64        0.3732  0.0172\n",
            "     65        0.3732  0.0197\n",
            "     66        0.3732  0.0174\n",
            "     67        0.3732  0.0186\n",
            "     68        0.3732  0.0178\n",
            "     69        0.3732  0.0176\n",
            "     70        0.3732  0.0181\n",
            "     71        0.3732  0.0178\n",
            "     72        0.3732  0.0172\n",
            "     73        0.3732  0.0188\n",
            "     74        0.3732  0.0173\n",
            "     75        0.3732  0.0174\n",
            "     76        0.3732  0.0227\n",
            "     77        0.3732  0.0183\n",
            "     78        0.3732  0.0174\n",
            "     79        0.3732  0.0184\n",
            "     80        0.3732  0.0201\n",
            "     81        0.3732  0.0277\n",
            "     82        0.3732  0.0250\n",
            "     83        0.3732  0.0289\n",
            "     84        0.3732  0.0283\n",
            "     85        0.3732  0.0290\n",
            "     86        0.3732  0.0237\n",
            "     87        0.3732  0.0274\n",
            "     88        0.3732  0.0290\n",
            "     89        0.3732  0.0263\n",
            "     90        0.3732  0.0203\n",
            "     91        0.3732  0.0167\n",
            "     92        0.3732  0.0220\n",
            "     93        0.3732  0.0212\n",
            "     94        0.3732  0.0177\n",
            "     95        0.3732  0.0237\n",
            "     96        0.3732  0.0218\n",
            "     97        0.3732  0.0233\n",
            "     98        0.3732  0.0248\n",
            "     99        0.3732  0.0175\n",
            "    100        0.3732  0.0186\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4491\u001b[0m  0.0181\n",
            "      2        0.4491  0.0190\n",
            "      3        0.4491  0.0182\n",
            "      4        0.4491  0.0186\n",
            "      5        0.4491  0.0213\n",
            "      6        0.4491  0.0183\n",
            "      7        0.4491  0.0168\n",
            "      8        0.4491  0.0165\n",
            "      9        0.4491  0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.4491  0.0181\n",
            "     11        0.4491  0.0169\n",
            "     12        0.4491  0.0163\n",
            "     13        0.4491  0.0167\n",
            "     14        0.4491  0.0163\n",
            "     15        0.4491  0.0167\n",
            "     16        0.4491  0.0163\n",
            "     17        0.4491  0.0162\n",
            "     18        0.4491  0.0161\n",
            "     19        0.4491  0.0188\n",
            "     20        0.4491  0.0200\n",
            "     21        0.4491  0.0192\n",
            "     22        0.4491  0.0226\n",
            "     23        0.4491  0.0220\n",
            "     24        0.4491  0.0230\n",
            "     25        0.4491  0.0220\n",
            "     26        0.4491  0.0255\n",
            "     27        0.4491  0.0217\n",
            "     28        0.4491  0.0195\n",
            "     29        0.4491  0.0210\n",
            "     30        0.4491  0.0208\n",
            "     31        0.4491  0.0198\n",
            "     32        0.4491  0.0246\n",
            "     33        0.4491  0.0253\n",
            "     34        0.4491  0.0245\n",
            "     35        0.4491  0.0255\n",
            "     36        0.4491  0.0265\n",
            "     37        0.4491  0.0194\n",
            "     38        0.4491  0.0185\n",
            "     39        0.4491  0.0173\n",
            "     40        0.4491  0.0170\n",
            "     41        0.4491  0.0170\n",
            "     42        0.4491  0.0200\n",
            "     43        0.4491  0.0188\n",
            "     44        0.4491  0.0187\n",
            "     45        0.4491  0.0185\n",
            "     46        0.4491  0.0179\n",
            "     47        0.4491  0.0194\n",
            "     48        0.4491  0.0176\n",
            "     49        0.4491  0.0181\n",
            "     50        0.4491  0.0177\n",
            "     51        0.4491  0.0174\n",
            "     52        0.4491  0.0180\n",
            "     53        0.4491  0.0201\n",
            "     54        0.4491  0.0177\n",
            "     55        0.4491  0.0181\n",
            "     56        0.4491  0.0180\n",
            "     57        0.4491  0.0166\n",
            "     58        0.4491  0.0175\n",
            "     59        0.4491  0.0170\n",
            "     60        0.4491  0.0175\n",
            "     61        0.4491  0.0175\n",
            "     62        0.4491  0.0167\n",
            "     63        0.4491  0.0166\n",
            "     64        0.4491  0.0194\n",
            "     65        0.4491  0.0195\n",
            "     66        0.4491  0.0175\n",
            "     67        0.4491  0.0267\n",
            "     68        0.4491  0.0255\n",
            "     69        0.4491  0.0213\n",
            "     70        0.4491  0.0207\n",
            "     71        0.4491  0.0205\n",
            "     72        0.4491  0.0200\n",
            "     73        0.4491  0.0235\n",
            "     74        0.4491  0.0211\n",
            "     75        0.4491  0.0170\n",
            "     76        0.4491  0.0164\n",
            "     77        0.4491  0.0170\n",
            "     78        0.4491  0.0162\n",
            "     79        0.4491  0.0193\n",
            "     80        0.4491  0.0172\n",
            "     81        0.4491  0.0172\n",
            "     82        0.4491  0.0179\n",
            "     83        0.4491  0.0179\n",
            "     84        0.4491  0.0169\n",
            "     85        0.4491  0.0169\n",
            "     86        0.4491  0.0158\n",
            "     87        0.4491  0.0167\n",
            "     88        0.4491  0.0166\n",
            "     89        0.4491  0.0169\n",
            "     90        0.4491  0.0168\n",
            "     91        0.4491  0.0166\n",
            "     92        0.4491  0.0210\n",
            "     93        0.4491  0.0261\n",
            "     94        0.4491  0.0190\n",
            "     95        0.4491  0.0169\n",
            "     96        0.4491  0.0173\n",
            "     97        0.4491  0.0167\n",
            "     98        0.4491  0.0171\n",
            "     99        0.4491  0.0163\n",
            "    100        0.4491  0.0162\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9667\u001b[0m  0.0212\n",
            "      2        \u001b[36m0.9640\u001b[0m  0.0202\n",
            "      3        \u001b[36m0.9609\u001b[0m  0.0213\n",
            "      4        \u001b[36m0.9575\u001b[0m  0.0230\n",
            "      5        \u001b[36m0.9538\u001b[0m  0.0204\n",
            "      6        \u001b[36m0.9496\u001b[0m  0.0203\n",
            "      7        \u001b[36m0.9448\u001b[0m  0.0205\n",
            "      8        \u001b[36m0.9395\u001b[0m  0.0212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9335\u001b[0m  0.0256\n",
            "     10        \u001b[36m0.9267\u001b[0m  0.0250\n",
            "     11        \u001b[36m0.9189\u001b[0m  0.0247\n",
            "     12        \u001b[36m0.9099\u001b[0m  0.0244\n",
            "     13        \u001b[36m0.8995\u001b[0m  0.0220\n",
            "     14        \u001b[36m0.8874\u001b[0m  0.0255\n",
            "     15        \u001b[36m0.8731\u001b[0m  0.0245\n",
            "     16        \u001b[36m0.8561\u001b[0m  0.0250\n",
            "     17        \u001b[36m0.8356\u001b[0m  0.0285\n",
            "     18        \u001b[36m0.8111\u001b[0m  0.0222\n",
            "     19        \u001b[36m0.7822\u001b[0m  0.0276\n",
            "     20        \u001b[36m0.7494\u001b[0m  0.0264\n",
            "     21        \u001b[36m0.7140\u001b[0m  0.0239\n",
            "     22        \u001b[36m0.6781\u001b[0m  0.0223\n",
            "     23        \u001b[36m0.6434\u001b[0m  0.0209\n",
            "     24        \u001b[36m0.6116\u001b[0m  0.0213\n",
            "     25        \u001b[36m0.5836\u001b[0m  0.0231\n",
            "     26        \u001b[36m0.5597\u001b[0m  0.0212\n",
            "     27        \u001b[36m0.5401\u001b[0m  0.0208\n",
            "     28        \u001b[36m0.5240\u001b[0m  0.0205\n",
            "     29        \u001b[36m0.5108\u001b[0m  0.0216\n",
            "     30        \u001b[36m0.4996\u001b[0m  0.0228\n",
            "     31        \u001b[36m0.4900\u001b[0m  0.0226\n",
            "     32        \u001b[36m0.4817\u001b[0m  0.0207\n",
            "     33        \u001b[36m0.4743\u001b[0m  0.0230\n",
            "     34        \u001b[36m0.4677\u001b[0m  0.0259\n",
            "     35        \u001b[36m0.4619\u001b[0m  0.0313\n",
            "     36        \u001b[36m0.4566\u001b[0m  0.0231\n",
            "     37        \u001b[36m0.4518\u001b[0m  0.0230\n",
            "     38        \u001b[36m0.4475\u001b[0m  0.0233\n",
            "     39        \u001b[36m0.4435\u001b[0m  0.0228\n",
            "     40        \u001b[36m0.4399\u001b[0m  0.0233\n",
            "     41        \u001b[36m0.4366\u001b[0m  0.0217\n",
            "     42        \u001b[36m0.4336\u001b[0m  0.0210\n",
            "     43        \u001b[36m0.4308\u001b[0m  0.0227\n",
            "     44        \u001b[36m0.4282\u001b[0m  0.0227\n",
            "     45        \u001b[36m0.4257\u001b[0m  0.0215\n",
            "     46        \u001b[36m0.4235\u001b[0m  0.0251\n",
            "     47        \u001b[36m0.4214\u001b[0m  0.0350\n",
            "     48        \u001b[36m0.4195\u001b[0m  0.0325\n",
            "     49        \u001b[36m0.4177\u001b[0m  0.0278\n",
            "     50        \u001b[36m0.4160\u001b[0m  0.0253\n",
            "     51        \u001b[36m0.4144\u001b[0m  0.0254\n",
            "     52        \u001b[36m0.4129\u001b[0m  0.0246\n",
            "     53        \u001b[36m0.4114\u001b[0m  0.0262\n",
            "     54        \u001b[36m0.4101\u001b[0m  0.0264\n",
            "     55        \u001b[36m0.4088\u001b[0m  0.0231\n",
            "     56        \u001b[36m0.4077\u001b[0m  0.0223\n",
            "     57        \u001b[36m0.4065\u001b[0m  0.0230\n",
            "     58        \u001b[36m0.4055\u001b[0m  0.0212\n",
            "     59        \u001b[36m0.4045\u001b[0m  0.0205\n",
            "     60        \u001b[36m0.4035\u001b[0m  0.0205\n",
            "     61        \u001b[36m0.4026\u001b[0m  0.0220\n",
            "     62        \u001b[36m0.4017\u001b[0m  0.0240\n",
            "     63        \u001b[36m0.4009\u001b[0m  0.0225\n",
            "     64        \u001b[36m0.4001\u001b[0m  0.0204\n",
            "     65        \u001b[36m0.3993\u001b[0m  0.0205\n",
            "     66        \u001b[36m0.3986\u001b[0m  0.0211\n",
            "     67        \u001b[36m0.3979\u001b[0m  0.0203\n",
            "     68        \u001b[36m0.3972\u001b[0m  0.0230\n",
            "     69        \u001b[36m0.3966\u001b[0m  0.0213\n",
            "     70        \u001b[36m0.3960\u001b[0m  0.0204\n",
            "     71        \u001b[36m0.3954\u001b[0m  0.0207\n",
            "     72        \u001b[36m0.3949\u001b[0m  0.0210\n",
            "     73        \u001b[36m0.3943\u001b[0m  0.0203\n",
            "     74        \u001b[36m0.3938\u001b[0m  0.0279\n",
            "     75        \u001b[36m0.3933\u001b[0m  0.0281\n",
            "     76        \u001b[36m0.3928\u001b[0m  0.0230\n",
            "     77        \u001b[36m0.3923\u001b[0m  0.0210\n",
            "     78        \u001b[36m0.3919\u001b[0m  0.0214\n",
            "     79        \u001b[36m0.3915\u001b[0m  0.0210\n",
            "     80        \u001b[36m0.3910\u001b[0m  0.0222\n",
            "     81        \u001b[36m0.3906\u001b[0m  0.0208\n",
            "     82        \u001b[36m0.3902\u001b[0m  0.0203\n",
            "     83        \u001b[36m0.3898\u001b[0m  0.0212\n",
            "     84        \u001b[36m0.3895\u001b[0m  0.0215\n",
            "     85        \u001b[36m0.3891\u001b[0m  0.0249\n",
            "     86        \u001b[36m0.3888\u001b[0m  0.0254\n",
            "     87        \u001b[36m0.3884\u001b[0m  0.0209\n",
            "     88        \u001b[36m0.3881\u001b[0m  0.0237\n",
            "     89        \u001b[36m0.3878\u001b[0m  0.0261\n",
            "     90        \u001b[36m0.3875\u001b[0m  0.0249\n",
            "     91        \u001b[36m0.3872\u001b[0m  0.0245\n",
            "     92        \u001b[36m0.3869\u001b[0m  0.0252\n",
            "     93        \u001b[36m0.3866\u001b[0m  0.0248\n",
            "     94        \u001b[36m0.3863\u001b[0m  0.0249\n",
            "     95        \u001b[36m0.3861\u001b[0m  0.0211\n",
            "     96        \u001b[36m0.3858\u001b[0m  0.0212\n",
            "     97        \u001b[36m0.3855\u001b[0m  0.0212\n",
            "     98        \u001b[36m0.3853\u001b[0m  0.0213\n",
            "     99        \u001b[36m0.3851\u001b[0m  0.0211\n",
            "    100        \u001b[36m0.3848\u001b[0m  0.0215\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9979\u001b[0m  0.0209\n",
            "      2        \u001b[36m0.9977\u001b[0m  0.0211\n",
            "      3        \u001b[36m0.9975\u001b[0m  0.0223\n",
            "      4        \u001b[36m0.9973\u001b[0m  0.0214\n",
            "      5        \u001b[36m0.9970\u001b[0m  0.0206\n",
            "      6        \u001b[36m0.9966\u001b[0m  0.0210\n",
            "      7        \u001b[36m0.9962\u001b[0m  0.0204\n",
            "      8        \u001b[36m0.9957\u001b[0m  0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9951\u001b[0m  0.0228\n",
            "     10        \u001b[36m0.9943\u001b[0m  0.0210\n",
            "     11        \u001b[36m0.9932\u001b[0m  0.0210\n",
            "     12        \u001b[36m0.9917\u001b[0m  0.0219\n",
            "     13        \u001b[36m0.9896\u001b[0m  0.0208\n",
            "     14        \u001b[36m0.9865\u001b[0m  0.0208\n",
            "     15        \u001b[36m0.9818\u001b[0m  0.0208\n",
            "     16        \u001b[36m0.9747\u001b[0m  0.0246\n",
            "     17        \u001b[36m0.9638\u001b[0m  0.0290\n",
            "     18        \u001b[36m0.9467\u001b[0m  0.0231\n",
            "     19        \u001b[36m0.9193\u001b[0m  0.0205\n",
            "     20        \u001b[36m0.8755\u001b[0m  0.0212\n",
            "     21        \u001b[36m0.8089\u001b[0m  0.0206\n",
            "     22        \u001b[36m0.7198\u001b[0m  0.0209\n",
            "     23        \u001b[36m0.6235\u001b[0m  0.0203\n",
            "     24        \u001b[36m0.5424\u001b[0m  0.0254\n",
            "     25        \u001b[36m0.4870\u001b[0m  0.0247\n",
            "     26        \u001b[36m0.4532\u001b[0m  0.0201\n",
            "     27        \u001b[36m0.4329\u001b[0m  0.0253\n",
            "     28        \u001b[36m0.4202\u001b[0m  0.0247\n",
            "     29        \u001b[36m0.4118\u001b[0m  0.0256\n",
            "     30        \u001b[36m0.4058\u001b[0m  0.0251\n",
            "     31        \u001b[36m0.4014\u001b[0m  0.0253\n",
            "     32        \u001b[36m0.3981\u001b[0m  0.0266\n",
            "     33        \u001b[36m0.3954\u001b[0m  0.0250\n",
            "     34        \u001b[36m0.3933\u001b[0m  0.0213\n",
            "     35        \u001b[36m0.3915\u001b[0m  0.0206\n",
            "     36        \u001b[36m0.3901\u001b[0m  0.0208\n",
            "     37        \u001b[36m0.3889\u001b[0m  0.0210\n",
            "     38        \u001b[36m0.3879\u001b[0m  0.0227\n",
            "     39        \u001b[36m0.3870\u001b[0m  0.0215\n",
            "     40        \u001b[36m0.3862\u001b[0m  0.0220\n",
            "     41        \u001b[36m0.3855\u001b[0m  0.0211\n",
            "     42        \u001b[36m0.3849\u001b[0m  0.0211\n",
            "     43        \u001b[36m0.3844\u001b[0m  0.0215\n",
            "     44        \u001b[36m0.3839\u001b[0m  0.0224\n",
            "     45        \u001b[36m0.3834\u001b[0m  0.0212\n",
            "     46        \u001b[36m0.3830\u001b[0m  0.0209\n",
            "     47        \u001b[36m0.3826\u001b[0m  0.0221\n",
            "     48        \u001b[36m0.3823\u001b[0m  0.0203\n",
            "     49        \u001b[36m0.3819\u001b[0m  0.0212\n",
            "     50        \u001b[36m0.3816\u001b[0m  0.0208\n",
            "     51        \u001b[36m0.3813\u001b[0m  0.0209\n",
            "     52        \u001b[36m0.3810\u001b[0m  0.0203\n",
            "     53        \u001b[36m0.3808\u001b[0m  0.0210\n",
            "     54        \u001b[36m0.3805\u001b[0m  0.0229\n",
            "     55        \u001b[36m0.3803\u001b[0m  0.0209\n",
            "     56        \u001b[36m0.3801\u001b[0m  0.0212\n",
            "     57        \u001b[36m0.3798\u001b[0m  0.0212\n",
            "     58        \u001b[36m0.3796\u001b[0m  0.0273\n",
            "     59        \u001b[36m0.3794\u001b[0m  0.0262\n",
            "     60        \u001b[36m0.3793\u001b[0m  0.0247\n",
            "     61        \u001b[36m0.3791\u001b[0m  0.0202\n",
            "     62        \u001b[36m0.3789\u001b[0m  0.0215\n",
            "     63        \u001b[36m0.3788\u001b[0m  0.0223\n",
            "     64        \u001b[36m0.3786\u001b[0m  0.0270\n",
            "     65        \u001b[36m0.3785\u001b[0m  0.0224\n",
            "     66        \u001b[36m0.3783\u001b[0m  0.0252\n",
            "     67        \u001b[36m0.3782\u001b[0m  0.0264\n",
            "     68        \u001b[36m0.3780\u001b[0m  0.0260\n",
            "     69        \u001b[36m0.3779\u001b[0m  0.0257\n",
            "     70        \u001b[36m0.3778\u001b[0m  0.0251\n",
            "     71        \u001b[36m0.3777\u001b[0m  0.0283\n",
            "     72        \u001b[36m0.3776\u001b[0m  0.0309\n",
            "     73        \u001b[36m0.3774\u001b[0m  0.0248\n",
            "     74        \u001b[36m0.3773\u001b[0m  0.0207\n",
            "     75        \u001b[36m0.3772\u001b[0m  0.0269\n",
            "     76        \u001b[36m0.3771\u001b[0m  0.0226\n",
            "     77        \u001b[36m0.3770\u001b[0m  0.0211\n",
            "     78        \u001b[36m0.3769\u001b[0m  0.0262\n",
            "     79        \u001b[36m0.3769\u001b[0m  0.0215\n",
            "     80        \u001b[36m0.3768\u001b[0m  0.0210\n",
            "     81        \u001b[36m0.3767\u001b[0m  0.0211\n",
            "     82        \u001b[36m0.3766\u001b[0m  0.0209\n",
            "     83        \u001b[36m0.3765\u001b[0m  0.0204\n",
            "     84        \u001b[36m0.3764\u001b[0m  0.0213\n",
            "     85        \u001b[36m0.3764\u001b[0m  0.0221\n",
            "     86        \u001b[36m0.3763\u001b[0m  0.0210\n",
            "     87        \u001b[36m0.3762\u001b[0m  0.0211\n",
            "     88        \u001b[36m0.3761\u001b[0m  0.0211\n",
            "     89        \u001b[36m0.3761\u001b[0m  0.0206\n",
            "     90        \u001b[36m0.3760\u001b[0m  0.0209\n",
            "     91        \u001b[36m0.3759\u001b[0m  0.0207\n",
            "     92        \u001b[36m0.3759\u001b[0m  0.0216\n",
            "     93        \u001b[36m0.3758\u001b[0m  0.0211\n",
            "     94        \u001b[36m0.3758\u001b[0m  0.0209\n",
            "     95        \u001b[36m0.3757\u001b[0m  0.0221\n",
            "     96        \u001b[36m0.3756\u001b[0m  0.0219\n",
            "     97        \u001b[36m0.3756\u001b[0m  0.0217\n",
            "     98        \u001b[36m0.3755\u001b[0m  0.0207\n",
            "     99        \u001b[36m0.3755\u001b[0m  0.0265\n",
            "    100        \u001b[36m0.3754\u001b[0m  0.0291\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9936\u001b[0m  0.0197\n",
            "      2        \u001b[36m0.9936\u001b[0m  0.0192\n",
            "      3        \u001b[36m0.9936\u001b[0m  0.0177\n",
            "      4        \u001b[36m0.9936\u001b[0m  0.0178\n",
            "      5        \u001b[36m0.9936\u001b[0m  0.0194\n",
            "      6        \u001b[36m0.9936\u001b[0m  0.0191\n",
            "      7        \u001b[36m0.9936\u001b[0m  0.0189\n",
            "      8        \u001b[36m0.9936\u001b[0m  0.0180\n",
            "      9        \u001b[36m0.9936\u001b[0m  0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.9936\u001b[0m  0.0196\n",
            "     11        \u001b[36m0.9936\u001b[0m  0.0193\n",
            "     12        \u001b[36m0.9936\u001b[0m  0.0200\n",
            "     13        \u001b[36m0.9936\u001b[0m  0.0181\n",
            "     14        \u001b[36m0.9936\u001b[0m  0.0164\n",
            "     15        \u001b[36m0.9936\u001b[0m  0.0160\n",
            "     16        \u001b[36m0.9935\u001b[0m  0.0164\n",
            "     17        \u001b[36m0.9935\u001b[0m  0.0167\n",
            "     18        \u001b[36m0.9935\u001b[0m  0.0172\n",
            "     19        \u001b[36m0.9935\u001b[0m  0.0173\n",
            "     20        \u001b[36m0.9935\u001b[0m  0.0160\n",
            "     21        \u001b[36m0.9935\u001b[0m  0.0166\n",
            "     22        \u001b[36m0.9935\u001b[0m  0.0200\n",
            "     23        \u001b[36m0.9935\u001b[0m  0.0170\n",
            "     24        \u001b[36m0.9935\u001b[0m  0.0182\n",
            "     25        \u001b[36m0.9935\u001b[0m  0.0166\n",
            "     26        \u001b[36m0.9935\u001b[0m  0.0167\n",
            "     27        \u001b[36m0.9935\u001b[0m  0.0169\n",
            "     28        \u001b[36m0.9935\u001b[0m  0.0181\n",
            "     29        \u001b[36m0.9935\u001b[0m  0.0171\n",
            "     30        \u001b[36m0.9935\u001b[0m  0.0174\n",
            "     31        \u001b[36m0.9935\u001b[0m  0.0162\n",
            "     32        \u001b[36m0.9935\u001b[0m  0.0162\n",
            "     33        \u001b[36m0.9935\u001b[0m  0.0192\n",
            "     34        \u001b[36m0.9935\u001b[0m  0.0159\n",
            "     35        \u001b[36m0.9935\u001b[0m  0.0167\n",
            "     36        \u001b[36m0.9935\u001b[0m  0.0183\n",
            "     37        \u001b[36m0.9935\u001b[0m  0.0166\n",
            "     38        \u001b[36m0.9935\u001b[0m  0.0162\n",
            "     39        \u001b[36m0.9935\u001b[0m  0.0184\n",
            "     40        \u001b[36m0.9935\u001b[0m  0.0168\n",
            "     41        \u001b[36m0.9935\u001b[0m  0.0167\n",
            "     42        \u001b[36m0.9935\u001b[0m  0.0193\n",
            "     43        \u001b[36m0.9934\u001b[0m  0.0173\n",
            "     44        \u001b[36m0.9934\u001b[0m  0.0183\n",
            "     45        \u001b[36m0.9934\u001b[0m  0.0166\n",
            "     46        \u001b[36m0.9934\u001b[0m  0.0174\n",
            "     47        \u001b[36m0.9934\u001b[0m  0.0171\n",
            "     48        \u001b[36m0.9934\u001b[0m  0.0169\n",
            "     49        \u001b[36m0.9934\u001b[0m  0.0160\n",
            "     50        \u001b[36m0.9934\u001b[0m  0.0248\n",
            "     51        \u001b[36m0.9934\u001b[0m  0.0225\n",
            "     52        \u001b[36m0.9934\u001b[0m  0.0311\n",
            "     53        \u001b[36m0.9934\u001b[0m  0.0237\n",
            "     54        \u001b[36m0.9934\u001b[0m  0.0197\n",
            "     55        \u001b[36m0.9934\u001b[0m  0.0202\n",
            "     56        \u001b[36m0.9934\u001b[0m  0.0188\n",
            "     57        \u001b[36m0.9934\u001b[0m  0.0198\n",
            "     58        \u001b[36m0.9934\u001b[0m  0.0187\n",
            "     59        \u001b[36m0.9934\u001b[0m  0.0179\n",
            "     60        \u001b[36m0.9934\u001b[0m  0.0225\n",
            "     61        \u001b[36m0.9934\u001b[0m  0.0179\n",
            "     62        \u001b[36m0.9934\u001b[0m  0.0199\n",
            "     63        \u001b[36m0.9934\u001b[0m  0.0199\n",
            "     64        \u001b[36m0.9934\u001b[0m  0.0153\n",
            "     65        \u001b[36m0.9934\u001b[0m  0.0200\n",
            "     66        \u001b[36m0.9934\u001b[0m  0.0183\n",
            "     67        \u001b[36m0.9934\u001b[0m  0.0197\n",
            "     68        \u001b[36m0.9934\u001b[0m  0.0177\n",
            "     69        \u001b[36m0.9933\u001b[0m  0.0195\n",
            "     70        \u001b[36m0.9933\u001b[0m  0.0158\n",
            "     71        \u001b[36m0.9933\u001b[0m  0.0156\n",
            "     72        \u001b[36m0.9933\u001b[0m  0.0170\n",
            "     73        \u001b[36m0.9933\u001b[0m  0.0179\n",
            "     74        \u001b[36m0.9933\u001b[0m  0.0172\n",
            "     75        \u001b[36m0.9933\u001b[0m  0.0157\n",
            "     76        \u001b[36m0.9933\u001b[0m  0.0156\n",
            "     77        \u001b[36m0.9933\u001b[0m  0.0169\n",
            "     78        \u001b[36m0.9933\u001b[0m  0.0168\n",
            "     79        \u001b[36m0.9933\u001b[0m  0.0179\n",
            "     80        \u001b[36m0.9933\u001b[0m  0.0169\n",
            "     81        \u001b[36m0.9933\u001b[0m  0.0177\n",
            "     82        \u001b[36m0.9933\u001b[0m  0.0165\n",
            "     83        \u001b[36m0.9933\u001b[0m  0.0164\n",
            "     84        \u001b[36m0.9933\u001b[0m  0.0174\n",
            "     85        \u001b[36m0.9933\u001b[0m  0.0173\n",
            "     86        \u001b[36m0.9933\u001b[0m  0.0173\n",
            "     87        \u001b[36m0.9933\u001b[0m  0.0167\n",
            "     88        \u001b[36m0.9933\u001b[0m  0.0169\n",
            "     89        \u001b[36m0.9933\u001b[0m  0.0167\n",
            "     90        \u001b[36m0.9933\u001b[0m  0.0169\n",
            "     91        \u001b[36m0.9933\u001b[0m  0.0187\n",
            "     92        \u001b[36m0.9933\u001b[0m  0.0188\n",
            "     93        \u001b[36m0.9933\u001b[0m  0.0173\n",
            "     94        \u001b[36m0.9932\u001b[0m  0.0172\n",
            "     95        \u001b[36m0.9932\u001b[0m  0.0162\n",
            "     96        \u001b[36m0.9932\u001b[0m  0.0167\n",
            "     97        \u001b[36m0.9932\u001b[0m  0.0188\n",
            "     98        \u001b[36m0.9932\u001b[0m  0.0206\n",
            "     99        \u001b[36m0.9932\u001b[0m  0.0196\n",
            "    100        \u001b[36m0.9932\u001b[0m  0.0259\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9891\u001b[0m  0.0199\n",
            "      2        \u001b[36m0.9891\u001b[0m  0.0193\n",
            "      3        \u001b[36m0.9891\u001b[0m  0.0168\n",
            "      4        \u001b[36m0.9891\u001b[0m  0.0176\n",
            "      5        \u001b[36m0.9891\u001b[0m  0.0233\n",
            "      6        \u001b[36m0.9891\u001b[0m  0.0195\n",
            "      7        \u001b[36m0.9891\u001b[0m  0.0195\n",
            "      8        \u001b[36m0.9891\u001b[0m  0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.9891\u001b[0m  0.0215\n",
            "     10        \u001b[36m0.9890\u001b[0m  0.0212\n",
            "     11        \u001b[36m0.9890\u001b[0m  0.0206\n",
            "     12        \u001b[36m0.9890\u001b[0m  0.0171\n",
            "     13        \u001b[36m0.9890\u001b[0m  0.0169\n",
            "     14        \u001b[36m0.9890\u001b[0m  0.0169\n",
            "     15        \u001b[36m0.9890\u001b[0m  0.0165\n",
            "     16        \u001b[36m0.9890\u001b[0m  0.0169\n",
            "     17        \u001b[36m0.9890\u001b[0m  0.0165\n",
            "     18        \u001b[36m0.9890\u001b[0m  0.0164\n",
            "     19        \u001b[36m0.9889\u001b[0m  0.0172\n",
            "     20        \u001b[36m0.9889\u001b[0m  0.0169\n",
            "     21        \u001b[36m0.9889\u001b[0m  0.0168\n",
            "     22        \u001b[36m0.9889\u001b[0m  0.0219\n",
            "     23        \u001b[36m0.9889\u001b[0m  0.0181\n",
            "     24        \u001b[36m0.9889\u001b[0m  0.0172\n",
            "     25        \u001b[36m0.9889\u001b[0m  0.0160\n",
            "     26        \u001b[36m0.9889\u001b[0m  0.0217\n",
            "     27        \u001b[36m0.9889\u001b[0m  0.0174\n",
            "     28        \u001b[36m0.9888\u001b[0m  0.0160\n",
            "     29        \u001b[36m0.9888\u001b[0m  0.0195\n",
            "     30        \u001b[36m0.9888\u001b[0m  0.0166\n",
            "     31        \u001b[36m0.9888\u001b[0m  0.0199\n",
            "     32        \u001b[36m0.9888\u001b[0m  0.0225\n",
            "     33        \u001b[36m0.9888\u001b[0m  0.0167\n",
            "     34        \u001b[36m0.9888\u001b[0m  0.0195\n",
            "     35        \u001b[36m0.9888\u001b[0m  0.0221\n",
            "     36        \u001b[36m0.9888\u001b[0m  0.0196\n",
            "     37        \u001b[36m0.9887\u001b[0m  0.0244\n",
            "     38        \u001b[36m0.9887\u001b[0m  0.0202\n",
            "     39        \u001b[36m0.9887\u001b[0m  0.0177\n",
            "     40        \u001b[36m0.9887\u001b[0m  0.0181\n",
            "     41        \u001b[36m0.9887\u001b[0m  0.0219\n",
            "     42        \u001b[36m0.9887\u001b[0m  0.0217\n",
            "     43        \u001b[36m0.9887\u001b[0m  0.0266\n",
            "     44        \u001b[36m0.9887\u001b[0m  0.0237\n",
            "     45        \u001b[36m0.9887\u001b[0m  0.0282\n",
            "     46        \u001b[36m0.9886\u001b[0m  0.0246\n",
            "     47        \u001b[36m0.9886\u001b[0m  0.0290\n",
            "     48        \u001b[36m0.9886\u001b[0m  0.0262\n",
            "     49        \u001b[36m0.9886\u001b[0m  0.0250\n",
            "     50        \u001b[36m0.9886\u001b[0m  0.0242\n",
            "     51        \u001b[36m0.9886\u001b[0m  0.0220\n",
            "     52        \u001b[36m0.9886\u001b[0m  0.0203\n",
            "     53        \u001b[36m0.9886\u001b[0m  0.0225\n",
            "     54        \u001b[36m0.9886\u001b[0m  0.0191\n",
            "     55        \u001b[36m0.9885\u001b[0m  0.0239\n",
            "     56        \u001b[36m0.9885\u001b[0m  0.0279\n",
            "     57        \u001b[36m0.9885\u001b[0m  0.0249\n",
            "     58        \u001b[36m0.9885\u001b[0m  0.0208\n",
            "     59        \u001b[36m0.9885\u001b[0m  0.0192\n",
            "     60        \u001b[36m0.9885\u001b[0m  0.0183\n",
            "     61        \u001b[36m0.9885\u001b[0m  0.0168\n",
            "     62        \u001b[36m0.9885\u001b[0m  0.0177\n",
            "     63        \u001b[36m0.9884\u001b[0m  0.0168\n",
            "     64        \u001b[36m0.9884\u001b[0m  0.0158\n",
            "     65        \u001b[36m0.9884\u001b[0m  0.0171\n",
            "     66        \u001b[36m0.9884\u001b[0m  0.0174\n",
            "     67        \u001b[36m0.9884\u001b[0m  0.0165\n",
            "     68        \u001b[36m0.9884\u001b[0m  0.0173\n",
            "     69        \u001b[36m0.9884\u001b[0m  0.0176\n",
            "     70        \u001b[36m0.9884\u001b[0m  0.0171\n",
            "     71        \u001b[36m0.9883\u001b[0m  0.0167\n",
            "     72        \u001b[36m0.9883\u001b[0m  0.0178\n",
            "     73        \u001b[36m0.9883\u001b[0m  0.0170\n",
            "     74        \u001b[36m0.9883\u001b[0m  0.0175\n",
            "     75        \u001b[36m0.9883\u001b[0m  0.0177\n",
            "     76        \u001b[36m0.9883\u001b[0m  0.0173\n",
            "     77        \u001b[36m0.9883\u001b[0m  0.0173\n",
            "     78        \u001b[36m0.9883\u001b[0m  0.0170\n",
            "     79        \u001b[36m0.9883\u001b[0m  0.0177\n",
            "     80        \u001b[36m0.9882\u001b[0m  0.0170\n",
            "     81        \u001b[36m0.9882\u001b[0m  0.0171\n",
            "     82        \u001b[36m0.9882\u001b[0m  0.0165\n",
            "     83        \u001b[36m0.9882\u001b[0m  0.0180\n",
            "     84        \u001b[36m0.9882\u001b[0m  0.0173\n",
            "     85        \u001b[36m0.9882\u001b[0m  0.0193\n",
            "     86        \u001b[36m0.9882\u001b[0m  0.0201\n",
            "     87        \u001b[36m0.9882\u001b[0m  0.0215\n",
            "     88        \u001b[36m0.9881\u001b[0m  0.0205\n",
            "     89        \u001b[36m0.9881\u001b[0m  0.0200\n",
            "     90        \u001b[36m0.9881\u001b[0m  0.0204\n",
            "     91        \u001b[36m0.9881\u001b[0m  0.0161\n",
            "     92        \u001b[36m0.9881\u001b[0m  0.0177\n",
            "     93        \u001b[36m0.9881\u001b[0m  0.0205\n",
            "     94        \u001b[36m0.9881\u001b[0m  0.0198\n",
            "     95        \u001b[36m0.9880\u001b[0m  0.0169\n",
            "     96        \u001b[36m0.9880\u001b[0m  0.0220\n",
            "     97        \u001b[36m0.9880\u001b[0m  0.0173\n",
            "     98        \u001b[36m0.9880\u001b[0m  0.0168\n",
            "     99        \u001b[36m0.9880\u001b[0m  0.0165\n",
            "    100        \u001b[36m0.9880\u001b[0m  0.0168\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9998\u001b[0m  0.0251\n",
            "      2        \u001b[36m0.9997\u001b[0m  0.0270\n",
            "      3        \u001b[36m0.9997\u001b[0m  0.0221\n",
            "      4        \u001b[36m0.9996\u001b[0m  0.0224\n",
            "      5        \u001b[36m0.9995\u001b[0m  0.0233\n",
            "      6        \u001b[36m0.9994\u001b[0m  0.0207\n",
            "      7        \u001b[36m0.9993\u001b[0m  0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.9991\u001b[0m  0.0241\n",
            "      9        \u001b[36m0.9989\u001b[0m  0.0229\n",
            "     10        \u001b[36m0.9985\u001b[0m  0.0212\n",
            "     11        \u001b[36m0.9981\u001b[0m  0.0227\n",
            "     12        \u001b[36m0.9974\u001b[0m  0.0202\n",
            "     13        \u001b[36m0.9965\u001b[0m  0.0206\n",
            "     14        \u001b[36m0.9952\u001b[0m  0.0207\n",
            "     15        \u001b[36m0.9933\u001b[0m  0.0207\n",
            "     16        \u001b[36m0.9904\u001b[0m  0.0200\n",
            "     17        \u001b[36m0.9861\u001b[0m  0.0220\n",
            "     18        \u001b[36m0.9793\u001b[0m  0.0214\n",
            "     19        \u001b[36m0.9683\u001b[0m  0.0208\n",
            "     20        \u001b[36m0.9489\u001b[0m  0.0254\n",
            "     21        \u001b[36m0.9133\u001b[0m  0.0297\n",
            "     22        \u001b[36m0.8533\u001b[0m  0.0209\n",
            "     23        \u001b[36m0.7742\u001b[0m  0.0210\n",
            "     24        \u001b[36m0.6930\u001b[0m  0.0231\n",
            "     25        \u001b[36m0.6226\u001b[0m  0.0231\n",
            "     26        \u001b[36m0.5670\u001b[0m  0.0240\n",
            "     27        \u001b[36m0.5255\u001b[0m  0.0273\n",
            "     28        \u001b[36m0.4954\u001b[0m  0.0255\n",
            "     29        \u001b[36m0.4735\u001b[0m  0.0258\n",
            "     30        \u001b[36m0.4572\u001b[0m  0.0247\n",
            "     31        \u001b[36m0.4442\u001b[0m  0.0265\n",
            "     32        \u001b[36m0.4326\u001b[0m  0.0221\n",
            "     33        \u001b[36m0.4202\u001b[0m  0.0284\n",
            "     34        \u001b[36m0.4080\u001b[0m  0.0243\n",
            "     35        \u001b[36m0.3993\u001b[0m  0.0270\n",
            "     36        \u001b[36m0.3937\u001b[0m  0.0271\n",
            "     37        \u001b[36m0.3891\u001b[0m  0.0244\n",
            "     38        \u001b[36m0.3858\u001b[0m  0.0248\n",
            "     39        \u001b[36m0.3839\u001b[0m  0.0229\n",
            "     40        \u001b[36m0.3829\u001b[0m  0.0317\n",
            "     41        \u001b[36m0.3822\u001b[0m  0.0265\n",
            "     42        \u001b[36m0.3818\u001b[0m  0.0255\n",
            "     43        \u001b[36m0.3815\u001b[0m  0.0373\n",
            "     44        \u001b[36m0.3813\u001b[0m  0.0265\n",
            "     45        \u001b[36m0.3811\u001b[0m  0.0294\n",
            "     46        \u001b[36m0.3809\u001b[0m  0.0304\n",
            "     47        \u001b[36m0.3807\u001b[0m  0.0236\n",
            "     48        \u001b[36m0.3805\u001b[0m  0.0207\n",
            "     49        \u001b[36m0.3804\u001b[0m  0.0235\n",
            "     50        \u001b[36m0.3802\u001b[0m  0.0296\n",
            "     51        \u001b[36m0.3801\u001b[0m  0.0276\n",
            "     52        \u001b[36m0.3799\u001b[0m  0.0213\n",
            "     53        \u001b[36m0.3798\u001b[0m  0.0214\n",
            "     54        \u001b[36m0.3797\u001b[0m  0.0209\n",
            "     55        \u001b[36m0.3795\u001b[0m  0.0214\n",
            "     56        \u001b[36m0.3794\u001b[0m  0.0214\n",
            "     57        \u001b[36m0.3793\u001b[0m  0.0258\n",
            "     58        \u001b[36m0.3792\u001b[0m  0.0264\n",
            "     59        \u001b[36m0.3791\u001b[0m  0.0237\n",
            "     60        \u001b[36m0.3789\u001b[0m  0.0285\n",
            "     61        \u001b[36m0.3788\u001b[0m  0.0356\n",
            "     62        \u001b[36m0.3787\u001b[0m  0.0314\n",
            "     63        \u001b[36m0.3786\u001b[0m  0.0311\n",
            "     64        \u001b[36m0.3784\u001b[0m  0.0307\n",
            "     65        \u001b[36m0.3781\u001b[0m  0.0354\n",
            "     66        \u001b[36m0.3780\u001b[0m  0.0297\n",
            "     67        \u001b[36m0.3778\u001b[0m  0.0352\n",
            "     68        \u001b[36m0.3778\u001b[0m  0.0262\n",
            "     69        \u001b[36m0.3777\u001b[0m  0.0239\n",
            "     70        \u001b[36m0.3776\u001b[0m  0.0301\n",
            "     71        \u001b[36m0.3775\u001b[0m  0.0277\n",
            "     72        \u001b[36m0.3773\u001b[0m  0.0259\n",
            "     73        \u001b[36m0.3768\u001b[0m  0.0259\n",
            "     74        \u001b[36m0.3763\u001b[0m  0.0268\n",
            "     75        \u001b[36m0.3761\u001b[0m  0.0251\n",
            "     76        \u001b[36m0.3760\u001b[0m  0.0231\n",
            "     77        \u001b[36m0.3759\u001b[0m  0.0233\n",
            "     78        \u001b[36m0.3759\u001b[0m  0.0270\n",
            "     79        \u001b[36m0.3759\u001b[0m  0.0225\n",
            "     80        \u001b[36m0.3758\u001b[0m  0.0239\n",
            "     81        \u001b[36m0.3758\u001b[0m  0.0237\n",
            "     82        \u001b[36m0.3758\u001b[0m  0.0225\n",
            "     83        \u001b[36m0.3758\u001b[0m  0.0244\n",
            "     84        \u001b[36m0.3757\u001b[0m  0.0232\n",
            "     85        \u001b[36m0.3757\u001b[0m  0.0227\n",
            "     86        \u001b[36m0.3757\u001b[0m  0.0225\n",
            "     87        \u001b[36m0.3757\u001b[0m  0.0231\n",
            "     88        \u001b[36m0.3756\u001b[0m  0.0230\n",
            "     89        \u001b[36m0.3756\u001b[0m  0.0235\n",
            "     90        \u001b[36m0.3756\u001b[0m  0.0257\n",
            "     91        \u001b[36m0.3756\u001b[0m  0.0289\n",
            "     92        \u001b[36m0.3756\u001b[0m  0.0331\n",
            "     93        \u001b[36m0.3755\u001b[0m  0.0309\n",
            "     94        \u001b[36m0.3755\u001b[0m  0.0290\n",
            "     95        \u001b[36m0.3755\u001b[0m  0.0318\n",
            "     96        \u001b[36m0.3755\u001b[0m  0.0339\n",
            "     97        \u001b[36m0.3754\u001b[0m  0.0375\n",
            "     98        \u001b[36m0.3754\u001b[0m  0.0347\n",
            "     99        \u001b[36m0.3754\u001b[0m  0.0299\n",
            "    100        \u001b[36m0.3754\u001b[0m  0.0321\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9994\u001b[0m  0.0263\n",
            "      2        \u001b[36m0.9993\u001b[0m  0.0323\n",
            "      3        \u001b[36m0.9992\u001b[0m  0.0278\n",
            "      4        \u001b[36m0.9991\u001b[0m  0.0310\n",
            "      5        \u001b[36m0.9989\u001b[0m  0.0291\n",
            "      6        \u001b[36m0.9986\u001b[0m  0.0257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.9983\u001b[0m  0.0363\n",
            "      8        \u001b[36m0.9979\u001b[0m  0.0283\n",
            "      9        \u001b[36m0.9973\u001b[0m  0.0279\n",
            "     10        \u001b[36m0.9966\u001b[0m  0.0329\n",
            "     11        \u001b[36m0.9955\u001b[0m  0.0244\n",
            "     12        \u001b[36m0.9940\u001b[0m  0.0267\n",
            "     13        \u001b[36m0.9919\u001b[0m  0.0270\n",
            "     14        \u001b[36m0.9889\u001b[0m  0.0252\n",
            "     15        \u001b[36m0.9846\u001b[0m  0.0262\n",
            "     16        \u001b[36m0.9782\u001b[0m  0.0302\n",
            "     17        \u001b[36m0.9689\u001b[0m  0.0230\n",
            "     18        \u001b[36m0.9554\u001b[0m  0.0215\n",
            "     19        \u001b[36m0.9360\u001b[0m  0.0214\n",
            "     20        \u001b[36m0.9085\u001b[0m  0.0209\n",
            "     21        \u001b[36m0.8710\u001b[0m  0.0210\n",
            "     22        \u001b[36m0.8217\u001b[0m  0.0207\n",
            "     23        \u001b[36m0.7594\u001b[0m  0.0210\n",
            "     24        \u001b[36m0.6834\u001b[0m  0.0223\n",
            "     25        \u001b[36m0.5980\u001b[0m  0.0305\n",
            "     26        \u001b[36m0.5229\u001b[0m  0.0311\n",
            "     27        \u001b[36m0.4755\u001b[0m  0.0250\n",
            "     28        \u001b[36m0.4482\u001b[0m  0.0235\n",
            "     29        \u001b[36m0.4285\u001b[0m  0.0230\n",
            "     30        \u001b[36m0.4109\u001b[0m  0.0232\n",
            "     31        \u001b[36m0.3972\u001b[0m  0.0227\n",
            "     32        \u001b[36m0.3889\u001b[0m  0.0217\n",
            "     33        \u001b[36m0.3838\u001b[0m  0.0251\n",
            "     34        \u001b[36m0.3808\u001b[0m  0.0269\n",
            "     35        \u001b[36m0.3793\u001b[0m  0.0212\n",
            "     36        \u001b[36m0.3786\u001b[0m  0.0218\n",
            "     37        \u001b[36m0.3783\u001b[0m  0.0223\n",
            "     38        \u001b[36m0.3780\u001b[0m  0.0217\n",
            "     39        \u001b[36m0.3778\u001b[0m  0.0235\n",
            "     40        \u001b[36m0.3777\u001b[0m  0.0285\n",
            "     41        \u001b[36m0.3775\u001b[0m  0.0281\n",
            "     42        \u001b[36m0.3774\u001b[0m  0.0219\n",
            "     43        \u001b[36m0.3773\u001b[0m  0.0203\n",
            "     44        \u001b[36m0.3772\u001b[0m  0.0196\n",
            "     45        \u001b[36m0.3770\u001b[0m  0.0208\n",
            "     46        \u001b[36m0.3769\u001b[0m  0.0227\n",
            "     47        \u001b[36m0.3769\u001b[0m  0.0223\n",
            "     48        \u001b[36m0.3768\u001b[0m  0.0207\n",
            "     49        \u001b[36m0.3767\u001b[0m  0.0205\n",
            "     50        \u001b[36m0.3766\u001b[0m  0.0213\n",
            "     51        \u001b[36m0.3765\u001b[0m  0.0228\n",
            "     52        \u001b[36m0.3764\u001b[0m  0.0217\n",
            "     53        \u001b[36m0.3764\u001b[0m  0.0220\n",
            "     54        \u001b[36m0.3763\u001b[0m  0.0214\n",
            "     55        \u001b[36m0.3762\u001b[0m  0.0220\n",
            "     56        \u001b[36m0.3761\u001b[0m  0.0327\n",
            "     57        \u001b[36m0.3761\u001b[0m  0.0228\n",
            "     58        \u001b[36m0.3760\u001b[0m  0.0222\n",
            "     59        \u001b[36m0.3758\u001b[0m  0.0224\n",
            "     60        \u001b[36m0.3755\u001b[0m  0.0226\n",
            "     61        \u001b[36m0.3750\u001b[0m  0.0316\n",
            "     62        \u001b[36m0.3747\u001b[0m  0.0379\n",
            "     63        \u001b[36m0.3746\u001b[0m  0.0248\n",
            "     64        \u001b[36m0.3746\u001b[0m  0.0339\n",
            "     65        \u001b[36m0.3745\u001b[0m  0.0370\n",
            "     66        \u001b[36m0.3744\u001b[0m  0.0344\n",
            "     67        \u001b[36m0.3744\u001b[0m  0.0255\n",
            "     68        \u001b[36m0.3744\u001b[0m  0.0278\n",
            "     69        \u001b[36m0.3743\u001b[0m  0.0281\n",
            "     70        \u001b[36m0.3743\u001b[0m  0.0283\n",
            "     71        \u001b[36m0.3743\u001b[0m  0.0259\n",
            "     72        \u001b[36m0.3743\u001b[0m  0.0393\n",
            "     73        \u001b[36m0.3742\u001b[0m  0.0214\n",
            "     74        \u001b[36m0.3742\u001b[0m  0.0215\n",
            "     75        \u001b[36m0.3742\u001b[0m  0.0220\n",
            "     76        \u001b[36m0.3742\u001b[0m  0.0237\n",
            "     77        \u001b[36m0.3742\u001b[0m  0.0248\n",
            "     78        \u001b[36m0.3741\u001b[0m  0.0277\n",
            "     79        \u001b[36m0.3741\u001b[0m  0.0218\n",
            "     80        \u001b[36m0.3741\u001b[0m  0.0222\n",
            "     81        \u001b[36m0.3741\u001b[0m  0.0218\n",
            "     82        \u001b[36m0.3741\u001b[0m  0.0227\n",
            "     83        \u001b[36m0.3740\u001b[0m  0.0215\n",
            "     84        \u001b[36m0.3740\u001b[0m  0.0211\n",
            "     85        \u001b[36m0.3740\u001b[0m  0.0219\n",
            "     86        \u001b[36m0.3740\u001b[0m  0.0245\n",
            "     87        \u001b[36m0.3740\u001b[0m  0.0211\n",
            "     88        \u001b[36m0.3739\u001b[0m  0.0221\n",
            "     89        \u001b[36m0.3739\u001b[0m  0.0219\n",
            "     90        \u001b[36m0.3739\u001b[0m  0.0216\n",
            "     91        \u001b[36m0.3739\u001b[0m  0.0212\n",
            "     92        \u001b[36m0.3739\u001b[0m  0.0226\n",
            "     93        \u001b[36m0.3739\u001b[0m  0.0226\n",
            "     94        \u001b[36m0.3738\u001b[0m  0.0213\n",
            "     95        \u001b[36m0.3738\u001b[0m  0.0218\n",
            "     96        \u001b[36m0.3738\u001b[0m  0.0303\n",
            "     97        \u001b[36m0.3738\u001b[0m  0.0351\n",
            "     98        \u001b[36m0.3738\u001b[0m  0.0381\n",
            "     99        \u001b[36m0.3738\u001b[0m  0.0231\n",
            "    100        \u001b[36m0.3737\u001b[0m  0.0246\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0196\n",
            "      2        0.9999  0.0183\n",
            "      3        0.9999  0.0170\n",
            "      4        0.9999  0.0176\n",
            "      5        0.9999  0.0177\n",
            "      6        0.9999  0.0166\n",
            "      7        0.9999  0.0166\n",
            "      8        0.9999  0.0171\n",
            "      9        0.9999  0.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.9999  0.0180\n",
            "     11        0.9999  0.0173\n",
            "     12        0.9999  0.0175\n",
            "     13        0.9999  0.0182\n",
            "     14        0.9999  0.0181\n",
            "     15        0.9999  0.0167\n",
            "     16        0.9999  0.0166\n",
            "     17        0.9999  0.0165\n",
            "     18        0.9999  0.0171\n",
            "     19        \u001b[36m0.9999\u001b[0m  0.0163\n",
            "     20        \u001b[36m0.9999\u001b[0m  0.0202\n",
            "     21        0.9999  0.0177\n",
            "     22        0.9999  0.0224\n",
            "     23        0.9999  0.0173\n",
            "     24        0.9999  0.0165\n",
            "     25        0.9999  0.0163\n",
            "     26        0.9999  0.0175\n",
            "     27        0.9999  0.0170\n",
            "     28        0.9999  0.0170\n",
            "     29        0.9999  0.0173\n",
            "     30        0.9999  0.0182\n",
            "     31        0.9999  0.0186\n",
            "     32        0.9999  0.0168\n",
            "     33        0.9999  0.0168\n",
            "     34        0.9999  0.0172\n",
            "     35        0.9999  0.0170\n",
            "     36        0.9999  0.0169\n",
            "     37        0.9999  0.0166\n",
            "     38        0.9999  0.0163\n",
            "     39        0.9999  0.0163\n",
            "     40        0.9999  0.0164\n",
            "     41        0.9999  0.0169\n",
            "     42        0.9999  0.0190\n",
            "     43        0.9999  0.0192\n",
            "     44        0.9999  0.0190\n",
            "     45        \u001b[36m0.9999\u001b[0m  0.0187\n",
            "     46        0.9999  0.0195\n",
            "     47        0.9999  0.0191\n",
            "     48        0.9999  0.0192\n",
            "     49        0.9999  0.0167\n",
            "     50        0.9999  0.0192\n",
            "     51        0.9999  0.0194\n",
            "     52        0.9999  0.0193\n",
            "     53        0.9999  0.0188\n",
            "     54        0.9999  0.0196\n",
            "     55        0.9999  0.0193\n",
            "     56        0.9999  0.0192\n",
            "     57        0.9999  0.0194\n",
            "     58        0.9999  0.0168\n",
            "     59        0.9999  0.0170\n",
            "     60        0.9999  0.0177\n",
            "     61        0.9999  0.0183\n",
            "     62        0.9999  0.0181\n",
            "     63        0.9999  0.0170\n",
            "     64        0.9999  0.0169\n",
            "     65        0.9999  0.0174\n",
            "     66        0.9999  0.0173\n",
            "     67        0.9999  0.0175\n",
            "     68        0.9999  0.0169\n",
            "     69        0.9999  0.0166\n",
            "     70        \u001b[36m0.9999\u001b[0m  0.0164\n",
            "     71        \u001b[36m0.9999\u001b[0m  0.0178\n",
            "     72        0.9999  0.0190\n",
            "     73        0.9999  0.0251\n",
            "     74        0.9999  0.0197\n",
            "     75        0.9999  0.0174\n",
            "     76        0.9999  0.0172\n",
            "     77        0.9999  0.0169\n",
            "     78        0.9999  0.0173\n",
            "     79        0.9999  0.0178\n",
            "     80        0.9999  0.0192\n",
            "     81        0.9999  0.0174\n",
            "     82        0.9999  0.0171\n",
            "     83        0.9999  0.0168\n",
            "     84        0.9999  0.0170\n",
            "     85        0.9999  0.0170\n",
            "     86        0.9999  0.0170\n",
            "     87        0.9999  0.0169\n",
            "     88        0.9999  0.0174\n",
            "     89        0.9999  0.0177\n",
            "     90        0.9999  0.0205\n",
            "     91        0.9999  0.0200\n",
            "     92        0.9999  0.0197\n",
            "     93        0.9999  0.0165\n",
            "     94        0.9999  0.0175\n",
            "     95        \u001b[36m0.9999\u001b[0m  0.0185\n",
            "     96        \u001b[36m0.9999\u001b[0m  0.0188\n",
            "     97        0.9999  0.0187\n",
            "     98        0.9999  0.0188\n",
            "     99        0.9999  0.0191\n",
            "    100        0.9999  0.0170\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9999\u001b[0m  0.0190\n",
            "      2        0.9999  0.0192\n",
            "      3        0.9999  0.0184\n",
            "      4        0.9999  0.0188\n",
            "      5        \u001b[36m0.9999\u001b[0m  0.0164\n",
            "      6        \u001b[36m0.9999\u001b[0m  0.0172\n",
            "      7        0.9999  0.0161\n",
            "      8        0.9999  0.0176\n",
            "      9        0.9999  0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        0.9999  0.0189\n",
            "     11        0.9999  0.0173\n",
            "     12        0.9999  0.0169\n",
            "     13        0.9999  0.0166\n",
            "     14        0.9999  0.0168\n",
            "     15        0.9999  0.0159\n",
            "     16        0.9999  0.0163\n",
            "     17        0.9999  0.0169\n",
            "     18        0.9999  0.0169\n",
            "     19        0.9999  0.0162\n",
            "     20        0.9999  0.0168\n",
            "     21        0.9999  0.0171\n",
            "     22        0.9999  0.0209\n",
            "     23        0.9999  0.0210\n",
            "     24        0.9999  0.0238\n",
            "     25        0.9999  0.0193\n",
            "     26        0.9999  0.0182\n",
            "     27        0.9999  0.0178\n",
            "     28        0.9999  0.0198\n",
            "     29        0.9999  0.0198\n",
            "     30        0.9999  0.0181\n",
            "     31        0.9999  0.0179\n",
            "     32        0.9999  0.0172\n",
            "     33        0.9999  0.0179\n",
            "     34        0.9999  0.0163\n",
            "     35        0.9999  0.0167\n",
            "     36        0.9999  0.0200\n",
            "     37        0.9999  0.0195\n",
            "     38        0.9999  0.0174\n",
            "     39        0.9999  0.0207\n",
            "     40        0.9999  0.0201\n",
            "     41        0.9999  0.0207\n",
            "     42        0.9999  0.0205\n",
            "     43        0.9999  0.0203\n",
            "     44        0.9999  0.0204\n",
            "     45        0.9999  0.0192\n",
            "     46        0.9999  0.0189\n",
            "     47        0.9999  0.0203\n",
            "     48        0.9999  0.0201\n",
            "     49        0.9999  0.0206\n",
            "     50        0.9999  0.0161\n",
            "     51        0.9999  0.0161\n",
            "     52        0.9999  0.0181\n",
            "     53        0.9999  0.0187\n",
            "     54        0.9999  0.0182\n",
            "     55        0.9999  0.0187\n",
            "     56        0.9999  0.0185\n",
            "     57        0.9999  0.0174\n",
            "     58        0.9999  0.0170\n",
            "     59        0.9999  0.0178\n",
            "     60        0.9999  0.0189\n",
            "     61        0.9999  0.0180\n",
            "     62        0.9999  0.0175\n",
            "     63        0.9999  0.0182\n",
            "     64        0.9999  0.0168\n",
            "     65        0.9999  0.0180\n",
            "     66        0.9999  0.0175\n",
            "     67        0.9999  0.0177\n",
            "     68        0.9999  0.0166\n",
            "     69        0.9999  0.0177\n",
            "     70        0.9999  0.0176\n",
            "     71        0.9999  0.0227\n",
            "     72        0.9999  0.0234\n",
            "     73        \u001b[36m0.9999\u001b[0m  0.0207\n",
            "     74        0.9999  0.0202\n",
            "     75        0.9999  0.0163\n",
            "     76        0.9999  0.0196\n",
            "     77        0.9999  0.0179\n",
            "     78        0.9999  0.0175\n",
            "     79        0.9999  0.0177\n",
            "     80        0.9999  0.0176\n",
            "     81        0.9999  0.0174\n",
            "     82        0.9999  0.0168\n",
            "     83        0.9999  0.0178\n",
            "     84        0.9999  0.0203\n",
            "     85        0.9999  0.0201\n",
            "     86        0.9999  0.0205\n",
            "     87        0.9999  0.0195\n",
            "     88        0.9999  0.0197\n",
            "     89        0.9999  0.0202\n",
            "     90        0.9999  0.0201\n",
            "     91        0.9999  0.0210\n",
            "     92        0.9999  0.0200\n",
            "     93        0.9999  0.0204\n",
            "     94        0.9999  0.0187\n",
            "     95        0.9999  0.0188\n",
            "     96        0.9999  0.0204\n",
            "     97        0.9999  0.0202\n",
            "     98        0.9999  0.0173\n",
            "     99        0.9999  0.0181\n",
            "    100        0.9999  0.0171\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7423\u001b[0m  0.0228\n",
            "      2        \u001b[36m0.7172\u001b[0m  0.0227\n",
            "      3        \u001b[36m0.6898\u001b[0m  0.0220\n",
            "      4        \u001b[36m0.6605\u001b[0m  0.0228\n",
            "      5        \u001b[36m0.6333\u001b[0m  0.0229\n",
            "      6        \u001b[36m0.6087\u001b[0m  0.0223\n",
            "      7        \u001b[36m0.5845\u001b[0m  0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5624\u001b[0m  0.0245\n",
            "      9        \u001b[36m0.5430\u001b[0m  0.0222\n",
            "     10        \u001b[36m0.5264\u001b[0m  0.0221\n",
            "     11        \u001b[36m0.5111\u001b[0m  0.0220\n",
            "     12        \u001b[36m0.4980\u001b[0m  0.0222\n",
            "     13        \u001b[36m0.4876\u001b[0m  0.0221\n",
            "     14        \u001b[36m0.4789\u001b[0m  0.0224\n",
            "     15        \u001b[36m0.4715\u001b[0m  0.0232\n",
            "     16        \u001b[36m0.4653\u001b[0m  0.0237\n",
            "     17        \u001b[36m0.4598\u001b[0m  0.0231\n",
            "     18        \u001b[36m0.4550\u001b[0m  0.0322\n",
            "     19        \u001b[36m0.4507\u001b[0m  0.0217\n",
            "     20        \u001b[36m0.4469\u001b[0m  0.0207\n",
            "     21        \u001b[36m0.4435\u001b[0m  0.0203\n",
            "     22        \u001b[36m0.4407\u001b[0m  0.0207\n",
            "     23        \u001b[36m0.4376\u001b[0m  0.0255\n",
            "     24        \u001b[36m0.4350\u001b[0m  0.0231\n",
            "     25        \u001b[36m0.4326\u001b[0m  0.0234\n",
            "     26        \u001b[36m0.4304\u001b[0m  0.0235\n",
            "     27        \u001b[36m0.4284\u001b[0m  0.0251\n",
            "     28        \u001b[36m0.4264\u001b[0m  0.0245\n",
            "     29        \u001b[36m0.4246\u001b[0m  0.0244\n",
            "     30        \u001b[36m0.4228\u001b[0m  0.0223\n",
            "     31        \u001b[36m0.4211\u001b[0m  0.0247\n",
            "     32        \u001b[36m0.4195\u001b[0m  0.0223\n",
            "     33        \u001b[36m0.4180\u001b[0m  0.0215\n",
            "     34        \u001b[36m0.4164\u001b[0m  0.0244\n",
            "     35        \u001b[36m0.4150\u001b[0m  0.0224\n",
            "     36        \u001b[36m0.4136\u001b[0m  0.0218\n",
            "     37        \u001b[36m0.4123\u001b[0m  0.0215\n",
            "     38        \u001b[36m0.4110\u001b[0m  0.0213\n",
            "     39        \u001b[36m0.4070\u001b[0m  0.0252\n",
            "     40        \u001b[36m0.4031\u001b[0m  0.0225\n",
            "     41        \u001b[36m0.4021\u001b[0m  0.0217\n",
            "     42        \u001b[36m0.4012\u001b[0m  0.0226\n",
            "     43        \u001b[36m0.4003\u001b[0m  0.0210\n",
            "     44        \u001b[36m0.3995\u001b[0m  0.0208\n",
            "     45        \u001b[36m0.3987\u001b[0m  0.0217\n",
            "     46        \u001b[36m0.3980\u001b[0m  0.0218\n",
            "     47        \u001b[36m0.3973\u001b[0m  0.0221\n",
            "     48        \u001b[36m0.3966\u001b[0m  0.0214\n",
            "     49        \u001b[36m0.3960\u001b[0m  0.0219\n",
            "     50        \u001b[36m0.3954\u001b[0m  0.0221\n",
            "     51        \u001b[36m0.3948\u001b[0m  0.0232\n",
            "     52        \u001b[36m0.3943\u001b[0m  0.0223\n",
            "     53        \u001b[36m0.3937\u001b[0m  0.0217\n",
            "     54        \u001b[36m0.3932\u001b[0m  0.0221\n",
            "     55        \u001b[36m0.3927\u001b[0m  0.0201\n",
            "     56        \u001b[36m0.3923\u001b[0m  0.0222\n",
            "     57        \u001b[36m0.3918\u001b[0m  0.0222\n",
            "     58        \u001b[36m0.3914\u001b[0m  0.0246\n",
            "     59        \u001b[36m0.3909\u001b[0m  0.0285\n",
            "     60        \u001b[36m0.3905\u001b[0m  0.0227\n",
            "     61        \u001b[36m0.3901\u001b[0m  0.0208\n",
            "     62        \u001b[36m0.3897\u001b[0m  0.0247\n",
            "     63        \u001b[36m0.3893\u001b[0m  0.0260\n",
            "     64        \u001b[36m0.3889\u001b[0m  0.0257\n",
            "     65        \u001b[36m0.3886\u001b[0m  0.0259\n",
            "     66        \u001b[36m0.3882\u001b[0m  0.0253\n",
            "     67        \u001b[36m0.3879\u001b[0m  0.0256\n",
            "     68        \u001b[36m0.3876\u001b[0m  0.0250\n",
            "     69        \u001b[36m0.3872\u001b[0m  0.0248\n",
            "     70        \u001b[36m0.3869\u001b[0m  0.0226\n",
            "     71        \u001b[36m0.3865\u001b[0m  0.0244\n",
            "     72        \u001b[36m0.3862\u001b[0m  0.0232\n",
            "     73        \u001b[36m0.3860\u001b[0m  0.0241\n",
            "     74        \u001b[36m0.3857\u001b[0m  0.0211\n",
            "     75        \u001b[36m0.3854\u001b[0m  0.0218\n",
            "     76        \u001b[36m0.3852\u001b[0m  0.0217\n",
            "     77        \u001b[36m0.3849\u001b[0m  0.0215\n",
            "     78        \u001b[36m0.3847\u001b[0m  0.0240\n",
            "     79        \u001b[36m0.3844\u001b[0m  0.0239\n",
            "     80        \u001b[36m0.3842\u001b[0m  0.0225\n",
            "     81        \u001b[36m0.3840\u001b[0m  0.0217\n",
            "     82        \u001b[36m0.3837\u001b[0m  0.0213\n",
            "     83        \u001b[36m0.3835\u001b[0m  0.0212\n",
            "     84        \u001b[36m0.3833\u001b[0m  0.0209\n",
            "     85        \u001b[36m0.3831\u001b[0m  0.0212\n",
            "     86        \u001b[36m0.3829\u001b[0m  0.0211\n",
            "     87        \u001b[36m0.3827\u001b[0m  0.0209\n",
            "     88        \u001b[36m0.3825\u001b[0m  0.0209\n",
            "     89        \u001b[36m0.3824\u001b[0m  0.0216\n",
            "     90        \u001b[36m0.3822\u001b[0m  0.0213\n",
            "     91        \u001b[36m0.3820\u001b[0m  0.0221\n",
            "     92        \u001b[36m0.3818\u001b[0m  0.0220\n",
            "     93        \u001b[36m0.3817\u001b[0m  0.0223\n",
            "     94        \u001b[36m0.3815\u001b[0m  0.0206\n",
            "     95        \u001b[36m0.3814\u001b[0m  0.0215\n",
            "     96        \u001b[36m0.3812\u001b[0m  0.0222\n",
            "     97        \u001b[36m0.3810\u001b[0m  0.0210\n",
            "     98        \u001b[36m0.3808\u001b[0m  0.0278\n",
            "     99        \u001b[36m0.3806\u001b[0m  0.0243\n",
            "    100        \u001b[36m0.3803\u001b[0m  0.0288\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6880\u001b[0m  0.0238\n",
            "      2        \u001b[36m0.6651\u001b[0m  0.0240\n",
            "      3        \u001b[36m0.6437\u001b[0m  0.0240\n",
            "      4        \u001b[36m0.6274\u001b[0m  0.0257\n",
            "      5        \u001b[36m0.6130\u001b[0m  0.0249\n",
            "      6        \u001b[36m0.6023\u001b[0m  0.0249\n",
            "      7        \u001b[36m0.5921\u001b[0m  0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5815\u001b[0m  0.0285\n",
            "      9        \u001b[36m0.5718\u001b[0m  0.0238\n",
            "     10        \u001b[36m0.5628\u001b[0m  0.0224\n",
            "     11        \u001b[36m0.5546\u001b[0m  0.0243\n",
            "     12        \u001b[36m0.5469\u001b[0m  0.0213\n",
            "     13        \u001b[36m0.5393\u001b[0m  0.0201\n",
            "     14        \u001b[36m0.5320\u001b[0m  0.0225\n",
            "     15        \u001b[36m0.5257\u001b[0m  0.0224\n",
            "     16        \u001b[36m0.5192\u001b[0m  0.0231\n",
            "     17        \u001b[36m0.5126\u001b[0m  0.0205\n",
            "     18        \u001b[36m0.5065\u001b[0m  0.0231\n",
            "     19        \u001b[36m0.5005\u001b[0m  0.0215\n",
            "     20        \u001b[36m0.4945\u001b[0m  0.0215\n",
            "     21        \u001b[36m0.4893\u001b[0m  0.0222\n",
            "     22        \u001b[36m0.4842\u001b[0m  0.0205\n",
            "     23        \u001b[36m0.4793\u001b[0m  0.0209\n",
            "     24        \u001b[36m0.4746\u001b[0m  0.0220\n",
            "     25        \u001b[36m0.4701\u001b[0m  0.0225\n",
            "     26        \u001b[36m0.4658\u001b[0m  0.0234\n",
            "     27        \u001b[36m0.4610\u001b[0m  0.0216\n",
            "     28        \u001b[36m0.4564\u001b[0m  0.0223\n",
            "     29        \u001b[36m0.4529\u001b[0m  0.0220\n",
            "     30        \u001b[36m0.4495\u001b[0m  0.0221\n",
            "     31        \u001b[36m0.4458\u001b[0m  0.0206\n",
            "     32        \u001b[36m0.4429\u001b[0m  0.0219\n",
            "     33        \u001b[36m0.4401\u001b[0m  0.0268\n",
            "     34        \u001b[36m0.4376\u001b[0m  0.0278\n",
            "     35        \u001b[36m0.4352\u001b[0m  0.0238\n",
            "     36        \u001b[36m0.4329\u001b[0m  0.0220\n",
            "     37        \u001b[36m0.4309\u001b[0m  0.0281\n",
            "     38        \u001b[36m0.4289\u001b[0m  0.0293\n",
            "     39        \u001b[36m0.4271\u001b[0m  0.0344\n",
            "     40        \u001b[36m0.4255\u001b[0m  0.0311\n",
            "     41        \u001b[36m0.4239\u001b[0m  0.0335\n",
            "     42        \u001b[36m0.4225\u001b[0m  0.0240\n",
            "     43        \u001b[36m0.4211\u001b[0m  0.0236\n",
            "     44        \u001b[36m0.4198\u001b[0m  0.0254\n",
            "     45        \u001b[36m0.4186\u001b[0m  0.0242\n",
            "     46        \u001b[36m0.4174\u001b[0m  0.0227\n",
            "     47        \u001b[36m0.4163\u001b[0m  0.0289\n",
            "     48        \u001b[36m0.4153\u001b[0m  0.0236\n",
            "     49        \u001b[36m0.4142\u001b[0m  0.0250\n",
            "     50        \u001b[36m0.4133\u001b[0m  0.0250\n",
            "     51        \u001b[36m0.4123\u001b[0m  0.0247\n",
            "     52        \u001b[36m0.4114\u001b[0m  0.0275\n",
            "     53        \u001b[36m0.4102\u001b[0m  0.0220\n",
            "     54        \u001b[36m0.4094\u001b[0m  0.0255\n",
            "     55        \u001b[36m0.4086\u001b[0m  0.0228\n",
            "     56        \u001b[36m0.4078\u001b[0m  0.0221\n",
            "     57        \u001b[36m0.4071\u001b[0m  0.0210\n",
            "     58        \u001b[36m0.4063\u001b[0m  0.0215\n",
            "     59        \u001b[36m0.4056\u001b[0m  0.0216\n",
            "     60        \u001b[36m0.4050\u001b[0m  0.0232\n",
            "     61        \u001b[36m0.4043\u001b[0m  0.0263\n",
            "     62        \u001b[36m0.4037\u001b[0m  0.0257\n",
            "     63        \u001b[36m0.4031\u001b[0m  0.0258\n",
            "     64        \u001b[36m0.4025\u001b[0m  0.0249\n",
            "     65        \u001b[36m0.4019\u001b[0m  0.0262\n",
            "     66        \u001b[36m0.4014\u001b[0m  0.0253\n",
            "     67        \u001b[36m0.4008\u001b[0m  0.0254\n",
            "     68        \u001b[36m0.4001\u001b[0m  0.0294\n",
            "     69        \u001b[36m0.3991\u001b[0m  0.0279\n",
            "     70        \u001b[36m0.3987\u001b[0m  0.0267\n",
            "     71        \u001b[36m0.3982\u001b[0m  0.0227\n",
            "     72        \u001b[36m0.3977\u001b[0m  0.0218\n",
            "     73        \u001b[36m0.3973\u001b[0m  0.0238\n",
            "     74        \u001b[36m0.3969\u001b[0m  0.0223\n",
            "     75        \u001b[36m0.3965\u001b[0m  0.0241\n",
            "     76        \u001b[36m0.3961\u001b[0m  0.0241\n",
            "     77        \u001b[36m0.3957\u001b[0m  0.0248\n",
            "     78        \u001b[36m0.3953\u001b[0m  0.0287\n",
            "     79        \u001b[36m0.3949\u001b[0m  0.0310\n",
            "     80        \u001b[36m0.3945\u001b[0m  0.0317\n",
            "     81        \u001b[36m0.3941\u001b[0m  0.0252\n",
            "     82        \u001b[36m0.3938\u001b[0m  0.0240\n",
            "     83        \u001b[36m0.3934\u001b[0m  0.0228\n",
            "     84        \u001b[36m0.3931\u001b[0m  0.0263\n",
            "     85        \u001b[36m0.3927\u001b[0m  0.0233\n",
            "     86        \u001b[36m0.3924\u001b[0m  0.0223\n",
            "     87        \u001b[36m0.3920\u001b[0m  0.0270\n",
            "     88        \u001b[36m0.3917\u001b[0m  0.0258\n",
            "     89        \u001b[36m0.3914\u001b[0m  0.0232\n",
            "     90        \u001b[36m0.3910\u001b[0m  0.0233\n",
            "     91        \u001b[36m0.3907\u001b[0m  0.0232\n",
            "     92        \u001b[36m0.3904\u001b[0m  0.0225\n",
            "     93        \u001b[36m0.3901\u001b[0m  0.0215\n",
            "     94        \u001b[36m0.3898\u001b[0m  0.0214\n",
            "     95        \u001b[36m0.3894\u001b[0m  0.0217\n",
            "     96        \u001b[36m0.3891\u001b[0m  0.0209\n",
            "     97        \u001b[36m0.3888\u001b[0m  0.0206\n",
            "     98        \u001b[36m0.3885\u001b[0m  0.0203\n",
            "     99        \u001b[36m0.3882\u001b[0m  0.0211\n",
            "    100        \u001b[36m0.3879\u001b[0m  0.0214\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9741\u001b[0m  0.0154\n",
            "      2        \u001b[36m0.9740\u001b[0m  0.0166\n",
            "      3        \u001b[36m0.9740\u001b[0m  0.0171\n",
            "      4        \u001b[36m0.9740\u001b[0m  0.0167\n",
            "      5        \u001b[36m0.9739\u001b[0m  0.0170\n",
            "      6        \u001b[36m0.9739\u001b[0m  0.0174\n",
            "      7        \u001b[36m0.9739\u001b[0m  0.0158\n",
            "      8        \u001b[36m0.9738\u001b[0m  0.0172\n",
            "      9        \u001b[36m0.9738\u001b[0m  0.0175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.9738\u001b[0m  0.0171\n",
            "     11        \u001b[36m0.9737\u001b[0m  0.0174\n",
            "     12        \u001b[36m0.9737\u001b[0m  0.0165\n",
            "     13        \u001b[36m0.9737\u001b[0m  0.0186\n",
            "     14        \u001b[36m0.9736\u001b[0m  0.0193\n",
            "     15        \u001b[36m0.9736\u001b[0m  0.0191\n",
            "     16        \u001b[36m0.9736\u001b[0m  0.0187\n",
            "     17        \u001b[36m0.9735\u001b[0m  0.0188\n",
            "     18        \u001b[36m0.9735\u001b[0m  0.0198\n",
            "     19        \u001b[36m0.9735\u001b[0m  0.0195\n",
            "     20        \u001b[36m0.9734\u001b[0m  0.0193\n",
            "     21        \u001b[36m0.9734\u001b[0m  0.0170\n",
            "     22        \u001b[36m0.9734\u001b[0m  0.0179\n",
            "     23        \u001b[36m0.9733\u001b[0m  0.0209\n",
            "     24        \u001b[36m0.9733\u001b[0m  0.0166\n",
            "     25        \u001b[36m0.9733\u001b[0m  0.0195\n",
            "     26        \u001b[36m0.9732\u001b[0m  0.0224\n",
            "     27        \u001b[36m0.9732\u001b[0m  0.0215\n",
            "     28        \u001b[36m0.9731\u001b[0m  0.0163\n",
            "     29        \u001b[36m0.9731\u001b[0m  0.0161\n",
            "     30        \u001b[36m0.9731\u001b[0m  0.0166\n",
            "     31        \u001b[36m0.9730\u001b[0m  0.0168\n",
            "     32        \u001b[36m0.9730\u001b[0m  0.0168\n",
            "     33        \u001b[36m0.9730\u001b[0m  0.0169\n",
            "     34        \u001b[36m0.9729\u001b[0m  0.0154\n",
            "     35        \u001b[36m0.9729\u001b[0m  0.0157\n",
            "     36        \u001b[36m0.9729\u001b[0m  0.0170\n",
            "     37        \u001b[36m0.9728\u001b[0m  0.0160\n",
            "     38        \u001b[36m0.9728\u001b[0m  0.0176\n",
            "     39        \u001b[36m0.9728\u001b[0m  0.0172\n",
            "     40        \u001b[36m0.9727\u001b[0m  0.0168\n",
            "     41        \u001b[36m0.9727\u001b[0m  0.0157\n",
            "     42        \u001b[36m0.9726\u001b[0m  0.0162\n",
            "     43        \u001b[36m0.9726\u001b[0m  0.0169\n",
            "     44        \u001b[36m0.9726\u001b[0m  0.0171\n",
            "     45        \u001b[36m0.9725\u001b[0m  0.0167\n",
            "     46        \u001b[36m0.9725\u001b[0m  0.0170\n",
            "     47        \u001b[36m0.9725\u001b[0m  0.0170\n",
            "     48        \u001b[36m0.9724\u001b[0m  0.0165\n",
            "     49        \u001b[36m0.9724\u001b[0m  0.0172\n",
            "     50        \u001b[36m0.9724\u001b[0m  0.0170\n",
            "     51        \u001b[36m0.9723\u001b[0m  0.0169\n",
            "     52        \u001b[36m0.9723\u001b[0m  0.0166\n",
            "     53        \u001b[36m0.9722\u001b[0m  0.0165\n",
            "     54        \u001b[36m0.9722\u001b[0m  0.0160\n",
            "     55        \u001b[36m0.9722\u001b[0m  0.0173\n",
            "     56        \u001b[36m0.9721\u001b[0m  0.0165\n",
            "     57        \u001b[36m0.9721\u001b[0m  0.0176\n",
            "     58        \u001b[36m0.9721\u001b[0m  0.0172\n",
            "     59        \u001b[36m0.9720\u001b[0m  0.0175\n",
            "     60        \u001b[36m0.9720\u001b[0m  0.0160\n",
            "     61        \u001b[36m0.9719\u001b[0m  0.0171\n",
            "     62        \u001b[36m0.9719\u001b[0m  0.0174\n",
            "     63        \u001b[36m0.9719\u001b[0m  0.0250\n",
            "     64        \u001b[36m0.9718\u001b[0m  0.0186\n",
            "     65        \u001b[36m0.9718\u001b[0m  0.0201\n",
            "     66        \u001b[36m0.9718\u001b[0m  0.0233\n",
            "     67        \u001b[36m0.9717\u001b[0m  0.0208\n",
            "     68        \u001b[36m0.9717\u001b[0m  0.0193\n",
            "     69        \u001b[36m0.9716\u001b[0m  0.0202\n",
            "     70        \u001b[36m0.9716\u001b[0m  0.0199\n",
            "     71        \u001b[36m0.9716\u001b[0m  0.0201\n",
            "     72        \u001b[36m0.9715\u001b[0m  0.0243\n",
            "     73        \u001b[36m0.9715\u001b[0m  0.0240\n",
            "     74        \u001b[36m0.9714\u001b[0m  0.0209\n",
            "     75        \u001b[36m0.9714\u001b[0m  0.0239\n",
            "     76        \u001b[36m0.9714\u001b[0m  0.0172\n",
            "     77        \u001b[36m0.9713\u001b[0m  0.0229\n",
            "     78        \u001b[36m0.9713\u001b[0m  0.0199\n",
            "     79        \u001b[36m0.9713\u001b[0m  0.0165\n",
            "     80        \u001b[36m0.9712\u001b[0m  0.0181\n",
            "     81        \u001b[36m0.9712\u001b[0m  0.0209\n",
            "     82        \u001b[36m0.9711\u001b[0m  0.0187\n",
            "     83        \u001b[36m0.9711\u001b[0m  0.0170\n",
            "     84        \u001b[36m0.9711\u001b[0m  0.0173\n",
            "     85        \u001b[36m0.9710\u001b[0m  0.0182\n",
            "     86        \u001b[36m0.9710\u001b[0m  0.0172\n",
            "     87        \u001b[36m0.9709\u001b[0m  0.0172\n",
            "     88        \u001b[36m0.9709\u001b[0m  0.0173\n",
            "     89        \u001b[36m0.9708\u001b[0m  0.0227\n",
            "     90        \u001b[36m0.9708\u001b[0m  0.0221\n",
            "     91        \u001b[36m0.9708\u001b[0m  0.0200\n",
            "     92        \u001b[36m0.9707\u001b[0m  0.0201\n",
            "     93        \u001b[36m0.9707\u001b[0m  0.0199\n",
            "     94        \u001b[36m0.9706\u001b[0m  0.0206\n",
            "     95        \u001b[36m0.9706\u001b[0m  0.0242\n",
            "     96        \u001b[36m0.9706\u001b[0m  0.0232\n",
            "     97        \u001b[36m0.9705\u001b[0m  0.0193\n",
            "     98        \u001b[36m0.9705\u001b[0m  0.0225\n",
            "     99        \u001b[36m0.9704\u001b[0m  0.0244\n",
            "    100        \u001b[36m0.9704\u001b[0m  0.0223\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7110\u001b[0m  0.0199\n",
            "      2        \u001b[36m0.7091\u001b[0m  0.0206\n",
            "      3        \u001b[36m0.7077\u001b[0m  0.0275\n",
            "      4        \u001b[36m0.7063\u001b[0m  0.0230\n",
            "      5        \u001b[36m0.7049\u001b[0m  0.0266\n",
            "      6        \u001b[36m0.7035\u001b[0m  0.0241\n",
            "      7        \u001b[36m0.7021\u001b[0m  0.0296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.7007\u001b[0m  0.0222\n",
            "      9        \u001b[36m0.6993\u001b[0m  0.0271\n",
            "     10        \u001b[36m0.6979\u001b[0m  0.0266\n",
            "     11        \u001b[36m0.6965\u001b[0m  0.0235\n",
            "     12        \u001b[36m0.6951\u001b[0m  0.0186\n",
            "     13        \u001b[36m0.6937\u001b[0m  0.0198\n",
            "     14        \u001b[36m0.6923\u001b[0m  0.0184\n",
            "     15        \u001b[36m0.6909\u001b[0m  0.0200\n",
            "     16        \u001b[36m0.6895\u001b[0m  0.0246\n",
            "     17        \u001b[36m0.6881\u001b[0m  0.0198\n",
            "     18        \u001b[36m0.6867\u001b[0m  0.0255\n",
            "     19        \u001b[36m0.6853\u001b[0m  0.0266\n",
            "     20        \u001b[36m0.6839\u001b[0m  0.0285\n",
            "     21        \u001b[36m0.6824\u001b[0m  0.0242\n",
            "     22        \u001b[36m0.6810\u001b[0m  0.0193\n",
            "     23        \u001b[36m0.6796\u001b[0m  0.0227\n",
            "     24        \u001b[36m0.6782\u001b[0m  0.0257\n",
            "     25        \u001b[36m0.6768\u001b[0m  0.0215\n",
            "     26        \u001b[36m0.6754\u001b[0m  0.0240\n",
            "     27        \u001b[36m0.6739\u001b[0m  0.0256\n",
            "     28        \u001b[36m0.6725\u001b[0m  0.0213\n",
            "     29        \u001b[36m0.6711\u001b[0m  0.0274\n",
            "     30        \u001b[36m0.6697\u001b[0m  0.0274\n",
            "     31        \u001b[36m0.6683\u001b[0m  0.0254\n",
            "     32        \u001b[36m0.6669\u001b[0m  0.0178\n",
            "     33        \u001b[36m0.6655\u001b[0m  0.0271\n",
            "     34        \u001b[36m0.6640\u001b[0m  0.0192\n",
            "     35        \u001b[36m0.6626\u001b[0m  0.0219\n",
            "     36        \u001b[36m0.6612\u001b[0m  0.0251\n",
            "     37        \u001b[36m0.6598\u001b[0m  0.0196\n",
            "     38        \u001b[36m0.6584\u001b[0m  0.0220\n",
            "     39        \u001b[36m0.6570\u001b[0m  0.0244\n",
            "     40        \u001b[36m0.6556\u001b[0m  0.0224\n",
            "     41        \u001b[36m0.6542\u001b[0m  0.0169\n",
            "     42        \u001b[36m0.6528\u001b[0m  0.0195\n",
            "     43        \u001b[36m0.6514\u001b[0m  0.0241\n",
            "     44        \u001b[36m0.6500\u001b[0m  0.0221\n",
            "     45        \u001b[36m0.6487\u001b[0m  0.0260\n",
            "     46        \u001b[36m0.6473\u001b[0m  0.0232\n",
            "     47        \u001b[36m0.6459\u001b[0m  0.0247\n",
            "     48        \u001b[36m0.6445\u001b[0m  0.0256\n",
            "     49        \u001b[36m0.6431\u001b[0m  0.0182\n",
            "     50        \u001b[36m0.6418\u001b[0m  0.0281\n",
            "     51        \u001b[36m0.6404\u001b[0m  0.0246\n",
            "     52        \u001b[36m0.6390\u001b[0m  0.0223\n",
            "     53        \u001b[36m0.6377\u001b[0m  0.0206\n",
            "     54        \u001b[36m0.6363\u001b[0m  0.0182\n",
            "     55        \u001b[36m0.6350\u001b[0m  0.0178\n",
            "     56        \u001b[36m0.6336\u001b[0m  0.0169\n",
            "     57        \u001b[36m0.6323\u001b[0m  0.0179\n",
            "     58        \u001b[36m0.6310\u001b[0m  0.0169\n",
            "     59        \u001b[36m0.6296\u001b[0m  0.0169\n",
            "     60        \u001b[36m0.6283\u001b[0m  0.0211\n",
            "     61        \u001b[36m0.6270\u001b[0m  0.0182\n",
            "     62        \u001b[36m0.6257\u001b[0m  0.0188\n",
            "     63        \u001b[36m0.6244\u001b[0m  0.0158\n",
            "     64        \u001b[36m0.6231\u001b[0m  0.0174\n",
            "     65        \u001b[36m0.6218\u001b[0m  0.0174\n",
            "     66        \u001b[36m0.6205\u001b[0m  0.0169\n",
            "     67        \u001b[36m0.6192\u001b[0m  0.0179\n",
            "     68        \u001b[36m0.6179\u001b[0m  0.0170\n",
            "     69        \u001b[36m0.6166\u001b[0m  0.0166\n",
            "     70        \u001b[36m0.6153\u001b[0m  0.0169\n",
            "     71        \u001b[36m0.6141\u001b[0m  0.0175\n",
            "     72        \u001b[36m0.6128\u001b[0m  0.0173\n",
            "     73        \u001b[36m0.6116\u001b[0m  0.0171\n",
            "     74        \u001b[36m0.6103\u001b[0m  0.0177\n",
            "     75        \u001b[36m0.6091\u001b[0m  0.0170\n",
            "     76        \u001b[36m0.6078\u001b[0m  0.0171\n",
            "     77        \u001b[36m0.6066\u001b[0m  0.0159\n",
            "     78        \u001b[36m0.6054\u001b[0m  0.0179\n",
            "     79        \u001b[36m0.6042\u001b[0m  0.0175\n",
            "     80        \u001b[36m0.6030\u001b[0m  0.0178\n",
            "     81        \u001b[36m0.6018\u001b[0m  0.0184\n",
            "     82        \u001b[36m0.6006\u001b[0m  0.0182\n",
            "     83        \u001b[36m0.5994\u001b[0m  0.0174\n",
            "     84        \u001b[36m0.5982\u001b[0m  0.0174\n",
            "     85        \u001b[36m0.5970\u001b[0m  0.0207\n",
            "     86        \u001b[36m0.5958\u001b[0m  0.0189\n",
            "     87        \u001b[36m0.5947\u001b[0m  0.0169\n",
            "     88        \u001b[36m0.5935\u001b[0m  0.0177\n",
            "     89        \u001b[36m0.5924\u001b[0m  0.0188\n",
            "     90        \u001b[36m0.5912\u001b[0m  0.0186\n",
            "     91        \u001b[36m0.5901\u001b[0m  0.0186\n",
            "     92        \u001b[36m0.5890\u001b[0m  0.0192\n",
            "     93        \u001b[36m0.5878\u001b[0m  0.0183\n",
            "     94        \u001b[36m0.5867\u001b[0m  0.0188\n",
            "     95        \u001b[36m0.5856\u001b[0m  0.0216\n",
            "     96        \u001b[36m0.5845\u001b[0m  0.0206\n",
            "     97        \u001b[36m0.5834\u001b[0m  0.0196\n",
            "     98        \u001b[36m0.5823\u001b[0m  0.0192\n",
            "     99        \u001b[36m0.5813\u001b[0m  0.0177\n",
            "    100        \u001b[36m0.5802\u001b[0m  0.0205\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8853\u001b[0m  0.0225\n",
            "      2        \u001b[36m0.8497\u001b[0m  0.0231\n",
            "      3        \u001b[36m0.8081\u001b[0m  0.0237\n",
            "      4        \u001b[36m0.7526\u001b[0m  0.0212\n",
            "      5        \u001b[36m0.6901\u001b[0m  0.0237\n",
            "      6        \u001b[36m0.6371\u001b[0m  0.0287\n",
            "      7        \u001b[36m0.5871\u001b[0m  0.0331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.5530\u001b[0m  0.0225\n",
            "      9        \u001b[36m0.5170\u001b[0m  0.0209\n",
            "     10        \u001b[36m0.4910\u001b[0m  0.0201\n",
            "     11        \u001b[36m0.4675\u001b[0m  0.0216\n",
            "     12        \u001b[36m0.4475\u001b[0m  0.0207\n",
            "     13        \u001b[36m0.4341\u001b[0m  0.0216\n",
            "     14        \u001b[36m0.4236\u001b[0m  0.0219\n",
            "     15        \u001b[36m0.4174\u001b[0m  0.0202\n",
            "     16        \u001b[36m0.4128\u001b[0m  0.0214\n",
            "     17        \u001b[36m0.4093\u001b[0m  0.0215\n",
            "     18        \u001b[36m0.4065\u001b[0m  0.0208\n",
            "     19        \u001b[36m0.4051\u001b[0m  0.0237\n",
            "     20        \u001b[36m0.4018\u001b[0m  0.0212\n",
            "     21        \u001b[36m0.4004\u001b[0m  0.0218\n",
            "     22        \u001b[36m0.3993\u001b[0m  0.0212\n",
            "     23        \u001b[36m0.3982\u001b[0m  0.0217\n",
            "     24        \u001b[36m0.3973\u001b[0m  0.0215\n",
            "     25        \u001b[36m0.3965\u001b[0m  0.0211\n",
            "     26        \u001b[36m0.3957\u001b[0m  0.0242\n",
            "     27        \u001b[36m0.3950\u001b[0m  0.0246\n",
            "     28        \u001b[36m0.3943\u001b[0m  0.0246\n",
            "     29        \u001b[36m0.3937\u001b[0m  0.0269\n",
            "     30        \u001b[36m0.3931\u001b[0m  0.0242\n",
            "     31        \u001b[36m0.3906\u001b[0m  0.0240\n",
            "     32        \u001b[36m0.3901\u001b[0m  0.0238\n",
            "     33        \u001b[36m0.3896\u001b[0m  0.0228\n",
            "     34        \u001b[36m0.3891\u001b[0m  0.0211\n",
            "     35        \u001b[36m0.3886\u001b[0m  0.0214\n",
            "     36        \u001b[36m0.3881\u001b[0m  0.0210\n",
            "     37        \u001b[36m0.3877\u001b[0m  0.0216\n",
            "     38        \u001b[36m0.3872\u001b[0m  0.0223\n",
            "     39        0.3897  0.0236\n",
            "     40        0.3885  0.0212\n",
            "     41        0.3880  0.0209\n",
            "     42        0.3875  0.0235\n",
            "     43        0.3877  0.0211\n",
            "     44        \u001b[36m0.3866\u001b[0m  0.0208\n",
            "     45        \u001b[36m0.3844\u001b[0m  0.0202\n",
            "     46        \u001b[36m0.3839\u001b[0m  0.0211\n",
            "     47        \u001b[36m0.3835\u001b[0m  0.0212\n",
            "     48        \u001b[36m0.3831\u001b[0m  0.0231\n",
            "     49        \u001b[36m0.3827\u001b[0m  0.0288\n",
            "     50        \u001b[36m0.3822\u001b[0m  0.0251\n",
            "     51        \u001b[36m0.3819\u001b[0m  0.0198\n",
            "     52        \u001b[36m0.3816\u001b[0m  0.0208\n",
            "     53        \u001b[36m0.3806\u001b[0m  0.0208\n",
            "     54        \u001b[36m0.3804\u001b[0m  0.0210\n",
            "     55        0.3806  0.0207\n",
            "     56        \u001b[36m0.3804\u001b[0m  0.0212\n",
            "     57        \u001b[36m0.3802\u001b[0m  0.0218\n",
            "     58        \u001b[36m0.3800\u001b[0m  0.0207\n",
            "     59        \u001b[36m0.3798\u001b[0m  0.0208\n",
            "     60        \u001b[36m0.3793\u001b[0m  0.0215\n",
            "     61        \u001b[36m0.3792\u001b[0m  0.0216\n",
            "     62        \u001b[36m0.3791\u001b[0m  0.0208\n",
            "     63        \u001b[36m0.3789\u001b[0m  0.0207\n",
            "     64        \u001b[36m0.3788\u001b[0m  0.0207\n",
            "     65        \u001b[36m0.3787\u001b[0m  0.0200\n",
            "     66        \u001b[36m0.3786\u001b[0m  0.0228\n",
            "     67        \u001b[36m0.3785\u001b[0m  0.0254\n",
            "     68        \u001b[36m0.3784\u001b[0m  0.0276\n",
            "     69        \u001b[36m0.3783\u001b[0m  0.0300\n",
            "     70        \u001b[36m0.3782\u001b[0m  0.0266\n",
            "     71        \u001b[36m0.3781\u001b[0m  0.0248\n",
            "     72        \u001b[36m0.3780\u001b[0m  0.0259\n",
            "     73        \u001b[36m0.3779\u001b[0m  0.0288\n",
            "     74        \u001b[36m0.3778\u001b[0m  0.0263\n",
            "     75        \u001b[36m0.3777\u001b[0m  0.0235\n",
            "     76        \u001b[36m0.3776\u001b[0m  0.0234\n",
            "     77        \u001b[36m0.3776\u001b[0m  0.0238\n",
            "     78        \u001b[36m0.3775\u001b[0m  0.0252\n",
            "     79        \u001b[36m0.3774\u001b[0m  0.0217\n",
            "     80        \u001b[36m0.3773\u001b[0m  0.0213\n",
            "     81        \u001b[36m0.3773\u001b[0m  0.0235\n",
            "     82        \u001b[36m0.3772\u001b[0m  0.0243\n",
            "     83        \u001b[36m0.3771\u001b[0m  0.0222\n",
            "     84        \u001b[36m0.3771\u001b[0m  0.0202\n",
            "     85        \u001b[36m0.3768\u001b[0m  0.0214\n",
            "     86        \u001b[36m0.3767\u001b[0m  0.0208\n",
            "     87        \u001b[36m0.3767\u001b[0m  0.0213\n",
            "     88        \u001b[36m0.3764\u001b[0m  0.0222\n",
            "     89        \u001b[36m0.3764\u001b[0m  0.0242\n",
            "     90        \u001b[36m0.3763\u001b[0m  0.0263\n",
            "     91        \u001b[36m0.3763\u001b[0m  0.0288\n",
            "     92        \u001b[36m0.3763\u001b[0m  0.0208\n",
            "     93        \u001b[36m0.3762\u001b[0m  0.0211\n",
            "     94        \u001b[36m0.3761\u001b[0m  0.0201\n",
            "     95        \u001b[36m0.3761\u001b[0m  0.0204\n",
            "     96        \u001b[36m0.3761\u001b[0m  0.0206\n",
            "     97        \u001b[36m0.3759\u001b[0m  0.0203\n",
            "     98        \u001b[36m0.3759\u001b[0m  0.0208\n",
            "     99        \u001b[36m0.3758\u001b[0m  0.0205\n",
            "    100        \u001b[36m0.3758\u001b[0m  0.0211\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.5191\u001b[0m  0.0210\n",
            "      2        \u001b[36m0.5019\u001b[0m  0.0200\n",
            "      3        \u001b[36m0.4906\u001b[0m  0.0203\n",
            "      4        \u001b[36m0.4836\u001b[0m  0.0242\n",
            "      5        \u001b[36m0.4785\u001b[0m  0.0239\n",
            "      6        \u001b[36m0.4750\u001b[0m  0.0244\n",
            "      7        \u001b[36m0.4701\u001b[0m  0.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.4676\u001b[0m  0.0256\n",
            "      9        \u001b[36m0.4656\u001b[0m  0.0254\n",
            "     10        \u001b[36m0.4638\u001b[0m  0.0241\n",
            "     11        \u001b[36m0.4622\u001b[0m  0.0246\n",
            "     12        \u001b[36m0.4607\u001b[0m  0.0207\n",
            "     13        \u001b[36m0.4600\u001b[0m  0.0240\n",
            "     14        0.4603  0.0210\n",
            "     15        \u001b[36m0.4594\u001b[0m  0.0228\n",
            "     16        \u001b[36m0.4562\u001b[0m  0.0206\n",
            "     17        \u001b[36m0.4554\u001b[0m  0.0234\n",
            "     18        \u001b[36m0.4520\u001b[0m  0.0215\n",
            "     19        \u001b[36m0.4513\u001b[0m  0.0212\n",
            "     20        \u001b[36m0.4503\u001b[0m  0.0224\n",
            "     21        \u001b[36m0.4497\u001b[0m  0.0209\n",
            "     22        \u001b[36m0.4491\u001b[0m  0.0226\n",
            "     23        \u001b[36m0.4458\u001b[0m  0.0203\n",
            "     24        \u001b[36m0.4452\u001b[0m  0.0221\n",
            "     25        \u001b[36m0.4444\u001b[0m  0.0207\n",
            "     26        \u001b[36m0.4439\u001b[0m  0.0205\n",
            "     27        \u001b[36m0.4434\u001b[0m  0.0208\n",
            "     28        \u001b[36m0.4429\u001b[0m  0.0208\n",
            "     29        \u001b[36m0.4423\u001b[0m  0.0212\n",
            "     30        \u001b[36m0.4418\u001b[0m  0.0206\n",
            "     31        \u001b[36m0.4413\u001b[0m  0.0211\n",
            "     32        \u001b[36m0.4408\u001b[0m  0.0221\n",
            "     33        \u001b[36m0.4401\u001b[0m  0.0308\n",
            "     34        \u001b[36m0.4391\u001b[0m  0.0205\n",
            "     35        \u001b[36m0.4377\u001b[0m  0.0209\n",
            "     36        \u001b[36m0.4351\u001b[0m  0.0202\n",
            "     37        \u001b[36m0.4298\u001b[0m  0.0207\n",
            "     38        \u001b[36m0.4192\u001b[0m  0.0203\n",
            "     39        \u001b[36m0.4054\u001b[0m  0.0215\n",
            "     40        \u001b[36m0.3950\u001b[0m  0.0211\n",
            "     41        \u001b[36m0.3891\u001b[0m  0.0209\n",
            "     42        \u001b[36m0.3865\u001b[0m  0.0207\n",
            "     43        \u001b[36m0.3849\u001b[0m  0.0207\n",
            "     44        \u001b[36m0.3840\u001b[0m  0.0240\n",
            "     45        \u001b[36m0.3834\u001b[0m  0.0236\n",
            "     46        \u001b[36m0.3829\u001b[0m  0.0241\n",
            "     47        \u001b[36m0.3825\u001b[0m  0.0240\n",
            "     48        \u001b[36m0.3820\u001b[0m  0.0250\n",
            "     49        \u001b[36m0.3817\u001b[0m  0.0235\n",
            "     50        \u001b[36m0.3814\u001b[0m  0.0233\n",
            "     51        \u001b[36m0.3811\u001b[0m  0.0239\n",
            "     52        \u001b[36m0.3808\u001b[0m  0.0214\n",
            "     53        \u001b[36m0.3805\u001b[0m  0.0234\n",
            "     54        \u001b[36m0.3802\u001b[0m  0.0230\n",
            "     55        \u001b[36m0.3799\u001b[0m  0.0208\n",
            "     56        \u001b[36m0.3796\u001b[0m  0.0207\n",
            "     57        \u001b[36m0.3793\u001b[0m  0.0198\n",
            "     58        \u001b[36m0.3789\u001b[0m  0.0218\n",
            "     59        \u001b[36m0.3786\u001b[0m  0.0205\n",
            "     60        \u001b[36m0.3782\u001b[0m  0.0213\n",
            "     61        \u001b[36m0.3779\u001b[0m  0.0221\n",
            "     62        \u001b[36m0.3776\u001b[0m  0.0205\n",
            "     63        \u001b[36m0.3774\u001b[0m  0.0212\n",
            "     64        \u001b[36m0.3771\u001b[0m  0.0223\n",
            "     65        \u001b[36m0.3769\u001b[0m  0.0204\n",
            "     66        \u001b[36m0.3767\u001b[0m  0.0206\n",
            "     67        \u001b[36m0.3765\u001b[0m  0.0203\n",
            "     68        \u001b[36m0.3755\u001b[0m  0.0210\n",
            "     69        \u001b[36m0.3753\u001b[0m  0.0206\n",
            "     70        \u001b[36m0.3751\u001b[0m  0.0213\n",
            "     71        \u001b[36m0.3749\u001b[0m  0.0207\n",
            "     72        \u001b[36m0.3748\u001b[0m  0.0206\n",
            "     73        \u001b[36m0.3746\u001b[0m  0.0200\n",
            "     74        \u001b[36m0.3745\u001b[0m  0.0204\n",
            "     75        \u001b[36m0.3743\u001b[0m  0.0270\n",
            "     76        \u001b[36m0.3742\u001b[0m  0.0296\n",
            "     77        \u001b[36m0.3741\u001b[0m  0.0203\n",
            "     78        \u001b[36m0.3739\u001b[0m  0.0206\n",
            "     79        \u001b[36m0.3738\u001b[0m  0.0203\n",
            "     80        \u001b[36m0.3738\u001b[0m  0.0202\n",
            "     81        \u001b[36m0.3737\u001b[0m  0.0220\n",
            "     82        \u001b[36m0.3736\u001b[0m  0.0202\n",
            "     83        \u001b[36m0.3735\u001b[0m  0.0205\n",
            "     84        \u001b[36m0.3735\u001b[0m  0.0220\n",
            "     85        \u001b[36m0.3734\u001b[0m  0.0237\n",
            "     86        \u001b[36m0.3734\u001b[0m  0.0235\n",
            "     87        \u001b[36m0.3733\u001b[0m  0.0237\n",
            "     88        0.3735  0.0226\n",
            "     89        0.3734  0.0240\n",
            "     90        0.3733  0.0254\n",
            "     91        \u001b[36m0.3733\u001b[0m  0.0242\n",
            "     92        \u001b[36m0.3733\u001b[0m  0.0207\n",
            "     93        \u001b[36m0.3732\u001b[0m  0.0240\n",
            "     94        \u001b[36m0.3732\u001b[0m  0.0250\n",
            "     95        \u001b[36m0.3731\u001b[0m  0.0220\n",
            "     96        \u001b[36m0.3731\u001b[0m  0.0201\n",
            "     97        \u001b[36m0.3731\u001b[0m  0.0212\n",
            "     98        \u001b[36m0.3731\u001b[0m  0.0219\n",
            "     99        \u001b[36m0.3730\u001b[0m  0.0210\n",
            "    100        0.3730  0.0208\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4526\u001b[0m  0.0162\n",
            "      2        \u001b[36m0.4452\u001b[0m  0.0156\n",
            "      3        0.4453  0.0159\n",
            "      4        \u001b[36m0.4452\u001b[0m  0.0174\n",
            "      5        \u001b[36m0.4451\u001b[0m  0.0174\n",
            "      6        \u001b[36m0.4449\u001b[0m  0.0177\n",
            "      7        \u001b[36m0.4448\u001b[0m  0.0157\n",
            "      8        \u001b[36m0.4447\u001b[0m  0.0162\n",
            "      9        \u001b[36m0.4446\u001b[0m  0.0157\n",
            "     10        \u001b[36m0.4445\u001b[0m  0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.4444\u001b[0m  0.0170\n",
            "     12        \u001b[36m0.4443\u001b[0m  0.0166\n",
            "     13        \u001b[36m0.4442\u001b[0m  0.0162\n",
            "     14        \u001b[36m0.4441\u001b[0m  0.0166\n",
            "     15        \u001b[36m0.4439\u001b[0m  0.0160\n",
            "     16        \u001b[36m0.4438\u001b[0m  0.0168\n",
            "     17        \u001b[36m0.4437\u001b[0m  0.0166\n",
            "     18        \u001b[36m0.4436\u001b[0m  0.0168\n",
            "     19        \u001b[36m0.4435\u001b[0m  0.0164\n",
            "     20        \u001b[36m0.4434\u001b[0m  0.0168\n",
            "     21        \u001b[36m0.4433\u001b[0m  0.0193\n",
            "     22        \u001b[36m0.4432\u001b[0m  0.0184\n",
            "     23        \u001b[36m0.4431\u001b[0m  0.0192\n",
            "     24        \u001b[36m0.4430\u001b[0m  0.0221\n",
            "     25        \u001b[36m0.4429\u001b[0m  0.0167\n",
            "     26        \u001b[36m0.4428\u001b[0m  0.0163\n",
            "     27        \u001b[36m0.4427\u001b[0m  0.0160\n",
            "     28        \u001b[36m0.4426\u001b[0m  0.0174\n",
            "     29        \u001b[36m0.4425\u001b[0m  0.0163\n",
            "     30        \u001b[36m0.4424\u001b[0m  0.0191\n",
            "     31        \u001b[36m0.4422\u001b[0m  0.0190\n",
            "     32        \u001b[36m0.4421\u001b[0m  0.0186\n",
            "     33        \u001b[36m0.4420\u001b[0m  0.0192\n",
            "     34        \u001b[36m0.4419\u001b[0m  0.0196\n",
            "     35        \u001b[36m0.4418\u001b[0m  0.0195\n",
            "     36        \u001b[36m0.4417\u001b[0m  0.0195\n",
            "     37        \u001b[36m0.4416\u001b[0m  0.0188\n",
            "     38        \u001b[36m0.4415\u001b[0m  0.0163\n",
            "     39        \u001b[36m0.4414\u001b[0m  0.0186\n",
            "     40        \u001b[36m0.4413\u001b[0m  0.0193\n",
            "     41        \u001b[36m0.4412\u001b[0m  0.0195\n",
            "     42        \u001b[36m0.4411\u001b[0m  0.0194\n",
            "     43        \u001b[36m0.4410\u001b[0m  0.0192\n",
            "     44        \u001b[36m0.4409\u001b[0m  0.0184\n",
            "     45        \u001b[36m0.4408\u001b[0m  0.0163\n",
            "     46        \u001b[36m0.4407\u001b[0m  0.0165\n",
            "     47        \u001b[36m0.4406\u001b[0m  0.0194\n",
            "     48        \u001b[36m0.4405\u001b[0m  0.0170\n",
            "     49        \u001b[36m0.4404\u001b[0m  0.0166\n",
            "     50        \u001b[36m0.4403\u001b[0m  0.0181\n",
            "     51        \u001b[36m0.4402\u001b[0m  0.0166\n",
            "     52        \u001b[36m0.4401\u001b[0m  0.0157\n",
            "     53        \u001b[36m0.4400\u001b[0m  0.0162\n",
            "     54        \u001b[36m0.4399\u001b[0m  0.0154\n",
            "     55        \u001b[36m0.4398\u001b[0m  0.0164\n",
            "     56        \u001b[36m0.4397\u001b[0m  0.0171\n",
            "     57        \u001b[36m0.4397\u001b[0m  0.0165\n",
            "     58        \u001b[36m0.4396\u001b[0m  0.0165\n",
            "     59        \u001b[36m0.4395\u001b[0m  0.0163\n",
            "     60        \u001b[36m0.4394\u001b[0m  0.0181\n",
            "     61        \u001b[36m0.4393\u001b[0m  0.0167\n",
            "     62        \u001b[36m0.4392\u001b[0m  0.0167\n",
            "     63        \u001b[36m0.4391\u001b[0m  0.0164\n",
            "     64        \u001b[36m0.4390\u001b[0m  0.0166\n",
            "     65        \u001b[36m0.4389\u001b[0m  0.0168\n",
            "     66        \u001b[36m0.4388\u001b[0m  0.0166\n",
            "     67        \u001b[36m0.4387\u001b[0m  0.0162\n",
            "     68        \u001b[36m0.4386\u001b[0m  0.0175\n",
            "     69        \u001b[36m0.4385\u001b[0m  0.0161\n",
            "     70        \u001b[36m0.4384\u001b[0m  0.0164\n",
            "     71        \u001b[36m0.4383\u001b[0m  0.0168\n",
            "     72        \u001b[36m0.4382\u001b[0m  0.0166\n",
            "     73        \u001b[36m0.4381\u001b[0m  0.0177\n",
            "     74        \u001b[36m0.4380\u001b[0m  0.0196\n",
            "     75        \u001b[36m0.4380\u001b[0m  0.0207\n",
            "     76        \u001b[36m0.4379\u001b[0m  0.0206\n",
            "     77        \u001b[36m0.4378\u001b[0m  0.0192\n",
            "     78        \u001b[36m0.4377\u001b[0m  0.0187\n",
            "     79        \u001b[36m0.4376\u001b[0m  0.0185\n",
            "     80        \u001b[36m0.4375\u001b[0m  0.0184\n",
            "     81        \u001b[36m0.4374\u001b[0m  0.0188\n",
            "     82        \u001b[36m0.4373\u001b[0m  0.0189\n",
            "     83        \u001b[36m0.4372\u001b[0m  0.0210\n",
            "     84        \u001b[36m0.4371\u001b[0m  0.0173\n",
            "     85        \u001b[36m0.4370\u001b[0m  0.0165\n",
            "     86        \u001b[36m0.4370\u001b[0m  0.0198\n",
            "     87        \u001b[36m0.4369\u001b[0m  0.0189\n",
            "     88        \u001b[36m0.4368\u001b[0m  0.0192\n",
            "     89        \u001b[36m0.4367\u001b[0m  0.0189\n",
            "     90        \u001b[36m0.4366\u001b[0m  0.0185\n",
            "     91        \u001b[36m0.4365\u001b[0m  0.0186\n",
            "     92        \u001b[36m0.4364\u001b[0m  0.0191\n",
            "     93        \u001b[36m0.4363\u001b[0m  0.0187\n",
            "     94        \u001b[36m0.4363\u001b[0m  0.0161\n",
            "     95        \u001b[36m0.4362\u001b[0m  0.0162\n",
            "     96        \u001b[36m0.4361\u001b[0m  0.0188\n",
            "     97        \u001b[36m0.4360\u001b[0m  0.0174\n",
            "     98        \u001b[36m0.4359\u001b[0m  0.0179\n",
            "     99        \u001b[36m0.4358\u001b[0m  0.0177\n",
            "    100        \u001b[36m0.4357\u001b[0m  0.0167\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.4660\u001b[0m  0.0163\n",
            "      2        \u001b[36m0.4650\u001b[0m  0.0161\n",
            "      3        \u001b[36m0.4646\u001b[0m  0.0160\n",
            "      4        \u001b[36m0.4644\u001b[0m  0.0167\n",
            "      5        \u001b[36m0.4643\u001b[0m  0.0164\n",
            "      6        \u001b[36m0.4641\u001b[0m  0.0177\n",
            "      7        \u001b[36m0.4640\u001b[0m  0.0170\n",
            "      8        \u001b[36m0.4638\u001b[0m  0.0167\n",
            "      9        \u001b[36m0.4636\u001b[0m  0.0161\n",
            "     10        \u001b[36m0.4635\u001b[0m  0.0166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.4633\u001b[0m  0.0172\n",
            "     12        \u001b[36m0.4631\u001b[0m  0.0183\n",
            "     13        \u001b[36m0.4630\u001b[0m  0.0165\n",
            "     14        \u001b[36m0.4628\u001b[0m  0.0168\n",
            "     15        \u001b[36m0.4627\u001b[0m  0.0161\n",
            "     16        \u001b[36m0.4626\u001b[0m  0.0163\n",
            "     17        \u001b[36m0.4624\u001b[0m  0.0162\n",
            "     18        \u001b[36m0.4623\u001b[0m  0.0161\n",
            "     19        \u001b[36m0.4621\u001b[0m  0.0163\n",
            "     20        \u001b[36m0.4620\u001b[0m  0.0167\n",
            "     21        \u001b[36m0.4618\u001b[0m  0.0162\n",
            "     22        \u001b[36m0.4616\u001b[0m  0.0173\n",
            "     23        \u001b[36m0.4615\u001b[0m  0.0164\n",
            "     24        \u001b[36m0.4614\u001b[0m  0.0174\n",
            "     25        \u001b[36m0.4612\u001b[0m  0.0178\n",
            "     26        \u001b[36m0.4611\u001b[0m  0.0165\n",
            "     27        \u001b[36m0.4609\u001b[0m  0.0233\n",
            "     28        \u001b[36m0.4608\u001b[0m  0.0274\n",
            "     29        \u001b[36m0.4606\u001b[0m  0.0246\n",
            "     30        \u001b[36m0.4605\u001b[0m  0.0181\n",
            "     31        \u001b[36m0.4603\u001b[0m  0.0174\n",
            "     32        \u001b[36m0.4602\u001b[0m  0.0191\n",
            "     33        \u001b[36m0.4601\u001b[0m  0.0197\n",
            "     34        \u001b[36m0.4600\u001b[0m  0.0195\n",
            "     35        \u001b[36m0.4598\u001b[0m  0.0191\n",
            "     36        \u001b[36m0.4596\u001b[0m  0.0199\n",
            "     37        \u001b[36m0.4595\u001b[0m  0.0196\n",
            "     38        \u001b[36m0.4594\u001b[0m  0.0191\n",
            "     39        \u001b[36m0.4593\u001b[0m  0.0196\n",
            "     40        \u001b[36m0.4591\u001b[0m  0.0165\n",
            "     41        \u001b[36m0.4590\u001b[0m  0.0164\n",
            "     42        \u001b[36m0.4588\u001b[0m  0.0169\n",
            "     43        \u001b[36m0.4587\u001b[0m  0.0168\n",
            "     44        \u001b[36m0.4586\u001b[0m  0.0199\n",
            "     45        \u001b[36m0.4585\u001b[0m  0.0176\n",
            "     46        \u001b[36m0.4583\u001b[0m  0.0165\n",
            "     47        \u001b[36m0.4582\u001b[0m  0.0170\n",
            "     48        \u001b[36m0.4581\u001b[0m  0.0166\n",
            "     49        \u001b[36m0.4579\u001b[0m  0.0162\n",
            "     50        \u001b[36m0.4578\u001b[0m  0.0168\n",
            "     51        \u001b[36m0.4577\u001b[0m  0.0162\n",
            "     52        \u001b[36m0.4575\u001b[0m  0.0167\n",
            "     53        \u001b[36m0.4574\u001b[0m  0.0178\n",
            "     54        \u001b[36m0.4573\u001b[0m  0.0163\n",
            "     55        \u001b[36m0.4572\u001b[0m  0.0165\n",
            "     56        \u001b[36m0.4571\u001b[0m  0.0178\n",
            "     57        \u001b[36m0.4569\u001b[0m  0.0184\n",
            "     58        \u001b[36m0.4568\u001b[0m  0.0168\n",
            "     59        \u001b[36m0.4567\u001b[0m  0.0167\n",
            "     60        \u001b[36m0.4566\u001b[0m  0.0168\n",
            "     61        \u001b[36m0.4564\u001b[0m  0.0165\n",
            "     62        \u001b[36m0.4563\u001b[0m  0.0162\n",
            "     63        \u001b[36m0.4562\u001b[0m  0.0168\n",
            "     64        \u001b[36m0.4561\u001b[0m  0.0171\n",
            "     65        \u001b[36m0.4560\u001b[0m  0.0161\n",
            "     66        \u001b[36m0.4558\u001b[0m  0.0167\n",
            "     67        \u001b[36m0.4557\u001b[0m  0.0177\n",
            "     68        \u001b[36m0.4556\u001b[0m  0.0169\n",
            "     69        \u001b[36m0.4555\u001b[0m  0.0167\n",
            "     70        \u001b[36m0.4554\u001b[0m  0.0169\n",
            "     71        \u001b[36m0.4552\u001b[0m  0.0167\n",
            "     72        \u001b[36m0.4551\u001b[0m  0.0172\n",
            "     73        \u001b[36m0.4550\u001b[0m  0.0167\n",
            "     74        \u001b[36m0.4549\u001b[0m  0.0169\n",
            "     75        \u001b[36m0.4548\u001b[0m  0.0168\n",
            "     76        \u001b[36m0.4547\u001b[0m  0.0177\n",
            "     77        \u001b[36m0.4546\u001b[0m  0.0192\n",
            "     78        \u001b[36m0.4545\u001b[0m  0.0179\n",
            "     79        \u001b[36m0.4543\u001b[0m  0.0206\n",
            "     80        \u001b[36m0.4542\u001b[0m  0.0209\n",
            "     81        \u001b[36m0.4541\u001b[0m  0.0232\n",
            "     82        \u001b[36m0.4540\u001b[0m  0.0200\n",
            "     83        \u001b[36m0.4539\u001b[0m  0.0215\n",
            "     84        \u001b[36m0.4538\u001b[0m  0.0191\n",
            "     85        \u001b[36m0.4537\u001b[0m  0.0195\n",
            "     86        \u001b[36m0.4536\u001b[0m  0.0192\n",
            "     87        \u001b[36m0.4534\u001b[0m  0.0198\n",
            "     88        \u001b[36m0.4533\u001b[0m  0.0204\n",
            "     89        \u001b[36m0.4532\u001b[0m  0.0194\n",
            "     90        \u001b[36m0.4531\u001b[0m  0.0168\n",
            "     91        \u001b[36m0.4530\u001b[0m  0.0181\n",
            "     92        \u001b[36m0.4529\u001b[0m  0.0195\n",
            "     93        \u001b[36m0.4528\u001b[0m  0.0223\n",
            "     94        \u001b[36m0.4527\u001b[0m  0.0211\n",
            "     95        \u001b[36m0.4526\u001b[0m  0.0194\n",
            "     96        \u001b[36m0.4525\u001b[0m  0.0235\n",
            "     97        \u001b[36m0.4524\u001b[0m  0.0205\n",
            "     98        \u001b[36m0.4523\u001b[0m  0.0169\n",
            "     99        \u001b[36m0.4522\u001b[0m  0.0190\n",
            "    100        \u001b[36m0.4521\u001b[0m  0.0180\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1       \u001b[36m37.2583\u001b[0m  0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
            "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/skorch/classifier.py\", line 381, in predict\n",
            "    return (y_proba[:, 1] > self.threshold).astype('uint8')\n",
            "            ~~~~~~~^^^^^^\n",
            "IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.63621819 0.62741537 0.62741537 0.62741537 0.53589696 0.50065481\n",
            " 0.55533111 0.50096368 0.62741537 0.62741537 0.62741537 0.62741537\n",
            " 0.59397084 0.54128984 0.67664319 0.52718681 0.75945762 0.62741537\n",
            " 0.74009143 0.62741537 0.57988634 0.56931678 0.61338028 0.53794169\n",
            " 0.62741537 0.62741537 0.62741537 0.62741537 0.67301087 0.54824561\n",
            " 0.66609834 0.63431554        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.62741537 0.62741537\n",
            " 0.62741537 0.62741537 0.47805164 0.59583642 0.39891277 0.53443291\n",
            " 0.62741537 0.62741537 0.62741537 0.62741537 0.61861873 0.52912034\n",
            " 0.61513467 0.54661478 0.62741537 0.62741537 0.62741537 0.62741537\n",
            " 0.42359773 0.53264146 0.56949592 0.5112429  0.62741537 0.62741537\n",
            " 0.62741537 0.62741537 0.62039783 0.61517173 0.66609217 0.57281319\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2       37.2583  0.1173\n",
            "      3       37.2583  0.1081\n",
            "      4       37.2583  0.1168\n",
            "      5       37.2583  0.1234\n",
            "      6       37.2583  0.1268\n",
            "      7       37.2583  0.1347\n",
            "      8       37.2583  0.1126\n",
            "      9       37.2583  0.1017\n",
            "     10       37.2583  0.1048\n",
            "     11       37.2583  0.1009\n",
            "     12       37.2583  0.1080\n",
            "     13       37.2583  0.1118\n",
            "     14       37.2583  0.0970\n",
            "     15       37.2583  0.1103\n",
            "     16       37.2583  0.1089\n",
            "     17       37.2583  0.0961\n",
            "     18       37.2583  0.0972\n",
            "     19       \u001b[36m25.6044\u001b[0m  0.0995\n",
            "     20        \u001b[36m0.7398\u001b[0m  0.0991\n",
            "     21        \u001b[36m0.5741\u001b[0m  0.1012\n",
            "     22        \u001b[36m0.5199\u001b[0m  0.1030\n",
            "     23        \u001b[36m0.5026\u001b[0m  0.1075\n",
            "     24        \u001b[36m0.4894\u001b[0m  0.1013\n",
            "     25        \u001b[36m0.4748\u001b[0m  0.1050\n",
            "     26        \u001b[36m0.4741\u001b[0m  0.1298\n",
            "     27        \u001b[36m0.4441\u001b[0m  0.1227\n",
            "     28        \u001b[36m0.4329\u001b[0m  0.1066\n",
            "     29        \u001b[36m0.4226\u001b[0m  0.1018\n",
            "     30        \u001b[36m0.4099\u001b[0m  0.1180\n",
            "     31        \u001b[36m0.3963\u001b[0m  0.1345\n",
            "     32        \u001b[36m0.3858\u001b[0m  0.1130\n",
            "     33        \u001b[36m0.3781\u001b[0m  0.1334\n",
            "     34        \u001b[36m0.3693\u001b[0m  0.1340\n",
            "     35        \u001b[36m0.3607\u001b[0m  0.1113\n",
            "     36        \u001b[36m0.3532\u001b[0m  0.1278\n",
            "     37        \u001b[36m0.3461\u001b[0m  0.1148\n",
            "     38        \u001b[36m0.3401\u001b[0m  0.1040\n",
            "     39        \u001b[36m0.3352\u001b[0m  0.1144\n",
            "     40        \u001b[36m0.3287\u001b[0m  0.1055\n",
            "     41        \u001b[36m0.3245\u001b[0m  0.1038\n",
            "     42        \u001b[36m0.3189\u001b[0m  0.1064\n",
            "     43        \u001b[36m0.3138\u001b[0m  0.1112\n",
            "     44        \u001b[36m0.3103\u001b[0m  0.1183\n",
            "     45        \u001b[36m0.3065\u001b[0m  0.1054\n",
            "     46        \u001b[36m0.3034\u001b[0m  0.1082\n",
            "     47        \u001b[36m0.2995\u001b[0m  0.1061\n",
            "     48        \u001b[36m0.2966\u001b[0m  0.1148\n",
            "     49        \u001b[36m0.2929\u001b[0m  0.1051\n",
            "     50        \u001b[36m0.2892\u001b[0m  0.1162\n",
            "     51        \u001b[36m0.2866\u001b[0m  0.1188\n",
            "     52        \u001b[36m0.2836\u001b[0m  0.1331\n",
            "     53        \u001b[36m0.2811\u001b[0m  0.1316\n",
            "     54        \u001b[36m0.2796\u001b[0m  0.0999\n",
            "     55        \u001b[36m0.2765\u001b[0m  0.1024\n",
            "     56        \u001b[36m0.2733\u001b[0m  0.1055\n",
            "     57        \u001b[36m0.2721\u001b[0m  0.1108\n",
            "     58        \u001b[36m0.2695\u001b[0m  0.1003\n",
            "     59        \u001b[36m0.2673\u001b[0m  0.1038\n",
            "     60        \u001b[36m0.2650\u001b[0m  0.1055\n",
            "     61        \u001b[36m0.2631\u001b[0m  0.1009\n",
            "     62        \u001b[36m0.2612\u001b[0m  0.1025\n",
            "     63        \u001b[36m0.2603\u001b[0m  0.1176\n",
            "     64        \u001b[36m0.2592\u001b[0m  0.1027\n",
            "     65        \u001b[36m0.2558\u001b[0m  0.1124\n",
            "     66        \u001b[36m0.2542\u001b[0m  0.1153\n",
            "     67        \u001b[36m0.2529\u001b[0m  0.1049\n",
            "     68        \u001b[36m0.2505\u001b[0m  0.1027\n",
            "     69        \u001b[36m0.2480\u001b[0m  0.1056\n",
            "     70        \u001b[36m0.2403\u001b[0m  0.1026\n",
            "     71        0.2460  0.1026\n",
            "     72        0.2453  0.1004\n",
            "     73        0.2436  0.1206\n",
            "     74        \u001b[36m0.2391\u001b[0m  0.1066\n",
            "     75        0.2402  0.1154\n",
            "     76        \u001b[36m0.2359\u001b[0m  0.0998\n",
            "     77        \u001b[36m0.2331\u001b[0m  0.1025\n",
            "     78        \u001b[36m0.2306\u001b[0m  0.1038\n",
            "     79        \u001b[36m0.2300\u001b[0m  0.1059\n",
            "     80        \u001b[36m0.2227\u001b[0m  0.1030\n",
            "     81        0.2233  0.1089\n",
            "     82        \u001b[36m0.2210\u001b[0m  0.1068\n",
            "     83        \u001b[36m0.2189\u001b[0m  0.1177\n",
            "     84        \u001b[36m0.2169\u001b[0m  0.1140\n",
            "     85        \u001b[36m0.2161\u001b[0m  0.1242\n",
            "     86        \u001b[36m0.2127\u001b[0m  0.1089\n",
            "     87        \u001b[36m0.2115\u001b[0m  0.1105\n",
            "     88        \u001b[36m0.2077\u001b[0m  0.1032\n",
            "     89        \u001b[36m0.2059\u001b[0m  0.1157\n",
            "     90        \u001b[36m0.2028\u001b[0m  0.1035\n",
            "     91        \u001b[36m0.2016\u001b[0m  0.1030\n",
            "     92        \u001b[36m0.2005\u001b[0m  0.1396\n",
            "     93        \u001b[36m0.1984\u001b[0m  0.1524\n",
            "     94        \u001b[36m0.1978\u001b[0m  0.1003\n",
            "     95        \u001b[36m0.1968\u001b[0m  0.1083\n",
            "     96        \u001b[36m0.1955\u001b[0m  0.1026\n",
            "     97        \u001b[36m0.1931\u001b[0m  0.1016\n",
            "     98        \u001b[36m0.1921\u001b[0m  0.1099\n",
            "     99        \u001b[36m0.1906\u001b[0m  0.1020\n",
            "    100        \u001b[36m0.1903\u001b[0m  0.1029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_precisao = grid_search.best_score_"
      ],
      "metadata": {
        "id": "i9P92sm7XeIn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhores_parametros"
      ],
      "metadata": {
        "id": "qrMt6MtLXfXw",
        "outputId": "6386d8cc-1c9b-48f4-8340-2d3338f6ee46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 10,\n",
              " 'criterion': torch.nn.modules.loss.BCELoss,\n",
              " 'max_epochs': 100,\n",
              " 'module__activation': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
              " 'module__initializer': <function torch.nn.init.uniform_(tensor: torch.Tensor, a: float = 0.0, b: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor>,\n",
              " 'module__neurons': 8,\n",
              " 'optimizer': torch.optim.adam.Adam}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_precisao"
      ],
      "metadata": {
        "id": "uAOUV5KRXoR3",
        "outputId": "9e90913e-e686-459a-95ec-bc42d0fb01ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7594576229305658"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}