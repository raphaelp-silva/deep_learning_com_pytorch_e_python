{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QGDLesyDQpIb",
        "appMwDHtRTN5",
        "AyTjLzELSdQF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raphaelp-silva/deep_learning_com_pytorch_e_python/blob/main/Projeto_9_Regress%C3%A3o_carros_usados_valida%C3%A7%C3%A3o_cruzada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 9: Regressão carros usados - validação cruzada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QelcgTCeOscD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36e4074-da07-4e2d-d2be-dc4878b18acf"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.13.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/228.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skorch\n",
            "Successfully installed skorch-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf0FpJ35Lf-Z",
        "outputId": "30977d77-4f49-45de-ccc6-9f04e179e585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from skorch import NeuralNetRegressor\n",
        "import torch\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9aIu62WMGo8",
        "outputId": "c41712b9-6114-48df-bfad-93f63dd4a9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(123)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x796d50524810>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IqVnbpIW8mw"
      },
      "source": [
        "base = pd.read_csv('autos.csv', encoding = 'ISO-8859-1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln_ioElH_B-6"
      },
      "source": [
        "base = base.drop('dateCrawled', axis = 1)\n",
        "base = base.drop('dateCreated', axis = 1)\n",
        "base = base.drop('nrOfPictures', axis = 1)\n",
        "base = base.drop('postalCode', axis = 1)\n",
        "base = base.drop('lastSeen', axis = 1)\n",
        "base = base.drop('name', axis = 1)\n",
        "base = base.drop('seller', axis = 1)\n",
        "base = base.drop('offerType', axis = 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv4OfXz3_EZ-"
      },
      "source": [
        "base = base[base.price > 10]\n",
        "base = base.loc[base.price < 350000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWFSk-t_J7U"
      },
      "source": [
        "valores = {'vehicleType': 'limousine', 'gearbox': 'manuell',\n",
        "           'model': 'golf', 'fuelType': 'benzin',\n",
        "           'notRepairedDamage': 'nein'}\n",
        "base = base.fillna(value = valores)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpNizAF_OQZ"
      },
      "source": [
        "previsores = base.iloc[:, 1:13].values\n",
        "preco_real = base.iloc[:, 0].values.reshape(-1, 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7egm3uO-_Qry"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "onehotencoder = ColumnTransformer(transformers = [(\"OneHot\", OneHotEncoder(), [0,1,3,5,8,9,10])], remainder = 'passthrough')\n",
        "previsores = onehotencoder.fit_transform(previsores).toarray()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsADVo4_VUy"
      },
      "source": [
        "previsores = previsores.astype('float32')\n",
        "preco_real = preco_real.astype('float32')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Etapa 3: Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAbZXJAIQ-oK"
      },
      "source": [
        "class regressor_torch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense0 = nn.Linear(314, 158)\n",
        "        self.dense1 = nn.Linear(158, 158)\n",
        "        self.dense2 = nn.Linear(158, 1)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.dense0(X)\n",
        "        X = self.activation(X)\n",
        "        X = self.dense1(X)\n",
        "        X = self.activation(X)\n",
        "        X = self.dense2(X)\n",
        "        return X"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3Av0JgQfE-"
      },
      "source": [
        "regressor_sklearn = NeuralNetRegressor(module = regressor_torch,\n",
        "                                       criterion = torch.nn.L1Loss,\n",
        "                                       optimizer = torch.optim.Adam,\n",
        "                                       max_epochs = 100,\n",
        "                                       batch_size = 300,\n",
        "                                       train_split = False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appMwDHtRTN5"
      },
      "source": [
        "## Etapa 4: Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86WX5bDqR5Ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0b6ebb-2e4e-48f5-91a0-d1f0d6625938"
      },
      "source": [
        "resultados = cross_val_score(regressor_sklearn, previsores, preco_real, cv = 5,\n",
        "                             scoring = 'neg_mean_absolute_error')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m4103.7635\u001b[0m  2.3319\n",
            "      2     \u001b[36m3589.8935\u001b[0m  2.9639\n",
            "      3     \u001b[36m3188.2815\u001b[0m  2.6493\n",
            "      4     \u001b[36m3025.0123\u001b[0m  2.4414\n",
            "      5     \u001b[36m2960.8876\u001b[0m  2.4522\n",
            "      6     \u001b[36m2950.7207\u001b[0m  2.4910\n",
            "      7     \u001b[36m2893.0678\u001b[0m  3.2657\n",
            "      8     \u001b[36m2875.6276\u001b[0m  2.4734\n",
            "      9     \u001b[36m2871.2211\u001b[0m  2.4702\n",
            "     10     \u001b[36m2822.9350\u001b[0m  2.5382\n",
            "     11     \u001b[36m2802.8445\u001b[0m  2.8230\n",
            "     12     \u001b[36m2776.6138\u001b[0m  2.8913\n",
            "     13     \u001b[36m2755.1381\u001b[0m  2.4769\n",
            "     14     \u001b[36m2750.7410\u001b[0m  2.5122\n",
            "     15     \u001b[36m2725.4864\u001b[0m  2.4794\n",
            "     16     3324.0727  3.1941\n",
            "     17     3182.7799  2.4156\n",
            "     18     2780.8728  2.5042\n",
            "     19     2747.4493  2.5204\n",
            "     20     \u001b[36m2709.3517\u001b[0m  2.5853\n",
            "     21     \u001b[36m2672.6613\u001b[0m  3.2140\n",
            "     22     \u001b[36m2655.6054\u001b[0m  2.5584\n",
            "     23     \u001b[36m2639.8038\u001b[0m  2.5161\n",
            "     24     \u001b[36m2614.2661\u001b[0m  2.5408\n",
            "     25     \u001b[36m2599.6697\u001b[0m  3.1945\n",
            "     26     \u001b[36m2585.5229\u001b[0m  2.7177\n",
            "     27     \u001b[36m2562.6375\u001b[0m  2.5979\n",
            "     28     \u001b[36m2554.7761\u001b[0m  2.5197\n",
            "     29     2590.2302  2.6924\n",
            "     30     \u001b[36m2549.8095\u001b[0m  3.2933\n",
            "     31     \u001b[36m2510.7881\u001b[0m  2.6045\n",
            "     32     2517.3453  2.6260\n",
            "     33     2527.0251  2.8731\n",
            "     34     \u001b[36m2509.3374\u001b[0m  4.0219\n",
            "     35     \u001b[36m2489.5176\u001b[0m  2.4800\n",
            "     36     2490.8739  2.5207\n",
            "     37     2501.3089  2.5995\n",
            "     38     2682.8009  3.1212\n",
            "     39     2494.6742  2.7957\n",
            "     40     2500.3261  2.5719\n",
            "     41     \u001b[36m2462.8937\u001b[0m  2.5903\n",
            "     42     2512.4566  2.5674\n",
            "     43     2494.0338  3.4083\n",
            "     44     2489.1522  2.5428\n",
            "     45     2473.0661  2.5381\n",
            "     46     2463.5113  2.5414\n",
            "     47     2471.5193  3.0876\n",
            "     48     2465.1886  2.8321\n",
            "     49     \u001b[36m2462.1287\u001b[0m  2.5469\n",
            "     50     2467.3798  2.5640\n",
            "     51     2475.7427  2.5513\n",
            "     52     \u001b[36m2448.4509\u001b[0m  3.3633\n",
            "     53     2450.1922  2.5262\n",
            "     54     2464.6621  2.5612\n",
            "     55     2469.8464  2.5862\n",
            "     56     2451.5381  3.0057\n",
            "     57     2462.8040  2.8683\n",
            "     58     \u001b[36m2435.4189\u001b[0m  2.5403\n",
            "     59     2442.0429  2.6308\n",
            "     60     \u001b[36m2427.2155\u001b[0m  2.5734\n",
            "     61     2457.3862  3.3136\n",
            "     62     2429.8577  2.5147\n",
            "     63     2427.5132  2.5153\n",
            "     64     2434.1470  2.5023\n",
            "     65     2434.1604  2.8524\n",
            "     66     2433.9784  2.8915\n",
            "     67     2445.1457  2.5523\n",
            "     68     2446.5426  2.5013\n",
            "     69     2438.7063  2.4819\n",
            "     70     2431.0645  3.3281\n",
            "     71     2442.0702  2.5113\n",
            "     72     2433.1255  2.5208\n",
            "     73     2429.9221  2.4986\n",
            "     74     2439.2467  2.6358\n",
            "     75     \u001b[36m2418.2123\u001b[0m  3.1583\n",
            "     76     \u001b[36m2407.5846\u001b[0m  2.5523\n",
            "     77     2409.2184  2.4981\n",
            "     78     2426.0596  2.4843\n",
            "     79     2408.3058  3.2132\n",
            "     80     \u001b[36m2405.0273\u001b[0m  2.6295\n",
            "     81     2423.6640  2.5336\n",
            "     82     2420.8247  2.4436\n",
            "     83     \u001b[36m2399.8636\u001b[0m  2.4856\n",
            "     84     2407.7056  3.2965\n",
            "     85     \u001b[36m2396.6894\u001b[0m  2.4750\n",
            "     86     2412.2744  2.4958\n",
            "     87     2399.8997  2.4956\n",
            "     88     2405.2924  2.9406\n",
            "     89     2398.4628  2.9049\n",
            "     90     2397.5114  2.5174\n",
            "     91     2413.0008  2.5135\n",
            "     92     2396.8021  2.5479\n",
            "     93     2400.2326  3.2661\n",
            "     94     2406.5076  2.4938\n",
            "     95     2412.5469  2.4911\n",
            "     96     \u001b[36m2393.7826\u001b[0m  2.5216\n",
            "     97     2406.8986  2.7852\n",
            "     98     2409.6671  3.1023\n",
            "     99     2396.4466  2.5868\n",
            "    100     2401.4089  2.5928\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m4029.7885\u001b[0m  2.2130\n",
            "      2     \u001b[36m3330.1064\u001b[0m  3.1215\n",
            "      3     \u001b[36m3077.7154\u001b[0m  2.5290\n",
            "      4     \u001b[36m2962.0871\u001b[0m  2.5843\n",
            "      5     \u001b[36m2928.5586\u001b[0m  2.4739\n",
            "      6     \u001b[36m2850.4476\u001b[0m  2.6005\n",
            "      7     2854.0034  3.1185\n",
            "      8     \u001b[36m2840.9399\u001b[0m  2.4929\n",
            "      9     \u001b[36m2824.5384\u001b[0m  2.5526\n",
            "     10     \u001b[36m2800.8019\u001b[0m  2.4873\n",
            "     11     2803.4680  3.1389\n",
            "     12     \u001b[36m2778.0318\u001b[0m  2.6391\n",
            "     13     \u001b[36m2746.3513\u001b[0m  2.4923\n",
            "     14     \u001b[36m2722.2635\u001b[0m  2.4939\n",
            "     15     2730.9858  2.5338\n",
            "     16     \u001b[36m2696.9070\u001b[0m  3.3168\n",
            "     17     \u001b[36m2694.7220\u001b[0m  2.5422\n",
            "     18     \u001b[36m2673.6873\u001b[0m  2.4767\n",
            "     19     \u001b[36m2630.6910\u001b[0m  2.4865\n",
            "     20     2633.0976  2.8978\n",
            "     21     2631.4117  2.9534\n",
            "     22     \u001b[36m2623.7845\u001b[0m  2.5042\n",
            "     23     \u001b[36m2606.7318\u001b[0m  2.4316\n",
            "     24     \u001b[36m2583.5056\u001b[0m  2.4560\n",
            "     25     2606.7829  3.3120\n",
            "     26     2592.0689  2.4938\n",
            "     27     \u001b[36m2578.8574\u001b[0m  2.4782\n",
            "     28     \u001b[36m2573.4659\u001b[0m  2.5074\n",
            "     29     \u001b[36m2566.5725\u001b[0m  2.6770\n",
            "     30     \u001b[36m2521.1802\u001b[0m  3.1022\n",
            "     31     2545.3205  2.4598\n",
            "     32     2530.8065  2.4961\n",
            "     33     2548.0485  2.5201\n",
            "     34     2521.8969  3.1060\n",
            "     35     2531.7622  2.6209\n",
            "     36     \u001b[36m2510.0313\u001b[0m  2.4982\n",
            "     37     2514.2766  2.5026\n",
            "     38     \u001b[36m2493.0015\u001b[0m  2.5404\n",
            "     39     2524.8132  3.3644\n",
            "     40     2493.0610  2.5124\n",
            "     41     2503.9760  2.5769\n",
            "     42     2501.2775  2.5919\n",
            "     43     \u001b[36m2488.5310\u001b[0m  3.0233\n",
            "     44     \u001b[36m2464.1508\u001b[0m  2.9223\n",
            "     45     2471.2127  2.4808\n",
            "     46     2483.8758  2.4978\n",
            "     47     2475.1033  2.4660\n",
            "     48     2464.9410  3.2707\n",
            "     49     2475.0230  2.4969\n",
            "     50     2510.0359  2.5210\n",
            "     51     \u001b[36m2458.1378\u001b[0m  2.4795\n",
            "     52     \u001b[36m2445.3580\u001b[0m  2.6135\n",
            "     53     2467.6161  3.0630\n",
            "     54     2476.1347  2.5382\n",
            "     55     2471.4738  2.4501\n",
            "     56     2473.3882  2.4786\n",
            "     57     2456.2698  3.1574\n",
            "     58     2464.1622  2.6494\n",
            "     59     \u001b[36m2424.8284\u001b[0m  2.4948\n",
            "     60     2484.3026  2.5228\n",
            "     61     2437.9498  2.5087\n",
            "     62     2445.9968  3.2591\n",
            "     63     \u001b[36m2416.6756\u001b[0m  2.4842\n",
            "     64     \u001b[36m2416.0144\u001b[0m  2.5255\n",
            "     65     2438.6864  2.4925\n",
            "     66     \u001b[36m2401.0208\u001b[0m  2.9682\n",
            "     67     2431.0185  2.8526\n",
            "     68     2423.1903  2.4652\n",
            "     69     2421.8295  2.4274\n",
            "     70     2442.2975  2.4403\n",
            "     71     2427.6818  3.2773\n",
            "     72     2429.4365  2.5116\n",
            "     73     2423.1363  2.5060\n",
            "     74     2422.5172  2.5118\n",
            "     75     2415.5367  2.6049\n",
            "     76     2407.3737  3.1400\n",
            "     77     2415.2130  2.4775\n",
            "     78     2426.9010  2.4540\n",
            "     79     2404.7938  2.4909\n",
            "     80     2412.3793  3.0341\n",
            "     81     2404.4116  2.6927\n",
            "     82     2403.2729  2.6203\n",
            "     83     2417.5521  2.5010\n",
            "     84     \u001b[36m2398.7281\u001b[0m  2.5139\n",
            "     85     2403.2969  3.2429\n",
            "     86     2431.9869  2.4851\n",
            "     87     2414.0065  2.5092\n",
            "     88     2402.9437  2.5691\n",
            "     89     2411.8583  2.9385\n",
            "     90     2403.1409  2.8852\n",
            "     91     \u001b[36m2395.3119\u001b[0m  2.4965\n",
            "     92     \u001b[36m2387.3820\u001b[0m  2.5387\n",
            "     93     2404.3508  2.4906\n",
            "     94     2416.6939  3.2971\n",
            "     95     \u001b[36m2386.1121\u001b[0m  2.5460\n",
            "     96     2395.8526  2.5196\n",
            "     97     \u001b[36m2376.5692\u001b[0m  2.5100\n",
            "     98     2391.5814  2.6439\n",
            "     99     2403.5326  3.1080\n",
            "    100     2387.7314  2.5494\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m4038.9857\u001b[0m  2.1843\n",
            "      2     \u001b[36m3353.4180\u001b[0m  2.2520\n",
            "      3     \u001b[36m3169.8438\u001b[0m  3.0992\n",
            "      4     \u001b[36m3012.1406\u001b[0m  2.5902\n",
            "      5     \u001b[36m2982.3928\u001b[0m  2.4200\n",
            "      6     \u001b[36m2939.0262\u001b[0m  2.4743\n",
            "      7     \u001b[36m2902.1221\u001b[0m  2.4402\n",
            "      8     \u001b[36m2862.1205\u001b[0m  3.2299\n",
            "      9     \u001b[36m2852.6696\u001b[0m  2.4665\n",
            "     10     \u001b[36m2807.2056\u001b[0m  2.4379\n",
            "     11     2846.6514  2.5005\n",
            "     12     \u001b[36m2781.3901\u001b[0m  2.7331\n",
            "     13     2798.2782  2.9467\n",
            "     14     \u001b[36m2735.4830\u001b[0m  2.4512\n",
            "     15     2750.7416  2.4571\n",
            "     16     \u001b[36m2723.0412\u001b[0m  2.4645\n",
            "     17     \u001b[36m2692.6106\u001b[0m  3.1616\n",
            "     18     \u001b[36m2675.6529\u001b[0m  2.6088\n",
            "     19     \u001b[36m2660.7354\u001b[0m  2.5072\n",
            "     20     2670.5660  2.4501\n",
            "     21     \u001b[36m2657.6294\u001b[0m  2.4909\n",
            "     22     \u001b[36m2629.2813\u001b[0m  3.3398\n",
            "     23     \u001b[36m2616.8098\u001b[0m  2.4791\n",
            "     24     \u001b[36m2594.7328\u001b[0m  2.4823\n",
            "     25     2597.6780  2.4504\n",
            "     26     2605.8305  2.8291\n",
            "     27     2598.2266  2.9113\n",
            "     28     \u001b[36m2585.4472\u001b[0m  2.4776\n",
            "     29     \u001b[36m2567.4022\u001b[0m  2.5334\n",
            "     30     \u001b[36m2562.4937\u001b[0m  2.5158\n",
            "     31     \u001b[36m2515.9943\u001b[0m  3.3264\n",
            "     32     2560.4532  2.5127\n",
            "     33     2569.3916  2.4827\n",
            "     34     2536.0907  2.5106\n",
            "     35     \u001b[36m2511.8974\u001b[0m  2.6533\n",
            "     36     2522.7882  3.2337\n",
            "     37     \u001b[36m2503.8037\u001b[0m  2.4634\n",
            "     38     2514.6584  2.4626\n",
            "     39     \u001b[36m2496.4740\u001b[0m  2.4359\n",
            "     40     \u001b[36m2479.8691\u001b[0m  3.0794\n",
            "     41     2521.1612  2.6797\n",
            "     42     2486.8634  2.4435\n",
            "     43     2492.3758  2.4442\n",
            "     44     2500.6073  2.4582\n",
            "     45     2481.2254  3.2384\n",
            "     46     \u001b[36m2475.5820\u001b[0m  2.4273\n",
            "     47     \u001b[36m2467.0295\u001b[0m  2.3962\n",
            "     48     \u001b[36m2466.3483\u001b[0m  2.4124\n",
            "     49     \u001b[36m2464.6616\u001b[0m  2.4330\n",
            "     50     \u001b[36m2448.4918\u001b[0m  3.1640\n",
            "     51     2477.2307  2.6167\n",
            "     52     2467.3803  2.5569\n",
            "     53     2503.2367  2.4693\n",
            "     54     2459.8788  3.1301\n",
            "     55     2449.4790  2.7873\n",
            "     56     2449.2348  2.5721\n",
            "     57     2455.8006  2.5737\n",
            "     58     \u001b[36m2435.2786\u001b[0m  2.5484\n",
            "     59     2458.7034  3.3425\n",
            "     60     2459.6797  2.5855\n",
            "     61     2453.9440  2.5548\n",
            "     62     \u001b[36m2430.2575\u001b[0m  2.4769\n",
            "     63     2444.9015  3.1080\n",
            "     64     \u001b[36m2418.9055\u001b[0m  2.6692\n",
            "     65     2451.0749  2.5374\n",
            "     66     \u001b[36m2418.0303\u001b[0m  2.4974\n",
            "     67     2446.6045  2.5180\n",
            "     68     2435.1071  3.2778\n",
            "     69     2446.6590  2.5020\n",
            "     70     2436.1928  2.5294\n",
            "     71     2430.3426  2.5353\n",
            "     72     2448.5701  2.8727\n",
            "     73     2447.8157  2.8556\n",
            "     74     2432.2809  2.4974\n",
            "     75     2421.8095  2.4882\n",
            "     76     2429.2533  2.4776\n",
            "     77     2435.2351  3.2836\n",
            "     78     \u001b[36m2407.7992\u001b[0m  2.5173\n",
            "     79     2449.3929  2.4903\n",
            "     80     2418.5436  2.4632\n",
            "     81     2433.7857  2.5661\n",
            "     82     2428.2008  3.1410\n",
            "     83     \u001b[36m2398.9766\u001b[0m  2.4720\n",
            "     84     \u001b[36m2397.9493\u001b[0m  2.4672\n",
            "     85     2422.9211  2.4879\n",
            "     86     2412.1841  3.0358\n",
            "     87     2411.4266  2.6196\n",
            "     88     2402.7612  2.4783\n",
            "     89     2401.9935  2.4831\n",
            "     90     2414.6604  2.4895\n",
            "     91     2399.0451  3.2637\n",
            "     92     \u001b[36m2395.0153\u001b[0m  2.5082\n",
            "     93     2406.1425  2.5335\n",
            "     94     2415.6138  2.4651\n",
            "     95     \u001b[36m2388.7799\u001b[0m  2.8574\n",
            "     96     \u001b[36m2375.6942\u001b[0m  2.9968\n",
            "     97     2390.2949  2.5720\n",
            "     98     2418.1158  2.5742\n",
            "     99     2416.0676  2.5406\n",
            "    100     2386.9045  3.3487\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m4018.0130\u001b[0m  2.2876\n",
            "      2     \u001b[36m3297.0843\u001b[0m  2.3734\n",
            "      3     \u001b[36m3184.7356\u001b[0m  2.4999\n",
            "      4     \u001b[36m3018.5374\u001b[0m  2.8315\n",
            "      5     \u001b[36m2910.9367\u001b[0m  3.0047\n",
            "      6     \u001b[36m2890.6779\u001b[0m  2.5062\n",
            "      7     \u001b[36m2889.6535\u001b[0m  2.5533\n",
            "      8     \u001b[36m2881.2671\u001b[0m  2.5618\n",
            "      9     \u001b[36m2856.2725\u001b[0m  3.3206\n",
            "     10     \u001b[36m2817.6560\u001b[0m  2.5081\n",
            "     11     \u001b[36m2794.1592\u001b[0m  2.4959\n",
            "     12     \u001b[36m2758.1295\u001b[0m  2.5344\n",
            "     13     2792.5457  2.5780\n",
            "     14     2768.6625  3.1107\n",
            "     15     \u001b[36m2725.5445\u001b[0m  2.4536\n",
            "     16     \u001b[36m2699.7546\u001b[0m  2.4724\n",
            "     17     2702.5072  2.4598\n",
            "     18     \u001b[36m2659.1520\u001b[0m  3.0526\n",
            "     19     2659.7686  2.7526\n",
            "     20     2663.6802  2.4636\n",
            "     21     \u001b[36m2648.5253\u001b[0m  2.4770\n",
            "     22     \u001b[36m2607.3282\u001b[0m  2.4430\n",
            "     23     \u001b[36m2596.6405\u001b[0m  3.2826\n",
            "     24     \u001b[36m2592.1027\u001b[0m  2.4635\n",
            "     25     2614.4687  2.5210\n",
            "     26     \u001b[36m2583.3812\u001b[0m  2.4856\n",
            "     27     2585.4791  2.6943\n",
            "     28     \u001b[36m2556.8799\u001b[0m  3.0579\n",
            "     29     \u001b[36m2529.4257\u001b[0m  2.5565\n",
            "     30     2538.0396  2.4902\n",
            "     31     \u001b[36m2525.1074\u001b[0m  2.4862\n",
            "     32     \u001b[36m2510.8768\u001b[0m  3.1844\n",
            "     33     2525.1186  2.5164\n",
            "     34     2522.9973  2.4750\n",
            "     35     \u001b[36m2483.3785\u001b[0m  2.4864\n",
            "     36     2517.2769  2.4865\n",
            "     37     2502.2061  3.2633\n",
            "     38     2489.0335  2.4644\n",
            "     39     2504.1418  2.4375\n",
            "     40     2502.5612  2.4348\n",
            "     41     2534.1646  2.8235\n",
            "     42     \u001b[36m2472.7282\u001b[0m  2.9396\n",
            "     43     2501.5121  2.4609\n",
            "     44     \u001b[36m2453.7900\u001b[0m  2.4638\n",
            "     45     2500.5757  2.4668\n",
            "     46     \u001b[36m2450.7937\u001b[0m  3.3194\n",
            "     47     2470.3150  2.4388\n",
            "     48     2482.4564  2.4826\n",
            "     49     2458.6639  2.4714\n",
            "     50     \u001b[36m2450.1160\u001b[0m  2.4692\n",
            "     51     2459.8792  3.2850\n",
            "     52     2474.7559  2.4705\n",
            "     53     2480.3052  2.4832\n",
            "     54     2461.9053  2.5527\n",
            "     55     \u001b[36m2421.4571\u001b[0m  2.9459\n",
            "     56     2441.6409  2.8108\n",
            "     57     2449.1133  2.5037\n",
            "     58     2440.5043  2.4563\n",
            "     59     2435.9578  2.4666\n",
            "     60     2421.5617  3.2655\n",
            "     61     \u001b[36m2418.5771\u001b[0m  2.4790\n",
            "     62     \u001b[36m2417.4683\u001b[0m  2.4441\n",
            "     63     2435.0624  2.4352\n",
            "     64     2428.2081  2.5018\n",
            "     65     2419.3783  3.1872\n",
            "     66     \u001b[36m2413.1190\u001b[0m  2.4440\n",
            "     67     2421.5619  2.4425\n",
            "     68     2427.4574  2.4926\n",
            "     69     2424.5470  2.9279\n",
            "     70     2418.1659  2.7914\n",
            "     71     2428.7821  2.4456\n",
            "     72     \u001b[36m2395.2007\u001b[0m  2.4440\n",
            "     73     2414.5517  2.4980\n",
            "     74     2424.4008  3.2631\n",
            "     75     2397.6767  2.5269\n",
            "     76     2397.2272  2.4434\n",
            "     77     2404.5080  2.4867\n",
            "     78     2405.7680  2.4588\n",
            "     79     \u001b[36m2390.8282\u001b[0m  3.1580\n",
            "     80     2395.6256  2.5169\n",
            "     81     2398.5601  2.4975\n",
            "     82     2400.1542  2.4744\n",
            "     83     2391.1220  2.9686\n",
            "     84     2396.3675  2.7870\n",
            "     85     2403.7463  2.5455\n",
            "     86     2391.4331  2.4890\n",
            "     87     \u001b[36m2376.4655\u001b[0m  2.4933\n",
            "     88     2401.9333  3.3021\n",
            "     89     2392.8559  2.4754\n",
            "     90     2406.1260  2.5040\n",
            "     91     2402.9319  2.4928\n",
            "     92     \u001b[36m2372.6966\u001b[0m  2.7726\n",
            "     93     2379.5209  2.9879\n",
            "     94     2387.4801  2.4937\n",
            "     95     2377.3299  2.4733\n",
            "     96     2409.6547  2.5251\n",
            "     97     2398.8241  3.2859\n",
            "     98     \u001b[36m2361.9264\u001b[0m  2.4932\n",
            "     99     2405.6050  2.5165\n",
            "    100     2371.2416  2.5616\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m4005.0164\u001b[0m  2.3428\n",
            "      2     \u001b[36m3318.9530\u001b[0m  2.9484\n",
            "      3     \u001b[36m3100.1377\u001b[0m  2.4869\n",
            "      4     \u001b[36m3024.2459\u001b[0m  2.5228\n",
            "      5     \u001b[36m2968.4055\u001b[0m  2.5161\n",
            "      6     \u001b[36m2903.5612\u001b[0m  3.1008\n",
            "      7     2909.2244  2.6620\n",
            "      8     \u001b[36m2873.3028\u001b[0m  2.4861\n",
            "      9     \u001b[36m2854.9592\u001b[0m  2.5311\n",
            "     10     \u001b[36m2816.4608\u001b[0m  2.4928\n",
            "     11     2955.1969  3.3334\n",
            "     12     2820.5006  2.5802\n",
            "     13     \u001b[36m2744.8322\u001b[0m  2.5818\n",
            "     14     \u001b[36m2717.3939\u001b[0m  2.5388\n",
            "     15     \u001b[36m2696.6151\u001b[0m  2.9711\n",
            "     16     2892.2960  2.8359\n",
            "     17     \u001b[36m2674.0222\u001b[0m  2.5162\n",
            "     18     \u001b[36m2656.4723\u001b[0m  2.4704\n",
            "     19     \u001b[36m2640.1210\u001b[0m  2.5069\n",
            "     20     \u001b[36m2609.2630\u001b[0m  3.3339\n",
            "     21     \u001b[36m2604.6673\u001b[0m  2.5368\n",
            "     22     \u001b[36m2589.6191\u001b[0m  2.5878\n",
            "     23     \u001b[36m2582.0926\u001b[0m  2.7052\n",
            "     24     \u001b[36m2560.3224\u001b[0m  2.9001\n",
            "     25     \u001b[36m2534.8778\u001b[0m  3.0113\n",
            "     26     2553.1829  2.5315\n",
            "     27     \u001b[36m2525.6399\u001b[0m  2.5774\n",
            "     28     2542.6717  2.5542\n",
            "     29     2535.4675  3.3493\n",
            "     30     \u001b[36m2502.7075\u001b[0m  2.5269\n",
            "     31     \u001b[36m2498.1948\u001b[0m  2.5631\n",
            "     32     \u001b[36m2493.1632\u001b[0m  2.5277\n",
            "     33     2510.4680  2.9181\n",
            "     34     2523.5818  2.9739\n",
            "     35     \u001b[36m2476.5026\u001b[0m  2.5541\n",
            "     36     2489.1415  2.6399\n",
            "     37     2498.2550  2.5269\n",
            "     38     2482.6522  3.3415\n",
            "     39     2484.1971  2.5387\n",
            "     40     \u001b[36m2468.2206\u001b[0m  2.5576\n",
            "     41     \u001b[36m2462.8593\u001b[0m  2.5041\n",
            "     42     \u001b[36m2462.2251\u001b[0m  2.7959\n",
            "     43     2495.8761  3.0219\n",
            "     44     2472.5601  2.5676\n",
            "     45     2478.2433  2.5357\n",
            "     46     \u001b[36m2456.4362\u001b[0m  2.5750\n",
            "     47     \u001b[36m2453.9470\u001b[0m  3.3340\n",
            "     48     \u001b[36m2439.1604\u001b[0m  2.5691\n",
            "     49     2445.4414  2.5009\n",
            "     50     2460.8297  2.5727\n",
            "     51     2509.7178  2.7821\n",
            "     52     \u001b[36m2438.9812\u001b[0m  3.0224\n",
            "     53     2439.0708  2.5587\n",
            "     54     \u001b[36m2433.4337\u001b[0m  2.5170\n",
            "     55     2495.6154  2.5675\n",
            "     56     2467.3708  3.3225\n",
            "     57     2449.7156  2.5341\n",
            "     58     2450.8666  2.5836\n",
            "     59     2442.6704  2.5585\n",
            "     60     \u001b[36m2428.4537\u001b[0m  2.7611\n",
            "     61     \u001b[36m2426.9613\u001b[0m  3.0975\n",
            "     62     2433.9458  2.5220\n",
            "     63     2441.4632  2.4897\n",
            "     64     2439.0794  2.5153\n",
            "     65     2433.4134  3.3365\n",
            "     66     2435.7732  2.5731\n",
            "     67     \u001b[36m2405.4905\u001b[0m  2.5516\n",
            "     68     2436.5076  2.5528\n",
            "     69     \u001b[36m2397.8330\u001b[0m  2.6425\n",
            "     70     2454.6145  3.2335\n",
            "     71     2419.7460  2.5264\n",
            "     72     2423.0981  2.5284\n",
            "     73     2419.3518  2.5134\n",
            "     74     2410.6945  3.1849\n",
            "     75     2403.1170  2.6817\n",
            "     76     2430.9595  2.5033\n",
            "     77     2399.8290  2.5109\n",
            "     78     2399.6481  2.5436\n",
            "     79     2423.4744  3.2639\n",
            "     80     2401.2511  2.5789\n",
            "     81     2406.0967  2.5011\n",
            "     82     2403.5337  2.5179\n",
            "     83     2409.3203  3.0755\n",
            "     84     2410.4683  2.8510\n",
            "     85     \u001b[36m2383.2669\u001b[0m  2.5356\n",
            "     86     2412.7976  2.5574\n",
            "     87     2384.1143  2.5855\n",
            "     88     2385.1628  3.3605\n",
            "     89     2393.9836  2.5626\n",
            "     90     2386.9386  2.6087\n",
            "     91     2389.4578  2.6204\n",
            "     92     2399.3268  3.1927\n",
            "     93     \u001b[36m2368.6446\u001b[0m  2.6882\n",
            "     94     2381.2588  2.5846\n",
            "     95     2391.1020  2.5560\n",
            "     96     2389.6973  2.6087\n",
            "     97     2382.9963  3.3069\n",
            "     98     2376.2228  2.5675\n",
            "     99     2375.1788  2.5291\n",
            "    100     2386.9312  2.6112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If12DSJbQv61"
      },
      "source": [
        "media = resultados.mean()\n",
        "desvio = resultados.std()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "media"
      ],
      "metadata": {
        "id": "owfZQlSQotNh",
        "outputId": "ecbf054f-ca40-4b06-daea-2a4fea90d9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2344.43935546875"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desvio"
      ],
      "metadata": {
        "id": "WScEEsv6ouM3",
        "outputId": "f0a027b3-d8b3-40e2-9f4e-48ae2105c9a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.861341404137086"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}